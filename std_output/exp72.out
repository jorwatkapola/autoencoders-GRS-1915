2020-01-31 16:21:33.182292: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-31 16:21:33.301304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-31 16:21:33.302308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.73GiB
2020-01-31 16:21:33.302326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-01-31 16:21:33.534658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-31 16:21:33.534708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-01-31 16:21:33.534717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-01-31 16:21:33.534993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11348 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-01-31 16:21:33.855876: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x5607a9004500
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 30.36638, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 37s - loss: 41.2191 - val_loss: 30.3664
Epoch 2/8000

Epoch 00002: val_loss improved from 30.36638 to 25.11837, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 24.9611 - val_loss: 25.1184
Epoch 3/8000

Epoch 00003: val_loss improved from 25.11837 to 24.53441, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 23.7814 - val_loss: 24.5344
Epoch 4/8000

Epoch 00004: val_loss did not improve from 24.53441
 - 34s - loss: 23.6343 - val_loss: 24.6750
Epoch 5/8000

Epoch 00005: val_loss improved from 24.53441 to 23.70202, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 23.2866 - val_loss: 23.7020
Epoch 6/8000

Epoch 00006: val_loss improved from 23.70202 to 21.03509, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 21.5039 - val_loss: 21.0351
Epoch 7/8000

Epoch 00007: val_loss improved from 21.03509 to 20.53530, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 20.0555 - val_loss: 20.5353
Epoch 8/8000

Epoch 00008: val_loss improved from 20.53530 to 20.53309, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 19.7439 - val_loss: 20.5331
Epoch 9/8000

Epoch 00009: val_loss improved from 20.53309 to 19.54486, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 19.5956 - val_loss: 19.5449
Epoch 10/8000

Epoch 00010: val_loss did not improve from 19.54486
 - 34s - loss: 19.5382 - val_loss: 20.7671
Epoch 11/8000

Epoch 00011: val_loss improved from 19.54486 to 19.41547, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 18.5146 - val_loss: 19.4155
Epoch 12/8000

Epoch 00012: val_loss did not improve from 19.41547
 - 34s - loss: 18.9039 - val_loss: 19.8186
Epoch 13/8000

Epoch 00013: val_loss improved from 19.41547 to 18.55404, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 18.6707 - val_loss: 18.5540
Epoch 14/8000

Epoch 00014: val_loss did not improve from 18.55404
 - 35s - loss: 18.9868 - val_loss: 19.8969
Epoch 15/8000

Epoch 00015: val_loss did not improve from 18.55404
 - 35s - loss: 18.5359 - val_loss: 19.7340
Epoch 16/8000

Epoch 00016: val_loss did not improve from 18.55404
 - 35s - loss: 19.4404 - val_loss: 19.2392
Epoch 17/8000

Epoch 00017: val_loss did not improve from 18.55404
 - 34s - loss: 18.0564 - val_loss: 18.5574
Epoch 18/8000

Epoch 00018: val_loss improved from 18.55404 to 18.31485, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 17.8348 - val_loss: 18.3148
Epoch 19/8000

Epoch 00019: val_loss did not improve from 18.31485
 - 34s - loss: 17.4643 - val_loss: 18.7442
Epoch 20/8000

Epoch 00020: val_loss improved from 18.31485 to 17.67121, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 17.6148 - val_loss: 17.6712
Epoch 21/8000

Epoch 00021: val_loss did not improve from 17.67121
 - 34s - loss: 17.8458 - val_loss: 18.7862
Epoch 22/8000

Epoch 00022: val_loss did not improve from 17.67121
 - 35s - loss: 17.4246 - val_loss: 17.9434
Epoch 23/8000

Epoch 00023: val_loss improved from 17.67121 to 17.24296, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 17.2213 - val_loss: 17.2430
Epoch 24/8000

Epoch 00024: val_loss improved from 17.24296 to 17.19574, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 17.0052 - val_loss: 17.1957
Epoch 25/8000

Epoch 00025: val_loss improved from 17.19574 to 17.11448, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 17.0880 - val_loss: 17.1145
Epoch 26/8000

Epoch 00026: val_loss did not improve from 17.11448
 - 34s - loss: 17.4406 - val_loss: 20.3634
Epoch 27/8000

Epoch 00027: val_loss did not improve from 17.11448
 - 35s - loss: 17.9260 - val_loss: 19.0163
Epoch 28/8000

Epoch 00028: val_loss did not improve from 17.11448
 - 35s - loss: 17.3103 - val_loss: 18.5934
Epoch 29/8000

Epoch 00029: val_loss did not improve from 17.11448
 - 35s - loss: 17.3471 - val_loss: 18.2879
Epoch 30/8000

Epoch 00030: val_loss did not improve from 17.11448
 - 35s - loss: 16.7567 - val_loss: 17.7668
Epoch 31/8000

Epoch 00031: val_loss did not improve from 17.11448
 - 35s - loss: 16.8261 - val_loss: 17.4528
Epoch 32/8000

Epoch 00032: val_loss did not improve from 17.11448
 - 34s - loss: 17.1353 - val_loss: 17.1301
Epoch 33/8000

Epoch 00033: val_loss improved from 17.11448 to 16.65169, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 16.6164 - val_loss: 16.6517
Epoch 34/8000

Epoch 00034: val_loss improved from 16.65169 to 16.40454, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 16.4165 - val_loss: 16.4045
Epoch 35/8000

Epoch 00035: val_loss did not improve from 16.40454
 - 35s - loss: 16.7093 - val_loss: 17.0707
Epoch 36/8000

Epoch 00036: val_loss did not improve from 16.40454
 - 35s - loss: 16.1389 - val_loss: 16.4480
Epoch 37/8000

Epoch 00037: val_loss did not improve from 16.40454
 - 35s - loss: 16.6229 - val_loss: 18.7004
Epoch 38/8000

Epoch 00038: val_loss did not improve from 16.40454
 - 35s - loss: 17.0367 - val_loss: 16.8694
Epoch 39/8000

Epoch 00039: val_loss did not improve from 16.40454
 - 34s - loss: 16.4663 - val_loss: 16.5493
Epoch 40/8000

Epoch 00040: val_loss improved from 16.40454 to 16.04944, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 16.6483 - val_loss: 16.0494
Epoch 41/8000

Epoch 00041: val_loss did not improve from 16.04944
 - 35s - loss: 16.4806 - val_loss: 17.2261
Epoch 42/8000

Epoch 00042: val_loss did not improve from 16.04944
 - 35s - loss: 16.7046 - val_loss: 16.7639
Epoch 43/8000

Epoch 00043: val_loss did not improve from 16.04944
 - 35s - loss: 16.3830 - val_loss: 16.5572
Epoch 44/8000

Epoch 00044: val_loss did not improve from 16.04944
 - 35s - loss: 16.1914 - val_loss: 16.7286
Epoch 45/8000

Epoch 00045: val_loss did not improve from 16.04944
 - 34s - loss: 16.6268 - val_loss: 17.2518
Epoch 46/8000

Epoch 00046: val_loss did not improve from 16.04944
 - 34s - loss: 16.2573 - val_loss: 16.1607
Epoch 47/8000

Epoch 00047: val_loss did not improve from 16.04944
 - 34s - loss: 15.7407 - val_loss: 16.2298
Epoch 48/8000

Epoch 00048: val_loss did not improve from 16.04944
 - 35s - loss: 15.9793 - val_loss: 16.8925
Epoch 49/8000

Epoch 00049: val_loss did not improve from 16.04944
 - 35s - loss: 16.2075 - val_loss: 17.3763
Epoch 50/8000

Epoch 00050: val_loss did not improve from 16.04944
 - 35s - loss: 17.0050 - val_loss: 16.7182
Epoch 51/8000

Epoch 00051: val_loss did not improve from 16.04944
 - 35s - loss: 15.9671 - val_loss: 18.3298
Epoch 52/8000

Epoch 00052: val_loss did not improve from 16.04944
 - 34s - loss: 16.4134 - val_loss: 17.7875
Epoch 53/8000

Epoch 00053: val_loss did not improve from 16.04944
 - 34s - loss: 16.0816 - val_loss: 16.2405
Epoch 54/8000

Epoch 00054: val_loss did not improve from 16.04944
 - 34s - loss: 16.2424 - val_loss: 16.1249
Epoch 55/8000

Epoch 00055: val_loss did not improve from 16.04944
 - 35s - loss: 15.7478 - val_loss: 16.3234
Epoch 56/8000

Epoch 00056: val_loss did not improve from 16.04944
 - 35s - loss: 15.8088 - val_loss: 16.5771
Epoch 57/8000

Epoch 00057: val_loss did not improve from 16.04944
 - 35s - loss: 15.8012 - val_loss: 16.2480
Epoch 58/8000

Epoch 00058: val_loss improved from 16.04944 to 15.94254, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 16.1994 - val_loss: 15.9425
Epoch 59/8000

Epoch 00059: val_loss did not improve from 15.94254
 - 34s - loss: 17.5078 - val_loss: 17.8660
Epoch 60/8000

Epoch 00060: val_loss did not improve from 15.94254
 - 34s - loss: 16.9463 - val_loss: 20.2632
Epoch 61/8000

Epoch 00061: val_loss did not improve from 15.94254
 - 34s - loss: 17.6361 - val_loss: 17.5628
Epoch 62/8000

Epoch 00062: val_loss did not improve from 15.94254
 - 35s - loss: 17.1911 - val_loss: 17.4905
Epoch 63/8000

Epoch 00063: val_loss did not improve from 15.94254
 - 35s - loss: 16.4230 - val_loss: 18.4288
Epoch 64/8000

Epoch 00064: val_loss did not improve from 15.94254
 - 35s - loss: 16.3919 - val_loss: 17.0819
Epoch 65/8000

Epoch 00065: val_loss did not improve from 15.94254
 - 35s - loss: 16.3131 - val_loss: 15.9459
Epoch 66/8000

Epoch 00066: val_loss did not improve from 15.94254
 - 35s - loss: 15.8940 - val_loss: 16.1363
Epoch 67/8000

Epoch 00067: val_loss did not improve from 15.94254
 - 34s - loss: 16.0200 - val_loss: 16.5347
Epoch 68/8000

Epoch 00068: val_loss improved from 15.94254 to 15.79976, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 15.7120 - val_loss: 15.7998
Epoch 69/8000

Epoch 00069: val_loss improved from 15.79976 to 15.66729, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 15.2809 - val_loss: 15.6673
Epoch 70/8000

Epoch 00070: val_loss improved from 15.66729 to 15.42111, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 15.4357 - val_loss: 15.4211
Epoch 71/8000

Epoch 00071: val_loss did not improve from 15.42111
 - 35s - loss: 15.8713 - val_loss: 15.6544
Epoch 72/8000

Epoch 00072: val_loss did not improve from 15.42111
 - 35s - loss: 16.0311 - val_loss: 16.2889
Epoch 73/8000

Epoch 00073: val_loss did not improve from 15.42111
 - 34s - loss: 15.3549 - val_loss: 15.5889
Epoch 74/8000

Epoch 00074: val_loss did not improve from 15.42111
 - 34s - loss: 15.1989 - val_loss: 15.8344
Epoch 75/8000

Epoch 00075: val_loss did not improve from 15.42111
 - 34s - loss: 15.4884 - val_loss: 15.6689
Epoch 76/8000

Epoch 00076: val_loss did not improve from 15.42111
 - 35s - loss: 15.4441 - val_loss: 16.0607
Epoch 77/8000

Epoch 00077: val_loss did not improve from 15.42111
 - 35s - loss: 15.3697 - val_loss: 15.4376
Epoch 78/8000

Epoch 00078: val_loss did not improve from 15.42111
 - 35s - loss: 15.1964 - val_loss: 16.8276
Epoch 79/8000

Epoch 00079: val_loss did not improve from 15.42111
 - 35s - loss: 15.3016 - val_loss: 17.0413
Epoch 80/8000

Epoch 00080: val_loss improved from 15.42111 to 14.95837, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 15.4204 - val_loss: 14.9584
Epoch 81/8000

Epoch 00081: val_loss did not improve from 14.95837
 - 34s - loss: 15.1556 - val_loss: 15.7370
Epoch 82/8000

Epoch 00082: val_loss did not improve from 14.95837
 - 34s - loss: 15.2884 - val_loss: 15.6521
Epoch 83/8000

Epoch 00083: val_loss did not improve from 14.95837
 - 35s - loss: 15.3629 - val_loss: 17.0324
Epoch 84/8000

Epoch 00084: val_loss did not improve from 14.95837
 - 35s - loss: 14.9131 - val_loss: 15.2850
Epoch 85/8000

Epoch 00085: val_loss did not improve from 14.95837
 - 35s - loss: 15.1763 - val_loss: 15.3939
Epoch 86/8000

Epoch 00086: val_loss did not improve from 14.95837
 - 35s - loss: 14.8521 - val_loss: 16.0826
Epoch 87/8000

Epoch 00087: val_loss did not improve from 14.95837
 - 34s - loss: 15.1578 - val_loss: 15.4997
Epoch 88/8000

Epoch 00088: val_loss did not improve from 14.95837
 - 34s - loss: 15.0895 - val_loss: 15.8151
Epoch 89/8000

Epoch 00089: val_loss did not improve from 14.95837
 - 34s - loss: 15.3847 - val_loss: 15.2528
Epoch 90/8000

Epoch 00090: val_loss did not improve from 14.95837
 - 35s - loss: 15.0797 - val_loss: 15.9870
Epoch 91/8000

Epoch 00091: val_loss did not improve from 14.95837
 - 35s - loss: 14.8470 - val_loss: 15.2074
Epoch 92/8000

Epoch 00092: val_loss did not improve from 14.95837
 - 35s - loss: 14.8156 - val_loss: 15.4931
Epoch 93/8000

Epoch 00093: val_loss improved from 14.95837 to 14.79662, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 14.9208 - val_loss: 14.7966
Epoch 94/8000

Epoch 00094: val_loss did not improve from 14.79662
 - 35s - loss: 14.7271 - val_loss: 15.9096
Epoch 95/8000

Epoch 00095: val_loss improved from 14.79662 to 14.70682, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 14.8476 - val_loss: 14.7068
Epoch 96/8000

Epoch 00096: val_loss did not improve from 14.70682
 - 34s - loss: 14.9621 - val_loss: 15.0500
Epoch 97/8000

Epoch 00097: val_loss did not improve from 14.70682
 - 35s - loss: 14.9493 - val_loss: 14.8376
Epoch 98/8000

Epoch 00098: val_loss did not improve from 14.70682
 - 35s - loss: 14.7632 - val_loss: 15.0177
Epoch 99/8000

Epoch 00099: val_loss did not improve from 14.70682
 - 35s - loss: 15.6070 - val_loss: 14.9372
Epoch 100/8000

Epoch 00100: val_loss did not improve from 14.70682
 - 35s - loss: 15.1399 - val_loss: 15.0292
Epoch 101/8000

Epoch 00101: val_loss did not improve from 14.70682
 - 35s - loss: 14.7422 - val_loss: 15.3945
Epoch 102/8000

Epoch 00102: val_loss did not improve from 14.70682
 - 34s - loss: 14.6837 - val_loss: 15.3743
Epoch 103/8000

Epoch 00103: val_loss improved from 14.70682 to 14.68717, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 14.8103 - val_loss: 14.6872
Epoch 104/8000

Epoch 00104: val_loss did not improve from 14.68717
 - 35s - loss: 14.5688 - val_loss: 15.3239
Epoch 105/8000

Epoch 00105: val_loss did not improve from 14.68717
 - 34s - loss: 14.9744 - val_loss: 16.5521
Epoch 106/8000

Epoch 00106: val_loss did not improve from 14.68717
 - 35s - loss: 15.2140 - val_loss: 14.7813
Epoch 107/8000

Epoch 00107: val_loss did not improve from 14.68717
 - 35s - loss: 15.1399 - val_loss: 16.3684
Epoch 108/8000

Epoch 00108: val_loss did not improve from 14.68717
 - 34s - loss: 15.4106 - val_loss: 16.7356
Epoch 109/8000

Epoch 00109: val_loss did not improve from 14.68717
 - 34s - loss: 15.5739 - val_loss: 15.8259
Epoch 110/8000

Epoch 00110: val_loss did not improve from 14.68717
 - 34s - loss: 15.0620 - val_loss: 15.0697
Epoch 111/8000

Epoch 00111: val_loss did not improve from 14.68717
 - 35s - loss: 15.2591 - val_loss: 15.9668
Epoch 112/8000

Epoch 00112: val_loss did not improve from 14.68717
 - 35s - loss: 16.7661 - val_loss: 16.0704
Epoch 113/8000

Epoch 00113: val_loss did not improve from 14.68717
 - 35s - loss: 15.2527 - val_loss: 16.2148
Epoch 114/8000

Epoch 00114: val_loss did not improve from 14.68717
 - 35s - loss: 14.8194 - val_loss: 15.6696
Epoch 115/8000

Epoch 00115: val_loss did not improve from 14.68717
 - 34s - loss: 15.3568 - val_loss: 15.0463
Epoch 116/8000

Epoch 00116: val_loss did not improve from 14.68717
 - 34s - loss: 15.4667 - val_loss: 16.2661
Epoch 117/8000

Epoch 00117: val_loss did not improve from 14.68717
 - 34s - loss: 15.2254 - val_loss: 15.3248
Epoch 118/8000

Epoch 00118: val_loss did not improve from 14.68717
 - 35s - loss: 14.8537 - val_loss: 15.0878
Epoch 119/8000

Epoch 00119: val_loss did not improve from 14.68717
 - 35s - loss: 14.6518 - val_loss: 14.8627
Epoch 120/8000

Epoch 00120: val_loss did not improve from 14.68717
 - 35s - loss: 14.4740 - val_loss: 15.0725
Epoch 121/8000

Epoch 00121: val_loss did not improve from 14.68717
 - 35s - loss: 14.5546 - val_loss: 14.7452
Epoch 122/8000

Epoch 00122: val_loss did not improve from 14.68717
 - 35s - loss: 14.5389 - val_loss: 14.8017
Epoch 123/8000

Epoch 00123: val_loss did not improve from 14.68717
 - 34s - loss: 14.4174 - val_loss: 15.0761
Epoch 124/8000

Epoch 00124: val_loss did not improve from 14.68717
 - 34s - loss: 15.1108 - val_loss: 15.4220
Epoch 125/8000

Epoch 00125: val_loss did not improve from 14.68717
 - 35s - loss: 15.1596 - val_loss: 14.7650
Epoch 126/8000

Epoch 00126: val_loss did not improve from 14.68717
 - 35s - loss: 14.4513 - val_loss: 14.7516
Epoch 127/8000

Epoch 00127: val_loss did not improve from 14.68717
 - 35s - loss: 14.8359 - val_loss: 15.2526
Epoch 128/8000

Epoch 00128: val_loss improved from 14.68717 to 14.48729, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 15.0429 - val_loss: 14.4873
Epoch 129/8000

Epoch 00129: val_loss did not improve from 14.48729
 - 35s - loss: 15.1834 - val_loss: 16.8765
Epoch 130/8000

Epoch 00130: val_loss did not improve from 14.48729
 - 34s - loss: 16.2358 - val_loss: 16.9109
Epoch 131/8000

Epoch 00131: val_loss did not improve from 14.48729
 - 34s - loss: 15.5807 - val_loss: 16.3827
Epoch 132/8000

Epoch 00132: val_loss did not improve from 14.48729
 - 35s - loss: 15.3056 - val_loss: 15.8371
Epoch 133/8000

Epoch 00133: val_loss did not improve from 14.48729
 - 35s - loss: 15.7296 - val_loss: 15.7511
Epoch 134/8000

Epoch 00134: val_loss did not improve from 14.48729
 - 35s - loss: 15.4971 - val_loss: 15.7577
Epoch 135/8000

Epoch 00135: val_loss did not improve from 14.48729
 - 35s - loss: 15.0701 - val_loss: 16.0557
Epoch 136/8000

Epoch 00136: val_loss did not improve from 14.48729
 - 34s - loss: 15.3342 - val_loss: 14.7210
Epoch 137/8000

Epoch 00137: val_loss did not improve from 14.48729
 - 34s - loss: 14.8181 - val_loss: 15.2949
Epoch 138/8000

Epoch 00138: val_loss did not improve from 14.48729
 - 34s - loss: 14.8448 - val_loss: 14.8664
Epoch 139/8000

Epoch 00139: val_loss did not improve from 14.48729
 - 35s - loss: 14.8374 - val_loss: 16.1946
Epoch 140/8000

Epoch 00140: val_loss did not improve from 14.48729
 - 35s - loss: 15.5019 - val_loss: 15.4309
Epoch 141/8000

Epoch 00141: val_loss did not improve from 14.48729
 - 35s - loss: 14.5003 - val_loss: 15.0065
Epoch 142/8000

Epoch 00142: val_loss did not improve from 14.48729
 - 35s - loss: 15.0137 - val_loss: 15.4560
Epoch 143/8000

Epoch 00143: val_loss did not improve from 14.48729
 - 34s - loss: 14.7593 - val_loss: 14.6273
Epoch 144/8000

Epoch 00144: val_loss did not improve from 14.48729
 - 34s - loss: 14.7252 - val_loss: 14.7062
Epoch 145/8000

Epoch 00145: val_loss did not improve from 14.48729
 - 34s - loss: 14.7339 - val_loss: 14.7712
Epoch 146/8000

Epoch 00146: val_loss did not improve from 14.48729
 - 35s - loss: 14.6978 - val_loss: 16.1481
Epoch 147/8000

Epoch 00147: val_loss improved from 14.48729 to 14.30461, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 15.0249 - val_loss: 14.3046
Epoch 148/8000

Epoch 00148: val_loss did not improve from 14.30461
 - 35s - loss: 14.5748 - val_loss: 16.3689
Epoch 149/8000

Epoch 00149: val_loss did not improve from 14.30461
 - 35s - loss: 14.8082 - val_loss: 15.4652
Epoch 150/8000

Epoch 00150: val_loss did not improve from 14.30461
 - 35s - loss: 15.1276 - val_loss: 16.8607
Epoch 151/8000

Epoch 00151: val_loss did not improve from 14.30461
 - 34s - loss: 15.4656 - val_loss: 14.6814
Epoch 152/8000

Epoch 00152: val_loss did not improve from 14.30461
 - 34s - loss: 14.7640 - val_loss: 14.5996
Epoch 153/8000

Epoch 00153: val_loss did not improve from 14.30461
 - 35s - loss: 14.7078 - val_loss: 14.4715
Epoch 154/8000

Epoch 00154: val_loss did not improve from 14.30461
 - 35s - loss: 14.2482 - val_loss: 15.0292
Epoch 155/8000

Epoch 00155: val_loss did not improve from 14.30461
 - 35s - loss: 14.2240 - val_loss: 14.4075
Epoch 156/8000

Epoch 00156: val_loss did not improve from 14.30461
 - 35s - loss: 14.4870 - val_loss: 14.6696
Epoch 157/8000

Epoch 00157: val_loss did not improve from 14.30461
 - 34s - loss: 14.4019 - val_loss: 15.1097
Epoch 158/8000

Epoch 00158: val_loss did not improve from 14.30461
 - 34s - loss: 15.2148 - val_loss: 15.5192
Epoch 159/8000

Epoch 00159: val_loss did not improve from 14.30461
 - 34s - loss: 14.4009 - val_loss: 14.4938
Epoch 160/8000

Epoch 00160: val_loss did not improve from 14.30461
 - 35s - loss: 14.6461 - val_loss: 14.5214
Epoch 161/8000

Epoch 00161: val_loss did not improve from 14.30461
 - 35s - loss: 14.7946 - val_loss: 16.0646
Epoch 162/8000

Epoch 00162: val_loss did not improve from 14.30461
 - 35s - loss: 14.6804 - val_loss: 15.0634
Epoch 163/8000

Epoch 00163: val_loss did not improve from 14.30461
 - 35s - loss: 14.4222 - val_loss: 14.5543
Epoch 164/8000

Epoch 00164: val_loss did not improve from 14.30461
 - 35s - loss: 13.9803 - val_loss: 14.6282
Epoch 165/8000

Epoch 00165: val_loss did not improve from 14.30461
 - 34s - loss: 13.9576 - val_loss: 14.5155
Epoch 166/8000

Epoch 00166: val_loss did not improve from 14.30461
 - 34s - loss: 14.3640 - val_loss: 14.7304
Epoch 167/8000

Epoch 00167: val_loss did not improve from 14.30461
 - 35s - loss: 14.4139 - val_loss: 15.8059
Epoch 168/8000

Epoch 00168: val_loss did not improve from 14.30461
 - 35s - loss: 14.3765 - val_loss: 14.5145
Epoch 169/8000

Epoch 00169: val_loss improved from 14.30461 to 13.90907, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 14.0515 - val_loss: 13.9091
Epoch 170/8000

Epoch 00170: val_loss did not improve from 13.90907
 - 35s - loss: 14.4881 - val_loss: 14.4610
Epoch 171/8000

Epoch 00171: val_loss did not improve from 13.90907
 - 35s - loss: 14.4693 - val_loss: 15.3099
Epoch 172/8000

Epoch 00172: val_loss did not improve from 13.90907
 - 34s - loss: 14.4273 - val_loss: 14.8829
Epoch 173/8000

Epoch 00173: val_loss did not improve from 13.90907
 - 34s - loss: 14.4893 - val_loss: 14.7249
Epoch 174/8000

Epoch 00174: val_loss did not improve from 13.90907
 - 35s - loss: 14.8110 - val_loss: 15.2702
Epoch 175/8000

Epoch 00175: val_loss did not improve from 13.90907
 - 35s - loss: 14.3048 - val_loss: 14.5583
Epoch 176/8000

Epoch 00176: val_loss improved from 13.90907 to 13.74878, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 14.0274 - val_loss: 13.7488
Epoch 177/8000

Epoch 00177: val_loss did not improve from 13.74878
 - 35s - loss: 14.1261 - val_loss: 14.5660
Epoch 178/8000

Epoch 00178: val_loss did not improve from 13.74878
 - 34s - loss: 14.4182 - val_loss: 14.8349
Epoch 179/8000

Epoch 00179: val_loss did not improve from 13.74878
 - 34s - loss: 14.4946 - val_loss: 15.3680
Epoch 180/8000

Epoch 00180: val_loss did not improve from 13.74878
 - 34s - loss: 14.3006 - val_loss: 14.2698
Epoch 181/8000

Epoch 00181: val_loss did not improve from 13.74878
 - 35s - loss: 14.7463 - val_loss: 14.8527
Epoch 182/8000

Epoch 00182: val_loss did not improve from 13.74878
 - 35s - loss: 14.1156 - val_loss: 14.2535
Epoch 183/8000

Epoch 00183: val_loss did not improve from 13.74878
 - 35s - loss: 14.4698 - val_loss: 14.6626
Epoch 184/8000

Epoch 00184: val_loss did not improve from 13.74878
 - 35s - loss: 14.2185 - val_loss: 14.4158
Epoch 185/8000

Epoch 00185: val_loss did not improve from 13.74878
 - 34s - loss: 14.3117 - val_loss: 14.1540
Epoch 186/8000

Epoch 00186: val_loss did not improve from 13.74878
 - 34s - loss: 13.7255 - val_loss: 14.5093
Epoch 187/8000

Epoch 00187: val_loss did not improve from 13.74878
 - 34s - loss: 14.1580 - val_loss: 13.8899
Epoch 188/8000

Epoch 00188: val_loss did not improve from 13.74878
 - 35s - loss: 13.8813 - val_loss: 15.3355
Epoch 189/8000

Epoch 00189: val_loss did not improve from 13.74878
 - 35s - loss: 14.3058 - val_loss: 14.0746
Epoch 190/8000

Epoch 00190: val_loss did not improve from 13.74878
 - 35s - loss: 15.3940 - val_loss: 14.7078
Epoch 191/8000

Epoch 00191: val_loss did not improve from 13.74878
 - 35s - loss: 14.6136 - val_loss: 15.1510
Epoch 192/8000

Epoch 00192: val_loss did not improve from 13.74878
 - 35s - loss: 14.5296 - val_loss: 15.2549
Epoch 193/8000

Epoch 00193: val_loss did not improve from 13.74878
 - 34s - loss: 14.0500 - val_loss: 14.1638
Epoch 194/8000

Epoch 00194: val_loss did not improve from 13.74878
 - 34s - loss: 14.2754 - val_loss: 14.8783
Epoch 195/8000

Epoch 00195: val_loss did not improve from 13.74878
 - 35s - loss: 14.0916 - val_loss: 14.1539
Epoch 196/8000

Epoch 00196: val_loss did not improve from 13.74878
 - 35s - loss: 14.0549 - val_loss: 14.7482
Epoch 197/8000

Epoch 00197: val_loss did not improve from 13.74878
 - 35s - loss: 14.3656 - val_loss: 14.0500
Epoch 198/8000

Epoch 00198: val_loss did not improve from 13.74878
 - 35s - loss: 13.9241 - val_loss: 14.3052
Epoch 199/8000

Epoch 00199: val_loss did not improve from 13.74878
 - 35s - loss: 13.6578 - val_loss: 14.3710
Epoch 200/8000

Epoch 00200: val_loss did not improve from 13.74878
 - 34s - loss: 13.9969 - val_loss: 14.2430
Epoch 201/8000

Epoch 00201: val_loss did not improve from 13.74878
 - 34s - loss: 13.8745 - val_loss: 14.7427
Epoch 202/8000

Epoch 00202: val_loss did not improve from 13.74878
 - 35s - loss: 14.1221 - val_loss: 14.1324
Epoch 203/8000

Epoch 00203: val_loss did not improve from 13.74878
 - 35s - loss: 14.1844 - val_loss: 14.8803
Epoch 204/8000

Epoch 00204: val_loss did not improve from 13.74878
 - 35s - loss: 14.2305 - val_loss: 14.2417
Epoch 205/8000

Epoch 00205: val_loss did not improve from 13.74878
 - 35s - loss: 14.2429 - val_loss: 15.1251
Epoch 206/8000

Epoch 00206: val_loss did not improve from 13.74878
 - 35s - loss: 14.1849 - val_loss: 13.8546
Epoch 207/8000

Epoch 00207: val_loss did not improve from 13.74878
 - 34s - loss: 13.9173 - val_loss: 13.9481
Epoch 208/8000

Epoch 00208: val_loss did not improve from 13.74878
 - 34s - loss: 13.7930 - val_loss: 14.7521
Epoch 209/8000

Epoch 00209: val_loss did not improve from 13.74878
 - 35s - loss: 14.0894 - val_loss: 15.1212
Epoch 210/8000

Epoch 00210: val_loss did not improve from 13.74878
 - 35s - loss: 14.0751 - val_loss: 14.3606
Epoch 211/8000

Epoch 00211: val_loss did not improve from 13.74878
 - 35s - loss: 14.1051 - val_loss: 14.4540
Epoch 212/8000

Epoch 00212: val_loss did not improve from 13.74878
 - 35s - loss: 14.0526 - val_loss: 14.0991
Epoch 213/8000

Epoch 00213: val_loss did not improve from 13.74878
 - 34s - loss: 13.7805 - val_loss: 14.1441
Epoch 214/8000

Epoch 00214: val_loss did not improve from 13.74878
 - 34s - loss: 14.1485 - val_loss: 14.3616
Epoch 215/8000

Epoch 00215: val_loss did not improve from 13.74878
 - 34s - loss: 13.9174 - val_loss: 14.8144
Epoch 216/8000

Epoch 00216: val_loss did not improve from 13.74878
 - 35s - loss: 14.0292 - val_loss: 14.4188
Epoch 217/8000

Epoch 00217: val_loss did not improve from 13.74878
 - 35s - loss: 13.8705 - val_loss: 14.6211
Epoch 218/8000

Epoch 00218: val_loss did not improve from 13.74878
 - 35s - loss: 14.2293 - val_loss: 14.2168
Epoch 219/8000

Epoch 00219: val_loss did not improve from 13.74878
 - 35s - loss: 14.0106 - val_loss: 14.4043
Epoch 220/8000

Epoch 00220: val_loss did not improve from 13.74878
 - 34s - loss: 14.4362 - val_loss: 14.8171
Epoch 221/8000

Epoch 00221: val_loss did not improve from 13.74878
 - 34s - loss: 14.2998 - val_loss: 14.4438
Epoch 222/8000

Epoch 00222: val_loss did not improve from 13.74878
 - 34s - loss: 14.2176 - val_loss: 16.3761
Epoch 223/8000

Epoch 00223: val_loss did not improve from 13.74878
 - 35s - loss: 14.4408 - val_loss: 14.3407
Epoch 224/8000

Epoch 00224: val_loss did not improve from 13.74878
 - 35s - loss: 14.0796 - val_loss: 14.4237
Epoch 225/8000

Epoch 00225: val_loss did not improve from 13.74878
 - 35s - loss: 14.9203 - val_loss: 14.2920
Epoch 226/8000

Epoch 00226: val_loss did not improve from 13.74878
 - 35s - loss: 14.5160 - val_loss: 16.4179
Epoch 227/8000

Epoch 00227: val_loss did not improve from 13.74878
 - 35s - loss: 14.7895 - val_loss: 14.8777
Epoch 228/8000

Epoch 00228: val_loss did not improve from 13.74878
 - 34s - loss: 14.8401 - val_loss: 15.4979
Epoch 229/8000

Epoch 00229: val_loss did not improve from 13.74878
 - 34s - loss: 15.1613 - val_loss: 15.3155
Epoch 230/8000

Epoch 00230: val_loss did not improve from 13.74878
 - 35s - loss: 14.4697 - val_loss: 15.0936
Epoch 231/8000

Epoch 00231: val_loss did not improve from 13.74878
 - 35s - loss: 14.8681 - val_loss: 14.4157
Epoch 232/8000

Epoch 00232: val_loss did not improve from 13.74878
 - 35s - loss: 14.4068 - val_loss: 14.0015
Epoch 233/8000

Epoch 00233: val_loss did not improve from 13.74878
 - 35s - loss: 14.5214 - val_loss: 14.7603
Epoch 234/8000

Epoch 00234: val_loss did not improve from 13.74878
 - 34s - loss: 14.1694 - val_loss: 14.0275
Epoch 235/8000

Epoch 00235: val_loss did not improve from 13.74878
 - 34s - loss: 14.2184 - val_loss: 14.8845
Epoch 236/8000

Epoch 00236: val_loss did not improve from 13.74878
 - 34s - loss: 14.3789 - val_loss: 14.1841
Epoch 237/8000

Epoch 00237: val_loss did not improve from 13.74878
 - 35s - loss: 14.3092 - val_loss: 14.4172
Epoch 238/8000

Epoch 00238: val_loss did not improve from 13.74878
 - 34s - loss: 14.1273 - val_loss: 14.9166
Epoch 239/8000

Epoch 00239: val_loss did not improve from 13.74878
 - 35s - loss: 13.8369 - val_loss: 13.8473
Epoch 240/8000

Epoch 00240: val_loss did not improve from 13.74878
 - 35s - loss: 13.7437 - val_loss: 14.1031
Epoch 241/8000

Epoch 00241: val_loss improved from 13.74878 to 13.72980, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 14.1595 - val_loss: 13.7298
Epoch 242/8000

Epoch 00242: val_loss did not improve from 13.72980
 - 34s - loss: 13.8985 - val_loss: 13.8774
Epoch 243/8000

Epoch 00243: val_loss improved from 13.72980 to 13.65446, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 34s - loss: 13.9806 - val_loss: 13.6545
Epoch 244/8000

Epoch 00244: val_loss did not improve from 13.65446
 - 35s - loss: 14.6071 - val_loss: 15.7651
Epoch 245/8000

Epoch 00245: val_loss did not improve from 13.65446
 - 35s - loss: 13.9326 - val_loss: 15.0356
Epoch 246/8000

Epoch 00246: val_loss did not improve from 13.65446
 - 35s - loss: 14.2732 - val_loss: 14.9324
Epoch 247/8000

Epoch 00247: val_loss did not improve from 13.65446
 - 35s - loss: 14.1579 - val_loss: 14.4908
Epoch 248/8000

Epoch 00248: val_loss did not improve from 13.65446
 - 34s - loss: 14.6356 - val_loss: 14.9420
Epoch 249/8000

Epoch 00249: val_loss did not improve from 13.65446
 - 34s - loss: 14.7639 - val_loss: 14.7130
Epoch 250/8000

Epoch 00250: val_loss did not improve from 13.65446
 - 34s - loss: 13.9857 - val_loss: 15.5689
Epoch 251/8000

Epoch 00251: val_loss did not improve from 13.65446
 - 35s - loss: 13.8693 - val_loss: 14.1873
Epoch 252/8000

Epoch 00252: val_loss did not improve from 13.65446
 - 34s - loss: 14.0130 - val_loss: 13.9103
Epoch 253/8000

Epoch 00253: val_loss did not improve from 13.65446
 - 35s - loss: 14.2703 - val_loss: 15.2760
Epoch 254/8000

Epoch 00254: val_loss did not improve from 13.65446
 - 35s - loss: 14.4685 - val_loss: 14.6897
Epoch 255/8000

Epoch 00255: val_loss did not improve from 13.65446
 - 34s - loss: 14.8900 - val_loss: 16.1393
Epoch 256/8000

Epoch 00256: val_loss did not improve from 13.65446
 - 34s - loss: 14.4501 - val_loss: 16.2805
Epoch 257/8000

Epoch 00257: val_loss did not improve from 13.65446
 - 34s - loss: 14.5601 - val_loss: 14.7689
Epoch 258/8000

Epoch 00258: val_loss did not improve from 13.65446
 - 35s - loss: 14.2086 - val_loss: 15.0427
Epoch 259/8000

Epoch 00259: val_loss did not improve from 13.65446
 - 34s - loss: 14.2846 - val_loss: 14.5082
Epoch 260/8000

Epoch 00260: val_loss did not improve from 13.65446
 - 35s - loss: 14.1243 - val_loss: 13.9669
Epoch 261/8000

Epoch 00261: val_loss did not improve from 13.65446
 - 35s - loss: 14.5887 - val_loss: 15.7202
Epoch 262/8000

Epoch 00262: val_loss did not improve from 13.65446
 - 34s - loss: 13.9943 - val_loss: 13.9827
Epoch 263/8000

Epoch 00263: val_loss did not improve from 13.65446
 - 34s - loss: 14.1849 - val_loss: 14.1531
Epoch 264/8000

Epoch 00264: val_loss did not improve from 13.65446
 - 34s - loss: 15.1750 - val_loss: 15.4698
Epoch 265/8000

Epoch 00265: val_loss did not improve from 13.65446
 - 35s - loss: 14.5149 - val_loss: 14.9843
Epoch 266/8000

Epoch 00266: val_loss did not improve from 13.65446
 - 35s - loss: 13.9748 - val_loss: 14.4411
Epoch 267/8000

Epoch 00267: val_loss did not improve from 13.65446
 - 35s - loss: 14.1092 - val_loss: 15.0695
Epoch 268/8000

Epoch 00268: val_loss did not improve from 13.65446
 - 35s - loss: 14.3684 - val_loss: 14.2988
Epoch 269/8000

Epoch 00269: val_loss did not improve from 13.65446
 - 35s - loss: 13.9774 - val_loss: 13.9488
Epoch 270/8000

Epoch 00270: val_loss did not improve from 13.65446
 - 34s - loss: 13.8676 - val_loss: 14.1144
Epoch 271/8000

Epoch 00271: val_loss did not improve from 13.65446
 - 34s - loss: 14.0405 - val_loss: 14.0934
Epoch 272/8000

Epoch 00272: val_loss improved from 13.65446 to 13.60851, saving model to model_weights/model_2020-01-31_16-21-32.h5
 - 35s - loss: 13.9668 - val_loss: 13.6085
Epoch 273/8000

Epoch 00273: val_loss did not improve from 13.60851
 - 35s - loss: 13.8262 - val_loss: 15.1497
Epoch 274/8000

Epoch 00274: val_loss did not improve from 13.60851
 - 35s - loss: 13.9187 - val_loss: 13.9591
Epoch 275/8000

Epoch 00275: val_loss did not improve from 13.60851
 - 35s - loss: 13.5941 - val_loss: 14.6694
Epoch 276/8000

Epoch 00276: val_loss did not improve from 13.60851
 - 35s - loss: 14.4070 - val_loss: 14.2484
Epoch 277/8000

Epoch 00277: val_loss did not improve from 13.60851
 - 34s - loss: 14.3211 - val_loss: 15.1888
Epoch 278/8000

Epoch 00278: val_loss did not improve from 13.60851
 - 34s - loss: 14.0799 - val_loss: 14.8753
Epoch 279/8000

Epoch 00279: val_loss did not improve from 13.60851
 - 35s - loss: 14.3856 - val_loss: 14.4572
Epoch 280/8000

Epoch 00280: val_loss did not improve from 13.60851
 - 35s - loss: 13.7561 - val_loss: 14.2152
Epoch 281/8000

Epoch 00281: val_loss did not improve from 13.60851
 - 35s - loss: 13.8950 - val_loss: 14.5356
Epoch 282/8000

Epoch 00282: val_loss did not improve from 13.60851
 - 35s - loss: 13.9330 - val_loss: 14.1484
Epoch 283/8000

Epoch 00283: val_loss did not improve from 13.60851
 - 34s - loss: 14.3098 - val_loss: 14.7359
Epoch 284/8000

Epoch 00284: val_loss did not improve from 13.60851
 - 34s - loss: 13.9233 - val_loss: 14.1317
Epoch 285/8000

Epoch 00285: val_loss did not improve from 13.60851
 - 34s - loss: 14.5601 - val_loss: 14.6348
Epoch 286/8000

Epoch 00286: val_loss did not improve from 13.60851
 - 35s - loss: 13.9188 - val_loss: 14.5898
Epoch 287/8000

Epoch 00287: val_loss did not improve from 13.60851
 - 35s - loss: 14.1503 - val_loss: 14.8592
Epoch 288/8000

Epoch 00288: val_loss did not improve from 13.60851
 - 35s - loss: 14.0360 - val_loss: 14.1358
Epoch 289/8000

Epoch 00289: val_loss did not improve from 13.60851
 - 35s - loss: 14.2196 - val_loss: 15.3708
Epoch 290/8000

Epoch 00290: val_loss did not improve from 13.60851
 - 35s - loss: 15.2961 - val_loss: 15.2829
Epoch 291/8000

Epoch 00291: val_loss did not improve from 13.60851
 - 34s - loss: 14.2964 - val_loss: 14.6301
Epoch 292/8000

Epoch 00292: val_loss did not improve from 13.60851
 - 34s - loss: 14.4951 - val_loss: 14.0943
Epoch 293/8000

Epoch 00293: val_loss did not improve from 13.60851
 - 35s - loss: 14.1345 - val_loss: 13.9476
Epoch 294/8000

Epoch 00294: val_loss did not improve from 13.60851
 - 34s - loss: 13.8995 - val_loss: 14.6698
Epoch 295/8000

Epoch 00295: val_loss did not improve from 13.60851
 - 35s - loss: 14.6224 - val_loss: 14.4042
Epoch 296/8000

Epoch 00296: val_loss did not improve from 13.60851
 - 35s - loss: 14.1521 - val_loss: 14.8974
Epoch 297/8000

Epoch 00297: val_loss did not improve from 13.60851
 - 34s - loss: 14.4814 - val_loss: 15.1019
Epoch 298/8000

Epoch 00298: val_loss did not improve from 13.60851
 - 34s - loss: 24.9532 - val_loss: 23.8113
Epoch 299/8000

Epoch 00299: val_loss did not improve from 13.60851
 - 34s - loss: 21.3765 - val_loss: 21.3938
Epoch 300/8000

Epoch 00300: val_loss did not improve from 13.60851
 - 35s - loss: 20.1384 - val_loss: 20.3015
Epoch 301/8000

Epoch 00301: val_loss did not improve from 13.60851
 - 35s - loss: 19.4393 - val_loss: 19.8306
Epoch 302/8000

Epoch 00302: val_loss did not improve from 13.60851
 - 35s - loss: 18.7625 - val_loss: 19.5386
Epoch 303/8000

Epoch 00303: val_loss did not improve from 13.60851
 - 35s - loss: 18.4965 - val_loss: 19.5784
Epoch 304/8000

Epoch 00304: val_loss did not improve from 13.60851
 - 34s - loss: 18.2544 - val_loss: 18.3037
Epoch 305/8000

Epoch 00305: val_loss did not improve from 13.60851
 - 34s - loss: 17.8497 - val_loss: 17.8511
Epoch 306/8000

Epoch 00306: val_loss did not improve from 13.60851
 - 34s - loss: 17.4068 - val_loss: 17.7460
Epoch 307/8000

Epoch 00307: val_loss did not improve from 13.60851
 - 35s - loss: 17.2120 - val_loss: 17.4488
Epoch 308/8000

Epoch 00308: val_loss did not improve from 13.60851
 - 34s - loss: 17.1095 - val_loss: 17.8099
Epoch 309/8000

Epoch 00309: val_loss did not improve from 13.60851
 - 35s - loss: 16.9800 - val_loss: 17.3570
Epoch 310/8000

Epoch 00310: val_loss did not improve from 13.60851
 - 35s - loss: 16.9489 - val_loss: 17.3903
Epoch 311/8000

Epoch 00311: val_loss did not improve from 13.60851
 - 34s - loss: 16.7473 - val_loss: 16.9203
Epoch 312/8000

Epoch 00312: val_loss did not improve from 13.60851
 - 34s - loss: 16.5951 - val_loss: 17.2613
Epoch 313/8000

Epoch 00313: val_loss did not improve from 13.60851
 - 34s - loss: 16.8019 - val_loss: 17.1748
Epoch 314/8000

Epoch 00314: val_loss did not improve from 13.60851
 - 35s - loss: 16.6841 - val_loss: 16.7786
Epoch 315/8000

Epoch 00315: val_loss did not improve from 13.60851
 - 35s - loss: 16.3791 - val_loss: 16.1617
Epoch 316/8000

Epoch 00316: val_loss did not improve from 13.60851
 - 35s - loss: 16.2886 - val_loss: 16.6043
Epoch 317/8000

Epoch 00317: val_loss did not improve from 13.60851
 - 35s - loss: 16.1792 - val_loss: 16.7470
Epoch 318/8000

Epoch 00318: val_loss did not improve from 13.60851
 - 34s - loss: 16.1895 - val_loss: 16.5861
Epoch 319/8000

Epoch 00319: val_loss did not improve from 13.60851
 - 34s - loss: 16.4109 - val_loss: 16.5446
Epoch 320/8000

Epoch 00320: val_loss did not improve from 13.60851
 - 34s - loss: 16.3258 - val_loss: 16.6300
Epoch 321/8000

Epoch 00321: val_loss did not improve from 13.60851
 - 35s - loss: 16.2319 - val_loss: 16.8658
Epoch 322/8000

Epoch 00322: val_loss did not improve from 13.60851
 - 35s - loss: 16.0577 - val_loss: 15.7647
Epoch 323/8000

Epoch 00323: val_loss did not improve from 13.60851
 - 35s - loss: 15.9447 - val_loss: 16.1227
Epoch 324/8000

Epoch 00324: val_loss did not improve from 13.60851
 - 35s - loss: 16.1692 - val_loss: 16.9607
Epoch 325/8000

Epoch 00325: val_loss did not improve from 13.60851
 - 34s - loss: 16.4131 - val_loss: 16.4364
Epoch 326/8000

Epoch 00326: val_loss did not improve from 13.60851
 - 34s - loss: 16.0275 - val_loss: 16.1441
Epoch 327/8000

Epoch 00327: val_loss did not improve from 13.60851
 - 34s - loss: 16.1497 - val_loss: 16.7660
Epoch 328/8000

Epoch 00328: val_loss did not improve from 13.60851
 - 35s - loss: 15.9922 - val_loss: 16.4778
Epoch 329/8000

Epoch 00329: val_loss did not improve from 13.60851
 - 35s - loss: 15.9250 - val_loss: 17.1317
Epoch 330/8000

Epoch 00330: val_loss did not improve from 13.60851
 - 35s - loss: 16.0220 - val_loss: 16.3358
Epoch 331/8000

Epoch 00331: val_loss did not improve from 13.60851
 - 35s - loss: 16.2682 - val_loss: 16.3660
Epoch 332/8000

Epoch 00332: val_loss did not improve from 13.60851
 - 34s - loss: 15.9649 - val_loss: 16.1678
Epoch 333/8000

Epoch 00333: val_loss did not improve from 13.60851
 - 34s - loss: 16.2467 - val_loss: 16.1327
Epoch 334/8000

Epoch 00334: val_loss did not improve from 13.60851
 - 34s - loss: 15.9142 - val_loss: 17.3902
Epoch 335/8000

Epoch 00335: val_loss did not improve from 13.60851
 - 35s - loss: 15.9205 - val_loss: 16.2153
Epoch 336/8000

Epoch 00336: val_loss did not improve from 13.60851
 - 35s - loss: 15.9907 - val_loss: 16.2010
Epoch 337/8000

Epoch 00337: val_loss did not improve from 13.60851
 - 35s - loss: 15.9033 - val_loss: 15.7765
Epoch 338/8000

Epoch 00338: val_loss did not improve from 13.60851
 - 35s - loss: 15.7430 - val_loss: 16.4745
Epoch 339/8000

Epoch 00339: val_loss did not improve from 13.60851
 - 35s - loss: 15.8137 - val_loss: 15.9822
Epoch 340/8000

Epoch 00340: val_loss did not improve from 13.60851
 - 34s - loss: 15.9143 - val_loss: 16.6837
Epoch 341/8000

Epoch 00341: val_loss did not improve from 13.60851
 - 34s - loss: 15.7085 - val_loss: 16.8714
Epoch 342/8000

Epoch 00342: val_loss did not improve from 13.60851
 - 35s - loss: 15.7451 - val_loss: 16.0677
Epoch 343/8000

Epoch 00343: val_loss did not improve from 13.60851
 - 35s - loss: 15.6517 - val_loss: 16.3302
Epoch 344/8000

Epoch 00344: val_loss did not improve from 13.60851
 - 35s - loss: 15.5804 - val_loss: 17.3819
Epoch 345/8000

Epoch 00345: val_loss did not improve from 13.60851
 - 35s - loss: 15.6076 - val_loss: 16.0486
Epoch 346/8000

Epoch 00346: val_loss did not improve from 13.60851
 - 34s - loss: 15.7122 - val_loss: 15.6682
Epoch 347/8000

Epoch 00347: val_loss did not improve from 13.60851
 - 34s - loss: 15.5981 - val_loss: 16.2284
Epoch 348/8000

Epoch 00348: val_loss did not improve from 13.60851
 - 34s - loss: 15.5901 - val_loss: 15.7457
Epoch 349/8000

Epoch 00349: val_loss did not improve from 13.60851
 - 35s - loss: 15.6132 - val_loss: 16.2196
Epoch 350/8000

Epoch 00350: val_loss did not improve from 13.60851
 - 35s - loss: 15.2142 - val_loss: 16.1010
Epoch 351/8000

Epoch 00351: val_loss did not improve from 13.60851
 - 35s - loss: 15.5477 - val_loss: 15.5992
Epoch 352/8000

Epoch 00352: val_loss did not improve from 13.60851
 - 35s - loss: 15.4811 - val_loss: 16.5258
Epoch 353/8000

Epoch 00353: val_loss did not improve from 13.60851
 - 35s - loss: 15.3569 - val_loss: 15.4986
Epoch 354/8000

Epoch 00354: val_loss did not improve from 13.60851
 - 34s - loss: 15.3618 - val_loss: 16.1942
Epoch 355/8000

Epoch 00355: val_loss did not improve from 13.60851
 - 34s - loss: 15.7302 - val_loss: 15.6622
Epoch 356/8000

Epoch 00356: val_loss did not improve from 13.60851
 - 35s - loss: 15.4599 - val_loss: 16.1466
Epoch 357/8000

Epoch 00357: val_loss did not improve from 13.60851
 - 34s - loss: 15.3558 - val_loss: 15.1981
Epoch 358/8000

Epoch 00358: val_loss did not improve from 13.60851
 - 35s - loss: 15.4349 - val_loss: 15.6153
Epoch 359/8000

Epoch 00359: val_loss did not improve from 13.60851
 - 35s - loss: 15.1756 - val_loss: 15.4438
Epoch 360/8000

Epoch 00360: val_loss did not improve from 13.60851
 - 34s - loss: 15.4886 - val_loss: 15.2823
Epoch 361/8000

Epoch 00361: val_loss did not improve from 13.60851
 - 34s - loss: 15.6785 - val_loss: 15.8455
Epoch 362/8000

Epoch 00362: val_loss did not improve from 13.60851
 - 34s - loss: 15.4127 - val_loss: 15.5523
Epoch 363/8000

Epoch 00363: val_loss did not improve from 13.60851
 - 35s - loss: 15.2984 - val_loss: 16.0681
Epoch 364/8000

Epoch 00364: val_loss did not improve from 13.60851
 - 35s - loss: 15.2317 - val_loss: 15.8617
Epoch 365/8000

Epoch 00365: val_loss did not improve from 13.60851
 - 35s - loss: 15.4863 - val_loss: 15.4657
Epoch 366/8000

Epoch 00366: val_loss did not improve from 13.60851
 - 35s - loss: 15.2884 - val_loss: 15.2825
Epoch 367/8000

Epoch 00367: val_loss did not improve from 13.60851
 - 34s - loss: 15.3008 - val_loss: 15.9281
Epoch 368/8000

Epoch 00368: val_loss did not improve from 13.60851
 - 34s - loss: 15.3237 - val_loss: 15.8196
Epoch 369/8000

Epoch 00369: val_loss did not improve from 13.60851
 - 34s - loss: 15.3745 - val_loss: 15.3843
Epoch 370/8000

Epoch 00370: val_loss did not improve from 13.60851
 - 35s - loss: 15.6119 - val_loss: 15.2904
Epoch 371/8000

Epoch 00371: val_loss did not improve from 13.60851
 - 35s - loss: 15.1919 - val_loss: 15.6704
Epoch 372/8000

Epoch 00372: val_loss did not improve from 13.60851
 - 35s - loss: 15.2966 - val_loss: 15.7372
Epoch 00372: early stopping
