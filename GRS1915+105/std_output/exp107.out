2020-04-05 13:54:34.399180: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-04-05 13:54:34.718048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-05 13:54:34.718592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2020-04-05 13:54:34.718609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-04-05 13:54:34.989723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-05 13:54:34.989768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-04-05 13:54:34.989778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-04-05 13:54:34.990013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-05 13:54:35.681943: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x55706375b480
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 27.50594, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 297s - loss: 36.5261 - val_loss: 27.5059
Epoch 2/8000

Epoch 00002: val_loss did not improve from 27.50594
 - 292s - loss: 28.4841 - val_loss: 28.1672
Epoch 3/8000

Epoch 00003: val_loss improved from 27.50594 to 25.53551, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 293s - loss: 27.5434 - val_loss: 25.5355
Epoch 4/8000

Epoch 00004: val_loss improved from 25.53551 to 24.94364, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 294s - loss: 27.3039 - val_loss: 24.9436
Epoch 5/8000

Epoch 00005: val_loss did not improve from 24.94364
 - 293s - loss: 27.1299 - val_loss: 26.9816
Epoch 6/8000

Epoch 00006: val_loss did not improve from 24.94364
 - 295s - loss: 27.0959 - val_loss: 25.2428
Epoch 7/8000

Epoch 00007: val_loss improved from 24.94364 to 24.86536, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 293s - loss: 27.0393 - val_loss: 24.8654
Epoch 8/8000

Epoch 00008: val_loss did not improve from 24.86536
 - 297s - loss: 27.0355 - val_loss: 26.8547
Epoch 9/8000

Epoch 00009: val_loss did not improve from 24.86536
 - 294s - loss: 27.0433 - val_loss: 25.3931
Epoch 10/8000

Epoch 00010: val_loss improved from 24.86536 to 24.85177, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 295s - loss: 26.9663 - val_loss: 24.8518
Epoch 11/8000

Epoch 00011: val_loss did not improve from 24.85177
 - 294s - loss: 26.9503 - val_loss: 26.8195
Epoch 12/8000

Epoch 00012: val_loss did not improve from 24.85177
 - 294s - loss: 26.9521 - val_loss: 25.4280
Epoch 13/8000

Epoch 00013: val_loss improved from 24.85177 to 24.78376, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 296s - loss: 26.9552 - val_loss: 24.7838
Epoch 14/8000

Epoch 00014: val_loss did not improve from 24.78376
 - 293s - loss: 26.8869 - val_loss: 27.1402
Epoch 15/8000

Epoch 00015: val_loss did not improve from 24.78376
 - 298s - loss: 26.9177 - val_loss: 25.7515
Epoch 16/8000

Epoch 00016: val_loss did not improve from 24.78376
 - 294s - loss: 26.8854 - val_loss: 24.8243
Epoch 17/8000

Epoch 00017: val_loss did not improve from 24.78376
 - 295s - loss: 26.8816 - val_loss: 26.7441
Epoch 18/8000

Epoch 00018: val_loss did not improve from 24.78376
 - 295s - loss: 26.8996 - val_loss: 25.1120
Epoch 19/8000

Epoch 00019: val_loss did not improve from 24.78376
 - 294s - loss: 26.9022 - val_loss: 24.9339
Epoch 20/8000

Epoch 00020: val_loss did not improve from 24.78376
 - 295s - loss: 26.9391 - val_loss: 26.9694
Epoch 21/8000

Epoch 00021: val_loss did not improve from 24.78376
 - 294s - loss: 26.8372 - val_loss: 25.6329
Epoch 22/8000

Epoch 00022: val_loss improved from 24.78376 to 24.77387, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 298s - loss: 26.7604 - val_loss: 24.7739
Epoch 23/8000

Epoch 00023: val_loss did not improve from 24.77387
 - 293s - loss: 26.8594 - val_loss: 26.4433
Epoch 24/8000

Epoch 00024: val_loss did not improve from 24.77387
 - 295s - loss: 26.8502 - val_loss: 25.1493
Epoch 25/8000

Epoch 00025: val_loss improved from 24.77387 to 24.50943, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 295s - loss: 26.7952 - val_loss: 24.5094
Epoch 26/8000

Epoch 00026: val_loss did not improve from 24.50943
 - 294s - loss: 26.7321 - val_loss: 26.3826
Epoch 27/8000

Epoch 00027: val_loss did not improve from 24.50943
 - 295s - loss: 26.7795 - val_loss: 24.9612
Epoch 28/8000

Epoch 00028: val_loss did not improve from 24.50943
 - 294s - loss: 26.7539 - val_loss: 24.6566
Epoch 29/8000

Epoch 00029: val_loss did not improve from 24.50943
 - 298s - loss: 26.7147 - val_loss: 26.1365
Epoch 30/8000

Epoch 00030: val_loss did not improve from 24.50943
 - 295s - loss: 26.7597 - val_loss: 25.0528
Epoch 31/8000

Epoch 00031: val_loss did not improve from 24.50943
 - 295s - loss: 26.7277 - val_loss: 24.5552
Epoch 32/8000

Epoch 00032: val_loss did not improve from 24.50943
 - 295s - loss: 26.6801 - val_loss: 26.3141
Epoch 33/8000

Epoch 00033: val_loss did not improve from 24.50943
 - 295s - loss: 26.7004 - val_loss: 24.9261
Epoch 34/8000

Epoch 00034: val_loss did not improve from 24.50943
 - 295s - loss: 26.6650 - val_loss: 24.5729
Epoch 35/8000

Epoch 00035: val_loss did not improve from 24.50943
 - 294s - loss: 26.6107 - val_loss: 26.6272
Epoch 36/8000

Epoch 00036: val_loss did not improve from 24.50943
 - 298s - loss: 26.6436 - val_loss: 25.0250
Epoch 37/8000

Epoch 00037: val_loss improved from 24.50943 to 24.40067, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 294s - loss: 26.6184 - val_loss: 24.4007
Epoch 38/8000

Epoch 00038: val_loss did not improve from 24.40067
 - 295s - loss: 26.5937 - val_loss: 26.2382
Epoch 39/8000

Epoch 00039: val_loss did not improve from 24.40067
 - 295s - loss: 26.6414 - val_loss: 25.3039
Epoch 40/8000

Epoch 00040: val_loss did not improve from 24.40067
 - 294s - loss: 26.6123 - val_loss: 24.4963
Epoch 41/8000

Epoch 00041: val_loss did not improve from 24.40067
 - 296s - loss: 26.6394 - val_loss: 26.1658
Epoch 42/8000

Epoch 00042: val_loss did not improve from 24.40067
 - 295s - loss: 26.5964 - val_loss: 25.0907
Epoch 43/8000

Epoch 00043: val_loss did not improve from 24.40067
 - 298s - loss: 26.5958 - val_loss: 24.5150
Epoch 44/8000

Epoch 00044: val_loss did not improve from 24.40067
 - 294s - loss: 26.6019 - val_loss: 26.2417
Epoch 45/8000

Epoch 00045: val_loss did not improve from 24.40067
 - 297s - loss: 26.5948 - val_loss: 25.0695
Epoch 46/8000

Epoch 00046: val_loss did not improve from 24.40067
 - 297s - loss: 26.5727 - val_loss: 24.4308
Epoch 47/8000

Epoch 00047: val_loss did not improve from 24.40067
 - 294s - loss: 26.5878 - val_loss: 26.0660
Epoch 48/8000

Epoch 00048: val_loss did not improve from 24.40067
 - 296s - loss: 26.6039 - val_loss: 25.1975
Epoch 49/8000

Epoch 00049: val_loss did not improve from 24.40067
 - 295s - loss: 26.5710 - val_loss: 24.5280
Epoch 50/8000

Epoch 00050: val_loss did not improve from 24.40067
 - 297s - loss: 26.5505 - val_loss: 26.2796
Epoch 51/8000

Epoch 00051: val_loss did not improve from 24.40067
 - 294s - loss: 26.5587 - val_loss: 24.9040
Epoch 52/8000

Epoch 00052: val_loss improved from 24.40067 to 24.37351, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 297s - loss: 26.5124 - val_loss: 24.3735
Epoch 53/8000

Epoch 00053: val_loss did not improve from 24.37351
 - 296s - loss: 26.5187 - val_loss: 26.2555
Epoch 54/8000

Epoch 00054: val_loss did not improve from 24.37351
 - 295s - loss: 26.5223 - val_loss: 24.7146
Epoch 55/8000

Epoch 00055: val_loss did not improve from 24.37351
 - 297s - loss: 26.5950 - val_loss: 24.5188
Epoch 56/8000

Epoch 00056: val_loss did not improve from 24.37351
 - 296s - loss: 26.5378 - val_loss: 26.1365
Epoch 57/8000

Epoch 00057: val_loss did not improve from 24.37351
 - 299s - loss: 26.5108 - val_loss: 24.8668
Epoch 58/8000

Epoch 00058: val_loss did not improve from 24.37351
 - 294s - loss: 26.5363 - val_loss: 24.5025
Epoch 59/8000

Epoch 00059: val_loss did not improve from 24.37351
 - 297s - loss: 26.5531 - val_loss: 26.3813
Epoch 60/8000

Epoch 00060: val_loss did not improve from 24.37351
 - 296s - loss: 26.5135 - val_loss: 24.9220
Epoch 61/8000

Epoch 00061: val_loss improved from 24.37351 to 24.19449, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 295s - loss: 26.4596 - val_loss: 24.1945
Epoch 62/8000

Epoch 00062: val_loss did not improve from 24.19449
 - 297s - loss: 26.5156 - val_loss: 26.1403
Epoch 63/8000

Epoch 00063: val_loss did not improve from 24.19449
 - 296s - loss: 26.4623 - val_loss: 25.0416
Epoch 64/8000

Epoch 00064: val_loss did not improve from 24.19449
 - 298s - loss: 26.4921 - val_loss: 24.3709
Epoch 65/8000

Epoch 00065: val_loss did not improve from 24.19449
 - 295s - loss: 26.4757 - val_loss: 25.9769
Epoch 66/8000

Epoch 00066: val_loss did not improve from 24.19449
 - 297s - loss: 26.4795 - val_loss: 24.6464
Epoch 67/8000

Epoch 00067: val_loss did not improve from 24.19449
 - 295s - loss: 26.4464 - val_loss: 24.3091
Epoch 68/8000

Epoch 00068: val_loss did not improve from 24.19449
 - 295s - loss: 26.4730 - val_loss: 26.5402
Epoch 69/8000

Epoch 00069: val_loss did not improve from 24.19449
 - 297s - loss: 26.5030 - val_loss: 25.0869
Epoch 70/8000

Epoch 00070: val_loss did not improve from 24.19449
 - 295s - loss: 26.4587 - val_loss: 24.3659
Epoch 71/8000

Epoch 00071: val_loss did not improve from 24.19449
 - 297s - loss: 29.3969 - val_loss: 25.1303
Epoch 72/8000

Epoch 00072: val_loss improved from 24.19449 to 24.10421, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 292s - loss: 26.5520 - val_loss: 24.1042
Epoch 73/8000

Epoch 00073: val_loss did not improve from 24.10421
 - 292s - loss: 26.4029 - val_loss: 25.8769
Epoch 74/8000

Epoch 00074: val_loss did not improve from 24.10421
 - 290s - loss: 26.2965 - val_loss: 24.6142
Epoch 75/8000

Epoch 00075: val_loss did not improve from 24.10421
 - 290s - loss: 26.3414 - val_loss: 24.2671
Epoch 76/8000

Epoch 00076: val_loss did not improve from 24.10421
 - 293s - loss: 26.2799 - val_loss: 26.0563
Epoch 77/8000

Epoch 00077: val_loss did not improve from 24.10421
 - 292s - loss: 28.2266 - val_loss: 26.5359
Epoch 78/8000

Epoch 00078: val_loss did not improve from 24.10421
 - 290s - loss: 27.2447 - val_loss: 26.8429
Epoch 79/8000

Epoch 00079: val_loss did not improve from 24.10421
 - 287s - loss: 26.7921 - val_loss: 24.9196
Epoch 80/8000

Epoch 00080: val_loss did not improve from 24.10421
 - 289s - loss: 26.7568 - val_loss: 24.4924
Epoch 81/8000

Epoch 00081: val_loss did not improve from 24.10421
 - 288s - loss: 26.6026 - val_loss: 26.6019
Epoch 82/8000

Epoch 00082: val_loss did not improve from 24.10421
 - 287s - loss: 26.6480 - val_loss: 24.8744
Epoch 83/8000

Epoch 00083: val_loss did not improve from 24.10421
 - 290s - loss: 26.6021 - val_loss: 24.3994
Epoch 84/8000

Epoch 00084: val_loss did not improve from 24.10421
 - 289s - loss: 26.5733 - val_loss: 26.3696
Epoch 85/8000

Epoch 00085: val_loss did not improve from 24.10421
 - 292s - loss: 28.3857 - val_loss: 24.1680
Epoch 86/8000

Epoch 00086: val_loss did not improve from 24.10421
 - 296s - loss: 25.5262 - val_loss: 24.3057
Epoch 87/8000

Epoch 00087: val_loss did not improve from 24.10421
 - 297s - loss: 25.5545 - val_loss: 24.2475
Epoch 88/8000

Epoch 00088: val_loss did not improve from 24.10421
 - 294s - loss: 25.5460 - val_loss: 24.2708
Epoch 89/8000

Epoch 00089: val_loss did not improve from 24.10421
 - 294s - loss: 25.5377 - val_loss: 24.2855
Epoch 90/8000

Epoch 00090: val_loss did not improve from 24.10421
 - 297s - loss: 25.5463 - val_loss: 24.2034
Epoch 91/8000

Epoch 00091: val_loss did not improve from 24.10421
 - 295s - loss: 25.5436 - val_loss: 24.1741
Epoch 92/8000

Epoch 00092: val_loss did not improve from 24.10421
 - 298s - loss: 25.5498 - val_loss: 24.1108
Epoch 93/8000

Epoch 00093: val_loss did not improve from 24.10421
 - 295s - loss: 25.5411 - val_loss: 24.2296
Epoch 94/8000

Epoch 00094: val_loss did not improve from 24.10421
 - 296s - loss: 25.5958 - val_loss: 24.2208
Epoch 95/8000

Epoch 00095: val_loss did not improve from 24.10421
 - 294s - loss: 25.5721 - val_loss: 24.2064
Epoch 96/8000

Epoch 00096: val_loss did not improve from 24.10421
 - 295s - loss: 25.5504 - val_loss: 24.1764
Epoch 97/8000

Epoch 00097: val_loss did not improve from 24.10421
 - 297s - loss: 25.5562 - val_loss: 24.2745
Epoch 98/8000

Epoch 00098: val_loss did not improve from 24.10421
 - 294s - loss: 25.5338 - val_loss: 24.3566
Epoch 99/8000

Epoch 00099: val_loss did not improve from 24.10421
 - 297s - loss: 25.5692 - val_loss: 24.2383
Epoch 100/8000

Epoch 00100: val_loss did not improve from 24.10421
 - 295s - loss: 25.5696 - val_loss: 24.2116
Epoch 101/8000

Epoch 00101: val_loss did not improve from 24.10421
 - 296s - loss: 25.5535 - val_loss: 24.1057
Epoch 102/8000

Epoch 00102: val_loss did not improve from 24.10421
 - 295s - loss: 25.5599 - val_loss: 24.2357
Epoch 103/8000

Epoch 00103: val_loss did not improve from 24.10421
 - 294s - loss: 25.5471 - val_loss: 24.2889
Epoch 104/8000

Epoch 00104: val_loss did not improve from 24.10421
 - 297s - loss: 25.5710 - val_loss: 24.1861
Epoch 105/8000

Epoch 00105: val_loss did not improve from 24.10421
 - 295s - loss: 25.5536 - val_loss: 24.2698
Epoch 106/8000

Epoch 00106: val_loss improved from 24.10421 to 24.07416, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 298s - loss: 25.5622 - val_loss: 24.0742
Epoch 107/8000

Epoch 00107: val_loss did not improve from 24.07416
 - 295s - loss: 25.5541 - val_loss: 24.2358
Epoch 108/8000

Epoch 00108: val_loss did not improve from 24.07416
 - 296s - loss: 25.5477 - val_loss: 24.1542
Epoch 109/8000

Epoch 00109: val_loss did not improve from 24.07416
 - 294s - loss: 25.5240 - val_loss: 24.1429
Epoch 110/8000

Epoch 00110: val_loss did not improve from 24.07416
 - 294s - loss: 25.5590 - val_loss: 24.1884
Epoch 111/8000

Epoch 00111: val_loss did not improve from 24.07416
 - 297s - loss: 25.5421 - val_loss: 24.3764
Epoch 112/8000

Epoch 00112: val_loss did not improve from 24.07416
 - 294s - loss: 25.5364 - val_loss: 24.4225
Epoch 113/8000

Epoch 00113: val_loss did not improve from 24.07416
 - 298s - loss: 25.5835 - val_loss: 24.2317
Epoch 114/8000

Epoch 00114: val_loss did not improve from 24.07416
 - 295s - loss: 25.5469 - val_loss: 24.2922
Epoch 115/8000

Epoch 00115: val_loss improved from 24.07416 to 24.03665, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 296s - loss: 25.5181 - val_loss: 24.0367
Epoch 116/8000

Epoch 00116: val_loss did not improve from 24.03665
 - 294s - loss: 25.5436 - val_loss: 24.2368
Epoch 117/8000

Epoch 00117: val_loss did not improve from 24.03665
 - 295s - loss: 25.5325 - val_loss: 24.2650
Epoch 118/8000

Epoch 00118: val_loss did not improve from 24.03665
 - 296s - loss: 25.5482 - val_loss: 24.3987
Epoch 119/8000

Epoch 00119: val_loss did not improve from 24.03665
 - 294s - loss: 25.5521 - val_loss: 24.2995
Epoch 120/8000

Epoch 00120: val_loss did not improve from 24.03665
 - 298s - loss: 25.5412 - val_loss: 24.1653
Epoch 121/8000

Epoch 00121: val_loss did not improve from 24.03665
 - 295s - loss: 25.5341 - val_loss: 24.2196
Epoch 122/8000

Epoch 00122: val_loss improved from 24.03665 to 23.98619, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 295s - loss: 25.5198 - val_loss: 23.9862
Epoch 123/8000

Epoch 00123: val_loss did not improve from 23.98619
 - 294s - loss: 25.5380 - val_loss: 24.1563
Epoch 124/8000

Epoch 00124: val_loss did not improve from 23.98619
 - 294s - loss: 25.5346 - val_loss: 24.1386
Epoch 125/8000

Epoch 00125: val_loss did not improve from 23.98619
 - 297s - loss: 25.5364 - val_loss: 24.2506
Epoch 126/8000

Epoch 00126: val_loss did not improve from 23.98619
 - 294s - loss: 25.5302 - val_loss: 24.3032
Epoch 127/8000

Epoch 00127: val_loss did not improve from 23.98619
 - 297s - loss: 25.5308 - val_loss: 24.2606
Epoch 128/8000

Epoch 00128: val_loss did not improve from 23.98619
 - 295s - loss: 25.5307 - val_loss: 24.2103
Epoch 129/8000

Epoch 00129: val_loss did not improve from 23.98619
 - 296s - loss: 25.5452 - val_loss: 24.1256
Epoch 130/8000

Epoch 00130: val_loss did not improve from 23.98619
 - 294s - loss: 25.5286 - val_loss: 24.0206
Epoch 131/8000

Epoch 00131: val_loss did not improve from 23.98619
 - 295s - loss: 25.5180 - val_loss: 24.2451
Epoch 132/8000

Epoch 00132: val_loss did not improve from 23.98619
 - 296s - loss: 25.5222 - val_loss: 24.1735
Epoch 133/8000

Epoch 00133: val_loss did not improve from 23.98619
 - 294s - loss: 25.5338 - val_loss: 24.1723
Epoch 134/8000

Epoch 00134: val_loss did not improve from 23.98619
 - 298s - loss: 25.5188 - val_loss: 24.2671
Epoch 135/8000

Epoch 00135: val_loss did not improve from 23.98619
 - 295s - loss: 25.5416 - val_loss: 24.1312
Epoch 136/8000

Epoch 00136: val_loss did not improve from 23.98619
 - 295s - loss: 25.5137 - val_loss: 24.0835
Epoch 137/8000

Epoch 00137: val_loss did not improve from 23.98619
 - 295s - loss: 25.5088 - val_loss: 24.3142
Epoch 138/8000

Epoch 00138: val_loss did not improve from 23.98619
 - 295s - loss: 25.5354 - val_loss: 24.2134
Epoch 139/8000

Epoch 00139: val_loss did not improve from 23.98619
 - 295s - loss: 25.5472 - val_loss: 24.1895
Epoch 140/8000

Epoch 00140: val_loss did not improve from 23.98619
 - 294s - loss: 25.5264 - val_loss: 24.2448
Epoch 141/8000

Epoch 00141: val_loss did not improve from 23.98619
 - 299s - loss: 25.5257 - val_loss: 24.2459
Epoch 142/8000

Epoch 00142: val_loss did not improve from 23.98619
 - 294s - loss: 25.5216 - val_loss: 24.0298
Epoch 143/8000

Epoch 00143: val_loss did not improve from 23.98619
 - 295s - loss: 25.5253 - val_loss: 24.3591
Epoch 144/8000

Epoch 00144: val_loss did not improve from 23.98619
 - 295s - loss: 25.5145 - val_loss: 24.2970
Epoch 145/8000

Epoch 00145: val_loss did not improve from 23.98619
 - 294s - loss: 25.5226 - val_loss: 24.1098
Epoch 146/8000

Epoch 00146: val_loss did not improve from 23.98619
 - 295s - loss: 25.5234 - val_loss: 24.3404
Epoch 147/8000

Epoch 00147: val_loss did not improve from 23.98619
 - 294s - loss: 25.5152 - val_loss: 24.2561
Epoch 148/8000

Epoch 00148: val_loss did not improve from 23.98619
 - 298s - loss: 25.4970 - val_loss: 24.2998
Epoch 149/8000

Epoch 00149: val_loss did not improve from 23.98619
 - 295s - loss: 25.5292 - val_loss: 24.2900
Epoch 150/8000

Epoch 00150: val_loss did not improve from 23.98619
 - 295s - loss: 25.5225 - val_loss: 24.1595
Epoch 151/8000

Epoch 00151: val_loss did not improve from 23.98619
 - 294s - loss: 25.5156 - val_loss: 24.0680
Epoch 152/8000

Epoch 00152: val_loss did not improve from 23.98619
 - 295s - loss: 25.5138 - val_loss: 24.0971
Epoch 153/8000

Epoch 00153: val_loss did not improve from 23.98619
 - 296s - loss: 25.5132 - val_loss: 24.2830
Epoch 154/8000

Epoch 00154: val_loss did not improve from 23.98619
 - 294s - loss: 25.5079 - val_loss: 24.0742
Epoch 155/8000

Epoch 00155: val_loss did not improve from 23.98619
 - 298s - loss: 25.5257 - val_loss: 24.2115
Epoch 156/8000

Epoch 00156: val_loss did not improve from 23.98619
 - 295s - loss: 25.5051 - val_loss: 24.1378
Epoch 157/8000

Epoch 00157: val_loss did not improve from 23.98619
 - 295s - loss: 25.5286 - val_loss: 24.1123
Epoch 158/8000

Epoch 00158: val_loss did not improve from 23.98619
 - 295s - loss: 25.5228 - val_loss: 24.1541
Epoch 159/8000

Epoch 00159: val_loss did not improve from 23.98619
 - 291s - loss: 35.2041 - val_loss: 29.3195
Epoch 160/8000

Epoch 00160: val_loss did not improve from 23.98619
 - 287s - loss: 28.1415 - val_loss: 25.7366
Epoch 161/8000

Epoch 00161: val_loss did not improve from 23.98619
 - 286s - loss: 26.6925 - val_loss: 25.3296
Epoch 162/8000

Epoch 00162: val_loss did not improve from 23.98619
 - 290s - loss: 26.1477 - val_loss: 24.6812
Epoch 163/8000

Epoch 00163: val_loss did not improve from 23.98619
 - 287s - loss: 25.9162 - val_loss: 24.8128
Epoch 164/8000

Epoch 00164: val_loss did not improve from 23.98619
 - 287s - loss: 26.5036 - val_loss: 29.6910
Epoch 165/8000

Epoch 00165: val_loss did not improve from 23.98619
 - 288s - loss: 27.6744 - val_loss: 24.5423
Epoch 166/8000

Epoch 00166: val_loss did not improve from 23.98619
 - 292s - loss: 29.3846 - val_loss: 30.9733
Epoch 167/8000

Epoch 00167: val_loss did not improve from 23.98619
 - 292s - loss: 30.2379 - val_loss: 26.1633
Epoch 168/8000

Epoch 00168: val_loss did not improve from 23.98619
 - 287s - loss: 34.4409 - val_loss: 27.0246
Epoch 169/8000

Epoch 00169: val_loss did not improve from 23.98619
 - 294s - loss: 30.8406 - val_loss: 29.0076
Epoch 170/8000

Epoch 00170: val_loss did not improve from 23.98619
 - 289s - loss: 31.5246 - val_loss: 28.5630
Epoch 171/8000

Epoch 00171: val_loss did not improve from 23.98619
 - 291s - loss: 29.3529 - val_loss: 25.0732
Epoch 172/8000

Epoch 00172: val_loss did not improve from 23.98619
 - 296s - loss: 25.8886 - val_loss: 24.0243
Epoch 173/8000

Epoch 00173: val_loss did not improve from 23.98619
 - 296s - loss: 25.7190 - val_loss: 24.1781
Epoch 174/8000

Epoch 00174: val_loss did not improve from 23.98619
 - 297s - loss: 25.9349 - val_loss: 25.9707
Epoch 175/8000

Epoch 00175: val_loss did not improve from 23.98619
 - 294s - loss: 26.8771 - val_loss: 27.8968
Epoch 176/8000

Epoch 00176: val_loss improved from 23.98619 to 23.93777, saving model to ../../model_weights/model_2020-04-05_13-54-33.h5
 - 299s - loss: 26.1593 - val_loss: 23.9378
Epoch 177/8000

Epoch 00177: val_loss did not improve from 23.93777
 - 295s - loss: 27.0513 - val_loss: 24.4033
Epoch 178/8000

Epoch 00178: val_loss did not improve from 23.93777
 - 294s - loss: 30.3396 - val_loss: 27.9152
Epoch 179/8000

Epoch 00179: val_loss did not improve from 23.93777
 - 294s - loss: 27.8793 - val_loss: 24.2471
Epoch 180/8000

Epoch 00180: val_loss did not improve from 23.93777
 - 294s - loss: 26.9348 - val_loss: 24.5703
Epoch 181/8000

Epoch 00181: val_loss did not improve from 23.93777
 - 295s - loss: 26.6751 - val_loss: 24.7581
Epoch 182/8000

Epoch 00182: val_loss did not improve from 23.93777
 - 294s - loss: 26.0381 - val_loss: 24.8863
Epoch 183/8000

Epoch 00183: val_loss did not improve from 23.93777
 - 297s - loss: 26.5600 - val_loss: 24.2312
Epoch 184/8000

Epoch 00184: val_loss did not improve from 23.93777
 - 293s - loss: 26.6836 - val_loss: 27.1478
Epoch 185/8000

Epoch 00185: val_loss did not improve from 23.93777
 - 293s - loss: 27.3712 - val_loss: 24.4451
Epoch 186/8000

Epoch 00186: val_loss did not improve from 23.93777
 - 292s - loss: 27.8483 - val_loss: 24.4639
Epoch 187/8000

Epoch 00187: val_loss did not improve from 23.93777
 - 292s - loss: 26.6341 - val_loss: 24.6880
Epoch 188/8000

Epoch 00188: val_loss did not improve from 23.93777
 - 293s - loss: 27.0048 - val_loss: 24.7268
Epoch 189/8000

Epoch 00189: val_loss did not improve from 23.93777
 - 290s - loss: 27.3778 - val_loss: 25.0618
Epoch 190/8000

Epoch 00190: val_loss did not improve from 23.93777
 - 295s - loss: 26.8651 - val_loss: 26.9681
Epoch 191/8000

Epoch 00191: val_loss did not improve from 23.93777
 - 292s - loss: 26.9477 - val_loss: 24.8766
Epoch 192/8000

Epoch 00192: val_loss did not improve from 23.93777
 - 291s - loss: 26.7891 - val_loss: 24.4645
Epoch 193/8000

Epoch 00193: val_loss did not improve from 23.93777
 - 296s - loss: 25.6019 - val_loss: 24.1838
Epoch 194/8000

Epoch 00194: val_loss did not improve from 23.93777
 - 295s - loss: 25.4767 - val_loss: 24.2432
Epoch 195/8000

Epoch 00195: val_loss did not improve from 23.93777
 - 296s - loss: 25.4972 - val_loss: 24.1508
Epoch 196/8000

Epoch 00196: val_loss did not improve from 23.93777
 - 293s - loss: 25.5034 - val_loss: 24.2367
Epoch 197/8000

Epoch 00197: val_loss did not improve from 23.93777
 - 298s - loss: 25.5130 - val_loss: 24.2582
Epoch 198/8000

Epoch 00198: val_loss did not improve from 23.93777
 - 295s - loss: 25.5140 - val_loss: 24.2162
Epoch 199/8000

Epoch 00199: val_loss did not improve from 23.93777
 - 296s - loss: 25.4986 - val_loss: 24.0808
Epoch 200/8000

Epoch 00200: val_loss did not improve from 23.93777
 - 294s - loss: 25.5048 - val_loss: 24.2510
Epoch 201/8000

Epoch 00201: val_loss did not improve from 23.93777
 - 294s - loss: 25.5104 - val_loss: 24.2867
Epoch 202/8000

Epoch 00202: val_loss did not improve from 23.93777
 - 296s - loss: 25.5126 - val_loss: 24.0379
Epoch 203/8000

Epoch 00203: val_loss did not improve from 23.93777
 - 295s - loss: 25.5115 - val_loss: 24.1707
Epoch 204/8000

Epoch 00204: val_loss did not improve from 23.93777
 - 297s - loss: 25.5136 - val_loss: 24.1644
Epoch 205/8000

Epoch 00205: val_loss did not improve from 23.93777
 - 295s - loss: 25.5190 - val_loss: 24.1444
Epoch 206/8000

Epoch 00206: val_loss did not improve from 23.93777
 - 297s - loss: 25.5379 - val_loss: 24.3594
Epoch 207/8000

Epoch 00207: val_loss did not improve from 23.93777
 - 296s - loss: 25.5244 - val_loss: 23.9688
Epoch 208/8000

Epoch 00208: val_loss did not improve from 23.93777
 - 296s - loss: 25.5136 - val_loss: 24.2407
Epoch 209/8000

Epoch 00209: val_loss did not improve from 23.93777
 - 299s - loss: 25.5064 - val_loss: 24.2661
Epoch 210/8000

Epoch 00210: val_loss did not improve from 23.93777
 - 296s - loss: 25.5324 - val_loss: 24.1287
Epoch 211/8000

Epoch 00211: val_loss did not improve from 23.93777
 - 299s - loss: 25.5199 - val_loss: 24.1929
Epoch 212/8000

Epoch 00212: val_loss did not improve from 23.93777
 - 296s - loss: 25.5188 - val_loss: 24.0667
Epoch 213/8000

Epoch 00213: val_loss did not improve from 23.93777
 - 298s - loss: 25.5127 - val_loss: 24.2340
Epoch 214/8000

Epoch 00214: val_loss did not improve from 23.93777
 - 296s - loss: 25.5220 - val_loss: 24.2870
Epoch 215/8000

Epoch 00215: val_loss did not improve from 23.93777
 - 296s - loss: 25.4939 - val_loss: 24.2180
Epoch 216/8000

Epoch 00216: val_loss did not improve from 23.93777
 - 298s - loss: 25.5196 - val_loss: 24.2179
Epoch 217/8000

Epoch 00217: val_loss did not improve from 23.93777
 - 296s - loss: 25.5153 - val_loss: 24.1769
Epoch 218/8000

Epoch 00218: val_loss did not improve from 23.93777
 - 299s - loss: 25.5118 - val_loss: 24.1481
Epoch 219/8000

Epoch 00219: val_loss did not improve from 23.93777
 - 297s - loss: 25.5070 - val_loss: 24.3533
Epoch 220/8000

Epoch 00220: val_loss did not improve from 23.93777
 - 298s - loss: 25.5101 - val_loss: 24.0464
Epoch 221/8000

Epoch 00221: val_loss did not improve from 23.93777
 - 295s - loss: 25.5234 - val_loss: 24.2345
Epoch 222/8000

Epoch 00222: val_loss did not improve from 23.93777
 - 296s - loss: 25.5257 - val_loss: 24.1628
Epoch 223/8000

Epoch 00223: val_loss did not improve from 23.93777
 - 299s - loss: 25.5237 - val_loss: 24.2498
Epoch 224/8000

Epoch 00224: val_loss did not improve from 23.93777
 - 297s - loss: 25.5218 - val_loss: 24.1478
Epoch 225/8000

Epoch 00225: val_loss did not improve from 23.93777
 - 300s - loss: 25.5015 - val_loss: 24.2081
Epoch 226/8000

Epoch 00226: val_loss did not improve from 23.93777
 - 280s - loss: 60.9746 - val_loss: 31.8437
Epoch 227/8000

Epoch 00227: val_loss did not improve from 23.93777
 - 281s - loss: 41.4051 - val_loss: 44.9407
Epoch 228/8000

Epoch 00228: val_loss did not improve from 23.93777
 - 280s - loss: 36.5316 - val_loss: 24.7170
Epoch 229/8000

Epoch 00229: val_loss did not improve from 23.93777
 - 277s - loss: 34.0472 - val_loss: 37.6699
Epoch 230/8000

Epoch 00230: val_loss did not improve from 23.93777
 - 281s - loss: 33.1098 - val_loss: 43.9416
Epoch 231/8000

Epoch 00231: val_loss did not improve from 23.93777
 - 281s - loss: 33.3966 - val_loss: 28.0778
Epoch 232/8000

Epoch 00232: val_loss did not improve from 23.93777
 - 282s - loss: 32.6454 - val_loss: 36.8143
Epoch 233/8000

Epoch 00233: val_loss did not improve from 23.93777
 - 278s - loss: 32.3397 - val_loss: 29.9217
Epoch 234/8000

Epoch 00234: val_loss did not improve from 23.93777
 - 281s - loss: 32.0564 - val_loss: 26.7379
Epoch 235/8000

Epoch 00235: val_loss did not improve from 23.93777
 - 281s - loss: 31.8455 - val_loss: 33.7530
Epoch 236/8000

Epoch 00236: val_loss did not improve from 23.93777
 - 278s - loss: 31.7506 - val_loss: 28.4559
Epoch 237/8000

Epoch 00237: val_loss did not improve from 23.93777
 - 280s - loss: 31.6585 - val_loss: 27.2174
Epoch 238/8000

Epoch 00238: val_loss did not improve from 23.93777
 - 280s - loss: 31.4310 - val_loss: 34.9436
Epoch 239/8000

Epoch 00239: val_loss did not improve from 23.93777
 - 282s - loss: 31.3816 - val_loss: 29.3066
Epoch 240/8000

Epoch 00240: val_loss did not improve from 23.93777
 - 278s - loss: 31.4146 - val_loss: 26.5005
Epoch 241/8000

Epoch 00241: val_loss did not improve from 23.93777
 - 281s - loss: 31.3511 - val_loss: 33.0081
Epoch 242/8000

Epoch 00242: val_loss did not improve from 23.93777
 - 281s - loss: 31.2885 - val_loss: 28.3305
Epoch 243/8000

Epoch 00243: val_loss did not improve from 23.93777
 - 278s - loss: 31.2847 - val_loss: 27.0884
Epoch 244/8000

Epoch 00244: val_loss did not improve from 23.93777
 - 281s - loss: 31.2232 - val_loss: 34.3281
Epoch 245/8000

Epoch 00245: val_loss did not improve from 23.93777
 - 281s - loss: 31.2699 - val_loss: 29.1741
Epoch 246/8000

Epoch 00246: val_loss did not improve from 23.93777
 - 281s - loss: 31.2140 - val_loss: 26.2786
Epoch 247/8000

Epoch 00247: val_loss did not improve from 23.93777
 - 277s - loss: 31.1959 - val_loss: 32.9147
Epoch 248/8000

Epoch 00248: val_loss did not improve from 23.93777
 - 279s - loss: 31.2864 - val_loss: 28.1508
Epoch 249/8000

Epoch 00249: val_loss did not improve from 23.93777
 - 280s - loss: 31.1778 - val_loss: 27.2432
Epoch 250/8000

Epoch 00250: val_loss did not improve from 23.93777
 - 281s - loss: 31.3110 - val_loss: 34.3602
Epoch 251/8000

Epoch 00251: val_loss did not improve from 23.93777
 - 279s - loss: 31.2285 - val_loss: 29.3016
Epoch 252/8000

Epoch 00252: val_loss did not improve from 23.93777
 - 278s - loss: 31.1665 - val_loss: 26.3973
Epoch 253/8000

Epoch 00253: val_loss did not improve from 23.93777
 - 284s - loss: 31.2267 - val_loss: 33.1459
Epoch 254/8000

Epoch 00254: val_loss did not improve from 23.93777
 - 279s - loss: 31.3013 - val_loss: 28.1572
Epoch 255/8000

Epoch 00255: val_loss did not improve from 23.93777
 - 279s - loss: 31.2144 - val_loss: 27.0502
Epoch 256/8000

Epoch 00256: val_loss did not improve from 23.93777
 - 280s - loss: 31.1965 - val_loss: 34.4584
Epoch 257/8000

Epoch 00257: val_loss did not improve from 23.93777
 - 280s - loss: 31.1937 - val_loss: 29.1927
Epoch 258/8000

Epoch 00258: val_loss did not improve from 23.93777
 - 279s - loss: 31.2569 - val_loss: 26.2267
Epoch 259/8000

Epoch 00259: val_loss did not improve from 23.93777
 - 278s - loss: 31.1919 - val_loss: 32.9951
Epoch 260/8000

Epoch 00260: val_loss did not improve from 23.93777
 - 284s - loss: 31.1816 - val_loss: 27.8139
Epoch 261/8000

Epoch 00261: val_loss did not improve from 23.93777
 - 279s - loss: 31.1606 - val_loss: 27.1750
Epoch 262/8000

Epoch 00262: val_loss did not improve from 23.93777
 - 279s - loss: 31.1938 - val_loss: 34.3912
Epoch 263/8000

Epoch 00263: val_loss did not improve from 23.93777
 - 280s - loss: 31.2303 - val_loss: 29.0820
Epoch 264/8000

Epoch 00264: val_loss did not improve from 23.93777
 - 280s - loss: 31.2364 - val_loss: 26.2875
Epoch 265/8000

Epoch 00265: val_loss did not improve from 23.93777
 - 280s - loss: 31.1471 - val_loss: 32.7369
Epoch 266/8000

Epoch 00266: val_loss did not improve from 23.93777
 - 279s - loss: 31.2981 - val_loss: 28.0832
Epoch 267/8000

Epoch 00267: val_loss did not improve from 23.93777
 - 284s - loss: 31.0926 - val_loss: 27.0930
Epoch 268/8000

Epoch 00268: val_loss did not improve from 23.93777
 - 278s - loss: 31.2017 - val_loss: 34.3719
Epoch 269/8000

Epoch 00269: val_loss did not improve from 23.93777
 - 279s - loss: 31.2544 - val_loss: 29.2639
Epoch 270/8000

Epoch 00270: val_loss did not improve from 23.93777
 - 280s - loss: 31.2045 - val_loss: 26.1719
Epoch 271/8000

Epoch 00271: val_loss did not improve from 23.93777
 - 280s - loss: 31.1072 - val_loss: 32.9328
Epoch 272/8000

Epoch 00272: val_loss did not improve from 23.93777
 - 279s - loss: 31.2536 - val_loss: 27.9303
Epoch 273/8000

Epoch 00273: val_loss did not improve from 23.93777
 - 278s - loss: 31.2522 - val_loss: 27.1326
Epoch 274/8000

Epoch 00274: val_loss did not improve from 23.93777
 - 281s - loss: 31.2270 - val_loss: 34.4489
Epoch 275/8000

Epoch 00275: val_loss did not improve from 23.93777
 - 280s - loss: 31.1738 - val_loss: 29.1884
Epoch 276/8000

Epoch 00276: val_loss did not improve from 23.93777
 - 280s - loss: 31.1569 - val_loss: 26.2609
Epoch 00276: early stopping
