2020-01-30 14:46:03.393653: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-30 14:46:03.528058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-30 14:46:03.528653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.73GiB
2020-01-30 14:46:03.528671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-01-30 14:46:03.761726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-30 14:46:03.761769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-01-30 14:46:03.761778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-01-30 14:46:03.762027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11346 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-01-30 14:46:04.028713: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x563068a876e0
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 43.03623, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 15s - loss: 45.5071 - val_loss: 43.0362
Epoch 2/8000

Epoch 00002: val_loss improved from 43.03623 to 30.09504, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 34.9062 - val_loss: 30.0950
Epoch 3/8000

Epoch 00003: val_loss improved from 30.09504 to 25.60821, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 26.3236 - val_loss: 25.6082
Epoch 4/8000

Epoch 00004: val_loss improved from 25.60821 to 24.88964, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 24.2135 - val_loss: 24.8896
Epoch 5/8000

Epoch 00005: val_loss improved from 24.88964 to 24.72336, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 23.8125 - val_loss: 24.7234
Epoch 6/8000

Epoch 00006: val_loss improved from 24.72336 to 24.34774, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 23.5520 - val_loss: 24.3477
Epoch 7/8000

Epoch 00007: val_loss improved from 24.34774 to 24.02550, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 23.2558 - val_loss: 24.0255
Epoch 8/8000

Epoch 00008: val_loss improved from 24.02550 to 23.31042, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 22.6619 - val_loss: 23.3104
Epoch 9/8000

Epoch 00009: val_loss improved from 23.31042 to 22.12742, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 21.5903 - val_loss: 22.1274
Epoch 10/8000

Epoch 00010: val_loss improved from 22.12742 to 21.37487, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 20.7096 - val_loss: 21.3749
Epoch 11/8000

Epoch 00011: val_loss improved from 21.37487 to 20.92523, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 20.1990 - val_loss: 20.9252
Epoch 12/8000

Epoch 00012: val_loss improved from 20.92523 to 20.49728, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 19.9298 - val_loss: 20.4973
Epoch 13/8000

Epoch 00013: val_loss did not improve from 20.49728
 - 12s - loss: 19.6408 - val_loss: 20.5153
Epoch 14/8000

Epoch 00014: val_loss improved from 20.49728 to 19.69573, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 19.3716 - val_loss: 19.6957
Epoch 15/8000

Epoch 00015: val_loss improved from 19.69573 to 19.43891, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 19.1647 - val_loss: 19.4389
Epoch 16/8000

Epoch 00016: val_loss improved from 19.43891 to 19.20213, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 18.8050 - val_loss: 19.2021
Epoch 17/8000

Epoch 00017: val_loss improved from 19.20213 to 19.08867, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 18.6472 - val_loss: 19.0887
Epoch 18/8000

Epoch 00018: val_loss did not improve from 19.08867
 - 12s - loss: 18.3749 - val_loss: 19.4297
Epoch 19/8000

Epoch 00019: val_loss improved from 19.08867 to 18.73590, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 18.2195 - val_loss: 18.7359
Epoch 20/8000

Epoch 00020: val_loss did not improve from 18.73590
 - 12s - loss: 18.2811 - val_loss: 19.2339
Epoch 21/8000

Epoch 00021: val_loss improved from 18.73590 to 18.59266, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 18.2226 - val_loss: 18.5927
Epoch 22/8000

Epoch 00022: val_loss did not improve from 18.59266
 - 12s - loss: 18.0631 - val_loss: 18.9254
Epoch 23/8000

Epoch 00023: val_loss improved from 18.59266 to 18.29775, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 17.9076 - val_loss: 18.2977
Epoch 24/8000

Epoch 00024: val_loss improved from 18.29775 to 18.22379, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 17.7773 - val_loss: 18.2238
Epoch 25/8000

Epoch 00025: val_loss did not improve from 18.22379
 - 12s - loss: 17.6809 - val_loss: 18.7569
Epoch 26/8000

Epoch 00026: val_loss improved from 18.22379 to 17.94656, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 17.6707 - val_loss: 17.9466
Epoch 27/8000

Epoch 00027: val_loss did not improve from 17.94656
 - 12s - loss: 17.5385 - val_loss: 18.3808
Epoch 28/8000

Epoch 00028: val_loss improved from 17.94656 to 17.78536, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 17.4757 - val_loss: 17.7854
Epoch 29/8000

Epoch 00029: val_loss did not improve from 17.78536
 - 12s - loss: 17.6327 - val_loss: 17.7890
Epoch 30/8000

Epoch 00030: val_loss improved from 17.78536 to 17.49252, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 17.2235 - val_loss: 17.4925
Epoch 31/8000

Epoch 00031: val_loss improved from 17.49252 to 17.45865, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 17.0624 - val_loss: 17.4586
Epoch 32/8000

Epoch 00032: val_loss did not improve from 17.45865
 - 12s - loss: 17.2084 - val_loss: 18.1006
Epoch 33/8000

Epoch 00033: val_loss did not improve from 17.45865
 - 12s - loss: 16.9750 - val_loss: 17.8964
Epoch 34/8000

Epoch 00034: val_loss did not improve from 17.45865
 - 12s - loss: 17.3138 - val_loss: 17.6615
Epoch 35/8000

Epoch 00035: val_loss improved from 17.45865 to 17.40395, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 16.9966 - val_loss: 17.4039
Epoch 36/8000

Epoch 00036: val_loss improved from 17.40395 to 17.34679, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 17.0062 - val_loss: 17.3468
Epoch 37/8000

Epoch 00037: val_loss did not improve from 17.34679
 - 12s - loss: 16.7439 - val_loss: 17.7699
Epoch 38/8000

Epoch 00038: val_loss did not improve from 17.34679
 - 12s - loss: 16.9427 - val_loss: 17.4657
Epoch 39/8000

Epoch 00039: val_loss improved from 17.34679 to 17.10340, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 16.7176 - val_loss: 17.1034
Epoch 40/8000

Epoch 00040: val_loss did not improve from 17.10340
 - 12s - loss: 16.6834 - val_loss: 17.3984
Epoch 41/8000

Epoch 00041: val_loss improved from 17.10340 to 16.80834, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 16.7503 - val_loss: 16.8083
Epoch 42/8000

Epoch 00042: val_loss did not improve from 16.80834
 - 12s - loss: 16.6133 - val_loss: 17.6303
Epoch 43/8000

Epoch 00043: val_loss did not improve from 16.80834
 - 12s - loss: 16.7869 - val_loss: 16.8940
Epoch 44/8000

Epoch 00044: val_loss did not improve from 16.80834
 - 12s - loss: 16.6450 - val_loss: 17.4985
Epoch 45/8000

Epoch 00045: val_loss did not improve from 16.80834
 - 12s - loss: 16.9176 - val_loss: 16.9803
Epoch 46/8000

Epoch 00046: val_loss did not improve from 16.80834
 - 12s - loss: 16.5711 - val_loss: 17.1315
Epoch 47/8000

Epoch 00047: val_loss improved from 16.80834 to 16.34430, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 16.5197 - val_loss: 16.3443
Epoch 48/8000

Epoch 00048: val_loss did not improve from 16.34430
 - 12s - loss: 16.5007 - val_loss: 16.9495
Epoch 49/8000

Epoch 00049: val_loss did not improve from 16.34430
 - 12s - loss: 16.4079 - val_loss: 16.4588
Epoch 50/8000

Epoch 00050: val_loss improved from 16.34430 to 16.23727, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 16.1419 - val_loss: 16.2373
Epoch 51/8000

Epoch 00051: val_loss did not improve from 16.23727
 - 12s - loss: 16.1762 - val_loss: 16.3221
Epoch 52/8000

Epoch 00052: val_loss did not improve from 16.23727
 - 12s - loss: 16.1008 - val_loss: 16.6758
Epoch 53/8000

Epoch 00053: val_loss improved from 16.23727 to 16.15956, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 16.0313 - val_loss: 16.1596
Epoch 54/8000

Epoch 00054: val_loss did not improve from 16.15956
 - 12s - loss: 15.9691 - val_loss: 16.2018
Epoch 55/8000

Epoch 00055: val_loss did not improve from 16.15956
 - 12s - loss: 15.8916 - val_loss: 16.2205
Epoch 56/8000

Epoch 00056: val_loss did not improve from 16.15956
 - 12s - loss: 15.8881 - val_loss: 16.2696
Epoch 57/8000

Epoch 00057: val_loss did not improve from 16.15956
 - 12s - loss: 15.7633 - val_loss: 17.5281
Epoch 58/8000

Epoch 00058: val_loss improved from 16.15956 to 15.73609, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 15.7272 - val_loss: 15.7361
Epoch 59/8000

Epoch 00059: val_loss did not improve from 15.73609
 - 12s - loss: 15.6953 - val_loss: 16.0286
Epoch 60/8000

Epoch 00060: val_loss did not improve from 15.73609
 - 12s - loss: 15.8067 - val_loss: 16.0563
Epoch 61/8000

Epoch 00061: val_loss did not improve from 15.73609
 - 12s - loss: 15.7035 - val_loss: 16.1193
Epoch 62/8000

Epoch 00062: val_loss did not improve from 15.73609
 - 12s - loss: 15.6884 - val_loss: 15.8121
Epoch 63/8000

Epoch 00063: val_loss did not improve from 15.73609
 - 12s - loss: 15.5942 - val_loss: 15.9620
Epoch 64/8000

Epoch 00064: val_loss did not improve from 15.73609
 - 12s - loss: 15.6170 - val_loss: 16.6153
Epoch 65/8000

Epoch 00065: val_loss did not improve from 15.73609
 - 12s - loss: 15.6083 - val_loss: 15.8311
Epoch 66/8000

Epoch 00066: val_loss improved from 15.73609 to 15.64675, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 15.5206 - val_loss: 15.6467
Epoch 67/8000

Epoch 00067: val_loss did not improve from 15.64675
 - 12s - loss: 15.5229 - val_loss: 15.8194
Epoch 68/8000

Epoch 00068: val_loss did not improve from 15.64675
 - 12s - loss: 15.5290 - val_loss: 15.7973
Epoch 69/8000

Epoch 00069: val_loss did not improve from 15.64675
 - 12s - loss: 15.4450 - val_loss: 15.9667
Epoch 70/8000

Epoch 00070: val_loss did not improve from 15.64675
 - 12s - loss: 15.4808 - val_loss: 15.7891
Epoch 71/8000

Epoch 00071: val_loss did not improve from 15.64675
 - 12s - loss: 15.4264 - val_loss: 15.9305
Epoch 72/8000

Epoch 00072: val_loss improved from 15.64675 to 15.49887, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 15.4029 - val_loss: 15.4989
Epoch 73/8000

Epoch 00073: val_loss did not improve from 15.49887
 - 12s - loss: 15.3671 - val_loss: 15.8920
Epoch 74/8000

Epoch 00074: val_loss did not improve from 15.49887
 - 12s - loss: 15.3572 - val_loss: 15.6100
Epoch 75/8000

Epoch 00075: val_loss did not improve from 15.49887
 - 12s - loss: 15.3571 - val_loss: 16.6241
Epoch 76/8000

Epoch 00076: val_loss did not improve from 15.49887
 - 12s - loss: 15.3654 - val_loss: 15.5723
Epoch 77/8000

Epoch 00077: val_loss did not improve from 15.49887
 - 12s - loss: 15.3013 - val_loss: 16.7153
Epoch 78/8000

Epoch 00078: val_loss improved from 15.49887 to 15.27223, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 15.4086 - val_loss: 15.2722
Epoch 79/8000

Epoch 00079: val_loss did not improve from 15.27223
 - 12s - loss: 15.2389 - val_loss: 15.3343
Epoch 80/8000

Epoch 00080: val_loss did not improve from 15.27223
 - 12s - loss: 15.2392 - val_loss: 16.1355
Epoch 81/8000

Epoch 00081: val_loss did not improve from 15.27223
 - 12s - loss: 15.2210 - val_loss: 16.2033
Epoch 82/8000

Epoch 00082: val_loss did not improve from 15.27223
 - 12s - loss: 15.3027 - val_loss: 15.5546
Epoch 83/8000

Epoch 00083: val_loss did not improve from 15.27223
 - 12s - loss: 15.1930 - val_loss: 15.6946
Epoch 84/8000

Epoch 00084: val_loss did not improve from 15.27223
 - 12s - loss: 15.2091 - val_loss: 15.8687
Epoch 85/8000

Epoch 00085: val_loss did not improve from 15.27223
 - 12s - loss: 15.1552 - val_loss: 15.6798
Epoch 86/8000

Epoch 00086: val_loss did not improve from 15.27223
 - 12s - loss: 15.1309 - val_loss: 15.2980
Epoch 87/8000

Epoch 00087: val_loss did not improve from 15.27223
 - 12s - loss: 15.1264 - val_loss: 15.7888
Epoch 88/8000

Epoch 00088: val_loss did not improve from 15.27223
 - 12s - loss: 15.1543 - val_loss: 15.4681
Epoch 89/8000

Epoch 00089: val_loss did not improve from 15.27223
 - 12s - loss: 14.9913 - val_loss: 15.5705
Epoch 90/8000

Epoch 00090: val_loss did not improve from 15.27223
 - 12s - loss: 15.0084 - val_loss: 16.6449
Epoch 91/8000

Epoch 00091: val_loss did not improve from 15.27223
 - 12s - loss: 15.0177 - val_loss: 15.8625
Epoch 92/8000

Epoch 00092: val_loss did not improve from 15.27223
 - 12s - loss: 15.1433 - val_loss: 15.7507
Epoch 93/8000

Epoch 00093: val_loss did not improve from 15.27223
 - 12s - loss: 15.0012 - val_loss: 15.8948
Epoch 94/8000

Epoch 00094: val_loss did not improve from 15.27223
 - 12s - loss: 15.0299 - val_loss: 15.2854
Epoch 95/8000

Epoch 00095: val_loss did not improve from 15.27223
 - 12s - loss: 15.0098 - val_loss: 15.3167
Epoch 96/8000

Epoch 00096: val_loss improved from 15.27223 to 15.18139, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 15.0520 - val_loss: 15.1814
Epoch 97/8000

Epoch 00097: val_loss did not improve from 15.18139
 - 12s - loss: 14.9363 - val_loss: 15.3062
Epoch 98/8000

Epoch 00098: val_loss improved from 15.18139 to 14.99978, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 15.0372 - val_loss: 14.9998
Epoch 99/8000

Epoch 00099: val_loss improved from 14.99978 to 14.96640, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.9064 - val_loss: 14.9664
Epoch 100/8000

Epoch 00100: val_loss did not improve from 14.96640
 - 12s - loss: 15.0989 - val_loss: 15.2683
Epoch 101/8000

Epoch 00101: val_loss did not improve from 14.96640
 - 12s - loss: 14.9067 - val_loss: 15.2780
Epoch 102/8000

Epoch 00102: val_loss did not improve from 14.96640
 - 12s - loss: 14.8676 - val_loss: 15.0210
Epoch 103/8000

Epoch 00103: val_loss did not improve from 14.96640
 - 12s - loss: 14.7998 - val_loss: 15.4273
Epoch 104/8000

Epoch 00104: val_loss improved from 14.96640 to 14.93329, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.7169 - val_loss: 14.9333
Epoch 105/8000

Epoch 00105: val_loss did not improve from 14.93329
 - 12s - loss: 14.8278 - val_loss: 15.2493
Epoch 106/8000

Epoch 00106: val_loss did not improve from 14.93329
 - 12s - loss: 14.7984 - val_loss: 15.4192
Epoch 107/8000

Epoch 00107: val_loss did not improve from 14.93329
 - 12s - loss: 14.7745 - val_loss: 15.3179
Epoch 108/8000

Epoch 00108: val_loss did not improve from 14.93329
 - 12s - loss: 14.8441 - val_loss: 15.3613
Epoch 109/8000

Epoch 00109: val_loss did not improve from 14.93329
 - 12s - loss: 14.8283 - val_loss: 15.0024
Epoch 110/8000

Epoch 00110: val_loss did not improve from 14.93329
 - 12s - loss: 14.8109 - val_loss: 15.2648
Epoch 111/8000

Epoch 00111: val_loss improved from 14.93329 to 14.82560, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.7357 - val_loss: 14.8256
Epoch 112/8000

Epoch 00112: val_loss did not improve from 14.82560
 - 12s - loss: 14.6905 - val_loss: 14.8368
Epoch 113/8000

Epoch 00113: val_loss improved from 14.82560 to 14.79919, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.7367 - val_loss: 14.7992
Epoch 114/8000

Epoch 00114: val_loss did not improve from 14.79919
 - 12s - loss: 14.7270 - val_loss: 15.6648
Epoch 115/8000

Epoch 00115: val_loss improved from 14.79919 to 14.63204, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.7464 - val_loss: 14.6320
Epoch 116/8000

Epoch 00116: val_loss did not improve from 14.63204
 - 12s - loss: 14.6860 - val_loss: 15.1680
Epoch 117/8000

Epoch 00117: val_loss did not improve from 14.63204
 - 12s - loss: 14.7184 - val_loss: 14.6932
Epoch 118/8000

Epoch 00118: val_loss did not improve from 14.63204
 - 12s - loss: 14.6247 - val_loss: 15.2867
Epoch 119/8000

Epoch 00119: val_loss did not improve from 14.63204
 - 12s - loss: 14.5876 - val_loss: 15.0324
Epoch 120/8000

Epoch 00120: val_loss did not improve from 14.63204
 - 12s - loss: 14.6044 - val_loss: 14.7586
Epoch 121/8000

Epoch 00121: val_loss did not improve from 14.63204
 - 12s - loss: 14.6016 - val_loss: 15.2070
Epoch 122/8000

Epoch 00122: val_loss did not improve from 14.63204
 - 12s - loss: 14.5988 - val_loss: 15.0635
Epoch 123/8000

Epoch 00123: val_loss did not improve from 14.63204
 - 12s - loss: 14.5018 - val_loss: 15.2562
Epoch 124/8000

Epoch 00124: val_loss did not improve from 14.63204
 - 12s - loss: 14.5188 - val_loss: 15.2635
Epoch 125/8000

Epoch 00125: val_loss did not improve from 14.63204
 - 12s - loss: 14.5618 - val_loss: 14.9342
Epoch 126/8000

Epoch 00126: val_loss improved from 14.63204 to 14.62224, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.5079 - val_loss: 14.6222
Epoch 127/8000

Epoch 00127: val_loss did not improve from 14.62224
 - 12s - loss: 14.5475 - val_loss: 15.3581
Epoch 128/8000

Epoch 00128: val_loss improved from 14.62224 to 14.46584, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.4825 - val_loss: 14.4658
Epoch 129/8000

Epoch 00129: val_loss did not improve from 14.46584
 - 12s - loss: 14.2885 - val_loss: 15.5909
Epoch 130/8000

Epoch 00130: val_loss did not improve from 14.46584
 - 12s - loss: 14.4067 - val_loss: 14.8482
Epoch 131/8000

Epoch 00131: val_loss did not improve from 14.46584
 - 12s - loss: 14.5633 - val_loss: 14.7638
Epoch 132/8000

Epoch 00132: val_loss did not improve from 14.46584
 - 12s - loss: 14.3812 - val_loss: 14.5290
Epoch 133/8000

Epoch 00133: val_loss did not improve from 14.46584
 - 12s - loss: 14.3462 - val_loss: 14.8072
Epoch 134/8000

Epoch 00134: val_loss improved from 14.46584 to 14.18591, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.3254 - val_loss: 14.1859
Epoch 135/8000

Epoch 00135: val_loss did not improve from 14.18591
 - 12s - loss: 14.3489 - val_loss: 14.5449
Epoch 136/8000

Epoch 00136: val_loss did not improve from 14.18591
 - 12s - loss: 14.5219 - val_loss: 16.9599
Epoch 137/8000

Epoch 00137: val_loss did not improve from 14.18591
 - 12s - loss: 14.4355 - val_loss: 14.2322
Epoch 138/8000

Epoch 00138: val_loss did not improve from 14.18591
 - 12s - loss: 14.3244 - val_loss: 14.9858
Epoch 139/8000

Epoch 00139: val_loss did not improve from 14.18591
 - 12s - loss: 14.2866 - val_loss: 14.8701
Epoch 140/8000

Epoch 00140: val_loss improved from 14.18591 to 14.08021, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.2142 - val_loss: 14.0802
Epoch 141/8000

Epoch 00141: val_loss did not improve from 14.08021
 - 12s - loss: 14.1951 - val_loss: 14.1409
Epoch 142/8000

Epoch 00142: val_loss did not improve from 14.08021
 - 12s - loss: 14.2191 - val_loss: 14.7513
Epoch 143/8000

Epoch 00143: val_loss did not improve from 14.08021
 - 12s - loss: 14.1513 - val_loss: 14.4390
Epoch 144/8000

Epoch 00144: val_loss did not improve from 14.08021
 - 12s - loss: 14.0974 - val_loss: 14.2518
Epoch 145/8000

Epoch 00145: val_loss did not improve from 14.08021
 - 12s - loss: 14.1372 - val_loss: 14.6157
Epoch 146/8000

Epoch 00146: val_loss improved from 14.08021 to 14.02190, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.1003 - val_loss: 14.0219
Epoch 147/8000

Epoch 00147: val_loss did not improve from 14.02190
 - 12s - loss: 14.0869 - val_loss: 14.2400
Epoch 148/8000

Epoch 00148: val_loss did not improve from 14.02190
 - 12s - loss: 14.1287 - val_loss: 14.2728
Epoch 149/8000

Epoch 00149: val_loss did not improve from 14.02190
 - 12s - loss: 14.1803 - val_loss: 14.2300
Epoch 150/8000

Epoch 00150: val_loss did not improve from 14.02190
 - 12s - loss: 14.1254 - val_loss: 14.2320
Epoch 151/8000

Epoch 00151: val_loss did not improve from 14.02190
 - 12s - loss: 14.0868 - val_loss: 14.0600
Epoch 152/8000

Epoch 00152: val_loss did not improve from 14.02190
 - 12s - loss: 14.0567 - val_loss: 14.1855
Epoch 153/8000

Epoch 00153: val_loss did not improve from 14.02190
 - 12s - loss: 14.0444 - val_loss: 14.5017
Epoch 154/8000

Epoch 00154: val_loss did not improve from 14.02190
 - 12s - loss: 13.9105 - val_loss: 14.6488
Epoch 155/8000

Epoch 00155: val_loss improved from 14.02190 to 13.89378, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 14.0610 - val_loss: 13.8938
Epoch 156/8000

Epoch 00156: val_loss did not improve from 13.89378
 - 12s - loss: 13.9738 - val_loss: 14.4907
Epoch 157/8000

Epoch 00157: val_loss did not improve from 13.89378
 - 12s - loss: 14.1218 - val_loss: 14.3623
Epoch 158/8000

Epoch 00158: val_loss did not improve from 13.89378
 - 12s - loss: 13.9879 - val_loss: 14.4021
Epoch 159/8000

Epoch 00159: val_loss did not improve from 13.89378
 - 12s - loss: 13.9898 - val_loss: 14.5738
Epoch 160/8000

Epoch 00160: val_loss did not improve from 13.89378
 - 12s - loss: 13.9145 - val_loss: 13.9707
Epoch 161/8000

Epoch 00161: val_loss did not improve from 13.89378
 - 12s - loss: 13.8805 - val_loss: 13.9533
Epoch 162/8000

Epoch 00162: val_loss did not improve from 13.89378
 - 12s - loss: 13.8694 - val_loss: 13.9259
Epoch 163/8000

Epoch 00163: val_loss did not improve from 13.89378
 - 12s - loss: 13.9499 - val_loss: 14.4960
Epoch 164/8000

Epoch 00164: val_loss did not improve from 13.89378
 - 12s - loss: 13.8019 - val_loss: 13.9520
Epoch 165/8000

Epoch 00165: val_loss did not improve from 13.89378
 - 12s - loss: 13.7504 - val_loss: 14.0097
Epoch 166/8000

Epoch 00166: val_loss improved from 13.89378 to 13.67819, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 13.8865 - val_loss: 13.6782
Epoch 167/8000

Epoch 00167: val_loss did not improve from 13.67819
 - 12s - loss: 13.8219 - val_loss: 14.1185
Epoch 168/8000

Epoch 00168: val_loss did not improve from 13.67819
 - 12s - loss: 13.8004 - val_loss: 14.0888
Epoch 169/8000

Epoch 00169: val_loss did not improve from 13.67819
 - 12s - loss: 13.7773 - val_loss: 14.6660
Epoch 170/8000

Epoch 00170: val_loss did not improve from 13.67819
 - 12s - loss: 13.7963 - val_loss: 13.8015
Epoch 171/8000

Epoch 00171: val_loss did not improve from 13.67819
 - 12s - loss: 13.7187 - val_loss: 13.7475
Epoch 172/8000

Epoch 00172: val_loss did not improve from 13.67819
 - 12s - loss: 13.7041 - val_loss: 14.0396
Epoch 173/8000

Epoch 00173: val_loss did not improve from 13.67819
 - 12s - loss: 13.7527 - val_loss: 13.8130
Epoch 174/8000

Epoch 00174: val_loss did not improve from 13.67819
 - 12s - loss: 13.7429 - val_loss: 13.7225
Epoch 175/8000

Epoch 00175: val_loss did not improve from 13.67819
 - 12s - loss: 13.6393 - val_loss: 14.8223
Epoch 176/8000

Epoch 00176: val_loss did not improve from 13.67819
 - 12s - loss: 13.7940 - val_loss: 13.8924
Epoch 177/8000

Epoch 00177: val_loss did not improve from 13.67819
 - 12s - loss: 13.6904 - val_loss: 14.5818
Epoch 178/8000

Epoch 00178: val_loss did not improve from 13.67819
 - 12s - loss: 13.6323 - val_loss: 14.4162
Epoch 179/8000

Epoch 00179: val_loss did not improve from 13.67819
 - 12s - loss: 13.6782 - val_loss: 13.7735
Epoch 180/8000

Epoch 00180: val_loss did not improve from 13.67819
 - 12s - loss: 13.6076 - val_loss: 13.8306
Epoch 181/8000

Epoch 00181: val_loss did not improve from 13.67819
 - 12s - loss: 13.5351 - val_loss: 14.4170
Epoch 182/8000

Epoch 00182: val_loss did not improve from 13.67819
 - 12s - loss: 13.6285 - val_loss: 14.1272
Epoch 183/8000

Epoch 00183: val_loss did not improve from 13.67819
 - 12s - loss: 13.6181 - val_loss: 13.9854
Epoch 184/8000

Epoch 00184: val_loss improved from 13.67819 to 13.65238, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 13.5922 - val_loss: 13.6524
Epoch 185/8000

Epoch 00185: val_loss did not improve from 13.65238
 - 12s - loss: 13.6041 - val_loss: 13.6844
Epoch 186/8000

Epoch 00186: val_loss did not improve from 13.65238
 - 12s - loss: 13.5821 - val_loss: 13.8223
Epoch 187/8000

Epoch 00187: val_loss did not improve from 13.65238
 - 12s - loss: 13.5014 - val_loss: 14.0304
Epoch 188/8000

Epoch 00188: val_loss did not improve from 13.65238
 - 12s - loss: 13.5596 - val_loss: 13.8958
Epoch 189/8000

Epoch 00189: val_loss improved from 13.65238 to 13.50299, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 13.4994 - val_loss: 13.5030
Epoch 190/8000

Epoch 00190: val_loss did not improve from 13.50299
 - 12s - loss: 13.5074 - val_loss: 14.0667
Epoch 191/8000

Epoch 00191: val_loss did not improve from 13.50299
 - 12s - loss: 13.4928 - val_loss: 13.8141
Epoch 192/8000

Epoch 00192: val_loss did not improve from 13.50299
 - 12s - loss: 13.4895 - val_loss: 13.5675
Epoch 193/8000

Epoch 00193: val_loss improved from 13.50299 to 13.46552, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 13.3723 - val_loss: 13.4655
Epoch 194/8000

Epoch 00194: val_loss did not improve from 13.46552
 - 12s - loss: 13.4003 - val_loss: 13.6995
Epoch 195/8000

Epoch 00195: val_loss did not improve from 13.46552
 - 12s - loss: 13.5114 - val_loss: 14.2037
Epoch 196/8000

Epoch 00196: val_loss did not improve from 13.46552
 - 12s - loss: 13.4711 - val_loss: 13.9713
Epoch 197/8000

Epoch 00197: val_loss did not improve from 13.46552
 - 12s - loss: 13.4344 - val_loss: 13.8826
Epoch 198/8000

Epoch 00198: val_loss did not improve from 13.46552
 - 12s - loss: 13.4897 - val_loss: 13.9835
Epoch 199/8000

Epoch 00199: val_loss did not improve from 13.46552
 - 12s - loss: 13.5185 - val_loss: 13.7437
Epoch 200/8000

Epoch 00200: val_loss did not improve from 13.46552
 - 12s - loss: 13.4976 - val_loss: 13.6548
Epoch 201/8000

Epoch 00201: val_loss did not improve from 13.46552
 - 12s - loss: 13.4646 - val_loss: 13.5265
Epoch 202/8000

Epoch 00202: val_loss did not improve from 13.46552
 - 12s - loss: 13.4394 - val_loss: 13.7745
Epoch 203/8000

Epoch 00203: val_loss did not improve from 13.46552
 - 12s - loss: 13.3808 - val_loss: 13.4684
Epoch 204/8000

Epoch 00204: val_loss did not improve from 13.46552
 - 12s - loss: 13.4420 - val_loss: 13.6996
Epoch 205/8000

Epoch 00205: val_loss did not improve from 13.46552
 - 12s - loss: 13.4960 - val_loss: 14.0194
Epoch 206/8000

Epoch 00206: val_loss did not improve from 13.46552
 - 12s - loss: 13.4517 - val_loss: 14.2396
Epoch 207/8000

Epoch 00207: val_loss did not improve from 13.46552
 - 12s - loss: 13.4537 - val_loss: 13.8135
Epoch 208/8000

Epoch 00208: val_loss did not improve from 13.46552
 - 12s - loss: 13.4089 - val_loss: 14.0737
Epoch 209/8000

Epoch 00209: val_loss did not improve from 13.46552
 - 12s - loss: 13.3448 - val_loss: 13.7015
Epoch 210/8000

Epoch 00210: val_loss did not improve from 13.46552
 - 12s - loss: 13.3045 - val_loss: 13.6419
Epoch 211/8000

Epoch 00211: val_loss improved from 13.46552 to 13.36897, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 13.3976 - val_loss: 13.3690
Epoch 212/8000

Epoch 00212: val_loss did not improve from 13.36897
 - 12s - loss: 13.3559 - val_loss: 13.7331
Epoch 213/8000

Epoch 00213: val_loss did not improve from 13.36897
 - 12s - loss: 13.2671 - val_loss: 13.6782
Epoch 214/8000

Epoch 00214: val_loss did not improve from 13.36897
 - 12s - loss: 13.3395 - val_loss: 13.5631
Epoch 215/8000

Epoch 00215: val_loss did not improve from 13.36897
 - 12s - loss: 13.5278 - val_loss: 13.5272
Epoch 216/8000

Epoch 00216: val_loss did not improve from 13.36897
 - 12s - loss: 13.4105 - val_loss: 13.8001
Epoch 217/8000

Epoch 00217: val_loss improved from 13.36897 to 13.36782, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 13.3648 - val_loss: 13.3678
Epoch 218/8000

Epoch 00218: val_loss did not improve from 13.36782
 - 12s - loss: 13.3294 - val_loss: 13.4255
Epoch 219/8000

Epoch 00219: val_loss did not improve from 13.36782
 - 12s - loss: 13.4018 - val_loss: 13.9947
Epoch 220/8000

Epoch 00220: val_loss did not improve from 13.36782
 - 12s - loss: 13.3900 - val_loss: 13.9340
Epoch 221/8000

Epoch 00221: val_loss did not improve from 13.36782
 - 12s - loss: 13.3831 - val_loss: 13.4567
Epoch 222/8000

Epoch 00222: val_loss did not improve from 13.36782
 - 12s - loss: 13.4030 - val_loss: 14.1042
Epoch 223/8000

Epoch 00223: val_loss did not improve from 13.36782
 - 12s - loss: 13.4304 - val_loss: 14.1596
Epoch 224/8000

Epoch 00224: val_loss did not improve from 13.36782
 - 12s - loss: 13.4308 - val_loss: 13.6658
Epoch 225/8000

Epoch 00225: val_loss did not improve from 13.36782
 - 12s - loss: 13.4200 - val_loss: 13.7449
Epoch 226/8000

Epoch 00226: val_loss did not improve from 13.36782
 - 12s - loss: 13.3905 - val_loss: 13.6704
Epoch 227/8000

Epoch 00227: val_loss did not improve from 13.36782
 - 12s - loss: 13.3533 - val_loss: 13.4050
Epoch 228/8000

Epoch 00228: val_loss did not improve from 13.36782
 - 12s - loss: 13.3756 - val_loss: 13.6198
Epoch 229/8000

Epoch 00229: val_loss improved from 13.36782 to 12.98292, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 13.2946 - val_loss: 12.9829
Epoch 230/8000

Epoch 00230: val_loss did not improve from 12.98292
 - 12s - loss: 13.2621 - val_loss: 13.3483
Epoch 231/8000

Epoch 00231: val_loss did not improve from 12.98292
 - 12s - loss: 13.2243 - val_loss: 13.1959
Epoch 232/8000

Epoch 00232: val_loss did not improve from 12.98292
 - 12s - loss: 13.3226 - val_loss: 13.3026
Epoch 233/8000

Epoch 00233: val_loss did not improve from 12.98292
 - 12s - loss: 13.2605 - val_loss: 13.1010
Epoch 234/8000

Epoch 00234: val_loss did not improve from 12.98292
 - 12s - loss: 13.2385 - val_loss: 13.4052
Epoch 235/8000

Epoch 00235: val_loss did not improve from 12.98292
 - 12s - loss: 13.2285 - val_loss: 13.1552
Epoch 236/8000

Epoch 00236: val_loss did not improve from 12.98292
 - 12s - loss: 13.2552 - val_loss: 13.4439
Epoch 237/8000

Epoch 00237: val_loss did not improve from 12.98292
 - 12s - loss: 13.2413 - val_loss: 13.5698
Epoch 238/8000

Epoch 00238: val_loss did not improve from 12.98292
 - 12s - loss: 13.2251 - val_loss: 13.6238
Epoch 239/8000

Epoch 00239: val_loss did not improve from 12.98292
 - 12s - loss: 13.2423 - val_loss: 13.2803
Epoch 240/8000

Epoch 00240: val_loss did not improve from 12.98292
 - 12s - loss: 13.1573 - val_loss: 13.4147
Epoch 241/8000

Epoch 00241: val_loss did not improve from 12.98292
 - 12s - loss: 13.2327 - val_loss: 13.3869
Epoch 242/8000

Epoch 00242: val_loss did not improve from 12.98292
 - 12s - loss: 13.1383 - val_loss: 13.6543
Epoch 243/8000

Epoch 00243: val_loss did not improve from 12.98292
 - 12s - loss: 13.1855 - val_loss: 13.2395
Epoch 244/8000

Epoch 00244: val_loss did not improve from 12.98292
 - 12s - loss: 13.2107 - val_loss: 13.6948
Epoch 245/8000

Epoch 00245: val_loss did not improve from 12.98292
 - 12s - loss: 13.2111 - val_loss: 13.4790
Epoch 246/8000

Epoch 00246: val_loss did not improve from 12.98292
 - 12s - loss: 13.1560 - val_loss: 13.3681
Epoch 247/8000

Epoch 00247: val_loss did not improve from 12.98292
 - 12s - loss: 13.1979 - val_loss: 13.2586
Epoch 248/8000

Epoch 00248: val_loss did not improve from 12.98292
 - 12s - loss: 13.0921 - val_loss: 13.4779
Epoch 249/8000

Epoch 00249: val_loss did not improve from 12.98292
 - 12s - loss: 13.1228 - val_loss: 13.4463
Epoch 250/8000

Epoch 00250: val_loss did not improve from 12.98292
 - 12s - loss: 13.1408 - val_loss: 13.5081
Epoch 251/8000

Epoch 00251: val_loss did not improve from 12.98292
 - 12s - loss: 13.1503 - val_loss: 13.3837
Epoch 252/8000

Epoch 00252: val_loss did not improve from 12.98292
 - 12s - loss: 13.1871 - val_loss: 13.2594
Epoch 253/8000

Epoch 00253: val_loss did not improve from 12.98292
 - 12s - loss: 13.2667 - val_loss: 13.3294
Epoch 254/8000

Epoch 00254: val_loss did not improve from 12.98292
 - 12s - loss: 13.2424 - val_loss: 13.5018
Epoch 255/8000

Epoch 00255: val_loss did not improve from 12.98292
 - 12s - loss: 13.2307 - val_loss: 13.6040
Epoch 256/8000

Epoch 00256: val_loss did not improve from 12.98292
 - 12s - loss: 13.2207 - val_loss: 13.6358
Epoch 257/8000

Epoch 00257: val_loss did not improve from 12.98292
 - 12s - loss: 13.2183 - val_loss: 13.4421
Epoch 258/8000

Epoch 00258: val_loss did not improve from 12.98292
 - 12s - loss: 13.1969 - val_loss: 13.5644
Epoch 259/8000

Epoch 00259: val_loss did not improve from 12.98292
 - 12s - loss: 13.1348 - val_loss: 13.3024
Epoch 260/8000

Epoch 00260: val_loss did not improve from 12.98292
 - 12s - loss: 13.2932 - val_loss: 13.2513
Epoch 261/8000

Epoch 00261: val_loss did not improve from 12.98292
 - 12s - loss: 13.1687 - val_loss: 13.2459
Epoch 262/8000

Epoch 00262: val_loss did not improve from 12.98292
 - 12s - loss: 13.1758 - val_loss: 13.1890
Epoch 263/8000

Epoch 00263: val_loss did not improve from 12.98292
 - 12s - loss: 13.1780 - val_loss: 13.0726
Epoch 264/8000

Epoch 00264: val_loss did not improve from 12.98292
 - 12s - loss: 13.2955 - val_loss: 13.4394
Epoch 265/8000

Epoch 00265: val_loss did not improve from 12.98292
 - 12s - loss: 13.2070 - val_loss: 13.6615
Epoch 266/8000

Epoch 00266: val_loss did not improve from 12.98292
 - 12s - loss: 13.2964 - val_loss: 13.8157
Epoch 267/8000

Epoch 00267: val_loss did not improve from 12.98292
 - 12s - loss: 13.2671 - val_loss: 13.5874
Epoch 268/8000

Epoch 00268: val_loss did not improve from 12.98292
 - 12s - loss: 13.2812 - val_loss: 13.6286
Epoch 269/8000

Epoch 00269: val_loss did not improve from 12.98292
 - 12s - loss: 13.1156 - val_loss: 13.8088
Epoch 270/8000

Epoch 00270: val_loss did not improve from 12.98292
 - 12s - loss: 13.1750 - val_loss: 13.5361
Epoch 271/8000

Epoch 00271: val_loss did not improve from 12.98292
 - 12s - loss: 13.2207 - val_loss: 14.2811
Epoch 272/8000

Epoch 00272: val_loss did not improve from 12.98292
 - 12s - loss: 13.2283 - val_loss: 13.2409
Epoch 273/8000

Epoch 00273: val_loss did not improve from 12.98292
 - 12s - loss: 13.4435 - val_loss: 13.5451
Epoch 274/8000

Epoch 00274: val_loss did not improve from 12.98292
 - 12s - loss: 13.2670 - val_loss: 13.8187
Epoch 275/8000

Epoch 00275: val_loss did not improve from 12.98292
 - 12s - loss: 13.3961 - val_loss: 13.5217
Epoch 276/8000

Epoch 00276: val_loss did not improve from 12.98292
 - 12s - loss: 13.2903 - val_loss: 13.2814
Epoch 277/8000

Epoch 00277: val_loss did not improve from 12.98292
 - 12s - loss: 13.2583 - val_loss: 13.9242
Epoch 278/8000

Epoch 00278: val_loss did not improve from 12.98292
 - 12s - loss: 13.3201 - val_loss: 13.3225
Epoch 279/8000

Epoch 00279: val_loss did not improve from 12.98292
 - 12s - loss: 13.2534 - val_loss: 13.1346
Epoch 280/8000

Epoch 00280: val_loss did not improve from 12.98292
 - 12s - loss: 13.2194 - val_loss: 13.5913
Epoch 281/8000

Epoch 00281: val_loss did not improve from 12.98292
 - 12s - loss: 13.2772 - val_loss: 13.5095
Epoch 282/8000

Epoch 00282: val_loss did not improve from 12.98292
 - 12s - loss: 13.1740 - val_loss: 13.4495
Epoch 283/8000

Epoch 00283: val_loss did not improve from 12.98292
 - 12s - loss: 13.3695 - val_loss: 13.9180
Epoch 284/8000

Epoch 00284: val_loss did not improve from 12.98292
 - 12s - loss: 13.2996 - val_loss: 13.5779
Epoch 285/8000

Epoch 00285: val_loss did not improve from 12.98292
 - 12s - loss: 13.1880 - val_loss: 13.7189
Epoch 286/8000

Epoch 00286: val_loss did not improve from 12.98292
 - 12s - loss: 13.2998 - val_loss: 13.5041
Epoch 287/8000

Epoch 00287: val_loss did not improve from 12.98292
 - 12s - loss: 13.3691 - val_loss: 13.3284
Epoch 288/8000

Epoch 00288: val_loss did not improve from 12.98292
 - 12s - loss: 13.2275 - val_loss: 13.7238
Epoch 289/8000

Epoch 00289: val_loss did not improve from 12.98292
 - 12s - loss: 13.1811 - val_loss: 13.2756
Epoch 290/8000

Epoch 00290: val_loss did not improve from 12.98292
 - 12s - loss: 13.2677 - val_loss: 13.6220
Epoch 291/8000

Epoch 00291: val_loss did not improve from 12.98292
 - 12s - loss: 13.4122 - val_loss: 13.6294
Epoch 292/8000

Epoch 00292: val_loss did not improve from 12.98292
 - 12s - loss: 13.4055 - val_loss: 13.4001
Epoch 293/8000

Epoch 00293: val_loss did not improve from 12.98292
 - 12s - loss: 13.3567 - val_loss: 14.0327
Epoch 294/8000

Epoch 00294: val_loss did not improve from 12.98292
 - 12s - loss: 13.2771 - val_loss: 13.4793
Epoch 295/8000

Epoch 00295: val_loss did not improve from 12.98292
 - 12s - loss: 13.3319 - val_loss: 14.0950
Epoch 296/8000

Epoch 00296: val_loss did not improve from 12.98292
 - 12s - loss: 13.3171 - val_loss: 13.9939
Epoch 297/8000

Epoch 00297: val_loss did not improve from 12.98292
 - 12s - loss: 13.3772 - val_loss: 13.3601
Epoch 298/8000

Epoch 00298: val_loss did not improve from 12.98292
 - 12s - loss: 13.3355 - val_loss: 13.9648
Epoch 299/8000

Epoch 00299: val_loss did not improve from 12.98292
 - 12s - loss: 13.1527 - val_loss: 14.2496
Epoch 300/8000

Epoch 00300: val_loss did not improve from 12.98292
 - 12s - loss: 13.3875 - val_loss: 13.5027
Epoch 301/8000

Epoch 00301: val_loss did not improve from 12.98292
 - 12s - loss: 13.2255 - val_loss: 13.5118
Epoch 302/8000

Epoch 00302: val_loss did not improve from 12.98292
 - 12s - loss: 13.2677 - val_loss: 13.2693
Epoch 303/8000

Epoch 00303: val_loss did not improve from 12.98292
 - 12s - loss: 13.2428 - val_loss: 13.7171
Epoch 304/8000

Epoch 00304: val_loss did not improve from 12.98292
 - 12s - loss: 13.2727 - val_loss: 13.9292
Epoch 305/8000

Epoch 00305: val_loss did not improve from 12.98292
 - 12s - loss: 13.2827 - val_loss: 13.4272
Epoch 306/8000

Epoch 00306: val_loss did not improve from 12.98292
 - 12s - loss: 13.2224 - val_loss: 13.4953
Epoch 307/8000

Epoch 00307: val_loss did not improve from 12.98292
 - 12s - loss: 13.2310 - val_loss: 14.3260
Epoch 308/8000

Epoch 00308: val_loss did not improve from 12.98292
 - 12s - loss: 13.3766 - val_loss: 13.6348
Epoch 309/8000

Epoch 00309: val_loss did not improve from 12.98292
 - 12s - loss: 13.1739 - val_loss: 13.3237
Epoch 310/8000

Epoch 00310: val_loss did not improve from 12.98292
 - 12s - loss: 13.2543 - val_loss: 13.2455
Epoch 311/8000

Epoch 00311: val_loss did not improve from 12.98292
 - 12s - loss: 13.2703 - val_loss: 13.5584
Epoch 312/8000

Epoch 00312: val_loss did not improve from 12.98292
 - 12s - loss: 13.1459 - val_loss: 13.7461
Epoch 313/8000

Epoch 00313: val_loss did not improve from 12.98292
 - 12s - loss: 13.1833 - val_loss: 13.7038
Epoch 314/8000

Epoch 00314: val_loss did not improve from 12.98292
 - 12s - loss: 13.1384 - val_loss: 13.3312
Epoch 315/8000

Epoch 00315: val_loss did not improve from 12.98292
 - 12s - loss: 13.1871 - val_loss: 13.5741
Epoch 316/8000

Epoch 00316: val_loss did not improve from 12.98292
 - 12s - loss: 13.2055 - val_loss: 13.9298
Epoch 317/8000

Epoch 00317: val_loss did not improve from 12.98292
 - 12s - loss: 13.2120 - val_loss: 13.4358
Epoch 318/8000

Epoch 00318: val_loss did not improve from 12.98292
 - 12s - loss: 13.1224 - val_loss: 13.4560
Epoch 319/8000

Epoch 00319: val_loss did not improve from 12.98292
 - 12s - loss: 13.0903 - val_loss: 13.9627
Epoch 320/8000

Epoch 00320: val_loss did not improve from 12.98292
 - 12s - loss: 13.1994 - val_loss: 13.5711
Epoch 321/8000

Epoch 00321: val_loss did not improve from 12.98292
 - 12s - loss: 13.2260 - val_loss: 13.4883
Epoch 322/8000

Epoch 00322: val_loss did not improve from 12.98292
 - 12s - loss: 13.2563 - val_loss: 13.3662
Epoch 323/8000

Epoch 00323: val_loss did not improve from 12.98292
 - 12s - loss: 13.2876 - val_loss: 13.2037
Epoch 324/8000

Epoch 00324: val_loss did not improve from 12.98292
 - 12s - loss: 13.1337 - val_loss: 13.1066
Epoch 325/8000

Epoch 00325: val_loss did not improve from 12.98292
 - 12s - loss: 13.3139 - val_loss: 13.5775
Epoch 326/8000

Epoch 00326: val_loss did not improve from 12.98292
 - 12s - loss: 13.1263 - val_loss: 13.4263
Epoch 327/8000

Epoch 00327: val_loss did not improve from 12.98292
 - 12s - loss: 13.1544 - val_loss: 13.2323
Epoch 328/8000

Epoch 00328: val_loss did not improve from 12.98292
 - 12s - loss: 13.1339 - val_loss: 12.9913
Epoch 329/8000

Epoch 00329: val_loss improved from 12.98292 to 12.91404, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 13.2109 - val_loss: 12.9140
Epoch 330/8000

Epoch 00330: val_loss did not improve from 12.91404
 - 12s - loss: 13.0955 - val_loss: 13.2907
Epoch 331/8000

Epoch 00331: val_loss did not improve from 12.91404
 - 12s - loss: 13.1486 - val_loss: 13.2944
Epoch 332/8000

Epoch 00332: val_loss did not improve from 12.91404
 - 12s - loss: 13.1287 - val_loss: 13.1241
Epoch 333/8000

Epoch 00333: val_loss did not improve from 12.91404
 - 12s - loss: 13.0434 - val_loss: 13.4170
Epoch 334/8000

Epoch 00334: val_loss did not improve from 12.91404
 - 12s - loss: 13.1598 - val_loss: 13.7618
Epoch 335/8000

Epoch 00335: val_loss did not improve from 12.91404
 - 12s - loss: 13.2528 - val_loss: 13.7689
Epoch 336/8000

Epoch 00336: val_loss did not improve from 12.91404
 - 12s - loss: 13.2246 - val_loss: 13.1820
Epoch 337/8000

Epoch 00337: val_loss did not improve from 12.91404
 - 12s - loss: 13.1882 - val_loss: 13.5298
Epoch 338/8000

Epoch 00338: val_loss did not improve from 12.91404
 - 12s - loss: 13.1918 - val_loss: 13.6612
Epoch 339/8000

Epoch 00339: val_loss did not improve from 12.91404
 - 12s - loss: 13.1773 - val_loss: 13.2459
Epoch 340/8000

Epoch 00340: val_loss did not improve from 12.91404
 - 12s - loss: 13.0966 - val_loss: 13.3894
Epoch 341/8000

Epoch 00341: val_loss did not improve from 12.91404
 - 12s - loss: 13.1581 - val_loss: 13.6563
Epoch 342/8000

Epoch 00342: val_loss did not improve from 12.91404
 - 12s - loss: 13.1947 - val_loss: 13.5430
Epoch 343/8000

Epoch 00343: val_loss did not improve from 12.91404
 - 12s - loss: 13.1792 - val_loss: 13.8315
Epoch 344/8000

Epoch 00344: val_loss did not improve from 12.91404
 - 12s - loss: 13.5686 - val_loss: 13.5439
Epoch 345/8000

Epoch 00345: val_loss did not improve from 12.91404
 - 12s - loss: 13.1254 - val_loss: 13.3041
Epoch 346/8000

Epoch 00346: val_loss did not improve from 12.91404
 - 12s - loss: 13.0841 - val_loss: 13.4132
Epoch 347/8000

Epoch 00347: val_loss did not improve from 12.91404
 - 12s - loss: 13.0780 - val_loss: 13.2538
Epoch 348/8000

Epoch 00348: val_loss did not improve from 12.91404
 - 12s - loss: 13.0579 - val_loss: 13.6314
Epoch 349/8000

Epoch 00349: val_loss did not improve from 12.91404
 - 12s - loss: 12.9310 - val_loss: 13.9122
Epoch 350/8000

Epoch 00350: val_loss did not improve from 12.91404
 - 12s - loss: 13.0826 - val_loss: 13.9699
Epoch 351/8000

Epoch 00351: val_loss did not improve from 12.91404
 - 12s - loss: 13.0916 - val_loss: 13.0230
Epoch 352/8000

Epoch 00352: val_loss did not improve from 12.91404
 - 12s - loss: 12.9146 - val_loss: 13.5502
Epoch 353/8000

Epoch 00353: val_loss did not improve from 12.91404
 - 12s - loss: 13.0880 - val_loss: 13.4650
Epoch 354/8000

Epoch 00354: val_loss improved from 12.91404 to 12.82400, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.9184 - val_loss: 12.8240
Epoch 355/8000

Epoch 00355: val_loss did not improve from 12.82400
 - 12s - loss: 13.0167 - val_loss: 13.0880
Epoch 356/8000

Epoch 00356: val_loss did not improve from 12.82400
 - 12s - loss: 12.9790 - val_loss: 13.1058
Epoch 357/8000

Epoch 00357: val_loss did not improve from 12.82400
 - 12s - loss: 12.9599 - val_loss: 13.3096
Epoch 358/8000

Epoch 00358: val_loss did not improve from 12.82400
 - 12s - loss: 13.3542 - val_loss: 13.2185
Epoch 359/8000

Epoch 00359: val_loss did not improve from 12.82400
 - 12s - loss: 12.9924 - val_loss: 13.1778
Epoch 360/8000

Epoch 00360: val_loss did not improve from 12.82400
 - 12s - loss: 12.9358 - val_loss: 13.1804
Epoch 361/8000

Epoch 00361: val_loss did not improve from 12.82400
 - 12s - loss: 13.0064 - val_loss: 13.1758
Epoch 362/8000

Epoch 00362: val_loss did not improve from 12.82400
 - 12s - loss: 12.8779 - val_loss: 13.3004
Epoch 363/8000

Epoch 00363: val_loss did not improve from 12.82400
 - 12s - loss: 13.0573 - val_loss: 13.4043
Epoch 364/8000

Epoch 00364: val_loss did not improve from 12.82400
 - 12s - loss: 13.0947 - val_loss: 13.1300
Epoch 365/8000

Epoch 00365: val_loss did not improve from 12.82400
 - 12s - loss: 13.0539 - val_loss: 13.1544
Epoch 366/8000

Epoch 00366: val_loss did not improve from 12.82400
 - 12s - loss: 13.0409 - val_loss: 13.0851
Epoch 367/8000

Epoch 00367: val_loss did not improve from 12.82400
 - 12s - loss: 13.0327 - val_loss: 12.9210
Epoch 368/8000

Epoch 00368: val_loss did not improve from 12.82400
 - 12s - loss: 12.9962 - val_loss: 13.4312
Epoch 369/8000

Epoch 00369: val_loss did not improve from 12.82400
 - 12s - loss: 13.0635 - val_loss: 13.2329
Epoch 370/8000

Epoch 00370: val_loss did not improve from 12.82400
 - 12s - loss: 13.0301 - val_loss: 13.2719
Epoch 371/8000

Epoch 00371: val_loss did not improve from 12.82400
 - 12s - loss: 13.0779 - val_loss: 13.1126
Epoch 372/8000

Epoch 00372: val_loss did not improve from 12.82400
 - 12s - loss: 13.0396 - val_loss: 13.1700
Epoch 373/8000

Epoch 00373: val_loss did not improve from 12.82400
 - 12s - loss: 13.1952 - val_loss: 13.1866
Epoch 374/8000

Epoch 00374: val_loss did not improve from 12.82400
 - 12s - loss: 12.9776 - val_loss: 13.0478
Epoch 375/8000

Epoch 00375: val_loss did not improve from 12.82400
 - 12s - loss: 13.0361 - val_loss: 13.1868
Epoch 376/8000

Epoch 00376: val_loss did not improve from 12.82400
 - 12s - loss: 12.9410 - val_loss: 13.4889
Epoch 377/8000

Epoch 00377: val_loss did not improve from 12.82400
 - 12s - loss: 13.0259 - val_loss: 13.2212
Epoch 378/8000

Epoch 00378: val_loss did not improve from 12.82400
 - 12s - loss: 12.9393 - val_loss: 13.5024
Epoch 379/8000

Epoch 00379: val_loss did not improve from 12.82400
 - 12s - loss: 12.9202 - val_loss: 13.1003
Epoch 380/8000

Epoch 00380: val_loss did not improve from 12.82400
 - 12s - loss: 12.9329 - val_loss: 13.5276
Epoch 381/8000

Epoch 00381: val_loss did not improve from 12.82400
 - 12s - loss: 13.0307 - val_loss: 13.4521
Epoch 382/8000

Epoch 00382: val_loss did not improve from 12.82400
 - 12s - loss: 13.0016 - val_loss: 13.4212
Epoch 383/8000

Epoch 00383: val_loss did not improve from 12.82400
 - 12s - loss: 12.9969 - val_loss: 13.1371
Epoch 384/8000

Epoch 00384: val_loss did not improve from 12.82400
 - 12s - loss: 12.8052 - val_loss: 13.2219
Epoch 385/8000

Epoch 00385: val_loss did not improve from 12.82400
 - 12s - loss: 12.8435 - val_loss: 12.9626
Epoch 386/8000

Epoch 00386: val_loss did not improve from 12.82400
 - 12s - loss: 12.9371 - val_loss: 13.0642
Epoch 387/8000

Epoch 00387: val_loss improved from 12.82400 to 12.79305, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.9276 - val_loss: 12.7930
Epoch 388/8000

Epoch 00388: val_loss did not improve from 12.79305
 - 12s - loss: 12.7839 - val_loss: 12.9656
Epoch 389/8000

Epoch 00389: val_loss did not improve from 12.79305
 - 12s - loss: 12.7616 - val_loss: 12.9175
Epoch 390/8000

Epoch 00390: val_loss improved from 12.79305 to 12.78877, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.7919 - val_loss: 12.7888
Epoch 391/8000

Epoch 00391: val_loss did not improve from 12.78877
 - 12s - loss: 12.8042 - val_loss: 13.3813
Epoch 392/8000

Epoch 00392: val_loss did not improve from 12.78877
 - 12s - loss: 12.7548 - val_loss: 13.2807
Epoch 393/8000

Epoch 00393: val_loss did not improve from 12.78877
 - 12s - loss: 12.8214 - val_loss: 12.9787
Epoch 394/8000

Epoch 00394: val_loss did not improve from 12.78877
 - 12s - loss: 12.8713 - val_loss: 13.0502
Epoch 395/8000

Epoch 00395: val_loss did not improve from 12.78877
 - 12s - loss: 12.7600 - val_loss: 13.0581
Epoch 396/8000

Epoch 00396: val_loss did not improve from 12.78877
 - 12s - loss: 12.8867 - val_loss: 13.2069
Epoch 397/8000

Epoch 00397: val_loss did not improve from 12.78877
 - 12s - loss: 12.6360 - val_loss: 12.9890
Epoch 398/8000

Epoch 00398: val_loss did not improve from 12.78877
 - 12s - loss: 12.8795 - val_loss: 13.3287
Epoch 399/8000

Epoch 00399: val_loss did not improve from 12.78877
 - 12s - loss: 12.8146 - val_loss: 13.1383
Epoch 400/8000

Epoch 00400: val_loss did not improve from 12.78877
 - 12s - loss: 12.8393 - val_loss: 13.3018
Epoch 401/8000

Epoch 00401: val_loss did not improve from 12.78877
 - 12s - loss: 12.9212 - val_loss: 12.8435
Epoch 402/8000

Epoch 00402: val_loss did not improve from 12.78877
 - 12s - loss: 12.8784 - val_loss: 13.2135
Epoch 403/8000

Epoch 00403: val_loss did not improve from 12.78877
 - 12s - loss: 12.9691 - val_loss: 13.5377
Epoch 404/8000

Epoch 00404: val_loss did not improve from 12.78877
 - 12s - loss: 12.9546 - val_loss: 12.8591
Epoch 405/8000

Epoch 00405: val_loss did not improve from 12.78877
 - 12s - loss: 12.7906 - val_loss: 13.1336
Epoch 406/8000

Epoch 00406: val_loss did not improve from 12.78877
 - 12s - loss: 12.8694 - val_loss: 13.2807
Epoch 407/8000

Epoch 00407: val_loss did not improve from 12.78877
 - 12s - loss: 12.9081 - val_loss: 13.0993
Epoch 408/8000

Epoch 00408: val_loss did not improve from 12.78877
 - 12s - loss: 12.8698 - val_loss: 12.9012
Epoch 409/8000

Epoch 00409: val_loss did not improve from 12.78877
 - 12s - loss: 12.9606 - val_loss: 12.8509
Epoch 410/8000

Epoch 00410: val_loss did not improve from 12.78877
 - 12s - loss: 12.9172 - val_loss: 13.2914
Epoch 411/8000

Epoch 00411: val_loss improved from 12.78877 to 12.74995, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.8423 - val_loss: 12.7499
Epoch 412/8000

Epoch 00412: val_loss did not improve from 12.74995
 - 12s - loss: 12.8758 - val_loss: 13.1632
Epoch 413/8000

Epoch 00413: val_loss improved from 12.74995 to 12.66794, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.8244 - val_loss: 12.6679
Epoch 414/8000

Epoch 00414: val_loss did not improve from 12.66794
 - 12s - loss: 12.7277 - val_loss: 13.1259
Epoch 415/8000

Epoch 00415: val_loss did not improve from 12.66794
 - 12s - loss: 12.8939 - val_loss: 13.5085
Epoch 416/8000

Epoch 00416: val_loss did not improve from 12.66794
 - 12s - loss: 12.9198 - val_loss: 13.1993
Epoch 417/8000

Epoch 00417: val_loss did not improve from 12.66794
 - 12s - loss: 12.7659 - val_loss: 13.1857
Epoch 418/8000

Epoch 00418: val_loss did not improve from 12.66794
 - 12s - loss: 12.7916 - val_loss: 13.1651
Epoch 419/8000

Epoch 00419: val_loss did not improve from 12.66794
 - 12s - loss: 12.8524 - val_loss: 13.4815
Epoch 420/8000

Epoch 00420: val_loss did not improve from 12.66794
 - 12s - loss: 12.8571 - val_loss: 13.2370
Epoch 421/8000

Epoch 00421: val_loss did not improve from 12.66794
 - 12s - loss: 12.8771 - val_loss: 13.5169
Epoch 422/8000

Epoch 00422: val_loss did not improve from 12.66794
 - 12s - loss: 12.7290 - val_loss: 12.6721
Epoch 423/8000

Epoch 00423: val_loss did not improve from 12.66794
 - 12s - loss: 12.7197 - val_loss: 12.7635
Epoch 424/8000

Epoch 00424: val_loss did not improve from 12.66794
 - 12s - loss: 12.8068 - val_loss: 12.9620
Epoch 425/8000

Epoch 00425: val_loss did not improve from 12.66794
 - 12s - loss: 12.8035 - val_loss: 13.1855
Epoch 426/8000

Epoch 00426: val_loss did not improve from 12.66794
 - 12s - loss: 12.8941 - val_loss: 13.6351
Epoch 427/8000

Epoch 00427: val_loss did not improve from 12.66794
 - 12s - loss: 12.8610 - val_loss: 13.3543
Epoch 428/8000

Epoch 00428: val_loss did not improve from 12.66794
 - 12s - loss: 12.7632 - val_loss: 12.9423
Epoch 429/8000

Epoch 00429: val_loss did not improve from 12.66794
 - 12s - loss: 12.7400 - val_loss: 13.1113
Epoch 430/8000

Epoch 00430: val_loss did not improve from 12.66794
 - 12s - loss: 12.7622 - val_loss: 13.3075
Epoch 431/8000

Epoch 00431: val_loss did not improve from 12.66794
 - 12s - loss: 12.7602 - val_loss: 13.8312
Epoch 432/8000

Epoch 00432: val_loss did not improve from 12.66794
 - 12s - loss: 12.7462 - val_loss: 13.1857
Epoch 433/8000

Epoch 00433: val_loss did not improve from 12.66794
 - 12s - loss: 12.8619 - val_loss: 12.8046
Epoch 434/8000

Epoch 00434: val_loss did not improve from 12.66794
 - 12s - loss: 12.7989 - val_loss: 12.7193
Epoch 435/8000

Epoch 00435: val_loss did not improve from 12.66794
 - 12s - loss: 12.8245 - val_loss: 13.0536
Epoch 436/8000

Epoch 00436: val_loss did not improve from 12.66794
 - 12s - loss: 12.8538 - val_loss: 12.9053
Epoch 437/8000

Epoch 00437: val_loss did not improve from 12.66794
 - 12s - loss: 12.8002 - val_loss: 12.8963
Epoch 438/8000

Epoch 00438: val_loss did not improve from 12.66794
 - 12s - loss: 12.8061 - val_loss: 15.1738
Epoch 439/8000

Epoch 00439: val_loss did not improve from 12.66794
 - 12s - loss: 12.9829 - val_loss: 13.1886
Epoch 440/8000

Epoch 00440: val_loss did not improve from 12.66794
 - 12s - loss: 12.8342 - val_loss: 12.7380
Epoch 441/8000

Epoch 00441: val_loss did not improve from 12.66794
 - 12s - loss: 12.7076 - val_loss: 12.9257
Epoch 442/8000

Epoch 00442: val_loss improved from 12.66794 to 12.55727, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.8719 - val_loss: 12.5573
Epoch 443/8000

Epoch 00443: val_loss did not improve from 12.55727
 - 12s - loss: 12.8049 - val_loss: 12.7864
Epoch 444/8000

Epoch 00444: val_loss did not improve from 12.55727
 - 12s - loss: 12.8731 - val_loss: 12.9951
Epoch 445/8000

Epoch 00445: val_loss did not improve from 12.55727
 - 12s - loss: 12.8848 - val_loss: 13.5052
Epoch 446/8000

Epoch 00446: val_loss did not improve from 12.55727
 - 12s - loss: 13.1011 - val_loss: 13.1981
Epoch 447/8000

Epoch 00447: val_loss did not improve from 12.55727
 - 12s - loss: 12.9989 - val_loss: 13.6023
Epoch 448/8000

Epoch 00448: val_loss did not improve from 12.55727
 - 12s - loss: 12.8646 - val_loss: 12.7281
Epoch 449/8000

Epoch 00449: val_loss did not improve from 12.55727
 - 12s - loss: 12.9558 - val_loss: 13.4564
Epoch 450/8000

Epoch 00450: val_loss did not improve from 12.55727
 - 12s - loss: 12.8594 - val_loss: 13.8114
Epoch 451/8000

Epoch 00451: val_loss did not improve from 12.55727
 - 12s - loss: 12.8946 - val_loss: 13.9908
Epoch 452/8000

Epoch 00452: val_loss did not improve from 12.55727
 - 12s - loss: 12.9150 - val_loss: 13.0214
Epoch 453/8000

Epoch 00453: val_loss did not improve from 12.55727
 - 12s - loss: 12.8920 - val_loss: 12.8844
Epoch 454/8000

Epoch 00454: val_loss did not improve from 12.55727
 - 12s - loss: 12.8993 - val_loss: 12.7302
Epoch 455/8000

Epoch 00455: val_loss did not improve from 12.55727
 - 12s - loss: 12.9152 - val_loss: 12.8425
Epoch 456/8000

Epoch 00456: val_loss did not improve from 12.55727
 - 12s - loss: 12.9458 - val_loss: 13.4176
Epoch 457/8000

Epoch 00457: val_loss did not improve from 12.55727
 - 12s - loss: 13.1928 - val_loss: 13.1767
Epoch 458/8000

Epoch 00458: val_loss did not improve from 12.55727
 - 12s - loss: 12.8847 - val_loss: 13.5262
Epoch 459/8000

Epoch 00459: val_loss did not improve from 12.55727
 - 12s - loss: 12.8342 - val_loss: 13.3394
Epoch 460/8000

Epoch 00460: val_loss did not improve from 12.55727
 - 12s - loss: 12.9845 - val_loss: 12.9782
Epoch 461/8000

Epoch 00461: val_loss did not improve from 12.55727
 - 12s - loss: 12.7955 - val_loss: 13.0135
Epoch 462/8000

Epoch 00462: val_loss did not improve from 12.55727
 - 12s - loss: 12.7830 - val_loss: 13.7271
Epoch 463/8000

Epoch 00463: val_loss did not improve from 12.55727
 - 12s - loss: 12.9545 - val_loss: 13.6948
Epoch 464/8000

Epoch 00464: val_loss did not improve from 12.55727
 - 12s - loss: 13.0836 - val_loss: 13.4542
Epoch 465/8000

Epoch 00465: val_loss did not improve from 12.55727
 - 12s - loss: 12.9199 - val_loss: 13.1999
Epoch 466/8000

Epoch 00466: val_loss did not improve from 12.55727
 - 12s - loss: 12.8819 - val_loss: 12.7382
Epoch 467/8000

Epoch 00467: val_loss did not improve from 12.55727
 - 12s - loss: 12.7484 - val_loss: 13.1243
Epoch 468/8000

Epoch 00468: val_loss did not improve from 12.55727
 - 12s - loss: 12.7925 - val_loss: 13.3391
Epoch 469/8000

Epoch 00469: val_loss did not improve from 12.55727
 - 12s - loss: 12.7755 - val_loss: 12.9218
Epoch 470/8000

Epoch 00470: val_loss improved from 12.55727 to 12.53416, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.7934 - val_loss: 12.5342
Epoch 471/8000

Epoch 00471: val_loss did not improve from 12.53416
 - 12s - loss: 12.8155 - val_loss: 13.5095
Epoch 472/8000

Epoch 00472: val_loss did not improve from 12.53416
 - 12s - loss: 12.7425 - val_loss: 13.1005
Epoch 473/8000

Epoch 00473: val_loss did not improve from 12.53416
 - 12s - loss: 12.6727 - val_loss: 12.6857
Epoch 474/8000

Epoch 00474: val_loss did not improve from 12.53416
 - 12s - loss: 12.6705 - val_loss: 12.8598
Epoch 475/8000

Epoch 00475: val_loss did not improve from 12.53416
 - 12s - loss: 12.6799 - val_loss: 12.9657
Epoch 476/8000

Epoch 00476: val_loss did not improve from 12.53416
 - 12s - loss: 12.7829 - val_loss: 12.8269
Epoch 477/8000

Epoch 00477: val_loss did not improve from 12.53416
 - 12s - loss: 12.7488 - val_loss: 12.8987
Epoch 478/8000

Epoch 00478: val_loss did not improve from 12.53416
 - 12s - loss: 12.6603 - val_loss: 12.7357
Epoch 479/8000

Epoch 00479: val_loss did not improve from 12.53416
 - 12s - loss: 12.7626 - val_loss: 12.9444
Epoch 480/8000

Epoch 00480: val_loss did not improve from 12.53416
 - 12s - loss: 12.7104 - val_loss: 12.8764
Epoch 481/8000

Epoch 00481: val_loss did not improve from 12.53416
 - 12s - loss: 12.7125 - val_loss: 13.1128
Epoch 482/8000

Epoch 00482: val_loss did not improve from 12.53416
 - 12s - loss: 12.6011 - val_loss: 12.7597
Epoch 483/8000

Epoch 00483: val_loss did not improve from 12.53416
 - 12s - loss: 12.5883 - val_loss: 12.6574
Epoch 484/8000

Epoch 00484: val_loss did not improve from 12.53416
 - 12s - loss: 12.6782 - val_loss: 12.7203
Epoch 485/8000

Epoch 00485: val_loss did not improve from 12.53416
 - 12s - loss: 12.7144 - val_loss: 12.9435
Epoch 486/8000

Epoch 00486: val_loss did not improve from 12.53416
 - 12s - loss: 12.6927 - val_loss: 13.2256
Epoch 487/8000

Epoch 00487: val_loss did not improve from 12.53416
 - 12s - loss: 12.7367 - val_loss: 12.6814
Epoch 488/8000

Epoch 00488: val_loss did not improve from 12.53416
 - 12s - loss: 12.7007 - val_loss: 13.0411
Epoch 489/8000

Epoch 00489: val_loss did not improve from 12.53416
 - 12s - loss: 12.6130 - val_loss: 13.0393
Epoch 490/8000

Epoch 00490: val_loss improved from 12.53416 to 12.51645, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.6194 - val_loss: 12.5165
Epoch 491/8000

Epoch 00491: val_loss did not improve from 12.51645
 - 12s - loss: 12.5470 - val_loss: 13.0251
Epoch 492/8000

Epoch 00492: val_loss did not improve from 12.51645
 - 12s - loss: 12.5722 - val_loss: 12.7198
Epoch 493/8000

Epoch 00493: val_loss did not improve from 12.51645
 - 12s - loss: 12.5763 - val_loss: 12.8265
Epoch 494/8000

Epoch 00494: val_loss did not improve from 12.51645
 - 12s - loss: 12.5067 - val_loss: 12.6656
Epoch 495/8000

Epoch 00495: val_loss did not improve from 12.51645
 - 12s - loss: 12.6690 - val_loss: 12.8095
Epoch 496/8000

Epoch 00496: val_loss did not improve from 12.51645
 - 12s - loss: 12.7028 - val_loss: 13.1659
Epoch 497/8000

Epoch 00497: val_loss did not improve from 12.51645
 - 12s - loss: 12.5457 - val_loss: 12.9412
Epoch 498/8000

Epoch 00498: val_loss did not improve from 12.51645
 - 12s - loss: 12.5882 - val_loss: 12.8600
Epoch 499/8000

Epoch 00499: val_loss did not improve from 12.51645
 - 12s - loss: 12.6060 - val_loss: 12.7153
Epoch 500/8000

Epoch 00500: val_loss did not improve from 12.51645
 - 12s - loss: 12.5787 - val_loss: 12.5379
Epoch 501/8000

Epoch 00501: val_loss did not improve from 12.51645
 - 12s - loss: 12.6306 - val_loss: 12.9668
Epoch 502/8000

Epoch 00502: val_loss did not improve from 12.51645
 - 12s - loss: 12.5512 - val_loss: 12.6946
Epoch 503/8000

Epoch 00503: val_loss did not improve from 12.51645
 - 12s - loss: 12.5866 - val_loss: 12.7406
Epoch 504/8000

Epoch 00504: val_loss improved from 12.51645 to 12.36879, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.5266 - val_loss: 12.3688
Epoch 505/8000

Epoch 00505: val_loss did not improve from 12.36879
 - 12s - loss: 12.6666 - val_loss: 13.3097
Epoch 506/8000

Epoch 00506: val_loss did not improve from 12.36879
 - 12s - loss: 12.9998 - val_loss: 13.6782
Epoch 507/8000

Epoch 00507: val_loss did not improve from 12.36879
 - 12s - loss: 13.1335 - val_loss: 13.3712
Epoch 508/8000

Epoch 00508: val_loss did not improve from 12.36879
 - 12s - loss: 13.2436 - val_loss: 13.4881
Epoch 509/8000

Epoch 00509: val_loss did not improve from 12.36879
 - 12s - loss: 13.0064 - val_loss: 13.5588
Epoch 510/8000

Epoch 00510: val_loss did not improve from 12.36879
 - 12s - loss: 12.7978 - val_loss: 13.2691
Epoch 511/8000

Epoch 00511: val_loss did not improve from 12.36879
 - 12s - loss: 12.7770 - val_loss: 13.7540
Epoch 512/8000

Epoch 00512: val_loss did not improve from 12.36879
 - 12s - loss: 12.7581 - val_loss: 13.1554
Epoch 513/8000

Epoch 00513: val_loss did not improve from 12.36879
 - 12s - loss: 12.6659 - val_loss: 12.8678
Epoch 514/8000

Epoch 00514: val_loss did not improve from 12.36879
 - 12s - loss: 12.6830 - val_loss: 13.5162
Epoch 515/8000

Epoch 00515: val_loss did not improve from 12.36879
 - 12s - loss: 13.0372 - val_loss: 13.0837
Epoch 516/8000

Epoch 00516: val_loss did not improve from 12.36879
 - 12s - loss: 12.8236 - val_loss: 13.5642
Epoch 517/8000

Epoch 00517: val_loss did not improve from 12.36879
 - 12s - loss: 12.9800 - val_loss: 13.2577
Epoch 518/8000

Epoch 00518: val_loss did not improve from 12.36879
 - 12s - loss: 12.9623 - val_loss: 13.2466
Epoch 519/8000

Epoch 00519: val_loss did not improve from 12.36879
 - 12s - loss: 12.7974 - val_loss: 13.0651
Epoch 520/8000

Epoch 00520: val_loss did not improve from 12.36879
 - 12s - loss: 12.8754 - val_loss: 13.6097
Epoch 521/8000

Epoch 00521: val_loss did not improve from 12.36879
 - 12s - loss: 12.7407 - val_loss: 13.1738
Epoch 522/8000

Epoch 00522: val_loss did not improve from 12.36879
 - 12s - loss: 12.5426 - val_loss: 13.0885
Epoch 523/8000

Epoch 00523: val_loss did not improve from 12.36879
 - 12s - loss: 12.6088 - val_loss: 13.2914
Epoch 524/8000

Epoch 00524: val_loss did not improve from 12.36879
 - 12s - loss: 12.6973 - val_loss: 12.8829
Epoch 525/8000

Epoch 00525: val_loss did not improve from 12.36879
 - 12s - loss: 12.6233 - val_loss: 12.5593
Epoch 526/8000

Epoch 00526: val_loss did not improve from 12.36879
 - 12s - loss: 12.6888 - val_loss: 13.1033
Epoch 527/8000

Epoch 00527: val_loss did not improve from 12.36879
 - 12s - loss: 12.6082 - val_loss: 13.2542
Epoch 528/8000

Epoch 00528: val_loss did not improve from 12.36879
 - 12s - loss: 12.4922 - val_loss: 12.7945
Epoch 529/8000

Epoch 00529: val_loss did not improve from 12.36879
 - 12s - loss: 12.4964 - val_loss: 12.5504
Epoch 530/8000

Epoch 00530: val_loss did not improve from 12.36879
 - 12s - loss: 12.5675 - val_loss: 12.6541
Epoch 531/8000

Epoch 00531: val_loss did not improve from 12.36879
 - 12s - loss: 12.6557 - val_loss: 13.0422
Epoch 532/8000

Epoch 00532: val_loss did not improve from 12.36879
 - 12s - loss: 12.6110 - val_loss: 13.2219
Epoch 533/8000

Epoch 00533: val_loss did not improve from 12.36879
 - 12s - loss: 12.7052 - val_loss: 12.9243
Epoch 534/8000

Epoch 00534: val_loss did not improve from 12.36879
 - 12s - loss: 12.6179 - val_loss: 12.6489
Epoch 535/8000

Epoch 00535: val_loss did not improve from 12.36879
 - 12s - loss: 12.5215 - val_loss: 12.4430
Epoch 536/8000

Epoch 00536: val_loss did not improve from 12.36879
 - 12s - loss: 12.4476 - val_loss: 12.5159
Epoch 537/8000

Epoch 00537: val_loss did not improve from 12.36879
 - 12s - loss: 12.4631 - val_loss: 12.7073
Epoch 538/8000

Epoch 00538: val_loss did not improve from 12.36879
 - 12s - loss: 12.5647 - val_loss: 12.6499
Epoch 539/8000

Epoch 00539: val_loss did not improve from 12.36879
 - 12s - loss: 12.5492 - val_loss: 12.4779
Epoch 540/8000

Epoch 00540: val_loss did not improve from 12.36879
 - 12s - loss: 12.4210 - val_loss: 12.6760
Epoch 541/8000

Epoch 00541: val_loss did not improve from 12.36879
 - 12s - loss: 12.4176 - val_loss: 13.1442
Epoch 542/8000

Epoch 00542: val_loss did not improve from 12.36879
 - 12s - loss: 12.4530 - val_loss: 12.3723
Epoch 543/8000

Epoch 00543: val_loss did not improve from 12.36879
 - 12s - loss: 12.4685 - val_loss: 12.3975
Epoch 544/8000

Epoch 00544: val_loss did not improve from 12.36879
 - 12s - loss: 12.6619 - val_loss: 12.6494
Epoch 545/8000

Epoch 00545: val_loss improved from 12.36879 to 12.27056, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.4534 - val_loss: 12.2706
Epoch 546/8000

Epoch 00546: val_loss did not improve from 12.27056
 - 12s - loss: 12.4090 - val_loss: 12.5307
Epoch 547/8000

Epoch 00547: val_loss did not improve from 12.27056
 - 12s - loss: 12.5862 - val_loss: 13.1576
Epoch 548/8000

Epoch 00548: val_loss did not improve from 12.27056
 - 12s - loss: 12.4285 - val_loss: 12.6792
Epoch 549/8000

Epoch 00549: val_loss did not improve from 12.27056
 - 12s - loss: 12.4672 - val_loss: 12.8476
Epoch 550/8000

Epoch 00550: val_loss did not improve from 12.27056
 - 12s - loss: 12.3603 - val_loss: 12.7165
Epoch 551/8000

Epoch 00551: val_loss did not improve from 12.27056
 - 12s - loss: 12.5418 - val_loss: 12.6110
Epoch 552/8000

Epoch 00552: val_loss did not improve from 12.27056
 - 12s - loss: 12.4007 - val_loss: 12.9606
Epoch 553/8000

Epoch 00553: val_loss did not improve from 12.27056
 - 12s - loss: 12.4499 - val_loss: 12.6800
Epoch 554/8000

Epoch 00554: val_loss did not improve from 12.27056
 - 12s - loss: 12.4291 - val_loss: 12.5465
Epoch 555/8000

Epoch 00555: val_loss did not improve from 12.27056
 - 12s - loss: 12.4688 - val_loss: 12.6301
Epoch 556/8000

Epoch 00556: val_loss did not improve from 12.27056
 - 12s - loss: 12.4593 - val_loss: 12.4640
Epoch 557/8000

Epoch 00557: val_loss did not improve from 12.27056
 - 12s - loss: 12.3835 - val_loss: 12.2836
Epoch 558/8000

Epoch 00558: val_loss did not improve from 12.27056
 - 12s - loss: 12.3003 - val_loss: 12.5248
Epoch 559/8000

Epoch 00559: val_loss did not improve from 12.27056
 - 12s - loss: 12.3828 - val_loss: 12.6167
Epoch 560/8000

Epoch 00560: val_loss did not improve from 12.27056
 - 12s - loss: 12.4482 - val_loss: 12.7839
Epoch 561/8000

Epoch 00561: val_loss did not improve from 12.27056
 - 12s - loss: 12.4784 - val_loss: 12.5452
Epoch 562/8000

Epoch 00562: val_loss did not improve from 12.27056
 - 12s - loss: 12.3183 - val_loss: 12.6441
Epoch 563/8000

Epoch 00563: val_loss did not improve from 12.27056
 - 12s - loss: 12.4951 - val_loss: 12.5944
Epoch 564/8000

Epoch 00564: val_loss did not improve from 12.27056
 - 12s - loss: 12.4066 - val_loss: 12.9082
Epoch 565/8000

Epoch 00565: val_loss did not improve from 12.27056
 - 12s - loss: 12.3964 - val_loss: 12.6011
Epoch 566/8000

Epoch 00566: val_loss did not improve from 12.27056
 - 12s - loss: 12.3805 - val_loss: 12.4292
Epoch 567/8000

Epoch 00567: val_loss did not improve from 12.27056
 - 12s - loss: 12.3122 - val_loss: 12.5801
Epoch 568/8000

Epoch 00568: val_loss did not improve from 12.27056
 - 12s - loss: 12.3856 - val_loss: 12.5701
Epoch 569/8000

Epoch 00569: val_loss did not improve from 12.27056
 - 12s - loss: 12.2924 - val_loss: 12.7241
Epoch 570/8000

Epoch 00570: val_loss did not improve from 12.27056
 - 12s - loss: 12.4802 - val_loss: 12.9462
Epoch 571/8000

Epoch 00571: val_loss did not improve from 12.27056
 - 12s - loss: 12.5143 - val_loss: 13.0657
Epoch 572/8000

Epoch 00572: val_loss did not improve from 12.27056
 - 12s - loss: 12.3819 - val_loss: 13.0508
Epoch 573/8000

Epoch 00573: val_loss did not improve from 12.27056
 - 12s - loss: 12.3115 - val_loss: 12.3168
Epoch 574/8000

Epoch 00574: val_loss improved from 12.27056 to 12.12229, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.3614 - val_loss: 12.1223
Epoch 575/8000

Epoch 00575: val_loss improved from 12.12229 to 12.11065, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.2508 - val_loss: 12.1106
Epoch 576/8000

Epoch 00576: val_loss did not improve from 12.11065
 - 12s - loss: 12.1661 - val_loss: 12.6738
Epoch 577/8000

Epoch 00577: val_loss did not improve from 12.11065
 - 12s - loss: 12.2819 - val_loss: 12.5554
Epoch 578/8000

Epoch 00578: val_loss did not improve from 12.11065
 - 12s - loss: 12.3560 - val_loss: 12.3983
Epoch 579/8000

Epoch 00579: val_loss did not improve from 12.11065
 - 12s - loss: 12.1929 - val_loss: 12.8584
Epoch 580/8000

Epoch 00580: val_loss did not improve from 12.11065
 - 12s - loss: 12.2485 - val_loss: 12.6355
Epoch 581/8000

Epoch 00581: val_loss improved from 12.11065 to 11.96097, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.2089 - val_loss: 11.9610
Epoch 582/8000

Epoch 00582: val_loss did not improve from 11.96097
 - 12s - loss: 12.4606 - val_loss: 12.4011
Epoch 583/8000

Epoch 00583: val_loss did not improve from 11.96097
 - 12s - loss: 12.2915 - val_loss: 12.2735
Epoch 584/8000

Epoch 00584: val_loss did not improve from 11.96097
 - 12s - loss: 12.2685 - val_loss: 12.5191
Epoch 585/8000

Epoch 00585: val_loss did not improve from 11.96097
 - 12s - loss: 12.2766 - val_loss: 12.7299
Epoch 586/8000

Epoch 00586: val_loss did not improve from 11.96097
 - 12s - loss: 12.1660 - val_loss: 12.3166
Epoch 587/8000

Epoch 00587: val_loss did not improve from 11.96097
 - 12s - loss: 12.2244 - val_loss: 12.0683
Epoch 588/8000

Epoch 00588: val_loss did not improve from 11.96097
 - 12s - loss: 12.2233 - val_loss: 12.2008
Epoch 589/8000

Epoch 00589: val_loss did not improve from 11.96097
 - 12s - loss: 12.2264 - val_loss: 12.1705
Epoch 590/8000

Epoch 00590: val_loss did not improve from 11.96097
 - 12s - loss: 12.1642 - val_loss: 12.2704
Epoch 591/8000

Epoch 00591: val_loss did not improve from 11.96097
 - 12s - loss: 12.3250 - val_loss: 12.4410
Epoch 592/8000

Epoch 00592: val_loss did not improve from 11.96097
 - 12s - loss: 12.2150 - val_loss: 12.3256
Epoch 593/8000

Epoch 00593: val_loss did not improve from 11.96097
 - 12s - loss: 12.1635 - val_loss: 12.6070
Epoch 594/8000

Epoch 00594: val_loss did not improve from 11.96097
 - 12s - loss: 12.2150 - val_loss: 12.2928
Epoch 595/8000

Epoch 00595: val_loss did not improve from 11.96097
 - 12s - loss: 12.1846 - val_loss: 12.2237
Epoch 596/8000

Epoch 00596: val_loss did not improve from 11.96097
 - 12s - loss: 12.0881 - val_loss: 12.1581
Epoch 597/8000

Epoch 00597: val_loss did not improve from 11.96097
 - 12s - loss: 12.1297 - val_loss: 12.7044
Epoch 598/8000

Epoch 00598: val_loss did not improve from 11.96097
 - 12s - loss: 12.2791 - val_loss: 12.0418
Epoch 599/8000

Epoch 00599: val_loss did not improve from 11.96097
 - 12s - loss: 12.0567 - val_loss: 12.9943
Epoch 600/8000

Epoch 00600: val_loss did not improve from 11.96097
 - 12s - loss: 12.4630 - val_loss: 12.9718
Epoch 601/8000

Epoch 00601: val_loss did not improve from 11.96097
 - 12s - loss: 12.3066 - val_loss: 12.6448
Epoch 602/8000

Epoch 00602: val_loss did not improve from 11.96097
 - 12s - loss: 12.3427 - val_loss: 12.6984
Epoch 603/8000

Epoch 00603: val_loss did not improve from 11.96097
 - 12s - loss: 12.0822 - val_loss: 11.9626
Epoch 604/8000

Epoch 00604: val_loss did not improve from 11.96097
 - 12s - loss: 12.3544 - val_loss: 13.1350
Epoch 605/8000

Epoch 00605: val_loss did not improve from 11.96097
 - 12s - loss: 12.9143 - val_loss: 13.1793
Epoch 606/8000

Epoch 00606: val_loss did not improve from 11.96097
 - 12s - loss: 12.5831 - val_loss: 12.6322
Epoch 607/8000

Epoch 00607: val_loss did not improve from 11.96097
 - 12s - loss: 12.2036 - val_loss: 12.6345
Epoch 608/8000

Epoch 00608: val_loss did not improve from 11.96097
 - 12s - loss: 12.3263 - val_loss: 12.6818
Epoch 609/8000

Epoch 00609: val_loss did not improve from 11.96097
 - 12s - loss: 12.2844 - val_loss: 12.3312
Epoch 610/8000

Epoch 00610: val_loss did not improve from 11.96097
 - 12s - loss: 12.1271 - val_loss: 12.3983
Epoch 611/8000

Epoch 00611: val_loss did not improve from 11.96097
 - 12s - loss: 12.1126 - val_loss: 12.5337
Epoch 612/8000

Epoch 00612: val_loss did not improve from 11.96097
 - 12s - loss: 12.1590 - val_loss: 12.3916
Epoch 613/8000

Epoch 00613: val_loss did not improve from 11.96097
 - 12s - loss: 12.2992 - val_loss: 12.2911
Epoch 614/8000

Epoch 00614: val_loss improved from 11.96097 to 11.90145, saving model to model_weights/model_2020-01-30_14-46-02.h5
 - 12s - loss: 12.2219 - val_loss: 11.9014
Epoch 615/8000

Epoch 00615: val_loss did not improve from 11.90145
 - 12s - loss: 12.2042 - val_loss: 12.3851
Epoch 616/8000

Epoch 00616: val_loss did not improve from 11.90145
 - 12s - loss: 12.3972 - val_loss: 12.6382
Epoch 617/8000

Epoch 00617: val_loss did not improve from 11.90145
 - 12s - loss: 12.6744 - val_loss: 12.5278
Epoch 618/8000

Epoch 00618: val_loss did not improve from 11.90145
 - 12s - loss: 12.3450 - val_loss: 12.6352
Epoch 619/8000

Epoch 00619: val_loss did not improve from 11.90145
 - 12s - loss: 12.3293 - val_loss: 12.6818
Epoch 620/8000

Epoch 00620: val_loss did not improve from 11.90145
 - 12s - loss: 12.3804 - val_loss: 13.1224
Epoch 621/8000

Epoch 00621: val_loss did not improve from 11.90145
 - 12s - loss: 12.5002 - val_loss: 12.8113
Epoch 622/8000

Epoch 00622: val_loss did not improve from 11.90145
 - 12s - loss: 12.1320 - val_loss: 12.2261
Epoch 623/8000

Epoch 00623: val_loss did not improve from 11.90145
 - 12s - loss: 12.2586 - val_loss: 12.5610
Epoch 624/8000

Epoch 00624: val_loss did not improve from 11.90145
 - 12s - loss: 12.1045 - val_loss: 12.1621
Epoch 625/8000

Epoch 00625: val_loss did not improve from 11.90145
 - 12s - loss: 12.2917 - val_loss: 12.9869
Epoch 626/8000

Epoch 00626: val_loss did not improve from 11.90145
 - 12s - loss: 12.4148 - val_loss: 12.5014
Epoch 627/8000

Epoch 00627: val_loss did not improve from 11.90145
 - 12s - loss: 12.1645 - val_loss: 12.2658
Epoch 628/8000

Epoch 00628: val_loss did not improve from 11.90145
 - 12s - loss: 12.3322 - val_loss: 12.4696
Epoch 629/8000

Epoch 00629: val_loss did not improve from 11.90145
 - 12s - loss: 12.0901 - val_loss: 12.6032
Epoch 630/8000

Epoch 00630: val_loss did not improve from 11.90145
 - 12s - loss: 12.0382 - val_loss: 12.1926
Epoch 631/8000

Epoch 00631: val_loss did not improve from 11.90145
 - 12s - loss: 12.2365 - val_loss: 12.6122
Epoch 632/8000

Epoch 00632: val_loss did not improve from 11.90145
 - 12s - loss: 12.3106 - val_loss: 12.7252
Epoch 633/8000

Epoch 00633: val_loss did not improve from 11.90145
 - 12s - loss: 12.5503 - val_loss: 12.9374
Epoch 634/8000

Epoch 00634: val_loss did not improve from 11.90145
 - 12s - loss: 12.2532 - val_loss: 12.5745
Epoch 635/8000

Epoch 00635: val_loss did not improve from 11.90145
 - 12s - loss: 12.3156 - val_loss: 12.2161
Epoch 636/8000

Epoch 00636: val_loss did not improve from 11.90145
 - 12s - loss: 12.1165 - val_loss: 12.6570
Epoch 637/8000

Epoch 00637: val_loss did not improve from 11.90145
 - 12s - loss: 12.5450 - val_loss: 12.5154
Epoch 638/8000

Epoch 00638: val_loss did not improve from 11.90145
 - 12s - loss: 12.4520 - val_loss: 13.0652
Epoch 639/8000

Epoch 00639: val_loss did not improve from 11.90145
 - 12s - loss: 12.3703 - val_loss: 12.6387
Epoch 640/8000

Epoch 00640: val_loss did not improve from 11.90145
 - 12s - loss: 12.3046 - val_loss: 12.3470
Epoch 641/8000

Epoch 00641: val_loss did not improve from 11.90145
 - 12s - loss: 12.6375 - val_loss: 13.6318
Epoch 642/8000

Epoch 00642: val_loss did not improve from 11.90145
 - 12s - loss: 12.7711 - val_loss: 12.4391
Epoch 643/8000

Epoch 00643: val_loss did not improve from 11.90145
 - 12s - loss: 12.3899 - val_loss: 12.1911
Epoch 644/8000

Epoch 00644: val_loss did not improve from 11.90145
 - 12s - loss: 12.2693 - val_loss: 12.4384
Epoch 645/8000

Epoch 00645: val_loss did not improve from 11.90145
 - 12s - loss: 12.2045 - val_loss: 12.0684
Epoch 646/8000

Epoch 00646: val_loss did not improve from 11.90145
 - 12s - loss: 14.8936 - val_loss: 14.6247
Epoch 647/8000

Epoch 00647: val_loss did not improve from 11.90145
 - 12s - loss: 13.9217 - val_loss: 13.3107
Epoch 648/8000

Epoch 00648: val_loss did not improve from 11.90145
 - 12s - loss: 12.7350 - val_loss: 12.7452
Epoch 649/8000

Epoch 00649: val_loss did not improve from 11.90145
 - 12s - loss: 12.4663 - val_loss: 13.0104
Epoch 650/8000

Epoch 00650: val_loss did not improve from 11.90145
 - 12s - loss: 12.4957 - val_loss: 13.1981
Epoch 651/8000

Epoch 00651: val_loss did not improve from 11.90145
 - 12s - loss: 12.5414 - val_loss: 12.6408
Epoch 652/8000

Epoch 00652: val_loss did not improve from 11.90145
 - 12s - loss: 12.2764 - val_loss: 12.2736
Epoch 653/8000

Epoch 00653: val_loss did not improve from 11.90145
 - 12s - loss: 12.0773 - val_loss: 12.3285
Epoch 654/8000

Epoch 00654: val_loss did not improve from 11.90145
 - 12s - loss: 12.2446 - val_loss: 12.3667
Epoch 655/8000

Epoch 00655: val_loss did not improve from 11.90145
 - 12s - loss: 12.2590 - val_loss: 12.6411
Epoch 656/8000

Epoch 00656: val_loss did not improve from 11.90145
 - 12s - loss: 12.3348 - val_loss: 12.6020
Epoch 657/8000

Epoch 00657: val_loss did not improve from 11.90145
 - 12s - loss: 12.2401 - val_loss: 12.3038
Epoch 658/8000

Epoch 00658: val_loss did not improve from 11.90145
 - 12s - loss: 12.2618 - val_loss: 12.9731
Epoch 659/8000

Epoch 00659: val_loss did not improve from 11.90145
 - 12s - loss: 12.4803 - val_loss: 12.8808
Epoch 660/8000

Epoch 00660: val_loss did not improve from 11.90145
 - 12s - loss: 12.1250 - val_loss: 12.6279
Epoch 661/8000

Epoch 00661: val_loss did not improve from 11.90145
 - 12s - loss: 12.3609 - val_loss: 13.4852
Epoch 662/8000

Epoch 00662: val_loss did not improve from 11.90145
 - 12s - loss: 12.7165 - val_loss: 12.5391
Epoch 663/8000

Epoch 00663: val_loss did not improve from 11.90145
 - 12s - loss: 12.1950 - val_loss: 12.3736
Epoch 664/8000

Epoch 00664: val_loss did not improve from 11.90145
 - 12s - loss: 12.1487 - val_loss: 12.5563
Epoch 665/8000

Epoch 00665: val_loss did not improve from 11.90145
 - 12s - loss: 11.9753 - val_loss: 12.1754
Epoch 666/8000

Epoch 00666: val_loss did not improve from 11.90145
 - 12s - loss: 12.0152 - val_loss: 12.0062
Epoch 667/8000

Epoch 00667: val_loss did not improve from 11.90145
 - 12s - loss: 12.0032 - val_loss: 11.9281
Epoch 668/8000

Epoch 00668: val_loss did not improve from 11.90145
 - 12s - loss: 11.9669 - val_loss: 12.2422
Epoch 669/8000

Epoch 00669: val_loss did not improve from 11.90145
 - 12s - loss: 12.1063 - val_loss: 12.5446
Epoch 670/8000

Epoch 00670: val_loss did not improve from 11.90145
 - 12s - loss: 12.0993 - val_loss: 12.1989
Epoch 671/8000

Epoch 00671: val_loss did not improve from 11.90145
 - 12s - loss: 12.1559 - val_loss: 12.4039
Epoch 672/8000

Epoch 00672: val_loss did not improve from 11.90145
 - 12s - loss: 12.1375 - val_loss: 13.2847
Epoch 673/8000

Epoch 00673: val_loss did not improve from 11.90145
 - 12s - loss: 12.4462 - val_loss: 12.1809
Epoch 674/8000

Epoch 00674: val_loss did not improve from 11.90145
 - 12s - loss: 12.0378 - val_loss: 12.1946
Epoch 675/8000

Epoch 00675: val_loss did not improve from 11.90145
 - 12s - loss: 12.0335 - val_loss: 12.5250
Epoch 676/8000

Epoch 00676: val_loss did not improve from 11.90145
 - 12s - loss: 12.0423 - val_loss: 12.1251
Epoch 677/8000

Epoch 00677: val_loss did not improve from 11.90145
 - 12s - loss: 11.9957 - val_loss: 12.4843
Epoch 678/8000

Epoch 00678: val_loss did not improve from 11.90145
 - 12s - loss: 12.1339 - val_loss: 12.2678
Epoch 679/8000

Epoch 00679: val_loss did not improve from 11.90145
 - 12s - loss: 11.9676 - val_loss: 12.5055
Epoch 680/8000

Epoch 00680: val_loss did not improve from 11.90145
 - 12s - loss: 11.9463 - val_loss: 12.1976
Epoch 681/8000

Epoch 00681: val_loss did not improve from 11.90145
 - 12s - loss: 12.0208 - val_loss: 12.4555
Epoch 682/8000

Epoch 00682: val_loss did not improve from 11.90145
 - 12s - loss: 11.9764 - val_loss: 12.3748
Epoch 683/8000

Epoch 00683: val_loss did not improve from 11.90145
 - 12s - loss: 11.9471 - val_loss: 12.1395
Epoch 684/8000

Epoch 00684: val_loss did not improve from 11.90145
 - 12s - loss: 12.0281 - val_loss: 12.0447
Epoch 685/8000

Epoch 00685: val_loss did not improve from 11.90145
 - 12s - loss: 12.0081 - val_loss: 12.4362
Epoch 686/8000

Epoch 00686: val_loss did not improve from 11.90145
 - 12s - loss: 12.1273 - val_loss: 12.4325
Epoch 687/8000

Epoch 00687: val_loss did not improve from 11.90145
 - 12s - loss: 12.1108 - val_loss: 12.3561
Epoch 688/8000

Epoch 00688: val_loss did not improve from 11.90145
 - 12s - loss: 12.3160 - val_loss: 12.6604
Epoch 689/8000

Epoch 00689: val_loss did not improve from 11.90145
 - 12s - loss: 12.0342 - val_loss: 11.9725
Epoch 690/8000

Epoch 00690: val_loss did not improve from 11.90145
 - 12s - loss: 12.0037 - val_loss: 12.7802
Epoch 691/8000

Epoch 00691: val_loss did not improve from 11.90145
 - 12s - loss: 11.9120 - val_loss: 12.2211
Epoch 692/8000

Epoch 00692: val_loss did not improve from 11.90145
 - 12s - loss: 12.0337 - val_loss: 12.3073
Epoch 693/8000

Epoch 00693: val_loss did not improve from 11.90145
 - 12s - loss: 12.1130 - val_loss: 12.2745
Epoch 694/8000

Epoch 00694: val_loss did not improve from 11.90145
 - 12s - loss: 12.2025 - val_loss: 11.9431
Epoch 695/8000

Epoch 00695: val_loss did not improve from 11.90145
 - 12s - loss: 12.2686 - val_loss: 12.7405
Epoch 696/8000

Epoch 00696: val_loss did not improve from 11.90145
 - 12s - loss: 12.2210 - val_loss: 12.2564
Epoch 697/8000

Epoch 00697: val_loss did not improve from 11.90145
 - 12s - loss: 12.3820 - val_loss: 13.0806
Epoch 698/8000

Epoch 00698: val_loss did not improve from 11.90145
 - 12s - loss: 12.4112 - val_loss: 12.5032
Epoch 699/8000

Epoch 00699: val_loss did not improve from 11.90145
 - 12s - loss: 12.3101 - val_loss: 12.8386
Epoch 700/8000

Epoch 00700: val_loss did not improve from 11.90145
 - 12s - loss: 12.3356 - val_loss: 12.8830
Epoch 701/8000

Epoch 00701: val_loss did not improve from 11.90145
 - 12s - loss: 12.2849 - val_loss: 12.6278
Epoch 702/8000

Epoch 00702: val_loss did not improve from 11.90145
 - 12s - loss: 12.4625 - val_loss: 12.3741
Epoch 703/8000

Epoch 00703: val_loss did not improve from 11.90145
 - 12s - loss: 12.4772 - val_loss: 12.6418
Epoch 704/8000

Epoch 00704: val_loss did not improve from 11.90145
 - 12s - loss: 12.3757 - val_loss: 12.9210
Epoch 705/8000

Epoch 00705: val_loss did not improve from 11.90145
 - 12s - loss: 12.3605 - val_loss: 12.3508
Epoch 706/8000

Epoch 00706: val_loss did not improve from 11.90145
 - 12s - loss: 12.2767 - val_loss: 12.3570
Epoch 707/8000

Epoch 00707: val_loss did not improve from 11.90145
 - 12s - loss: 12.1883 - val_loss: 12.1279
Epoch 708/8000

Epoch 00708: val_loss did not improve from 11.90145
 - 12s - loss: 12.0358 - val_loss: 12.4215
Epoch 709/8000

Epoch 00709: val_loss did not improve from 11.90145
 - 12s - loss: 12.1233 - val_loss: 12.9236
Epoch 710/8000

Epoch 00710: val_loss did not improve from 11.90145
 - 12s - loss: 12.4099 - val_loss: 12.3029
Epoch 711/8000

Epoch 00711: val_loss did not improve from 11.90145
 - 12s - loss: 12.5481 - val_loss: 12.3950
Epoch 712/8000

Epoch 00712: val_loss did not improve from 11.90145
 - 12s - loss: 12.3866 - val_loss: 12.6155
Epoch 713/8000

Epoch 00713: val_loss did not improve from 11.90145
 - 12s - loss: 12.3556 - val_loss: 12.4730
Epoch 714/8000

Epoch 00714: val_loss did not improve from 11.90145
 - 12s - loss: 12.5431 - val_loss: 12.5559
Epoch 00714: early stopping
