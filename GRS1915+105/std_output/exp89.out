2020-03-11 20:34:13.006375: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-03-11 20:34:13.261127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-11 20:34:13.261804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.73GiB
2020-03-11 20:34:13.261825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-03-11 20:34:18.612698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-11 20:34:18.612752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-03-11 20:34:18.612762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-03-11 20:34:18.613032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11348 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-03-11 20:34:19.458956: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x556ee0b88950
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 40.05718, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 89s - loss: 88.9490 - val_loss: 40.0572
Epoch 2/8000

Epoch 00002: val_loss improved from 40.05718 to 36.56854, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 75s - loss: 33.8770 - val_loss: 36.5685
Epoch 3/8000

Epoch 00003: val_loss did not improve from 36.56854
 - 75s - loss: 59.0340 - val_loss: 56.5532
Epoch 4/8000

Epoch 00004: val_loss improved from 36.56854 to 36.12228, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 75s - loss: 47.9577 - val_loss: 36.1223
Epoch 5/8000

Epoch 00005: val_loss did not improve from 36.12228
 - 77s - loss: 34.5102 - val_loss: 36.2468
Epoch 6/8000

Epoch 00006: val_loss improved from 36.12228 to 27.29406, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 29.5250 - val_loss: 27.2941
Epoch 7/8000

Epoch 00007: val_loss improved from 27.29406 to 27.14190, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 25.2460 - val_loss: 27.1419
Epoch 8/8000

Epoch 00008: val_loss improved from 27.14190 to 26.19036, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 24.3855 - val_loss: 26.1904
Epoch 9/8000

Epoch 00009: val_loss improved from 26.19036 to 25.04346, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 23.2120 - val_loss: 25.0435
Epoch 10/8000

Epoch 00010: val_loss did not improve from 25.04346
 - 76s - loss: 22.8476 - val_loss: 25.1353
Epoch 11/8000

Epoch 00011: val_loss improved from 25.04346 to 24.88656, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 22.5601 - val_loss: 24.8866
Epoch 12/8000

Epoch 00012: val_loss improved from 24.88656 to 24.40498, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 22.4687 - val_loss: 24.4050
Epoch 13/8000

Epoch 00013: val_loss improved from 24.40498 to 24.28696, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 22.3741 - val_loss: 24.2870
Epoch 14/8000

Epoch 00014: val_loss improved from 24.28696 to 23.80705, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 22.3272 - val_loss: 23.8071
Epoch 15/8000

Epoch 00015: val_loss did not improve from 23.80705
 - 76s - loss: 22.2464 - val_loss: 24.8756
Epoch 16/8000

Epoch 00016: val_loss improved from 23.80705 to 23.62114, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 22.2119 - val_loss: 23.6211
Epoch 17/8000

Epoch 00017: val_loss did not improve from 23.62114
 - 76s - loss: 22.1148 - val_loss: 24.2633
Epoch 18/8000

Epoch 00018: val_loss did not improve from 23.62114
 - 76s - loss: 22.1539 - val_loss: 23.9503
Epoch 19/8000

Epoch 00019: val_loss did not improve from 23.62114
 - 77s - loss: 22.0864 - val_loss: 24.6914
Epoch 20/8000

Epoch 00020: val_loss did not improve from 23.62114
 - 76s - loss: 22.0954 - val_loss: 24.5176
Epoch 21/8000

Epoch 00021: val_loss did not improve from 23.62114
 - 76s - loss: 22.0392 - val_loss: 24.0052
Epoch 22/8000

Epoch 00022: val_loss did not improve from 23.62114
 - 77s - loss: 22.0424 - val_loss: 24.6257
Epoch 23/8000

Epoch 00023: val_loss did not improve from 23.62114
 - 76s - loss: 22.0395 - val_loss: 24.1438
Epoch 24/8000

Epoch 00024: val_loss improved from 23.62114 to 23.58513, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 22.1716 - val_loss: 23.5851
Epoch 25/8000

Epoch 00025: val_loss did not improve from 23.58513
 - 76s - loss: 21.9220 - val_loss: 23.8309
Epoch 26/8000

Epoch 00026: val_loss improved from 23.58513 to 23.50232, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 21.8472 - val_loss: 23.5023
Epoch 27/8000

Epoch 00027: val_loss did not improve from 23.50232
 - 76s - loss: 21.8368 - val_loss: 24.0138
Epoch 28/8000

Epoch 00028: val_loss did not improve from 23.50232
 - 76s - loss: 21.8554 - val_loss: 24.0718
Epoch 29/8000

Epoch 00029: val_loss did not improve from 23.50232
 - 76s - loss: 21.8000 - val_loss: 23.7095
Epoch 30/8000

Epoch 00030: val_loss did not improve from 23.50232
 - 76s - loss: 21.9605 - val_loss: 23.7706
Epoch 31/8000

Epoch 00031: val_loss did not improve from 23.50232
 - 76s - loss: 21.8779 - val_loss: 24.2195
Epoch 32/8000

Epoch 00032: val_loss did not improve from 23.50232
 - 76s - loss: 21.8446 - val_loss: 23.7005
Epoch 33/8000

Epoch 00033: val_loss did not improve from 23.50232
 - 77s - loss: 21.8696 - val_loss: 24.4305
Epoch 34/8000

Epoch 00034: val_loss did not improve from 23.50232
 - 77s - loss: 23.0029 - val_loss: 24.2370
Epoch 35/8000

Epoch 00035: val_loss did not improve from 23.50232
 - 76s - loss: 22.1111 - val_loss: 23.7855
Epoch 36/8000

Epoch 00036: val_loss did not improve from 23.50232
 - 76s - loss: 21.8924 - val_loss: 23.5566
Epoch 37/8000

Epoch 00037: val_loss did not improve from 23.50232
 - 75s - loss: 22.0802 - val_loss: 24.0870
Epoch 38/8000

Epoch 00038: val_loss did not improve from 23.50232
 - 76s - loss: 21.8981 - val_loss: 23.8547
Epoch 39/8000

Epoch 00039: val_loss improved from 23.50232 to 23.46270, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 21.8721 - val_loss: 23.4627
Epoch 40/8000

Epoch 00040: val_loss did not improve from 23.46270
 - 76s - loss: 21.7995 - val_loss: 24.0261
Epoch 41/8000

Epoch 00041: val_loss did not improve from 23.46270
 - 76s - loss: 21.8722 - val_loss: 23.7276
Epoch 42/8000

Epoch 00042: val_loss did not improve from 23.46270
 - 76s - loss: 21.8608 - val_loss: 24.2441
Epoch 43/8000

Epoch 00043: val_loss did not improve from 23.46270
 - 76s - loss: 21.8008 - val_loss: 23.4900
Epoch 44/8000

Epoch 00044: val_loss did not improve from 23.46270
 - 76s - loss: 21.7916 - val_loss: 23.9487
Epoch 45/8000

Epoch 00045: val_loss did not improve from 23.46270
 - 76s - loss: 21.8954 - val_loss: 23.7114
Epoch 46/8000

Epoch 00046: val_loss improved from 23.46270 to 23.39654, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 21.8759 - val_loss: 23.3965
Epoch 47/8000

Epoch 00047: val_loss did not improve from 23.39654
 - 77s - loss: 21.7721 - val_loss: 23.4645
Epoch 48/8000

Epoch 00048: val_loss did not improve from 23.39654
 - 77s - loss: 22.0817 - val_loss: 24.1433
Epoch 49/8000

Epoch 00049: val_loss did not improve from 23.39654
 - 76s - loss: 22.2816 - val_loss: 24.6736
Epoch 50/8000

Epoch 00050: val_loss improved from 23.39654 to 21.43222, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 21.5986 - val_loss: 21.4322
Epoch 51/8000

Epoch 00051: val_loss did not improve from 21.43222
 - 75s - loss: 22.5658 - val_loss: 24.5924
Epoch 52/8000

Epoch 00052: val_loss did not improve from 21.43222
 - 75s - loss: 21.3570 - val_loss: 21.8719
Epoch 53/8000

Epoch 00053: val_loss improved from 21.43222 to 21.26845, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 20.9097 - val_loss: 21.2684
Epoch 54/8000

Epoch 00054: val_loss improved from 21.26845 to 19.96683, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 18.9753 - val_loss: 19.9668
Epoch 55/8000

Epoch 00055: val_loss did not improve from 19.96683
 - 76s - loss: 18.2938 - val_loss: 20.0299
Epoch 56/8000

Epoch 00056: val_loss improved from 19.96683 to 18.55429, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 17.8730 - val_loss: 18.5543
Epoch 57/8000

Epoch 00057: val_loss did not improve from 18.55429
 - 76s - loss: 17.6222 - val_loss: 18.7878
Epoch 58/8000

Epoch 00058: val_loss improved from 18.55429 to 18.39983, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 16.9588 - val_loss: 18.3998
Epoch 59/8000

Epoch 00059: val_loss improved from 18.39983 to 17.76238, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 16.4937 - val_loss: 17.7624
Epoch 60/8000

Epoch 00060: val_loss improved from 17.76238 to 17.38781, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 16.1571 - val_loss: 17.3878
Epoch 61/8000

Epoch 00061: val_loss improved from 17.38781 to 17.20875, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 16.0018 - val_loss: 17.2088
Epoch 62/8000

Epoch 00062: val_loss improved from 17.20875 to 17.08290, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 15.7130 - val_loss: 17.0829
Epoch 63/8000

Epoch 00063: val_loss improved from 17.08290 to 16.64894, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 15.3085 - val_loss: 16.6489
Epoch 64/8000

Epoch 00064: val_loss improved from 16.64894 to 16.28573, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 15.4264 - val_loss: 16.2857
Epoch 65/8000

Epoch 00065: val_loss did not improve from 16.28573
 - 75s - loss: 15.0732 - val_loss: 17.2508
Epoch 66/8000

Epoch 00066: val_loss improved from 16.28573 to 15.66874, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 15.1315 - val_loss: 15.6687
Epoch 67/8000

Epoch 00067: val_loss did not improve from 15.66874
 - 76s - loss: 14.6687 - val_loss: 16.1455
Epoch 68/8000

Epoch 00068: val_loss did not improve from 15.66874
 - 77s - loss: 14.4403 - val_loss: 16.3983
Epoch 69/8000

Epoch 00069: val_loss did not improve from 15.66874
 - 76s - loss: 14.3068 - val_loss: 16.5188
Epoch 70/8000

Epoch 00070: val_loss did not improve from 15.66874
 - 76s - loss: 14.2013 - val_loss: 15.9972
Epoch 71/8000

Epoch 00071: val_loss improved from 15.66874 to 14.97375, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 13.7932 - val_loss: 14.9737
Epoch 72/8000

Epoch 00072: val_loss did not improve from 14.97375
 - 76s - loss: 13.7778 - val_loss: 15.4434
Epoch 73/8000

Epoch 00073: val_loss did not improve from 14.97375
 - 76s - loss: 13.6844 - val_loss: 15.1768
Epoch 74/8000

Epoch 00074: val_loss improved from 14.97375 to 14.04027, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 13.2707 - val_loss: 14.0403
Epoch 75/8000

Epoch 00075: val_loss did not improve from 14.04027
 - 77s - loss: 13.2932 - val_loss: 15.5578
Epoch 76/8000

Epoch 00076: val_loss did not improve from 14.04027
 - 76s - loss: 13.5022 - val_loss: 15.1029
Epoch 77/8000

Epoch 00077: val_loss did not improve from 14.04027
 - 76s - loss: 13.3755 - val_loss: 14.7725
Epoch 78/8000

Epoch 00078: val_loss did not improve from 14.04027
 - 76s - loss: 13.1273 - val_loss: 14.3235
Epoch 79/8000

Epoch 00079: val_loss did not improve from 14.04027
 - 75s - loss: 13.4985 - val_loss: 14.5771
Epoch 80/8000

Epoch 00080: val_loss improved from 14.04027 to 13.82890, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 12.9041 - val_loss: 13.8289
Epoch 81/8000

Epoch 00081: val_loss did not improve from 13.82890
 - 76s - loss: 12.8791 - val_loss: 14.6354
Epoch 82/8000

Epoch 00082: val_loss did not improve from 13.82890
 - 77s - loss: 12.6749 - val_loss: 14.6687
Epoch 83/8000

Epoch 00083: val_loss improved from 13.82890 to 13.82253, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 12.7899 - val_loss: 13.8225
Epoch 84/8000

Epoch 00084: val_loss did not improve from 13.82253
 - 76s - loss: 13.0109 - val_loss: 13.9536
Epoch 85/8000

Epoch 00085: val_loss did not improve from 13.82253
 - 77s - loss: 12.5255 - val_loss: 14.5992
Epoch 86/8000

Epoch 00086: val_loss did not improve from 13.82253
 - 76s - loss: 12.5307 - val_loss: 14.2181
Epoch 87/8000

Epoch 00087: val_loss improved from 13.82253 to 13.56521, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 12.2437 - val_loss: 13.5652
Epoch 88/8000

Epoch 00088: val_loss did not improve from 13.56521
 - 76s - loss: 13.8777 - val_loss: 15.5447
Epoch 89/8000

Epoch 00089: val_loss did not improve from 13.56521
 - 77s - loss: 13.0318 - val_loss: 14.1286
Epoch 90/8000

Epoch 00090: val_loss did not improve from 13.56521
 - 76s - loss: 14.3387 - val_loss: 14.7611
Epoch 91/8000

Epoch 00091: val_loss did not improve from 13.56521
 - 76s - loss: 12.7965 - val_loss: 14.2262
Epoch 92/8000

Epoch 00092: val_loss improved from 13.56521 to 13.49458, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 12.4071 - val_loss: 13.4946
Epoch 93/8000

Epoch 00093: val_loss did not improve from 13.49458
 - 75s - loss: 12.3962 - val_loss: 13.7837
Epoch 94/8000

Epoch 00094: val_loss improved from 13.49458 to 13.26767, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 11.9678 - val_loss: 13.2677
Epoch 95/8000

Epoch 00095: val_loss did not improve from 13.26767
 - 76s - loss: 12.0437 - val_loss: 13.2985
Epoch 96/8000

Epoch 00096: val_loss did not improve from 13.26767
 - 77s - loss: 12.1344 - val_loss: 13.5399
Epoch 97/8000

Epoch 00097: val_loss improved from 13.26767 to 13.07177, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 11.9550 - val_loss: 13.0718
Epoch 98/8000

Epoch 00098: val_loss did not improve from 13.07177
 - 76s - loss: 11.7119 - val_loss: 14.0899
Epoch 99/8000

Epoch 00099: val_loss did not improve from 13.07177
 - 77s - loss: 12.3948 - val_loss: 13.2228
Epoch 100/8000

Epoch 00100: val_loss improved from 13.07177 to 12.89954, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 12.3011 - val_loss: 12.8995
Epoch 101/8000

Epoch 00101: val_loss improved from 12.89954 to 12.81574, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 11.7557 - val_loss: 12.8157
Epoch 102/8000

Epoch 00102: val_loss improved from 12.81574 to 12.41148, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 11.5533 - val_loss: 12.4115
Epoch 103/8000

Epoch 00103: val_loss did not improve from 12.41148
 - 77s - loss: 11.6857 - val_loss: 12.8209
Epoch 104/8000

Epoch 00104: val_loss did not improve from 12.41148
 - 77s - loss: 11.5749 - val_loss: 14.0900
Epoch 105/8000

Epoch 00105: val_loss did not improve from 12.41148
 - 76s - loss: 11.7848 - val_loss: 13.5310
Epoch 106/8000

Epoch 00106: val_loss did not improve from 12.41148
 - 77s - loss: 11.6068 - val_loss: 12.7852
Epoch 107/8000

Epoch 00107: val_loss did not improve from 12.41148
 - 75s - loss: 11.2619 - val_loss: 12.5627
Epoch 108/8000

Epoch 00108: val_loss did not improve from 12.41148
 - 76s - loss: 11.6870 - val_loss: 13.0475
Epoch 109/8000

Epoch 00109: val_loss did not improve from 12.41148
 - 76s - loss: 11.6826 - val_loss: 13.0418
Epoch 110/8000

Epoch 00110: val_loss improved from 12.41148 to 12.36398, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 11.6338 - val_loss: 12.3640
Epoch 111/8000

Epoch 00111: val_loss did not improve from 12.36398
 - 76s - loss: 11.4410 - val_loss: 14.0121
Epoch 112/8000

Epoch 00112: val_loss did not improve from 12.36398
 - 76s - loss: 12.2260 - val_loss: 13.0653
Epoch 113/8000

Epoch 00113: val_loss did not improve from 12.36398
 - 77s - loss: 12.2305 - val_loss: 12.7344
Epoch 114/8000

Epoch 00114: val_loss did not improve from 12.36398
 - 76s - loss: 11.7829 - val_loss: 12.9869
Epoch 115/8000

Epoch 00115: val_loss did not improve from 12.36398
 - 76s - loss: 11.3754 - val_loss: 13.0855
Epoch 116/8000

Epoch 00116: val_loss did not improve from 12.36398
 - 76s - loss: 12.6272 - val_loss: 13.2049
Epoch 117/8000

Epoch 00117: val_loss did not improve from 12.36398
 - 77s - loss: 11.3888 - val_loss: 12.5128
Epoch 118/8000

Epoch 00118: val_loss did not improve from 12.36398
 - 77s - loss: 11.2306 - val_loss: 12.5337
Epoch 119/8000

Epoch 00119: val_loss did not improve from 12.36398
 - 76s - loss: 11.4019 - val_loss: 12.6446
Epoch 120/8000

Epoch 00120: val_loss did not improve from 12.36398
 - 76s - loss: 11.6311 - val_loss: 12.4921
Epoch 121/8000

Epoch 00121: val_loss did not improve from 12.36398
 - 76s - loss: 11.4514 - val_loss: 13.0457
Epoch 122/8000

Epoch 00122: val_loss improved from 12.36398 to 12.19966, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 11.0176 - val_loss: 12.1997
Epoch 123/8000

Epoch 00123: val_loss did not improve from 12.19966
 - 76s - loss: 11.1607 - val_loss: 13.0492
Epoch 124/8000

Epoch 00124: val_loss improved from 12.19966 to 11.89769, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 10.8954 - val_loss: 11.8977
Epoch 125/8000

Epoch 00125: val_loss did not improve from 11.89769
 - 76s - loss: 11.1795 - val_loss: 13.0347
Epoch 126/8000

Epoch 00126: val_loss did not improve from 11.89769
 - 76s - loss: 12.1070 - val_loss: 13.8170
Epoch 127/8000

Epoch 00127: val_loss did not improve from 11.89769
 - 76s - loss: 11.6867 - val_loss: 12.3805
Epoch 128/8000

Epoch 00128: val_loss did not improve from 11.89769
 - 76s - loss: 11.2062 - val_loss: 12.4386
Epoch 129/8000

Epoch 00129: val_loss did not improve from 11.89769
 - 76s - loss: 13.0322 - val_loss: 13.6416
Epoch 130/8000

Epoch 00130: val_loss did not improve from 11.89769
 - 76s - loss: 11.3591 - val_loss: 12.2255
Epoch 131/8000

Epoch 00131: val_loss did not improve from 11.89769
 - 77s - loss: 11.0697 - val_loss: 12.3615
Epoch 132/8000

Epoch 00132: val_loss improved from 11.89769 to 11.82728, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 10.9045 - val_loss: 11.8273
Epoch 133/8000

Epoch 00133: val_loss did not improve from 11.82728
 - 76s - loss: 10.9632 - val_loss: 12.0371
Epoch 134/8000

Epoch 00134: val_loss improved from 11.82728 to 11.56305, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 10.7788 - val_loss: 11.5630
Epoch 135/8000

Epoch 00135: val_loss did not improve from 11.56305
 - 75s - loss: 10.9348 - val_loss: 11.7383
Epoch 136/8000

Epoch 00136: val_loss did not improve from 11.56305
 - 76s - loss: 10.7102 - val_loss: 13.0067
Epoch 137/8000

Epoch 00137: val_loss did not improve from 11.56305
 - 76s - loss: 11.3001 - val_loss: 12.0293
Epoch 138/8000

Epoch 00138: val_loss did not improve from 11.56305
 - 77s - loss: 10.9640 - val_loss: 11.7858
Epoch 139/8000

Epoch 00139: val_loss did not improve from 11.56305
 - 76s - loss: 10.8376 - val_loss: 12.4043
Epoch 140/8000

Epoch 00140: val_loss did not improve from 11.56305
 - 76s - loss: 11.2005 - val_loss: 12.5185
Epoch 141/8000

Epoch 00141: val_loss did not improve from 11.56305
 - 77s - loss: 11.1649 - val_loss: 11.8563
Epoch 142/8000

Epoch 00142: val_loss did not improve from 11.56305
 - 76s - loss: 11.1628 - val_loss: 12.0949
Epoch 143/8000

Epoch 00143: val_loss did not improve from 11.56305
 - 76s - loss: 11.2743 - val_loss: 13.0645
Epoch 144/8000

Epoch 00144: val_loss did not improve from 11.56305
 - 76s - loss: 11.1140 - val_loss: 12.2174
Epoch 145/8000

Epoch 00145: val_loss did not improve from 11.56305
 - 77s - loss: 10.9398 - val_loss: 11.8997
Epoch 146/8000

Epoch 00146: val_loss did not improve from 11.56305
 - 76s - loss: 10.9542 - val_loss: 12.4635
Epoch 147/8000

Epoch 00147: val_loss did not improve from 11.56305
 - 76s - loss: 10.7118 - val_loss: 11.5916
Epoch 148/8000

Epoch 00148: val_loss improved from 11.56305 to 11.49841, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 10.5518 - val_loss: 11.4984
Epoch 149/8000

Epoch 00149: val_loss did not improve from 11.49841
 - 75s - loss: 10.3044 - val_loss: 11.6634
Epoch 150/8000

Epoch 00150: val_loss did not improve from 11.49841
 - 76s - loss: 10.5917 - val_loss: 11.6348
Epoch 151/8000

Epoch 00151: val_loss did not improve from 11.49841
 - 76s - loss: 10.6385 - val_loss: 12.1051
Epoch 152/8000

Epoch 00152: val_loss did not improve from 11.49841
 - 77s - loss: 10.5963 - val_loss: 12.4906
Epoch 153/8000

Epoch 00153: val_loss did not improve from 11.49841
 - 76s - loss: 10.5618 - val_loss: 12.1365
Epoch 154/8000

Epoch 00154: val_loss did not improve from 11.49841
 - 76s - loss: 10.4240 - val_loss: 11.7340
Epoch 155/8000

Epoch 00155: val_loss did not improve from 11.49841
 - 77s - loss: 10.4209 - val_loss: 12.1674
Epoch 156/8000

Epoch 00156: val_loss improved from 11.49841 to 11.19740, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 10.0892 - val_loss: 11.1974
Epoch 157/8000

Epoch 00157: val_loss did not improve from 11.19740
 - 76s - loss: 10.1626 - val_loss: 11.6857
Epoch 158/8000

Epoch 00158: val_loss did not improve from 11.19740
 - 76s - loss: 11.1297 - val_loss: 11.5701
Epoch 159/8000

Epoch 00159: val_loss did not improve from 11.19740
 - 77s - loss: 10.3619 - val_loss: 12.0938
Epoch 160/8000

Epoch 00160: val_loss improved from 11.19740 to 11.12019, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 10.2831 - val_loss: 11.1202
Epoch 161/8000

Epoch 00161: val_loss did not improve from 11.12019
 - 76s - loss: 10.3152 - val_loss: 12.6100
Epoch 162/8000

Epoch 00162: val_loss did not improve from 11.12019
 - 76s - loss: 11.0810 - val_loss: 11.8644
Epoch 163/8000

Epoch 00163: val_loss did not improve from 11.12019
 - 76s - loss: 10.3066 - val_loss: 11.1628
Epoch 164/8000

Epoch 00164: val_loss did not improve from 11.12019
 - 76s - loss: 11.7264 - val_loss: 12.2925
Epoch 165/8000

Epoch 00165: val_loss did not improve from 11.12019
 - 76s - loss: 10.7131 - val_loss: 12.3847
Epoch 166/8000

Epoch 00166: val_loss did not improve from 11.12019
 - 77s - loss: 13.0549 - val_loss: 14.7203
Epoch 167/8000

Epoch 00167: val_loss did not improve from 11.12019
 - 77s - loss: 11.8019 - val_loss: 12.2029
Epoch 168/8000

Epoch 00168: val_loss did not improve from 11.12019
 - 76s - loss: 10.7372 - val_loss: 11.4641
Epoch 169/8000

Epoch 00169: val_loss did not improve from 11.12019
 - 77s - loss: 10.8902 - val_loss: 12.1572
Epoch 170/8000

Epoch 00170: val_loss did not improve from 11.12019
 - 76s - loss: 14.0815 - val_loss: 14.2436
Epoch 171/8000

Epoch 00171: val_loss did not improve from 11.12019
 - 76s - loss: 12.0576 - val_loss: 12.9310
Epoch 172/8000

Epoch 00172: val_loss did not improve from 11.12019
 - 76s - loss: 11.1909 - val_loss: 11.8954
Epoch 173/8000

Epoch 00173: val_loss did not improve from 11.12019
 - 77s - loss: 10.8698 - val_loss: 11.8671
Epoch 174/8000

Epoch 00174: val_loss did not improve from 11.12019
 - 76s - loss: 10.9020 - val_loss: 11.6683
Epoch 175/8000

Epoch 00175: val_loss did not improve from 11.12019
 - 76s - loss: 10.3056 - val_loss: 12.2217
Epoch 176/8000

Epoch 00176: val_loss did not improve from 11.12019
 - 76s - loss: 10.4354 - val_loss: 11.3789
Epoch 177/8000

Epoch 00177: val_loss did not improve from 11.12019
 - 76s - loss: 10.2245 - val_loss: 11.5302
Epoch 178/8000

Epoch 00178: val_loss did not improve from 11.12019
 - 76s - loss: 10.2409 - val_loss: 13.2114
Epoch 179/8000

Epoch 00179: val_loss did not improve from 11.12019
 - 76s - loss: 10.7961 - val_loss: 11.4035
Epoch 180/8000

Epoch 00180: val_loss did not improve from 11.12019
 - 77s - loss: 10.0754 - val_loss: 11.3813
Epoch 181/8000

Epoch 00181: val_loss did not improve from 11.12019
 - 77s - loss: 10.0641 - val_loss: 11.1677
Epoch 182/8000

Epoch 00182: val_loss improved from 11.12019 to 10.60534, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 9.9938 - val_loss: 10.6053
Epoch 183/8000

Epoch 00183: val_loss improved from 10.60534 to 10.47457, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 10.1187 - val_loss: 10.4746
Epoch 184/8000

Epoch 00184: val_loss did not improve from 10.47457
 - 76s - loss: 9.6933 - val_loss: 11.4301
Epoch 185/8000

Epoch 00185: val_loss did not improve from 10.47457
 - 76s - loss: 10.1122 - val_loss: 10.8090
Epoch 186/8000

Epoch 00186: val_loss did not improve from 10.47457
 - 76s - loss: 9.7044 - val_loss: 10.5972
Epoch 187/8000

Epoch 00187: val_loss did not improve from 10.47457
 - 76s - loss: 11.3335 - val_loss: 11.1484
Epoch 188/8000

Epoch 00188: val_loss did not improve from 10.47457
 - 76s - loss: 9.9487 - val_loss: 11.5696
Epoch 189/8000

Epoch 00189: val_loss did not improve from 10.47457
 - 76s - loss: 10.2640 - val_loss: 12.1508
Epoch 190/8000

Epoch 00190: val_loss did not improve from 10.47457
 - 76s - loss: 10.0381 - val_loss: 11.2536
Epoch 191/8000

Epoch 00191: val_loss did not improve from 10.47457
 - 75s - loss: 9.6499 - val_loss: 11.8893
Epoch 192/8000

Epoch 00192: val_loss did not improve from 10.47457
 - 76s - loss: 10.0800 - val_loss: 12.4975
Epoch 193/8000

Epoch 00193: val_loss did not improve from 10.47457
 - 76s - loss: 10.0574 - val_loss: 10.7309
Epoch 194/8000

Epoch 00194: val_loss did not improve from 10.47457
 - 77s - loss: 9.5516 - val_loss: 10.6643
Epoch 195/8000

Epoch 00195: val_loss improved from 10.47457 to 10.16385, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 9.5091 - val_loss: 10.1638
Epoch 196/8000

Epoch 00196: val_loss did not improve from 10.16385
 - 76s - loss: 9.4873 - val_loss: 10.6203
Epoch 197/8000

Epoch 00197: val_loss did not improve from 10.16385
 - 77s - loss: 9.4918 - val_loss: 11.4641
Epoch 198/8000

Epoch 00198: val_loss did not improve from 10.16385
 - 76s - loss: 9.8509 - val_loss: 14.6573
Epoch 199/8000

Epoch 00199: val_loss did not improve from 10.16385
 - 76s - loss: 10.8179 - val_loss: 11.0538
Epoch 200/8000

Epoch 00200: val_loss did not improve from 10.16385
 - 76s - loss: 9.9925 - val_loss: 11.8139
Epoch 201/8000

Epoch 00201: val_loss did not improve from 10.16385
 - 77s - loss: 9.5167 - val_loss: 10.2629
Epoch 202/8000

Epoch 00202: val_loss did not improve from 10.16385
 - 76s - loss: 9.3617 - val_loss: 10.3666
Epoch 203/8000

Epoch 00203: val_loss did not improve from 10.16385
 - 76s - loss: 9.5487 - val_loss: 12.1450
Epoch 204/8000

Epoch 00204: val_loss did not improve from 10.16385
 - 76s - loss: 9.8884 - val_loss: 10.3631
Epoch 205/8000

Epoch 00205: val_loss did not improve from 10.16385
 - 76s - loss: 9.2254 - val_loss: 10.5116
Epoch 206/8000

Epoch 00206: val_loss improved from 10.16385 to 10.10819, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 9.3023 - val_loss: 10.1082
Epoch 207/8000

Epoch 00207: val_loss did not improve from 10.10819
 - 76s - loss: 9.4327 - val_loss: 10.8273
Epoch 208/8000

Epoch 00208: val_loss did not improve from 10.10819
 - 77s - loss: 9.3745 - val_loss: 10.7312
Epoch 209/8000

Epoch 00209: val_loss did not improve from 10.10819
 - 76s - loss: 9.7023 - val_loss: 10.8955
Epoch 210/8000

Epoch 00210: val_loss did not improve from 10.10819
 - 76s - loss: 9.5070 - val_loss: 10.9443
Epoch 211/8000

Epoch 00211: val_loss did not improve from 10.10819
 - 76s - loss: 9.4919 - val_loss: 11.1328
Epoch 212/8000

Epoch 00212: val_loss did not improve from 10.10819
 - 76s - loss: 9.4290 - val_loss: 10.2127
Epoch 213/8000

Epoch 00213: val_loss did not improve from 10.10819
 - 76s - loss: 8.7776 - val_loss: 10.1155
Epoch 214/8000

Epoch 00214: val_loss did not improve from 10.10819
 - 76s - loss: 9.9461 - val_loss: 11.3832
Epoch 215/8000

Epoch 00215: val_loss did not improve from 10.10819
 - 77s - loss: 9.7087 - val_loss: 10.6294
Epoch 216/8000

Epoch 00216: val_loss did not improve from 10.10819
 - 76s - loss: 10.1955 - val_loss: 13.1616
Epoch 217/8000

Epoch 00217: val_loss did not improve from 10.10819
 - 76s - loss: 10.2648 - val_loss: 10.6206
Epoch 218/8000

Epoch 00218: val_loss did not improve from 10.10819
 - 76s - loss: 9.3896 - val_loss: 10.7915
Epoch 219/8000

Epoch 00219: val_loss did not improve from 10.10819
 - 75s - loss: 9.5415 - val_loss: 10.6825
Epoch 220/8000

Epoch 00220: val_loss did not improve from 10.10819
 - 76s - loss: 11.8600 - val_loss: 12.8370
Epoch 221/8000

Epoch 00221: val_loss did not improve from 10.10819
 - 76s - loss: 10.8639 - val_loss: 11.1515
Epoch 222/8000

Epoch 00222: val_loss did not improve from 10.10819
 - 77s - loss: 9.5812 - val_loss: 11.1585
Epoch 223/8000

Epoch 00223: val_loss did not improve from 10.10819
 - 76s - loss: 9.4369 - val_loss: 10.9854
Epoch 224/8000

Epoch 00224: val_loss did not improve from 10.10819
 - 76s - loss: 9.3496 - val_loss: 12.4698
Epoch 225/8000

Epoch 00225: val_loss did not improve from 10.10819
 - 77s - loss: 11.4234 - val_loss: 12.3877
Epoch 226/8000

Epoch 00226: val_loss did not improve from 10.10819
 - 76s - loss: 10.4821 - val_loss: 10.2661
Epoch 227/8000

Epoch 00227: val_loss did not improve from 10.10819
 - 76s - loss: 11.7735 - val_loss: 13.5682
Epoch 228/8000

Epoch 00228: val_loss did not improve from 10.10819
 - 76s - loss: 10.9419 - val_loss: 10.5364
Epoch 229/8000

Epoch 00229: val_loss did not improve from 10.10819
 - 77s - loss: 10.0854 - val_loss: 13.3739
Epoch 230/8000

Epoch 00230: val_loss did not improve from 10.10819
 - 76s - loss: 11.2346 - val_loss: 17.0263
Epoch 231/8000

Epoch 00231: val_loss did not improve from 10.10819
 - 76s - loss: 12.0420 - val_loss: 12.4863
Epoch 232/8000

Epoch 00232: val_loss did not improve from 10.10819
 - 76s - loss: 10.4623 - val_loss: 11.5152
Epoch 233/8000

Epoch 00233: val_loss did not improve from 10.10819
 - 75s - loss: 10.3652 - val_loss: 11.4688
Epoch 234/8000

Epoch 00234: val_loss did not improve from 10.10819
 - 76s - loss: 9.6296 - val_loss: 10.7834
Epoch 235/8000

Epoch 00235: val_loss did not improve from 10.10819
 - 76s - loss: 9.3405 - val_loss: 11.3317
Epoch 236/8000

Epoch 00236: val_loss did not improve from 10.10819
 - 77s - loss: 9.7227 - val_loss: 12.4772
Epoch 237/8000

Epoch 00237: val_loss improved from 10.10819 to 9.94989, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 9.3130 - val_loss: 9.9499
Epoch 238/8000

Epoch 00238: val_loss did not improve from 9.94989
 - 76s - loss: 9.2662 - val_loss: 10.6133
Epoch 239/8000

Epoch 00239: val_loss did not improve from 9.94989
 - 76s - loss: 10.4202 - val_loss: 11.6204
Epoch 240/8000

Epoch 00240: val_loss did not improve from 9.94989
 - 76s - loss: 10.2911 - val_loss: 12.7269
Epoch 241/8000

Epoch 00241: val_loss did not improve from 9.94989
 - 76s - loss: 10.8197 - val_loss: 12.2870
Epoch 242/8000

Epoch 00242: val_loss did not improve from 9.94989
 - 76s - loss: 11.6968 - val_loss: 13.3289
Epoch 243/8000

Epoch 00243: val_loss did not improve from 9.94989
 - 77s - loss: 11.0152 - val_loss: 12.1959
Epoch 244/8000

Epoch 00244: val_loss did not improve from 9.94989
 - 76s - loss: 11.5096 - val_loss: 14.3105
Epoch 245/8000

Epoch 00245: val_loss did not improve from 9.94989
 - 76s - loss: 10.9690 - val_loss: 12.2105
Epoch 246/8000

Epoch 00246: val_loss did not improve from 9.94989
 - 76s - loss: 10.8398 - val_loss: 12.4280
Epoch 247/8000

Epoch 00247: val_loss did not improve from 9.94989
 - 76s - loss: 11.3841 - val_loss: 12.5588
Epoch 248/8000

Epoch 00248: val_loss did not improve from 9.94989
 - 76s - loss: 10.6708 - val_loss: 11.4106
Epoch 249/8000

Epoch 00249: val_loss did not improve from 9.94989
 - 76s - loss: 10.1196 - val_loss: 10.9193
Epoch 250/8000

Epoch 00250: val_loss did not improve from 9.94989
 - 77s - loss: 10.1360 - val_loss: 10.4299
Epoch 251/8000

Epoch 00251: val_loss did not improve from 9.94989
 - 76s - loss: 9.3757 - val_loss: 10.3001
Epoch 252/8000

Epoch 00252: val_loss improved from 9.94989 to 9.51702, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 9.0931 - val_loss: 9.5170
Epoch 253/8000

Epoch 00253: val_loss did not improve from 9.51702
 - 77s - loss: 9.8051 - val_loss: 10.6339
Epoch 254/8000

Epoch 00254: val_loss did not improve from 9.51702
 - 76s - loss: 8.9638 - val_loss: 9.8690
Epoch 255/8000

Epoch 00255: val_loss did not improve from 9.51702
 - 76s - loss: 9.1814 - val_loss: 10.5937
Epoch 256/8000

Epoch 00256: val_loss improved from 9.51702 to 9.44101, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 8.8422 - val_loss: 9.4410
Epoch 257/8000

Epoch 00257: val_loss did not improve from 9.44101
 - 77s - loss: 8.9445 - val_loss: 10.4985
Epoch 258/8000

Epoch 00258: val_loss did not improve from 9.44101
 - 76s - loss: 9.1423 - val_loss: 9.7823
Epoch 259/8000

Epoch 00259: val_loss did not improve from 9.44101
 - 76s - loss: 8.8875 - val_loss: 10.5575
Epoch 260/8000

Epoch 00260: val_loss improved from 9.44101 to 9.15078, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 8.8031 - val_loss: 9.1508
Epoch 261/8000

Epoch 00261: val_loss did not improve from 9.15078
 - 76s - loss: 10.0730 - val_loss: 10.3471
Epoch 262/8000

Epoch 00262: val_loss did not improve from 9.15078
 - 76s - loss: 8.7337 - val_loss: 9.5406
Epoch 263/8000

Epoch 00263: val_loss did not improve from 9.15078
 - 76s - loss: 10.0635 - val_loss: 10.0394
Epoch 264/8000

Epoch 00264: val_loss did not improve from 9.15078
 - 77s - loss: 8.8387 - val_loss: 9.2568
Epoch 265/8000

Epoch 00265: val_loss did not improve from 9.15078
 - 77s - loss: 8.7674 - val_loss: 9.9131
Epoch 266/8000

Epoch 00266: val_loss did not improve from 9.15078
 - 76s - loss: 8.7283 - val_loss: 9.3383
Epoch 267/8000

Epoch 00267: val_loss improved from 9.15078 to 8.94963, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 8.3065 - val_loss: 8.9496
Epoch 268/8000

Epoch 00268: val_loss did not improve from 8.94963
 - 76s - loss: 8.4981 - val_loss: 9.4668
Epoch 269/8000

Epoch 00269: val_loss did not improve from 8.94963
 - 76s - loss: 8.4686 - val_loss: 9.5383
Epoch 270/8000

Epoch 00270: val_loss did not improve from 8.94963
 - 76s - loss: 10.6332 - val_loss: 11.3851
Epoch 271/8000

Epoch 00271: val_loss did not improve from 8.94963
 - 76s - loss: 10.9605 - val_loss: 11.7646
Epoch 272/8000

Epoch 00272: val_loss did not improve from 8.94963
 - 76s - loss: 10.4934 - val_loss: 10.5722
Epoch 273/8000

Epoch 00273: val_loss did not improve from 8.94963
 - 76s - loss: 9.0053 - val_loss: 9.4967
Epoch 274/8000

Epoch 00274: val_loss did not improve from 8.94963
 - 76s - loss: 9.0300 - val_loss: 11.9504
Epoch 275/8000

Epoch 00275: val_loss did not improve from 8.94963
 - 76s - loss: 9.0891 - val_loss: 11.8609
Epoch 276/8000

Epoch 00276: val_loss did not improve from 8.94963
 - 76s - loss: 10.7972 - val_loss: 14.2581
Epoch 277/8000

Epoch 00277: val_loss did not improve from 8.94963
 - 76s - loss: 10.7377 - val_loss: 11.6257
Epoch 278/8000

Epoch 00278: val_loss did not improve from 8.94963
 - 77s - loss: 10.2914 - val_loss: 10.6880
Epoch 279/8000

Epoch 00279: val_loss did not improve from 8.94963
 - 77s - loss: 9.1663 - val_loss: 10.9517
Epoch 280/8000

Epoch 00280: val_loss did not improve from 8.94963
 - 76s - loss: 8.6350 - val_loss: 9.4346
Epoch 281/8000

Epoch 00281: val_loss did not improve from 8.94963
 - 76s - loss: 10.4721 - val_loss: 10.7448
Epoch 282/8000

Epoch 00282: val_loss did not improve from 8.94963
 - 76s - loss: 9.4930 - val_loss: 9.8713
Epoch 283/8000

Epoch 00283: val_loss did not improve from 8.94963
 - 76s - loss: 8.9354 - val_loss: 10.0117
Epoch 284/8000

Epoch 00284: val_loss did not improve from 8.94963
 - 76s - loss: 8.6989 - val_loss: 9.0912
Epoch 285/8000

Epoch 00285: val_loss did not improve from 8.94963
 - 76s - loss: 8.5535 - val_loss: 9.0232
Epoch 286/8000

Epoch 00286: val_loss did not improve from 8.94963
 - 76s - loss: 8.4472 - val_loss: 9.8866
Epoch 287/8000

Epoch 00287: val_loss did not improve from 8.94963
 - 76s - loss: 8.3537 - val_loss: 10.2668
Epoch 288/8000

Epoch 00288: val_loss did not improve from 8.94963
 - 76s - loss: 9.6647 - val_loss: 9.8336
Epoch 289/8000

Epoch 00289: val_loss did not improve from 8.94963
 - 76s - loss: 8.5580 - val_loss: 9.7729
Epoch 290/8000

Epoch 00290: val_loss did not improve from 8.94963
 - 76s - loss: 8.1997 - val_loss: 9.3338
Epoch 291/8000

Epoch 00291: val_loss did not improve from 8.94963
 - 76s - loss: 8.3866 - val_loss: 9.2003
Epoch 292/8000

Epoch 00292: val_loss did not improve from 8.94963
 - 77s - loss: 8.3676 - val_loss: 9.3795
Epoch 293/8000

Epoch 00293: val_loss did not improve from 8.94963
 - 76s - loss: 10.6408 - val_loss: 11.7288
Epoch 294/8000

Epoch 00294: val_loss did not improve from 8.94963
 - 76s - loss: 8.8545 - val_loss: 9.4430
Epoch 295/8000

Epoch 00295: val_loss improved from 8.94963 to 8.87667, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 8.3874 - val_loss: 8.8767
Epoch 296/8000

Epoch 00296: val_loss did not improve from 8.87667
 - 76s - loss: 8.5454 - val_loss: 9.3360
Epoch 297/8000

Epoch 00297: val_loss did not improve from 8.87667
 - 76s - loss: 8.2543 - val_loss: 8.9934
Epoch 298/8000

Epoch 00298: val_loss improved from 8.87667 to 8.86399, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 7.7740 - val_loss: 8.8640
Epoch 299/8000

Epoch 00299: val_loss improved from 8.86399 to 8.56404, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 8.3378 - val_loss: 8.5640
Epoch 300/8000

Epoch 00300: val_loss did not improve from 8.56404
 - 76s - loss: 8.3323 - val_loss: 9.2327
Epoch 301/8000

Epoch 00301: val_loss did not improve from 8.56404
 - 76s - loss: 7.9584 - val_loss: 9.2971
Epoch 302/8000

Epoch 00302: val_loss improved from 8.56404 to 8.19449, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 7.7904 - val_loss: 8.1945
Epoch 303/8000

Epoch 00303: val_loss did not improve from 8.19449
 - 75s - loss: 7.7318 - val_loss: 8.7846
Epoch 304/8000

Epoch 00304: val_loss did not improve from 8.19449
 - 76s - loss: 7.6965 - val_loss: 8.5633
Epoch 305/8000

Epoch 00305: val_loss did not improve from 8.19449
 - 76s - loss: 7.8889 - val_loss: 8.3722
Epoch 306/8000

Epoch 00306: val_loss did not improve from 8.19449
 - 77s - loss: 7.9289 - val_loss: 9.0368
Epoch 307/8000

Epoch 00307: val_loss did not improve from 8.19449
 - 76s - loss: 8.3506 - val_loss: 9.6602
Epoch 308/8000

Epoch 00308: val_loss did not improve from 8.19449
 - 76s - loss: 11.2132 - val_loss: 16.6819
Epoch 309/8000

Epoch 00309: val_loss did not improve from 8.19449
 - 76s - loss: 12.6300 - val_loss: 12.6914
Epoch 310/8000

Epoch 00310: val_loss did not improve from 8.19449
 - 76s - loss: 10.8541 - val_loss: 11.6346
Epoch 311/8000

Epoch 00311: val_loss did not improve from 8.19449
 - 76s - loss: 10.1565 - val_loss: 11.8188
Epoch 312/8000

Epoch 00312: val_loss did not improve from 8.19449
 - 76s - loss: 10.7636 - val_loss: 11.4351
Epoch 313/8000

Epoch 00313: val_loss did not improve from 8.19449
 - 77s - loss: 9.1388 - val_loss: 11.2985
Epoch 314/8000

Epoch 00314: val_loss did not improve from 8.19449
 - 76s - loss: 9.0022 - val_loss: 11.2088
Epoch 315/8000

Epoch 00315: val_loss did not improve from 8.19449
 - 76s - loss: 9.0169 - val_loss: 10.9665
Epoch 316/8000

Epoch 00316: val_loss did not improve from 8.19449
 - 76s - loss: 8.4786 - val_loss: 11.5929
Epoch 317/8000

Epoch 00317: val_loss did not improve from 8.19449
 - 75s - loss: 9.0686 - val_loss: 11.3874
Epoch 318/8000

Epoch 00318: val_loss did not improve from 8.19449
 - 76s - loss: 9.6745 - val_loss: 9.3400
Epoch 319/8000

Epoch 00319: val_loss did not improve from 8.19449
 - 76s - loss: 8.9923 - val_loss: 11.3612
Epoch 320/8000

Epoch 00320: val_loss did not improve from 8.19449
 - 77s - loss: 9.2607 - val_loss: 9.4272
Epoch 321/8000

Epoch 00321: val_loss did not improve from 8.19449
 - 76s - loss: 8.6848 - val_loss: 9.2096
Epoch 322/8000

Epoch 00322: val_loss did not improve from 8.19449
 - 76s - loss: 8.6012 - val_loss: 13.0545
Epoch 323/8000

Epoch 00323: val_loss did not improve from 8.19449
 - 77s - loss: 8.8323 - val_loss: 9.1831
Epoch 324/8000

Epoch 00324: val_loss did not improve from 8.19449
 - 76s - loss: 10.3091 - val_loss: 10.2203
Epoch 325/8000

Epoch 00325: val_loss did not improve from 8.19449
 - 76s - loss: 9.7523 - val_loss: 9.7700
Epoch 326/8000

Epoch 00326: val_loss did not improve from 8.19449
 - 76s - loss: 8.9360 - val_loss: 10.1839
Epoch 327/8000

Epoch 00327: val_loss did not improve from 8.19449
 - 77s - loss: 9.0994 - val_loss: 11.3854
Epoch 328/8000

Epoch 00328: val_loss did not improve from 8.19449
 - 76s - loss: 9.5391 - val_loss: 8.6981
Epoch 329/8000

Epoch 00329: val_loss did not improve from 8.19449
 - 76s - loss: 10.1972 - val_loss: 13.2196
Epoch 330/8000

Epoch 00330: val_loss did not improve from 8.19449
 - 76s - loss: 10.2970 - val_loss: 11.0622
Epoch 331/8000

Epoch 00331: val_loss did not improve from 8.19449
 - 75s - loss: 8.8236 - val_loss: 9.5112
Epoch 332/8000

Epoch 00332: val_loss did not improve from 8.19449
 - 76s - loss: 8.7313 - val_loss: 9.0715
Epoch 333/8000

Epoch 00333: val_loss did not improve from 8.19449
 - 76s - loss: 8.4437 - val_loss: 9.0991
Epoch 334/8000

Epoch 00334: val_loss did not improve from 8.19449
 - 77s - loss: 8.3885 - val_loss: 8.8729
Epoch 335/8000

Epoch 00335: val_loss did not improve from 8.19449
 - 76s - loss: 8.1828 - val_loss: 9.5895
Epoch 336/8000

Epoch 00336: val_loss did not improve from 8.19449
 - 76s - loss: 8.7347 - val_loss: 9.3525
Epoch 337/8000

Epoch 00337: val_loss did not improve from 8.19449
 - 76s - loss: 8.7530 - val_loss: 10.5606
Epoch 338/8000

Epoch 00338: val_loss did not improve from 8.19449
 - 76s - loss: 8.3559 - val_loss: 9.0189
Epoch 339/8000

Epoch 00339: val_loss did not improve from 8.19449
 - 76s - loss: 7.8010 - val_loss: 9.4120
Epoch 340/8000

Epoch 00340: val_loss did not improve from 8.19449
 - 76s - loss: 8.3439 - val_loss: 9.0481
Epoch 341/8000

Epoch 00341: val_loss did not improve from 8.19449
 - 77s - loss: 9.6974 - val_loss: 10.3821
Epoch 342/8000

Epoch 00342: val_loss did not improve from 8.19449
 - 76s - loss: 9.0647 - val_loss: 9.4873
Epoch 343/8000

Epoch 00343: val_loss did not improve from 8.19449
 - 76s - loss: 8.7571 - val_loss: 9.9850
Epoch 344/8000

Epoch 00344: val_loss did not improve from 8.19449
 - 76s - loss: 8.8174 - val_loss: 10.5116
Epoch 345/8000

Epoch 00345: val_loss did not improve from 8.19449
 - 76s - loss: 8.6969 - val_loss: 9.5387
Epoch 346/8000

Epoch 00346: val_loss did not improve from 8.19449
 - 76s - loss: 8.2549 - val_loss: 8.9067
Epoch 347/8000

Epoch 00347: val_loss did not improve from 8.19449
 - 76s - loss: 8.2360 - val_loss: 8.5971
Epoch 348/8000

Epoch 00348: val_loss did not improve from 8.19449
 - 77s - loss: 8.2615 - val_loss: 10.2815
Epoch 349/8000

Epoch 00349: val_loss did not improve from 8.19449
 - 76s - loss: 8.6315 - val_loss: 9.3322
Epoch 350/8000

Epoch 00350: val_loss did not improve from 8.19449
 - 76s - loss: 8.1110 - val_loss: 8.9448
Epoch 351/8000

Epoch 00351: val_loss did not improve from 8.19449
 - 77s - loss: 8.0819 - val_loss: 10.7416
Epoch 352/8000

Epoch 00352: val_loss did not improve from 8.19449
 - 76s - loss: 8.3668 - val_loss: 9.0270
Epoch 353/8000

Epoch 00353: val_loss did not improve from 8.19449
 - 76s - loss: 8.1395 - val_loss: 8.6709
Epoch 354/8000

Epoch 00354: val_loss did not improve from 8.19449
 - 76s - loss: 8.1359 - val_loss: 9.2373
Epoch 355/8000

Epoch 00355: val_loss did not improve from 8.19449
 - 77s - loss: 8.0855 - val_loss: 8.9494
Epoch 356/8000

Epoch 00356: val_loss did not improve from 8.19449
 - 76s - loss: 7.9259 - val_loss: 8.6164
Epoch 357/8000

Epoch 00357: val_loss did not improve from 8.19449
 - 76s - loss: 8.0874 - val_loss: 8.5312
Epoch 358/8000

Epoch 00358: val_loss did not improve from 8.19449
 - 76s - loss: 8.0998 - val_loss: 8.9575
Epoch 359/8000

Epoch 00359: val_loss did not improve from 8.19449
 - 76s - loss: 7.9440 - val_loss: 9.1725
Epoch 360/8000

Epoch 00360: val_loss did not improve from 8.19449
 - 76s - loss: 8.1950 - val_loss: 9.7835
Epoch 361/8000

Epoch 00361: val_loss did not improve from 8.19449
 - 76s - loss: 8.0348 - val_loss: 8.8411
Epoch 362/8000

Epoch 00362: val_loss did not improve from 8.19449
 - 77s - loss: 7.9101 - val_loss: 8.8382
Epoch 363/8000

Epoch 00363: val_loss did not improve from 8.19449
 - 76s - loss: 7.7773 - val_loss: 9.3203
Epoch 364/8000

Epoch 00364: val_loss did not improve from 8.19449
 - 76s - loss: 7.9423 - val_loss: 8.6240
Epoch 365/8000

Epoch 00365: val_loss did not improve from 8.19449
 - 77s - loss: 8.3409 - val_loss: 11.0255
Epoch 366/8000

Epoch 00366: val_loss did not improve from 8.19449
 - 76s - loss: 8.4984 - val_loss: 9.5878
Epoch 367/8000

Epoch 00367: val_loss did not improve from 8.19449
 - 76s - loss: 8.4397 - val_loss: 8.8503
Epoch 368/8000

Epoch 00368: val_loss did not improve from 8.19449
 - 76s - loss: 9.9979 - val_loss: 10.7955
Epoch 369/8000

Epoch 00369: val_loss did not improve from 8.19449
 - 76s - loss: 10.1516 - val_loss: 11.2470
Epoch 370/8000

Epoch 00370: val_loss did not improve from 8.19449
 - 76s - loss: 9.8725 - val_loss: 10.9515
Epoch 371/8000

Epoch 00371: val_loss did not improve from 8.19449
 - 76s - loss: 8.7915 - val_loss: 9.8652
Epoch 372/8000

Epoch 00372: val_loss did not improve from 8.19449
 - 76s - loss: 8.2003 - val_loss: 9.2396
Epoch 373/8000

Epoch 00373: val_loss did not improve from 8.19449
 - 76s - loss: 7.7495 - val_loss: 8.9981
Epoch 374/8000

Epoch 00374: val_loss did not improve from 8.19449
 - 76s - loss: 7.6129 - val_loss: 8.4630
Epoch 375/8000

Epoch 00375: val_loss did not improve from 8.19449
 - 76s - loss: 7.8137 - val_loss: 9.5332
Epoch 376/8000

Epoch 00376: val_loss did not improve from 8.19449
 - 77s - loss: 8.2555 - val_loss: 9.2853
Epoch 377/8000

Epoch 00377: val_loss did not improve from 8.19449
 - 76s - loss: 7.8238 - val_loss: 10.4476
Epoch 378/8000

Epoch 00378: val_loss did not improve from 8.19449
 - 76s - loss: 7.6203 - val_loss: 9.8306
Epoch 379/8000

Epoch 00379: val_loss did not improve from 8.19449
 - 77s - loss: 7.7599 - val_loss: 9.2499
Epoch 380/8000

Epoch 00380: val_loss did not improve from 8.19449
 - 76s - loss: 7.7575 - val_loss: 9.1239
Epoch 381/8000

Epoch 00381: val_loss did not improve from 8.19449
 - 76s - loss: 8.2165 - val_loss: 9.0260
Epoch 382/8000

Epoch 00382: val_loss did not improve from 8.19449
 - 76s - loss: 7.9288 - val_loss: 8.8241
Epoch 383/8000

Epoch 00383: val_loss did not improve from 8.19449
 - 76s - loss: 7.4166 - val_loss: 9.8164
Epoch 384/8000

Epoch 00384: val_loss did not improve from 8.19449
 - 76s - loss: 7.6730 - val_loss: 8.4714
Epoch 385/8000

Epoch 00385: val_loss did not improve from 8.19449
 - 76s - loss: 7.6352 - val_loss: 8.2778
Epoch 386/8000

Epoch 00386: val_loss did not improve from 8.19449
 - 76s - loss: 7.5510 - val_loss: 8.3532
Epoch 387/8000

Epoch 00387: val_loss did not improve from 8.19449
 - 76s - loss: 7.2423 - val_loss: 9.3879
Epoch 388/8000

Epoch 00388: val_loss did not improve from 8.19449
 - 76s - loss: 7.5684 - val_loss: 8.2918
Epoch 389/8000

Epoch 00389: val_loss improved from 8.19449 to 8.00345, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 7.3805 - val_loss: 8.0034
Epoch 390/8000

Epoch 00390: val_loss did not improve from 8.00345
 - 77s - loss: 7.5529 - val_loss: 9.2734
Epoch 391/8000

Epoch 00391: val_loss did not improve from 8.00345
 - 76s - loss: 7.5141 - val_loss: 8.3499
Epoch 392/8000

Epoch 00392: val_loss did not improve from 8.00345
 - 76s - loss: 7.4421 - val_loss: 8.4075
Epoch 393/8000

Epoch 00393: val_loss did not improve from 8.00345
 - 77s - loss: 7.4623 - val_loss: 8.8223
Epoch 394/8000

Epoch 00394: val_loss did not improve from 8.00345
 - 76s - loss: 7.6607 - val_loss: 8.1275
Epoch 395/8000

Epoch 00395: val_loss did not improve from 8.00345
 - 76s - loss: 7.4635 - val_loss: 9.5917
Epoch 396/8000

Epoch 00396: val_loss did not improve from 8.00345
 - 76s - loss: 7.6513 - val_loss: 9.2546
Epoch 397/8000

Epoch 00397: val_loss did not improve from 8.00345
 - 77s - loss: 7.3548 - val_loss: 8.8499
Epoch 398/8000

Epoch 00398: val_loss did not improve from 8.00345
 - 77s - loss: 7.4083 - val_loss: 9.1692
Epoch 399/8000

Epoch 00399: val_loss did not improve from 8.00345
 - 76s - loss: 7.4066 - val_loss: 8.8228
Epoch 400/8000

Epoch 00400: val_loss improved from 8.00345 to 7.94645, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 7.4709 - val_loss: 7.9465
Epoch 401/8000

Epoch 00401: val_loss did not improve from 7.94645
 - 75s - loss: 7.7880 - val_loss: 10.4231
Epoch 402/8000

Epoch 00402: val_loss did not improve from 7.94645
 - 76s - loss: 7.8524 - val_loss: 8.3221
Epoch 403/8000

Epoch 00403: val_loss did not improve from 7.94645
 - 76s - loss: 7.8518 - val_loss: 9.2270
Epoch 404/8000

Epoch 00404: val_loss did not improve from 7.94645
 - 77s - loss: 7.9836 - val_loss: 9.3002
Epoch 405/8000

Epoch 00405: val_loss did not improve from 7.94645
 - 76s - loss: 7.8170 - val_loss: 8.6844
Epoch 406/8000

Epoch 00406: val_loss did not improve from 7.94645
 - 76s - loss: 8.2576 - val_loss: 9.7712
Epoch 407/8000

Epoch 00407: val_loss did not improve from 7.94645
 - 76s - loss: 8.0885 - val_loss: 8.8873
Epoch 408/8000

Epoch 00408: val_loss did not improve from 7.94645
 - 76s - loss: 7.9817 - val_loss: 9.5723
Epoch 409/8000

Epoch 00409: val_loss did not improve from 7.94645
 - 76s - loss: 7.7872 - val_loss: 8.9948
Epoch 410/8000

Epoch 00410: val_loss did not improve from 7.94645
 - 76s - loss: 7.8605 - val_loss: 10.3256
Epoch 411/8000

Epoch 00411: val_loss did not improve from 7.94645
 - 77s - loss: 8.0408 - val_loss: 9.1033
Epoch 412/8000

Epoch 00412: val_loss did not improve from 7.94645
 - 76s - loss: 7.8539 - val_loss: 8.5995
Epoch 413/8000

Epoch 00413: val_loss did not improve from 7.94645
 - 76s - loss: 7.9490 - val_loss: 8.8100
Epoch 414/8000

Epoch 00414: val_loss did not improve from 7.94645
 - 76s - loss: 7.7487 - val_loss: 10.1623
Epoch 415/8000

Epoch 00415: val_loss did not improve from 7.94645
 - 75s - loss: 8.4966 - val_loss: 9.4689
Epoch 416/8000

Epoch 00416: val_loss did not improve from 7.94645
 - 76s - loss: 7.9669 - val_loss: 8.6756
Epoch 417/8000

Epoch 00417: val_loss did not improve from 7.94645
 - 76s - loss: 7.8507 - val_loss: 9.2480
Epoch 418/8000

Epoch 00418: val_loss did not improve from 7.94645
 - 77s - loss: 8.5024 - val_loss: 9.7670
Epoch 419/8000

Epoch 00419: val_loss did not improve from 7.94645
 - 76s - loss: 8.1625 - val_loss: 8.8260
Epoch 420/8000

Epoch 00420: val_loss did not improve from 7.94645
 - 76s - loss: 8.0301 - val_loss: 9.6974
Epoch 421/8000

Epoch 00421: val_loss did not improve from 7.94645
 - 76s - loss: 7.8054 - val_loss: 8.8195
Epoch 422/8000

Epoch 00422: val_loss did not improve from 7.94645
 - 76s - loss: 7.6615 - val_loss: 9.3248
Epoch 423/8000

Epoch 00423: val_loss did not improve from 7.94645
 - 76s - loss: 7.6088 - val_loss: 9.3518
Epoch 424/8000

Epoch 00424: val_loss did not improve from 7.94645
 - 76s - loss: 7.5569 - val_loss: 8.4336
Epoch 425/8000

Epoch 00425: val_loss did not improve from 7.94645
 - 77s - loss: 7.5098 - val_loss: 8.7773
Epoch 426/8000

Epoch 00426: val_loss did not improve from 7.94645
 - 76s - loss: 7.9786 - val_loss: 8.8185
Epoch 427/8000

Epoch 00427: val_loss did not improve from 7.94645
 - 76s - loss: 7.4050 - val_loss: 9.1602
Epoch 428/8000

Epoch 00428: val_loss did not improve from 7.94645
 - 76s - loss: 7.6513 - val_loss: 9.3148
Epoch 429/8000

Epoch 00429: val_loss did not improve from 7.94645
 - 75s - loss: 7.5395 - val_loss: 8.4011
Epoch 430/8000

Epoch 00430: val_loss did not improve from 7.94645
 - 76s - loss: 7.3570 - val_loss: 9.0792
Epoch 431/8000

Epoch 00431: val_loss did not improve from 7.94645
 - 76s - loss: 7.3745 - val_loss: 9.2448
Epoch 432/8000

Epoch 00432: val_loss did not improve from 7.94645
 - 77s - loss: 7.8501 - val_loss: 8.9746
Epoch 433/8000

Epoch 00433: val_loss did not improve from 7.94645
 - 76s - loss: 7.2341 - val_loss: 8.5126
Epoch 434/8000

Epoch 00434: val_loss did not improve from 7.94645
 - 76s - loss: 7.8450 - val_loss: 8.5874
Epoch 435/8000

Epoch 00435: val_loss did not improve from 7.94645
 - 77s - loss: 8.0037 - val_loss: 9.3036
Epoch 436/8000

Epoch 00436: val_loss did not improve from 7.94645
 - 76s - loss: 7.7499 - val_loss: 8.8940
Epoch 437/8000

Epoch 00437: val_loss did not improve from 7.94645
 - 76s - loss: 7.6152 - val_loss: 9.7059
Epoch 438/8000

Epoch 00438: val_loss did not improve from 7.94645
 - 76s - loss: 7.6391 - val_loss: 8.5236
Epoch 439/8000

Epoch 00439: val_loss did not improve from 7.94645
 - 76s - loss: 7.4875 - val_loss: 8.7959
Epoch 440/8000

Epoch 00440: val_loss did not improve from 7.94645
 - 76s - loss: 8.6352 - val_loss: 10.0994
Epoch 441/8000

Epoch 00441: val_loss did not improve from 7.94645
 - 76s - loss: 8.2354 - val_loss: 9.3737
Epoch 442/8000

Epoch 00442: val_loss did not improve from 7.94645
 - 76s - loss: 7.6645 - val_loss: 8.3208
Epoch 443/8000

Epoch 00443: val_loss did not improve from 7.94645
 - 75s - loss: 7.5053 - val_loss: 8.3022
Epoch 444/8000

Epoch 00444: val_loss did not improve from 7.94645
 - 76s - loss: 7.8959 - val_loss: 9.4939
Epoch 445/8000

Epoch 00445: val_loss did not improve from 7.94645
 - 76s - loss: 8.5585 - val_loss: 10.2164
Epoch 446/8000

Epoch 00446: val_loss did not improve from 7.94645
 - 77s - loss: 7.6428 - val_loss: 8.6093
Epoch 447/8000

Epoch 00447: val_loss did not improve from 7.94645
 - 76s - loss: 7.7271 - val_loss: 9.6866
Epoch 448/8000

Epoch 00448: val_loss did not improve from 7.94645
 - 76s - loss: 7.9305 - val_loss: 8.9046
Epoch 449/8000

Epoch 00449: val_loss did not improve from 7.94645
 - 77s - loss: 7.8274 - val_loss: 8.1423
Epoch 450/8000

Epoch 00450: val_loss did not improve from 7.94645
 - 76s - loss: 7.1544 - val_loss: 8.8593
Epoch 451/8000

Epoch 00451: val_loss did not improve from 7.94645
 - 76s - loss: 7.3944 - val_loss: 8.4965
Epoch 452/8000

Epoch 00452: val_loss did not improve from 7.94645
 - 76s - loss: 7.5357 - val_loss: 9.4264
Epoch 453/8000

Epoch 00453: val_loss did not improve from 7.94645
 - 77s - loss: 7.1197 - val_loss: 9.0438
Epoch 454/8000

Epoch 00454: val_loss did not improve from 7.94645
 - 76s - loss: 7.5336 - val_loss: 9.2943
Epoch 455/8000

Epoch 00455: val_loss did not improve from 7.94645
 - 76s - loss: 8.2290 - val_loss: 9.6305
Epoch 456/8000

Epoch 00456: val_loss did not improve from 7.94645
 - 76s - loss: 8.1747 - val_loss: 10.0966
Epoch 457/8000

Epoch 00457: val_loss did not improve from 7.94645
 - 76s - loss: 8.0888 - val_loss: 8.2170
Epoch 458/8000

Epoch 00458: val_loss did not improve from 7.94645
 - 76s - loss: 7.2744 - val_loss: 8.8642
Epoch 459/8000

Epoch 00459: val_loss did not improve from 7.94645
 - 76s - loss: 7.8701 - val_loss: 10.3869
Epoch 460/8000

Epoch 00460: val_loss did not improve from 7.94645
 - 77s - loss: 7.7419 - val_loss: 11.1594
Epoch 461/8000

Epoch 00461: val_loss did not improve from 7.94645
 - 77s - loss: 7.6579 - val_loss: 8.8073
Epoch 462/8000

Epoch 00462: val_loss did not improve from 7.94645
 - 76s - loss: 7.4527 - val_loss: 8.6587
Epoch 463/8000

Epoch 00463: val_loss did not improve from 7.94645
 - 77s - loss: 7.7535 - val_loss: 8.2808
Epoch 464/8000

Epoch 00464: val_loss improved from 7.94645 to 7.90273, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 7.5195 - val_loss: 7.9027
Epoch 465/8000

Epoch 00465: val_loss did not improve from 7.90273
 - 76s - loss: 7.0486 - val_loss: 7.9185
Epoch 466/8000

Epoch 00466: val_loss did not improve from 7.90273
 - 76s - loss: 6.8692 - val_loss: 9.3386
Epoch 467/8000

Epoch 00467: val_loss did not improve from 7.90273
 - 77s - loss: 7.4346 - val_loss: 9.5892
Epoch 468/8000

Epoch 00468: val_loss did not improve from 7.90273
 - 76s - loss: 7.1709 - val_loss: 8.5551
Epoch 469/8000

Epoch 00469: val_loss did not improve from 7.90273
 - 76s - loss: 7.2170 - val_loss: 8.7497
Epoch 470/8000

Epoch 00470: val_loss did not improve from 7.90273
 - 76s - loss: 7.2448 - val_loss: 8.1122
Epoch 471/8000

Epoch 00471: val_loss improved from 7.90273 to 7.89682, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 76s - loss: 6.7737 - val_loss: 7.8968
Epoch 472/8000

Epoch 00472: val_loss did not improve from 7.89682
 - 76s - loss: 7.0280 - val_loss: 8.1075
Epoch 473/8000

Epoch 00473: val_loss did not improve from 7.89682
 - 76s - loss: 6.8656 - val_loss: 8.9806
Epoch 474/8000

Epoch 00474: val_loss improved from 7.89682 to 7.62243, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 7.2077 - val_loss: 7.6224
Epoch 475/8000

Epoch 00475: val_loss did not improve from 7.62243
 - 76s - loss: 7.0072 - val_loss: 8.1973
Epoch 476/8000

Epoch 00476: val_loss did not improve from 7.62243
 - 76s - loss: 7.0756 - val_loss: 9.1357
Epoch 477/8000

Epoch 00477: val_loss did not improve from 7.62243
 - 77s - loss: 7.6390 - val_loss: 10.7027
Epoch 478/8000

Epoch 00478: val_loss did not improve from 7.62243
 - 76s - loss: 8.3083 - val_loss: 8.2256
Epoch 479/8000

Epoch 00479: val_loss did not improve from 7.62243
 - 76s - loss: 6.9773 - val_loss: 7.6979
Epoch 480/8000

Epoch 00480: val_loss did not improve from 7.62243
 - 76s - loss: 7.0205 - val_loss: 9.2626
Epoch 481/8000

Epoch 00481: val_loss did not improve from 7.62243
 - 76s - loss: 6.8842 - val_loss: 7.8602
Epoch 482/8000

Epoch 00482: val_loss did not improve from 7.62243
 - 76s - loss: 6.7537 - val_loss: 9.1829
Epoch 483/8000

Epoch 00483: val_loss did not improve from 7.62243
 - 76s - loss: 6.9262 - val_loss: 8.3312
Epoch 484/8000

Epoch 00484: val_loss did not improve from 7.62243
 - 76s - loss: 6.6334 - val_loss: 9.2857
Epoch 485/8000

Epoch 00485: val_loss did not improve from 7.62243
 - 75s - loss: 7.1206 - val_loss: 8.4984
Epoch 486/8000

Epoch 00486: val_loss did not improve from 7.62243
 - 76s - loss: 7.2035 - val_loss: 8.2085
Epoch 487/8000

Epoch 00487: val_loss did not improve from 7.62243
 - 76s - loss: 6.6131 - val_loss: 8.3996
Epoch 488/8000

Epoch 00488: val_loss did not improve from 7.62243
 - 77s - loss: 6.8893 - val_loss: 8.6747
Epoch 489/8000

Epoch 00489: val_loss did not improve from 7.62243
 - 76s - loss: 7.2909 - val_loss: 8.5266
Epoch 490/8000

Epoch 00490: val_loss did not improve from 7.62243
 - 76s - loss: 7.4246 - val_loss: 8.8628
Epoch 491/8000

Epoch 00491: val_loss did not improve from 7.62243
 - 76s - loss: 8.4869 - val_loss: 9.6727
Epoch 492/8000

Epoch 00492: val_loss did not improve from 7.62243
 - 76s - loss: 8.0932 - val_loss: 9.5896
Epoch 493/8000

Epoch 00493: val_loss did not improve from 7.62243
 - 76s - loss: 7.9796 - val_loss: 9.0691
Epoch 494/8000

Epoch 00494: val_loss did not improve from 7.62243
 - 76s - loss: 7.3706 - val_loss: 8.5034
Epoch 495/8000

Epoch 00495: val_loss did not improve from 7.62243
 - 77s - loss: 7.7597 - val_loss: 11.5260
Epoch 496/8000

Epoch 00496: val_loss did not improve from 7.62243
 - 76s - loss: 8.4898 - val_loss: 9.2613
Epoch 497/8000

Epoch 00497: val_loss did not improve from 7.62243
 - 76s - loss: 8.0747 - val_loss: 10.3741
Epoch 498/8000

Epoch 00498: val_loss did not improve from 7.62243
 - 76s - loss: 8.5869 - val_loss: 9.7486
Epoch 499/8000

Epoch 00499: val_loss did not improve from 7.62243
 - 75s - loss: 7.8009 - val_loss: 8.4310
Epoch 500/8000

Epoch 00500: val_loss did not improve from 7.62243
 - 76s - loss: 7.3489 - val_loss: 10.3748
Epoch 501/8000

Epoch 00501: val_loss did not improve from 7.62243
 - 76s - loss: 7.9955 - val_loss: 9.1222
Epoch 502/8000

Epoch 00502: val_loss did not improve from 7.62243
 - 77s - loss: 7.2346 - val_loss: 8.6891
Epoch 503/8000

Epoch 00503: val_loss did not improve from 7.62243
 - 76s - loss: 7.2211 - val_loss: 8.2582
Epoch 504/8000

Epoch 00504: val_loss did not improve from 7.62243
 - 76s - loss: 7.3324 - val_loss: 7.9238
Epoch 505/8000

Epoch 00505: val_loss did not improve from 7.62243
 - 77s - loss: 7.0177 - val_loss: 8.4003
Epoch 506/8000

Epoch 00506: val_loss did not improve from 7.62243
 - 76s - loss: 6.8171 - val_loss: 8.4285
Epoch 507/8000

Epoch 00507: val_loss did not improve from 7.62243
 - 76s - loss: 7.1132 - val_loss: 8.1167
Epoch 508/8000

Epoch 00508: val_loss did not improve from 7.62243
 - 76s - loss: 7.0837 - val_loss: 9.1643
Epoch 509/8000

Epoch 00509: val_loss did not improve from 7.62243
 - 77s - loss: 6.9537 - val_loss: 7.7653
Epoch 510/8000

Epoch 00510: val_loss improved from 7.62243 to 7.28659, saving model to ../../model_weights/model_2020-03-11_20-34-12.h5
 - 77s - loss: 7.0914 - val_loss: 7.2866
Epoch 511/8000

Epoch 00511: val_loss did not improve from 7.28659
 - 76s - loss: 6.7981 - val_loss: 7.8632
