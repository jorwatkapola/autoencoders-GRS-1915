2020-08-30 05:44:06.835379: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-08-30 05:44:07.157052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-30 05:44:07.157653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2020-08-30 05:44:07.157672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-08-30 05:44:07.432474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-30 05:44:07.432518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-08-30 05:44:07.432527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-08-30 05:44:07.432778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-08-30 05:44:07.641087: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x5610682f4500
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 84.16655, saving model to ../../model_weights/model_2020-08-30_05-44-08.h5
 - 334s - loss: 85.7772 - kl_loss: 3.4963 - val_loss: 84.1666 - val_kl_loss: 3.4701
Epoch 2/8000

Epoch 00002: val_loss did not improve from 84.16655
 - 334s - loss: 84.1822 - kl_loss: 3.4958 - val_loss: 84.4771 - val_kl_loss: 3.5211
Epoch 3/8000

Epoch 00003: val_loss did not improve from 84.16655
 - 335s - loss: 85.2415 - kl_loss: 3.6187 - val_loss: 85.0762 - val_kl_loss: 3.6923
Epoch 4/8000

Epoch 00004: val_loss did not improve from 84.16655
 - 336s - loss: 85.2690 - kl_loss: 3.6843 - val_loss: 84.3805 - val_kl_loss: 3.7227
Epoch 5/8000

Epoch 00005: val_loss did not improve from 84.16655
 - 336s - loss: 85.4486 - kl_loss: 3.6825 - val_loss: 85.8554 - val_kl_loss: 3.9565
Epoch 6/8000

Epoch 00006: val_loss did not improve from 84.16655
 - 337s - loss: 86.2536 - kl_loss: 3.7711 - val_loss: 86.0925 - val_kl_loss: 3.7421
Epoch 7/8000

Epoch 00007: val_loss did not improve from 84.16655
 - 337s - loss: 86.6308 - kl_loss: 3.8053 - val_loss: 85.8399 - val_kl_loss: 3.8090
Epoch 8/8000

Epoch 00008: val_loss did not improve from 84.16655
 - 340s - loss: 86.9477 - kl_loss: 3.8680 - val_loss: 85.7393 - val_kl_loss: 3.5366
Epoch 9/8000

Epoch 00009: val_loss did not improve from 84.16655
 - 335s - loss: 85.4910 - kl_loss: 3.7629 - val_loss: 85.6300 - val_kl_loss: 3.8206
Epoch 10/8000

Epoch 00010: val_loss improved from 84.16655 to 83.78734, saving model to ../../model_weights/model_2020-08-30_05-44-08.h5
 - 336s - loss: 83.2196 - kl_loss: 3.6462 - val_loss: 83.7873 - val_kl_loss: 3.6556
Epoch 11/8000

Epoch 00011: val_loss improved from 83.78734 to 83.63822, saving model to ../../model_weights/model_2020-08-30_05-44-08.h5
 - 337s - loss: 82.9833 - kl_loss: 3.6881 - val_loss: 83.6382 - val_kl_loss: 3.7549
Epoch 12/8000

Epoch 00012: val_loss improved from 83.63822 to 83.60859, saving model to ../../model_weights/model_2020-08-30_05-44-08.h5
 - 335s - loss: 82.6690 - kl_loss: 3.7292 - val_loss: 83.6086 - val_kl_loss: 3.6989
Epoch 13/8000

Epoch 00013: val_loss improved from 83.60859 to 82.76760, saving model to ../../model_weights/model_2020-08-30_05-44-08.h5
 - 337s - loss: 83.5103 - kl_loss: 3.7940 - val_loss: 82.7676 - val_kl_loss: 3.7468
Epoch 14/8000

Epoch 00014: val_loss did not improve from 82.76760
 - 338s - loss: 83.0390 - kl_loss: 3.7247 - val_loss: 84.0464 - val_kl_loss: 3.7028
Epoch 15/8000

Epoch 00015: val_loss did not improve from 82.76760
 - 339s - loss: 83.1632 - kl_loss: 3.8061 - val_loss: 83.8644 - val_kl_loss: 3.8947
Epoch 16/8000

Epoch 00016: val_loss did not improve from 82.76760
 - 335s - loss: 83.6835 - kl_loss: 3.9069 - val_loss: 83.4093 - val_kl_loss: 3.7694
Epoch 17/8000

Epoch 00017: val_loss did not improve from 82.76760
 - 338s - loss: 83.2460 - kl_loss: 3.7963 - val_loss: 83.9436 - val_kl_loss: 3.8911
Epoch 18/8000

Epoch 00018: val_loss did not improve from 82.76760
 - 337s - loss: 82.9907 - kl_loss: 3.7670 - val_loss: 83.3294 - val_kl_loss: 3.5680
Epoch 19/8000

Epoch 00019: val_loss did not improve from 82.76760
 - 334s - loss: 82.2963 - kl_loss: 3.6741 - val_loss: 84.9789 - val_kl_loss: 3.6994
Epoch 20/8000

Epoch 00020: val_loss did not improve from 82.76760
 - 338s - loss: 83.1235 - kl_loss: 3.7907 - val_loss: 85.1561 - val_kl_loss: 3.7675
Epoch 21/8000

Epoch 00021: val_loss did not improve from 82.76760
 - 337s - loss: 83.6515 - kl_loss: 3.8361 - val_loss: 85.2711 - val_kl_loss: 3.8066
Epoch 22/8000

Epoch 00022: val_loss did not improve from 82.76760
 - 339s - loss: 84.8205 - kl_loss: 3.8880 - val_loss: 86.9905 - val_kl_loss: 3.9638
Epoch 23/8000

Epoch 00023: val_loss did not improve from 82.76760
 - 336s - loss: 87.1489 - kl_loss: 4.0452 - val_loss: 89.8144 - val_kl_loss: 4.2173
Epoch 24/8000

Epoch 00024: val_loss did not improve from 82.76760
 - 337s - loss: 89.1908 - kl_loss: 4.2010 - val_loss: 90.8899 - val_kl_loss: 4.3635
Epoch 25/8000

Epoch 00025: val_loss did not improve from 82.76760
 - 336s - loss: 96.4109 - kl_loss: 4.5095 - val_loss: 94.8781 - val_kl_loss: 4.3827
Epoch 26/8000

Epoch 00026: val_loss did not improve from 82.76760
 - 335s - loss: 98.0539 - kl_loss: 4.5892 - val_loss: 94.6316 - val_kl_loss: 4.5263
Epoch 27/8000

Epoch 00027: val_loss did not improve from 82.76760
 - 338s - loss: 108.0052 - kl_loss: 4.9906 - val_loss: 104.7821 - val_kl_loss: 4.9146
Epoch 28/8000

Epoch 00028: val_loss did not improve from 82.76760
 - 338s - loss: 106.8153 - kl_loss: 4.7119 - val_loss: 103.5281 - val_kl_loss: 4.7377
Epoch 29/8000

Epoch 00029: val_loss did not improve from 82.76760
 - 339s - loss: 106.9109 - kl_loss: 4.7482 - val_loss: 101.3103 - val_kl_loss: 4.6151
Epoch 30/8000

Epoch 00030: val_loss did not improve from 82.76760
 - 336s - loss: 103.5761 - kl_loss: 4.5258 - val_loss: 97.7396 - val_kl_loss: 4.3485
Epoch 31/8000

Epoch 00031: val_loss did not improve from 82.76760
 - 338s - loss: 105.1341 - kl_loss: 4.7149 - val_loss: 100.7022 - val_kl_loss: 4.8132
Epoch 32/8000

Epoch 00032: val_loss did not improve from 82.76760
 - 336s - loss: 102.1774 - kl_loss: 4.4659 - val_loss: 95.5946 - val_kl_loss: 4.0450
Epoch 33/8000

Epoch 00033: val_loss did not improve from 82.76760
 - 336s - loss: 101.4312 - kl_loss: 4.4737 - val_loss: 96.7559 - val_kl_loss: 4.3748
Epoch 34/8000

Epoch 00034: val_loss did not improve from 82.76760
 - 337s - loss: 101.5158 - kl_loss: 4.3924 - val_loss: 98.9710 - val_kl_loss: 4.3591
Epoch 35/8000

Epoch 00035: val_loss did not improve from 82.76760
 - 337s - loss: 101.6902 - kl_loss: 4.3711 - val_loss: 94.9123 - val_kl_loss: 4.1990
Epoch 36/8000

Epoch 00036: val_loss did not improve from 82.76760
 - 340s - loss: 103.0535 - kl_loss: 4.3959 - val_loss: 97.6624 - val_kl_loss: 4.1024
Epoch 37/8000

Epoch 00037: val_loss did not improve from 82.76760
 - 336s - loss: 105.9238 - kl_loss: 4.4294 - val_loss: 103.1462 - val_kl_loss: 4.4856
Epoch 38/8000

Epoch 00038: val_loss did not improve from 82.76760
 - 337s - loss: 104.0081 - kl_loss: 4.4060 - val_loss: 95.6763 - val_kl_loss: 4.0605
Epoch 39/8000

Epoch 00039: val_loss did not improve from 82.76760
 - 338s - loss: 101.8179 - kl_loss: 4.1567 - val_loss: 97.7276 - val_kl_loss: 4.2625
Epoch 40/8000

Epoch 00040: val_loss did not improve from 82.76760
 - 336s - loss: 101.9278 - kl_loss: 4.2511 - val_loss: 98.8993 - val_kl_loss: 4.1703
Epoch 41/8000

Epoch 00041: val_loss did not improve from 82.76760
 - 337s - loss: 102.8783 - kl_loss: 4.2381 - val_loss: 95.5194 - val_kl_loss: 4.0506
Epoch 42/8000

Epoch 00042: val_loss did not improve from 82.76760
 - 338s - loss: 107.8216 - kl_loss: 4.3299 - val_loss: 102.7843 - val_kl_loss: 4.2244
Epoch 43/8000

Epoch 00043: val_loss did not improve from 82.76760
 - 340s - loss: 107.6668 - kl_loss: 4.3674 - val_loss: 104.2083 - val_kl_loss: 4.0522
Epoch 44/8000

Epoch 00044: val_loss did not improve from 82.76760
 - 336s - loss: 113.4200 - kl_loss: 4.4107 - val_loss: 109.4513 - val_kl_loss: 4.3424
Epoch 45/8000

Epoch 00045: val_loss did not improve from 82.76760
 - 339s - loss: 114.6390 - kl_loss: 4.3446 - val_loss: 100.4908 - val_kl_loss: 3.9983
Epoch 46/8000

Epoch 00046: val_loss did not improve from 82.76760
 - 337s - loss: 111.1131 - kl_loss: 4.3513 - val_loss: 101.2652 - val_kl_loss: 4.0565
Epoch 47/8000

Epoch 00047: val_loss did not improve from 82.76760
 - 335s - loss: 108.9655 - kl_loss: 4.1641 - val_loss: 104.0762 - val_kl_loss: 4.1820
Epoch 48/8000

Epoch 00048: val_loss did not improve from 82.76760
 - 337s - loss: 104.3516 - kl_loss: 4.0089 - val_loss: 99.5167 - val_kl_loss: 3.8644
Epoch 49/8000

Epoch 00049: val_loss did not improve from 82.76760
 - 338s - loss: 100.0953 - kl_loss: 3.8639 - val_loss: 93.8760 - val_kl_loss: 3.8259
Epoch 50/8000

Epoch 00050: val_loss did not improve from 82.76760
 - 340s - loss: 99.0214 - kl_loss: 3.9021 - val_loss: 95.1047 - val_kl_loss: 3.8296
Epoch 51/8000

Epoch 00051: val_loss did not improve from 82.76760
 - 336s - loss: 98.2154 - kl_loss: 3.9122 - val_loss: 96.0120 - val_kl_loss: 4.0477
Epoch 52/8000

Epoch 00052: val_loss did not improve from 82.76760
 - 338s - loss: 97.7922 - kl_loss: 3.9636 - val_loss: 94.6790 - val_kl_loss: 3.9042
Epoch 53/8000

Epoch 00053: val_loss did not improve from 82.76760
 - 336s - loss: 96.1667 - kl_loss: 3.8635 - val_loss: 93.9139 - val_kl_loss: 3.7534
Epoch 54/8000

Epoch 00054: val_loss did not improve from 82.76760
 - 336s - loss: 95.4896 - kl_loss: 3.7798 - val_loss: 95.3756 - val_kl_loss: 3.9949
Epoch 55/8000

Epoch 00055: val_loss did not improve from 82.76760
 - 338s - loss: 96.3330 - kl_loss: 3.8394 - val_loss: 93.6261 - val_kl_loss: 3.9018
Epoch 56/8000

Epoch 00056: val_loss did not improve from 82.76760
 - 337s - loss: 94.6808 - kl_loss: 3.6851 - val_loss: 93.6125 - val_kl_loss: 3.6281
Epoch 57/8000

Epoch 00057: val_loss did not improve from 82.76760
 - 340s - loss: 92.0795 - kl_loss: 3.5259 - val_loss: 91.3672 - val_kl_loss: 3.5205
Epoch 58/8000

Epoch 00058: val_loss did not improve from 82.76760
 - 337s - loss: 91.4775 - kl_loss: 3.4547 - val_loss: 88.0681 - val_kl_loss: 3.4109
Epoch 59/8000

Epoch 00059: val_loss did not improve from 82.76760
 - 337s - loss: 89.8893 - kl_loss: 3.4238 - val_loss: 89.6109 - val_kl_loss: 3.4375
Epoch 60/8000

Epoch 00060: val_loss did not improve from 82.76760
 - 337s - loss: 88.9270 - kl_loss: 3.3975 - val_loss: 88.6253 - val_kl_loss: 3.3796
Epoch 61/8000

Epoch 00061: val_loss did not improve from 82.76760
 - 336s - loss: 88.6372 - kl_loss: 3.3707 - val_loss: 88.3326 - val_kl_loss: 3.4429
Epoch 62/8000

Epoch 00062: val_loss did not improve from 82.76760
 - 337s - loss: 88.1995 - kl_loss: 3.3567 - val_loss: 86.1990 - val_kl_loss: 3.4055
Epoch 63/8000

Epoch 00063: val_loss did not improve from 82.76760
 - 338s - loss: 87.4767 - kl_loss: 3.3985 - val_loss: 87.9213 - val_kl_loss: 3.4931
Epoch 00063: early stopping
