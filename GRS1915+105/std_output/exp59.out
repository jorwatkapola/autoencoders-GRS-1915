2020-01-27 12:52:37.920814: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-27 12:52:38.037745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-27 12:52:38.038325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.73GiB
2020-01-27 12:52:38.038342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-01-27 12:52:38.271452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-27 12:52:38.271492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-01-27 12:52:38.271501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-01-27 12:52:38.271774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11348 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-01-27 12:52:38.566468: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x55b1e1c72880
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 39.09566, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 16s - loss: 45.3136 - val_loss: 39.0957
Epoch 2/8000

Epoch 00002: val_loss improved from 39.09566 to 26.23290, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 31.3515 - val_loss: 26.2329
Epoch 3/8000

Epoch 00003: val_loss improved from 26.23290 to 25.03134, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 24.8005 - val_loss: 25.0313
Epoch 4/8000

Epoch 00004: val_loss improved from 25.03134 to 24.56982, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 24.2041 - val_loss: 24.5698
Epoch 5/8000

Epoch 00005: val_loss improved from 24.56982 to 24.34162, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 23.5850 - val_loss: 24.3416
Epoch 6/8000

Epoch 00006: val_loss improved from 24.34162 to 23.74098, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 23.1955 - val_loss: 23.7410
Epoch 7/8000

Epoch 00007: val_loss did not improve from 23.74098
 - 14s - loss: 23.5051 - val_loss: 23.8778
Epoch 8/8000

Epoch 00008: val_loss improved from 23.74098 to 21.20189, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 21.6216 - val_loss: 21.2019
Epoch 9/8000

Epoch 00009: val_loss improved from 21.20189 to 20.77641, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 20.3556 - val_loss: 20.7764
Epoch 10/8000

Epoch 00010: val_loss improved from 20.77641 to 20.38472, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 19.8992 - val_loss: 20.3847
Epoch 11/8000

Epoch 00011: val_loss improved from 20.38472 to 20.37472, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 19.5805 - val_loss: 20.3747
Epoch 12/8000

Epoch 00012: val_loss improved from 20.37472 to 19.08794, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 18.8009 - val_loss: 19.0879
Epoch 13/8000

Epoch 00013: val_loss improved from 19.08794 to 18.88986, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 18.2792 - val_loss: 18.8899
Epoch 14/8000

Epoch 00014: val_loss improved from 18.88986 to 18.38835, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 17.9278 - val_loss: 18.3884
Epoch 15/8000

Epoch 00015: val_loss improved from 18.38835 to 18.38448, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 17.7062 - val_loss: 18.3845
Epoch 16/8000

Epoch 00016: val_loss improved from 18.38448 to 17.81668, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 17.5710 - val_loss: 17.8167
Epoch 17/8000

Epoch 00017: val_loss improved from 17.81668 to 17.51760, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 17.3707 - val_loss: 17.5176
Epoch 18/8000

Epoch 00018: val_loss did not improve from 17.51760
 - 14s - loss: 17.2281 - val_loss: 17.8849
Epoch 19/8000

Epoch 00019: val_loss did not improve from 17.51760
 - 14s - loss: 16.8860 - val_loss: 17.6782
Epoch 20/8000

Epoch 00020: val_loss improved from 17.51760 to 17.14575, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 17.0503 - val_loss: 17.1458
Epoch 21/8000

Epoch 00021: val_loss improved from 17.14575 to 17.14021, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 16.7210 - val_loss: 17.1402
Epoch 22/8000

Epoch 00022: val_loss improved from 17.14021 to 16.78517, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 16.5489 - val_loss: 16.7852
Epoch 23/8000

Epoch 00023: val_loss did not improve from 16.78517
 - 14s - loss: 16.4276 - val_loss: 16.9641
Epoch 24/8000

Epoch 00024: val_loss improved from 16.78517 to 16.73853, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 16.3930 - val_loss: 16.7385
Epoch 25/8000

Epoch 00025: val_loss improved from 16.73853 to 16.54484, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 16.2441 - val_loss: 16.5448
Epoch 26/8000

Epoch 00026: val_loss improved from 16.54484 to 16.53322, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 16.2855 - val_loss: 16.5332
Epoch 27/8000

Epoch 00027: val_loss improved from 16.53322 to 16.28987, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 16.1469 - val_loss: 16.2899
Epoch 28/8000

Epoch 00028: val_loss did not improve from 16.28987
 - 14s - loss: 16.1779 - val_loss: 16.6781
Epoch 29/8000

Epoch 00029: val_loss improved from 16.28987 to 16.14755, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 15.9802 - val_loss: 16.1476
Epoch 30/8000

Epoch 00030: val_loss did not improve from 16.14755
 - 14s - loss: 15.8405 - val_loss: 16.1607
Epoch 31/8000

Epoch 00031: val_loss improved from 16.14755 to 15.94606, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 15.7737 - val_loss: 15.9461
Epoch 32/8000

Epoch 00032: val_loss did not improve from 15.94606
 - 14s - loss: 15.8207 - val_loss: 17.1479
Epoch 33/8000

Epoch 00033: val_loss improved from 15.94606 to 15.73933, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 15.5874 - val_loss: 15.7393
Epoch 34/8000

Epoch 00034: val_loss did not improve from 15.73933
 - 14s - loss: 15.4628 - val_loss: 16.8454
Epoch 35/8000

Epoch 00035: val_loss did not improve from 15.73933
 - 14s - loss: 15.4375 - val_loss: 16.0846
Epoch 36/8000

Epoch 00036: val_loss did not improve from 15.73933
 - 14s - loss: 15.4730 - val_loss: 15.7950
Epoch 37/8000

Epoch 00037: val_loss improved from 15.73933 to 15.68249, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 15.5003 - val_loss: 15.6825
Epoch 38/8000

Epoch 00038: val_loss improved from 15.68249 to 15.54001, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 15.1766 - val_loss: 15.5400
Epoch 39/8000

Epoch 00039: val_loss improved from 15.54001 to 15.48177, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 15.2662 - val_loss: 15.4818
Epoch 40/8000

Epoch 00040: val_loss did not improve from 15.48177
 - 14s - loss: 15.3384 - val_loss: 15.6079
Epoch 41/8000

Epoch 00041: val_loss did not improve from 15.48177
 - 14s - loss: 15.0661 - val_loss: 15.5852
Epoch 42/8000

Epoch 00042: val_loss improved from 15.48177 to 15.30978, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 15.1225 - val_loss: 15.3098
Epoch 43/8000

Epoch 00043: val_loss improved from 15.30978 to 15.14775, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 14.9020 - val_loss: 15.1477
Epoch 44/8000

Epoch 00044: val_loss did not improve from 15.14775
 - 14s - loss: 15.1444 - val_loss: 15.5509
Epoch 45/8000

Epoch 00045: val_loss did not improve from 15.14775
 - 14s - loss: 15.1166 - val_loss: 15.7713
Epoch 46/8000

Epoch 00046: val_loss did not improve from 15.14775
 - 14s - loss: 14.8935 - val_loss: 15.1587
Epoch 47/8000

Epoch 00047: val_loss did not improve from 15.14775
 - 14s - loss: 14.9286 - val_loss: 15.2292
Epoch 48/8000

Epoch 00048: val_loss improved from 15.14775 to 14.91469, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 14.8856 - val_loss: 14.9147
Epoch 49/8000

Epoch 00049: val_loss improved from 14.91469 to 14.76063, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 14.6312 - val_loss: 14.7606
Epoch 50/8000

Epoch 00050: val_loss did not improve from 14.76063
 - 14s - loss: 14.9006 - val_loss: 15.0518
Epoch 51/8000

Epoch 00051: val_loss did not improve from 14.76063
 - 14s - loss: 14.5761 - val_loss: 14.9706
Epoch 52/8000

Epoch 00052: val_loss did not improve from 14.76063
 - 14s - loss: 14.6713 - val_loss: 14.8452
Epoch 53/8000

Epoch 00053: val_loss did not improve from 14.76063
 - 14s - loss: 14.7361 - val_loss: 14.9002
Epoch 54/8000

Epoch 00054: val_loss improved from 14.76063 to 14.72275, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 14.5055 - val_loss: 14.7227
Epoch 55/8000

Epoch 00055: val_loss did not improve from 14.72275
 - 14s - loss: 14.6229 - val_loss: 15.8599
Epoch 56/8000

Epoch 00056: val_loss did not improve from 14.72275
 - 14s - loss: 14.5370 - val_loss: 14.7850
Epoch 57/8000

Epoch 00057: val_loss improved from 14.72275 to 14.51051, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 14.4045 - val_loss: 14.5105
Epoch 58/8000

Epoch 00058: val_loss did not improve from 14.51051
 - 14s - loss: 14.4436 - val_loss: 14.8348
Epoch 59/8000

Epoch 00059: val_loss improved from 14.51051 to 14.45004, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 14.2916 - val_loss: 14.4500
Epoch 60/8000

Epoch 00060: val_loss did not improve from 14.45004
 - 14s - loss: 14.4406 - val_loss: 15.1202
Epoch 61/8000

Epoch 00061: val_loss did not improve from 14.45004
 - 14s - loss: 14.4347 - val_loss: 15.0491
Epoch 62/8000

Epoch 00062: val_loss did not improve from 14.45004
 - 14s - loss: 14.5549 - val_loss: 14.7030
Epoch 63/8000

Epoch 00063: val_loss did not improve from 14.45004
 - 14s - loss: 14.3115 - val_loss: 14.6564
Epoch 64/8000

Epoch 00064: val_loss did not improve from 14.45004
 - 14s - loss: 14.4673 - val_loss: 14.5952
Epoch 65/8000

Epoch 00065: val_loss did not improve from 14.45004
 - 14s - loss: 14.1816 - val_loss: 14.6576
Epoch 66/8000

Epoch 00066: val_loss did not improve from 14.45004
 - 14s - loss: 14.2369 - val_loss: 15.5304
Epoch 67/8000

Epoch 00067: val_loss did not improve from 14.45004
 - 14s - loss: 14.0820 - val_loss: 14.4900
Epoch 68/8000

Epoch 00068: val_loss did not improve from 14.45004
 - 14s - loss: 14.6464 - val_loss: 14.4657
Epoch 69/8000

Epoch 00069: val_loss improved from 14.45004 to 14.32322, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 14.2149 - val_loss: 14.3232
Epoch 70/8000

Epoch 00070: val_loss did not improve from 14.32322
 - 14s - loss: 14.5381 - val_loss: 19.2053
Epoch 71/8000

Epoch 00071: val_loss did not improve from 14.32322
 - 14s - loss: 14.9574 - val_loss: 14.4909
Epoch 72/8000

Epoch 00072: val_loss improved from 14.32322 to 14.01504, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 14.0341 - val_loss: 14.0150
Epoch 73/8000

Epoch 00073: val_loss did not improve from 14.01504
 - 14s - loss: 14.0887 - val_loss: 14.6504
Epoch 74/8000

Epoch 00074: val_loss did not improve from 14.01504
 - 14s - loss: 13.9869 - val_loss: 14.6264
Epoch 75/8000

Epoch 00075: val_loss did not improve from 14.01504
 - 14s - loss: 14.1656 - val_loss: 15.1164
Epoch 76/8000

Epoch 00076: val_loss did not improve from 14.01504
 - 14s - loss: 14.0066 - val_loss: 14.4887
Epoch 77/8000

Epoch 00077: val_loss did not improve from 14.01504
 - 14s - loss: 14.1594 - val_loss: 14.4885
Epoch 78/8000

Epoch 00078: val_loss did not improve from 14.01504
 - 14s - loss: 13.8601 - val_loss: 14.0285
Epoch 79/8000

Epoch 00079: val_loss did not improve from 14.01504
 - 14s - loss: 13.9579 - val_loss: 16.3298
Epoch 80/8000

Epoch 00080: val_loss did not improve from 14.01504
 - 14s - loss: 18.0639 - val_loss: 16.4819
Epoch 81/8000

Epoch 00081: val_loss did not improve from 14.01504
 - 14s - loss: 15.2476 - val_loss: 14.8806
Epoch 82/8000

Epoch 00082: val_loss did not improve from 14.01504
 - 14s - loss: 14.5341 - val_loss: 14.6634
Epoch 83/8000

Epoch 00083: val_loss did not improve from 14.01504
 - 14s - loss: 14.0622 - val_loss: 14.1290
Epoch 84/8000

Epoch 00084: val_loss did not improve from 14.01504
 - 14s - loss: 13.8703 - val_loss: 14.2846
Epoch 85/8000

Epoch 00085: val_loss did not improve from 14.01504
 - 14s - loss: 13.6792 - val_loss: 14.0206
Epoch 86/8000

Epoch 00086: val_loss did not improve from 14.01504
 - 14s - loss: 13.7385 - val_loss: 14.4694
Epoch 87/8000

Epoch 00087: val_loss did not improve from 14.01504
 - 14s - loss: 13.9146 - val_loss: 14.4897
Epoch 88/8000

Epoch 00088: val_loss did not improve from 14.01504
 - 14s - loss: 13.6813 - val_loss: 14.3560
Epoch 89/8000

Epoch 00089: val_loss did not improve from 14.01504
 - 14s - loss: 13.6857 - val_loss: 14.2091
Epoch 90/8000

Epoch 00090: val_loss improved from 14.01504 to 13.84363, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 13.7561 - val_loss: 13.8436
Epoch 91/8000

Epoch 00091: val_loss did not improve from 13.84363
 - 14s - loss: 18.1691 - val_loss: 17.8615
Epoch 92/8000

Epoch 00092: val_loss did not improve from 13.84363
 - 14s - loss: 16.7330 - val_loss: 16.6054
Epoch 93/8000

Epoch 00093: val_loss did not improve from 13.84363
 - 14s - loss: 15.8769 - val_loss: 15.8213
Epoch 94/8000

Epoch 00094: val_loss did not improve from 13.84363
 - 14s - loss: 15.3960 - val_loss: 15.3066
Epoch 95/8000

Epoch 00095: val_loss did not improve from 13.84363
 - 14s - loss: 14.9217 - val_loss: 15.1827
Epoch 96/8000

Epoch 00096: val_loss did not improve from 13.84363
 - 14s - loss: 14.6202 - val_loss: 15.0686
Epoch 97/8000

Epoch 00097: val_loss did not improve from 13.84363
 - 14s - loss: 14.3954 - val_loss: 14.5324
Epoch 98/8000

Epoch 00098: val_loss did not improve from 13.84363
 - 14s - loss: 14.1559 - val_loss: 14.3564
Epoch 99/8000

Epoch 00099: val_loss did not improve from 13.84363
 - 14s - loss: 13.9142 - val_loss: 14.1131
Epoch 100/8000

Epoch 00100: val_loss did not improve from 13.84363
 - 14s - loss: 13.8024 - val_loss: 13.9608
Epoch 101/8000

Epoch 00101: val_loss did not improve from 13.84363
 - 14s - loss: 13.6803 - val_loss: 14.4123
Epoch 102/8000

Epoch 00102: val_loss did not improve from 13.84363
 - 14s - loss: 13.6497 - val_loss: 13.8558
Epoch 103/8000

Epoch 00103: val_loss did not improve from 13.84363
 - 14s - loss: 13.6012 - val_loss: 13.9635
Epoch 104/8000

Epoch 00104: val_loss did not improve from 13.84363
 - 14s - loss: 13.5123 - val_loss: 14.0803
Epoch 105/8000

Epoch 00105: val_loss did not improve from 13.84363
 - 14s - loss: 13.6970 - val_loss: 14.0283
Epoch 106/8000

Epoch 00106: val_loss improved from 13.84363 to 13.66199, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 13.5844 - val_loss: 13.6620
Epoch 107/8000

Epoch 00107: val_loss improved from 13.66199 to 13.35557, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 13.2799 - val_loss: 13.3556
Epoch 108/8000

Epoch 00108: val_loss did not improve from 13.35557
 - 14s - loss: 13.2046 - val_loss: 13.9147
Epoch 109/8000

Epoch 00109: val_loss did not improve from 13.35557
 - 14s - loss: 13.2745 - val_loss: 13.6010
Epoch 110/8000

Epoch 00110: val_loss did not improve from 13.35557
 - 14s - loss: 13.1981 - val_loss: 13.4987
Epoch 111/8000

Epoch 00111: val_loss improved from 13.35557 to 13.15781, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 12.9461 - val_loss: 13.1578
Epoch 112/8000

Epoch 00112: val_loss did not improve from 13.15781
 - 14s - loss: 13.0616 - val_loss: 13.3259
Epoch 113/8000

Epoch 00113: val_loss did not improve from 13.15781
 - 14s - loss: 13.0213 - val_loss: 13.7475
Epoch 114/8000

Epoch 00114: val_loss improved from 13.15781 to 13.12344, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 13.1565 - val_loss: 13.1234
Epoch 115/8000

Epoch 00115: val_loss did not improve from 13.12344
 - 14s - loss: 13.3655 - val_loss: 13.5061
Epoch 116/8000

Epoch 00116: val_loss did not improve from 13.12344
 - 14s - loss: 12.9005 - val_loss: 13.7155
Epoch 117/8000

Epoch 00117: val_loss improved from 13.12344 to 13.08233, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 13.1139 - val_loss: 13.0823
Epoch 118/8000

Epoch 00118: val_loss did not improve from 13.08233
 - 14s - loss: 12.6477 - val_loss: 13.2493
Epoch 119/8000

Epoch 00119: val_loss did not improve from 13.08233
 - 14s - loss: 12.7630 - val_loss: 14.0706
Epoch 120/8000

Epoch 00120: val_loss improved from 13.08233 to 12.68146, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 12.9187 - val_loss: 12.6815
Epoch 121/8000

Epoch 00121: val_loss did not improve from 12.68146
 - 14s - loss: 12.6994 - val_loss: 13.1352
Epoch 122/8000

Epoch 00122: val_loss did not improve from 12.68146
 - 14s - loss: 12.9204 - val_loss: 12.7127
Epoch 123/8000

Epoch 00123: val_loss did not improve from 12.68146
 - 14s - loss: 12.6504 - val_loss: 13.1420
Epoch 124/8000

Epoch 00124: val_loss did not improve from 12.68146
 - 14s - loss: 12.7424 - val_loss: 12.8703
Epoch 125/8000

Epoch 00125: val_loss did not improve from 12.68146
 - 14s - loss: 12.6040 - val_loss: 13.6970
Epoch 126/8000

Epoch 00126: val_loss did not improve from 12.68146
 - 14s - loss: 12.8047 - val_loss: 12.8125
Epoch 127/8000

Epoch 00127: val_loss did not improve from 12.68146
 - 14s - loss: 12.8245 - val_loss: 13.0612
Epoch 128/8000

Epoch 00128: val_loss did not improve from 12.68146
 - 14s - loss: 12.9756 - val_loss: 13.0041
Epoch 129/8000

Epoch 00129: val_loss did not improve from 12.68146
 - 14s - loss: 12.5927 - val_loss: 13.9965
Epoch 130/8000

Epoch 00130: val_loss did not improve from 12.68146
 - 14s - loss: 12.6071 - val_loss: 13.2028
Epoch 131/8000

Epoch 00131: val_loss did not improve from 12.68146
 - 14s - loss: 12.7713 - val_loss: 12.7212
Epoch 132/8000

Epoch 00132: val_loss did not improve from 12.68146
 - 14s - loss: 12.6221 - val_loss: 13.3118
Epoch 133/8000

Epoch 00133: val_loss did not improve from 12.68146
 - 14s - loss: 12.4835 - val_loss: 12.9063
Epoch 134/8000

Epoch 00134: val_loss did not improve from 12.68146
 - 14s - loss: 13.9509 - val_loss: 13.4831
Epoch 135/8000

Epoch 00135: val_loss did not improve from 12.68146
 - 14s - loss: 12.9674 - val_loss: 12.8181
Epoch 136/8000

Epoch 00136: val_loss did not improve from 12.68146
 - 14s - loss: 12.5744 - val_loss: 12.7645
Epoch 137/8000

Epoch 00137: val_loss did not improve from 12.68146
 - 14s - loss: 12.6176 - val_loss: 12.8865
Epoch 138/8000

Epoch 00138: val_loss did not improve from 12.68146
 - 14s - loss: 12.3342 - val_loss: 12.9755
Epoch 139/8000

Epoch 00139: val_loss did not improve from 12.68146
 - 14s - loss: 18.9712 - val_loss: 18.1219
Epoch 140/8000

Epoch 00140: val_loss did not improve from 12.68146
 - 14s - loss: 16.7430 - val_loss: 16.5856
Epoch 141/8000

Epoch 00141: val_loss did not improve from 12.68146
 - 14s - loss: 15.9491 - val_loss: 15.9894
Epoch 142/8000

Epoch 00142: val_loss did not improve from 12.68146
 - 14s - loss: 15.5198 - val_loss: 15.4447
Epoch 143/8000

Epoch 00143: val_loss did not improve from 12.68146
 - 14s - loss: 15.1532 - val_loss: 15.2268
Epoch 144/8000

Epoch 00144: val_loss did not improve from 12.68146
 - 14s - loss: 14.9109 - val_loss: 15.1733
Epoch 145/8000

Epoch 00145: val_loss did not improve from 12.68146
 - 14s - loss: 14.6896 - val_loss: 14.8937
Epoch 146/8000

Epoch 00146: val_loss did not improve from 12.68146
 - 14s - loss: 14.5003 - val_loss: 14.4423
Epoch 147/8000

Epoch 00147: val_loss did not improve from 12.68146
 - 14s - loss: 14.3788 - val_loss: 14.6582
Epoch 148/8000

Epoch 00148: val_loss did not improve from 12.68146
 - 14s - loss: 14.1066 - val_loss: 14.1353
Epoch 149/8000

Epoch 00149: val_loss did not improve from 12.68146
 - 14s - loss: 13.9637 - val_loss: 13.9298
Epoch 150/8000

Epoch 00150: val_loss did not improve from 12.68146
 - 14s - loss: 13.7773 - val_loss: 13.6399
Epoch 151/8000

Epoch 00151: val_loss did not improve from 12.68146
 - 14s - loss: 13.6023 - val_loss: 13.3839
Epoch 152/8000

Epoch 00152: val_loss did not improve from 12.68146
 - 14s - loss: 13.3112 - val_loss: 13.5174
Epoch 153/8000

Epoch 00153: val_loss did not improve from 12.68146
 - 14s - loss: 13.0970 - val_loss: 13.3225
Epoch 154/8000

Epoch 00154: val_loss did not improve from 12.68146
 - 14s - loss: 13.0803 - val_loss: 13.4076
Epoch 155/8000

Epoch 00155: val_loss did not improve from 12.68146
 - 14s - loss: 12.9464 - val_loss: 13.1628
Epoch 156/8000

Epoch 00156: val_loss did not improve from 12.68146
 - 14s - loss: 12.8243 - val_loss: 13.4050
Epoch 157/8000

Epoch 00157: val_loss did not improve from 12.68146
 - 14s - loss: 12.8141 - val_loss: 14.3942
Epoch 158/8000

Epoch 00158: val_loss did not improve from 12.68146
 - 14s - loss: 12.9259 - val_loss: 12.8723
Epoch 159/8000

Epoch 00159: val_loss improved from 12.68146 to 12.57534, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 12.7326 - val_loss: 12.5753
Epoch 160/8000

Epoch 00160: val_loss did not improve from 12.57534
 - 14s - loss: 12.5633 - val_loss: 13.0490
Epoch 161/8000

Epoch 00161: val_loss did not improve from 12.57534
 - 14s - loss: 12.6067 - val_loss: 12.6246
Epoch 162/8000

Epoch 00162: val_loss did not improve from 12.57534
 - 14s - loss: 13.1470 - val_loss: 13.1046
Epoch 163/8000

Epoch 00163: val_loss did not improve from 12.57534
 - 14s - loss: 12.4514 - val_loss: 13.5431
Epoch 164/8000

Epoch 00164: val_loss did not improve from 12.57534
 - 14s - loss: 12.7158 - val_loss: 13.0321
Epoch 165/8000

Epoch 00165: val_loss did not improve from 12.57534
 - 14s - loss: 12.3346 - val_loss: 12.5803
Epoch 166/8000

Epoch 00166: val_loss did not improve from 12.57534
 - 14s - loss: 14.3635 - val_loss: 13.9910
Epoch 167/8000

Epoch 00167: val_loss improved from 12.57534 to 12.53643, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 12.7245 - val_loss: 12.5364
Epoch 168/8000

Epoch 00168: val_loss did not improve from 12.53643
 - 14s - loss: 12.8296 - val_loss: 12.9204
Epoch 169/8000

Epoch 00169: val_loss improved from 12.53643 to 12.25348, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 12.3935 - val_loss: 12.2535
Epoch 170/8000

Epoch 00170: val_loss did not improve from 12.25348
 - 14s - loss: 13.3852 - val_loss: 13.3532
Epoch 171/8000

Epoch 00171: val_loss did not improve from 12.25348
 - 14s - loss: 12.5717 - val_loss: 14.0145
Epoch 172/8000

Epoch 00172: val_loss did not improve from 12.25348
 - 14s - loss: 13.1184 - val_loss: 13.4364
Epoch 173/8000

Epoch 00173: val_loss did not improve from 12.25348
 - 14s - loss: 12.7665 - val_loss: 12.5878
Epoch 174/8000

Epoch 00174: val_loss did not improve from 12.25348
 - 14s - loss: 12.5550 - val_loss: 12.6727
Epoch 175/8000

Epoch 00175: val_loss did not improve from 12.25348
 - 14s - loss: 12.3277 - val_loss: 12.6311
Epoch 176/8000

Epoch 00176: val_loss did not improve from 12.25348
 - 14s - loss: 12.2327 - val_loss: 12.4368
Epoch 177/8000

Epoch 00177: val_loss did not improve from 12.25348
 - 14s - loss: 12.3130 - val_loss: 12.9153
Epoch 178/8000

Epoch 00178: val_loss did not improve from 12.25348
 - 14s - loss: 12.1598 - val_loss: 12.5706
Epoch 179/8000

Epoch 00179: val_loss did not improve from 12.25348
 - 14s - loss: 14.9881 - val_loss: 15.6840
Epoch 180/8000

Epoch 00180: val_loss did not improve from 12.25348
 - 14s - loss: 14.3449 - val_loss: 14.0233
Epoch 181/8000

Epoch 00181: val_loss did not improve from 12.25348
 - 14s - loss: 13.5216 - val_loss: 13.7239
Epoch 182/8000

Epoch 00182: val_loss did not improve from 12.25348
 - 14s - loss: 13.1891 - val_loss: 13.2104
Epoch 183/8000

Epoch 00183: val_loss did not improve from 12.25348
 - 14s - loss: 12.9301 - val_loss: 12.9378
Epoch 184/8000

Epoch 00184: val_loss did not improve from 12.25348
 - 14s - loss: 12.7168 - val_loss: 13.2849
Epoch 185/8000

Epoch 00185: val_loss did not improve from 12.25348
 - 14s - loss: 12.5768 - val_loss: 12.5507
Epoch 186/8000

Epoch 00186: val_loss did not improve from 12.25348
 - 14s - loss: 12.3366 - val_loss: 13.1609
Epoch 187/8000

Epoch 00187: val_loss did not improve from 12.25348
 - 14s - loss: 12.4647 - val_loss: 12.6524
Epoch 188/8000

Epoch 00188: val_loss did not improve from 12.25348
 - 14s - loss: 12.2883 - val_loss: 12.4638
Epoch 189/8000

Epoch 00189: val_loss did not improve from 12.25348
 - 14s - loss: 12.1473 - val_loss: 12.4831
Epoch 190/8000

Epoch 00190: val_loss improved from 12.25348 to 12.06593, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.9130 - val_loss: 12.0659
Epoch 191/8000

Epoch 00191: val_loss did not improve from 12.06593
 - 14s - loss: 12.0701 - val_loss: 12.8951
Epoch 192/8000

Epoch 00192: val_loss did not improve from 12.06593
 - 14s - loss: 11.9107 - val_loss: 13.5470
Epoch 193/8000

Epoch 00193: val_loss improved from 12.06593 to 12.03715, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 12.3500 - val_loss: 12.0372
Epoch 194/8000

Epoch 00194: val_loss did not improve from 12.03715
 - 14s - loss: 12.0437 - val_loss: 12.4532
Epoch 195/8000

Epoch 00195: val_loss did not improve from 12.03715
 - 14s - loss: 12.0334 - val_loss: 12.2387
Epoch 196/8000

Epoch 00196: val_loss did not improve from 12.03715
 - 14s - loss: 12.0192 - val_loss: 12.4352
Epoch 197/8000

Epoch 00197: val_loss did not improve from 12.03715
 - 14s - loss: 14.1863 - val_loss: 13.5301
Epoch 198/8000

Epoch 00198: val_loss did not improve from 12.03715
 - 14s - loss: 13.0213 - val_loss: 12.9078
Epoch 199/8000

Epoch 00199: val_loss did not improve from 12.03715
 - 14s - loss: 12.5983 - val_loss: 12.8095
Epoch 200/8000

Epoch 00200: val_loss did not improve from 12.03715
 - 14s - loss: 12.3418 - val_loss: 12.6668
Epoch 201/8000

Epoch 00201: val_loss did not improve from 12.03715
 - 14s - loss: 12.1390 - val_loss: 13.5215
Epoch 202/8000

Epoch 00202: val_loss did not improve from 12.03715
 - 14s - loss: 12.0580 - val_loss: 12.0739
Epoch 203/8000

Epoch 00203: val_loss improved from 12.03715 to 12.03584, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.8639 - val_loss: 12.0358
Epoch 204/8000

Epoch 00204: val_loss did not improve from 12.03584
 - 14s - loss: 11.8587 - val_loss: 12.3577
Epoch 205/8000

Epoch 00205: val_loss did not improve from 12.03584
 - 14s - loss: 11.8553 - val_loss: 12.6191
Epoch 206/8000

Epoch 00206: val_loss improved from 12.03584 to 11.94180, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.9443 - val_loss: 11.9418
Epoch 207/8000

Epoch 00207: val_loss did not improve from 11.94180
 - 14s - loss: 11.7851 - val_loss: 11.9577
Epoch 208/8000

Epoch 00208: val_loss did not improve from 11.94180
 - 14s - loss: 11.8141 - val_loss: 12.1642
Epoch 209/8000

Epoch 00209: val_loss did not improve from 11.94180
 - 14s - loss: 11.7868 - val_loss: 11.9814
Epoch 210/8000

Epoch 00210: val_loss did not improve from 11.94180
 - 14s - loss: 11.8647 - val_loss: 11.9647
Epoch 211/8000

Epoch 00211: val_loss did not improve from 11.94180
 - 14s - loss: 11.7835 - val_loss: 15.3301
Epoch 212/8000

Epoch 00212: val_loss did not improve from 11.94180
 - 14s - loss: 13.8450 - val_loss: 12.7431
Epoch 213/8000

Epoch 00213: val_loss did not improve from 11.94180
 - 14s - loss: 12.0772 - val_loss: 12.1147
Epoch 214/8000

Epoch 00214: val_loss did not improve from 11.94180
 - 14s - loss: 12.0163 - val_loss: 12.3887
Epoch 215/8000

Epoch 00215: val_loss did not improve from 11.94180
 - 14s - loss: 12.0232 - val_loss: 12.1669
Epoch 216/8000

Epoch 00216: val_loss did not improve from 11.94180
 - 14s - loss: 11.8617 - val_loss: 11.9730
Epoch 217/8000

Epoch 00217: val_loss did not improve from 11.94180
 - 14s - loss: 15.1112 - val_loss: 20.9017
Epoch 218/8000

Epoch 00218: val_loss did not improve from 11.94180
 - 14s - loss: 17.3442 - val_loss: 16.5465
Epoch 219/8000

Epoch 00219: val_loss did not improve from 11.94180
 - 14s - loss: 15.6505 - val_loss: 15.4906
Epoch 220/8000

Epoch 00220: val_loss did not improve from 11.94180
 - 14s - loss: 14.9322 - val_loss: 14.8990
Epoch 221/8000

Epoch 00221: val_loss did not improve from 11.94180
 - 14s - loss: 14.4588 - val_loss: 14.8017
Epoch 222/8000

Epoch 00222: val_loss did not improve from 11.94180
 - 14s - loss: 14.2708 - val_loss: 14.3449
Epoch 223/8000

Epoch 00223: val_loss did not improve from 11.94180
 - 14s - loss: 13.8490 - val_loss: 14.1309
Epoch 224/8000

Epoch 00224: val_loss did not improve from 11.94180
 - 14s - loss: 13.5249 - val_loss: 13.7880
Epoch 225/8000

Epoch 00225: val_loss did not improve from 11.94180
 - 14s - loss: 13.2634 - val_loss: 13.3858
Epoch 226/8000

Epoch 00226: val_loss did not improve from 11.94180
 - 14s - loss: 13.1558 - val_loss: 13.3434
Epoch 227/8000

Epoch 00227: val_loss did not improve from 11.94180
 - 14s - loss: 13.0793 - val_loss: 13.7800
Epoch 228/8000

Epoch 00228: val_loss did not improve from 11.94180
 - 14s - loss: 13.0898 - val_loss: 13.0525
Epoch 229/8000

Epoch 00229: val_loss did not improve from 11.94180
 - 14s - loss: 12.6484 - val_loss: 13.3974
Epoch 230/8000

Epoch 00230: val_loss did not improve from 11.94180
 - 14s - loss: 12.5551 - val_loss: 12.6655
Epoch 231/8000

Epoch 00231: val_loss did not improve from 11.94180
 - 14s - loss: 12.5234 - val_loss: 12.5870
Epoch 232/8000

Epoch 00232: val_loss did not improve from 11.94180
 - 14s - loss: 12.3497 - val_loss: 12.3251
Epoch 233/8000

Epoch 00233: val_loss did not improve from 11.94180
 - 14s - loss: 12.2166 - val_loss: 12.2168
Epoch 234/8000

Epoch 00234: val_loss did not improve from 11.94180
 - 14s - loss: 11.9653 - val_loss: 12.4912
Epoch 235/8000

Epoch 00235: val_loss did not improve from 11.94180
 - 14s - loss: 13.1917 - val_loss: 13.8646
Epoch 236/8000

Epoch 00236: val_loss did not improve from 11.94180
 - 14s - loss: 12.6090 - val_loss: 12.1627
Epoch 237/8000

Epoch 00237: val_loss did not improve from 11.94180
 - 14s - loss: 12.1077 - val_loss: 12.1393
Epoch 238/8000

Epoch 00238: val_loss did not improve from 11.94180
 - 14s - loss: 11.8088 - val_loss: 12.3694
Epoch 239/8000

Epoch 00239: val_loss did not improve from 11.94180
 - 14s - loss: 11.9883 - val_loss: 12.0169
Epoch 240/8000

Epoch 00240: val_loss did not improve from 11.94180
 - 14s - loss: 11.8380 - val_loss: 12.1172
Epoch 241/8000

Epoch 00241: val_loss improved from 11.94180 to 11.72893, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.7487 - val_loss: 11.7289
Epoch 242/8000

Epoch 00242: val_loss did not improve from 11.72893
 - 14s - loss: 11.7339 - val_loss: 12.0276
Epoch 243/8000

Epoch 00243: val_loss did not improve from 11.72893
 - 14s - loss: 11.6336 - val_loss: 12.2103
Epoch 244/8000

Epoch 00244: val_loss improved from 11.72893 to 11.60132, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.6527 - val_loss: 11.6013
Epoch 245/8000

Epoch 00245: val_loss did not improve from 11.60132
 - 14s - loss: 11.5622 - val_loss: 12.1805
Epoch 246/8000

Epoch 00246: val_loss did not improve from 11.60132
 - 14s - loss: 11.6190 - val_loss: 11.7866
Epoch 247/8000

Epoch 00247: val_loss did not improve from 11.60132
 - 14s - loss: 11.4610 - val_loss: 12.2199
Epoch 248/8000

Epoch 00248: val_loss did not improve from 11.60132
 - 14s - loss: 11.5930 - val_loss: 12.4997
Epoch 249/8000

Epoch 00249: val_loss did not improve from 11.60132
 - 14s - loss: 11.5836 - val_loss: 12.8486
Epoch 250/8000

Epoch 00250: val_loss did not improve from 11.60132
 - 14s - loss: 11.8865 - val_loss: 12.2471
Epoch 251/8000

Epoch 00251: val_loss did not improve from 11.60132
 - 14s - loss: 11.5954 - val_loss: 11.8509
Epoch 252/8000

Epoch 00252: val_loss did not improve from 11.60132
 - 14s - loss: 11.5235 - val_loss: 11.9128
Epoch 253/8000

Epoch 00253: val_loss did not improve from 11.60132
 - 14s - loss: 11.5272 - val_loss: 11.6927
Epoch 254/8000

Epoch 00254: val_loss did not improve from 11.60132
 - 14s - loss: 12.7327 - val_loss: 13.4708
Epoch 255/8000

Epoch 00255: val_loss did not improve from 11.60132
 - 14s - loss: 12.0912 - val_loss: 12.1631
Epoch 256/8000

Epoch 00256: val_loss did not improve from 11.60132
 - 14s - loss: 11.7763 - val_loss: 11.9300
Epoch 257/8000

Epoch 00257: val_loss did not improve from 11.60132
 - 14s - loss: 11.7026 - val_loss: 12.4612
Epoch 258/8000

Epoch 00258: val_loss did not improve from 11.60132
 - 14s - loss: 11.6623 - val_loss: 11.7810
Epoch 259/8000

Epoch 00259: val_loss did not improve from 11.60132
 - 14s - loss: 11.7164 - val_loss: 11.8396
Epoch 260/8000

Epoch 00260: val_loss did not improve from 11.60132
 - 14s - loss: 11.7666 - val_loss: 11.9654
Epoch 261/8000

Epoch 00261: val_loss did not improve from 11.60132
 - 14s - loss: 11.5172 - val_loss: 11.6044
Epoch 262/8000

Epoch 00262: val_loss did not improve from 11.60132
 - 14s - loss: 11.6084 - val_loss: 11.7142
Epoch 263/8000

Epoch 00263: val_loss improved from 11.60132 to 11.49601, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.5118 - val_loss: 11.4960
Epoch 264/8000

Epoch 00264: val_loss did not improve from 11.49601
 - 14s - loss: 11.9516 - val_loss: 12.2768
Epoch 265/8000

Epoch 00265: val_loss did not improve from 11.49601
 - 14s - loss: 11.7256 - val_loss: 12.1644
Epoch 266/8000

Epoch 00266: val_loss did not improve from 11.49601
 - 14s - loss: 11.4506 - val_loss: 11.6924
Epoch 267/8000

Epoch 00267: val_loss did not improve from 11.49601
 - 14s - loss: 11.3815 - val_loss: 11.5987
Epoch 268/8000

Epoch 00268: val_loss did not improve from 11.49601
 - 14s - loss: 11.7467 - val_loss: 11.5274
Epoch 269/8000

Epoch 00269: val_loss did not improve from 11.49601
 - 14s - loss: 11.3360 - val_loss: 11.6431
Epoch 270/8000

Epoch 00270: val_loss did not improve from 11.49601
 - 14s - loss: 11.5721 - val_loss: 11.7335
Epoch 271/8000

Epoch 00271: val_loss did not improve from 11.49601
 - 14s - loss: 11.5737 - val_loss: 11.7138
Epoch 272/8000

Epoch 00272: val_loss did not improve from 11.49601
 - 14s - loss: 11.5552 - val_loss: 11.5454
Epoch 273/8000

Epoch 00273: val_loss did not improve from 11.49601
 - 14s - loss: 11.4686 - val_loss: 11.6238
Epoch 274/8000

Epoch 00274: val_loss did not improve from 11.49601
 - 14s - loss: 11.5064 - val_loss: 11.4984
Epoch 275/8000

Epoch 00275: val_loss did not improve from 11.49601
 - 14s - loss: 11.4585 - val_loss: 11.9510
Epoch 276/8000

Epoch 00276: val_loss did not improve from 11.49601
 - 14s - loss: 11.4852 - val_loss: 11.5127
Epoch 277/8000

Epoch 00277: val_loss did not improve from 11.49601
 - 14s - loss: 12.3268 - val_loss: 11.7234
Epoch 278/8000

Epoch 00278: val_loss did not improve from 11.49601
 - 14s - loss: 11.4848 - val_loss: 11.5965
Epoch 279/8000

Epoch 00279: val_loss improved from 11.49601 to 11.45201, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.3899 - val_loss: 11.4520
Epoch 280/8000

Epoch 00280: val_loss did not improve from 11.45201
 - 14s - loss: 11.8726 - val_loss: 11.5946
Epoch 281/8000

Epoch 00281: val_loss did not improve from 11.45201
 - 14s - loss: 11.4779 - val_loss: 11.6329
Epoch 282/8000

Epoch 00282: val_loss did not improve from 11.45201
 - 14s - loss: 11.2011 - val_loss: 11.6179
Epoch 283/8000

Epoch 00283: val_loss did not improve from 11.45201
 - 14s - loss: 11.1630 - val_loss: 11.7679
Epoch 284/8000

Epoch 00284: val_loss improved from 11.45201 to 11.39964, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.2991 - val_loss: 11.3996
Epoch 285/8000

Epoch 00285: val_loss improved from 11.39964 to 11.33985, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.2426 - val_loss: 11.3399
Epoch 286/8000

Epoch 00286: val_loss did not improve from 11.33985
 - 14s - loss: 11.1829 - val_loss: 12.1093
Epoch 287/8000

Epoch 00287: val_loss did not improve from 11.33985
 - 14s - loss: 12.3375 - val_loss: 12.7510
Epoch 288/8000

Epoch 00288: val_loss did not improve from 11.33985
 - 14s - loss: 11.3892 - val_loss: 11.5185
Epoch 289/8000

Epoch 00289: val_loss did not improve from 11.33985
 - 14s - loss: 11.9429 - val_loss: 12.0028
Epoch 290/8000

Epoch 00290: val_loss did not improve from 11.33985
 - 14s - loss: 12.2608 - val_loss: 11.6923
Epoch 291/8000

Epoch 00291: val_loss did not improve from 11.33985
 - 14s - loss: 11.5573 - val_loss: 12.2278
Epoch 292/8000

Epoch 00292: val_loss did not improve from 11.33985
 - 14s - loss: 11.6989 - val_loss: 12.3533
Epoch 293/8000

Epoch 00293: val_loss improved from 11.33985 to 11.33528, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.2972 - val_loss: 11.3353
Epoch 294/8000

Epoch 00294: val_loss improved from 11.33528 to 11.16955, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.1036 - val_loss: 11.1696
Epoch 295/8000

Epoch 00295: val_loss did not improve from 11.16955
 - 14s - loss: 11.0900 - val_loss: 11.2864
Epoch 296/8000

Epoch 00296: val_loss did not improve from 11.16955
 - 14s - loss: 11.2983 - val_loss: 11.1759
Epoch 297/8000

Epoch 00297: val_loss did not improve from 11.16955
 - 14s - loss: 11.0962 - val_loss: 11.2844
Epoch 298/8000

Epoch 00298: val_loss did not improve from 11.16955
 - 14s - loss: 11.3188 - val_loss: 11.2708
Epoch 299/8000

Epoch 00299: val_loss did not improve from 11.16955
 - 14s - loss: 11.0439 - val_loss: 11.2619
Epoch 300/8000

Epoch 00300: val_loss did not improve from 11.16955
 - 14s - loss: 10.9750 - val_loss: 11.5096
Epoch 301/8000

Epoch 00301: val_loss did not improve from 11.16955
 - 14s - loss: 12.0517 - val_loss: 14.5257
Epoch 302/8000

Epoch 00302: val_loss did not improve from 11.16955
 - 14s - loss: 12.2071 - val_loss: 11.4961
Epoch 303/8000

Epoch 00303: val_loss did not improve from 11.16955
 - 14s - loss: 11.4648 - val_loss: 13.3440
Epoch 304/8000

Epoch 00304: val_loss did not improve from 11.16955
 - 14s - loss: 12.0340 - val_loss: 12.6025
Epoch 305/8000

Epoch 00305: val_loss did not improve from 11.16955
 - 14s - loss: 11.6659 - val_loss: 13.1966
Epoch 306/8000

Epoch 00306: val_loss did not improve from 11.16955
 - 14s - loss: 11.5801 - val_loss: 11.7290
Epoch 307/8000

Epoch 00307: val_loss did not improve from 11.16955
 - 14s - loss: 11.8576 - val_loss: 12.6233
Epoch 308/8000

Epoch 00308: val_loss did not improve from 11.16955
 - 14s - loss: 12.4132 - val_loss: 11.6314
Epoch 309/8000

Epoch 00309: val_loss did not improve from 11.16955
 - 14s - loss: 11.2517 - val_loss: 11.1723
Epoch 310/8000

Epoch 00310: val_loss did not improve from 11.16955
 - 14s - loss: 11.3747 - val_loss: 11.4257
Epoch 311/8000

Epoch 00311: val_loss did not improve from 11.16955
 - 14s - loss: 11.1511 - val_loss: 11.2960
Epoch 312/8000

Epoch 00312: val_loss improved from 11.16955 to 11.03852, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 10.9771 - val_loss: 11.0385
Epoch 313/8000

Epoch 00313: val_loss did not improve from 11.03852
 - 14s - loss: 11.6705 - val_loss: 11.5356
Epoch 314/8000

Epoch 00314: val_loss did not improve from 11.03852
 - 14s - loss: 11.2965 - val_loss: 11.6247
Epoch 315/8000

Epoch 00315: val_loss did not improve from 11.03852
 - 14s - loss: 11.5770 - val_loss: 12.6874
Epoch 316/8000

Epoch 00316: val_loss did not improve from 11.03852
 - 14s - loss: 11.8537 - val_loss: 11.6964
Epoch 317/8000

Epoch 00317: val_loss did not improve from 11.03852
 - 14s - loss: 11.3496 - val_loss: 11.2334
Epoch 318/8000

Epoch 00318: val_loss did not improve from 11.03852
 - 14s - loss: 11.1482 - val_loss: 12.1083
Epoch 319/8000

Epoch 00319: val_loss did not improve from 11.03852
 - 14s - loss: 11.4926 - val_loss: 11.2312
Epoch 320/8000

Epoch 00320: val_loss did not improve from 11.03852
 - 14s - loss: 11.1317 - val_loss: 11.0790
Epoch 321/8000

Epoch 00321: val_loss did not improve from 11.03852
 - 14s - loss: 11.3909 - val_loss: 12.5090
Epoch 322/8000

Epoch 00322: val_loss did not improve from 11.03852
 - 14s - loss: 11.5177 - val_loss: 11.3207
Epoch 323/8000

Epoch 00323: val_loss did not improve from 11.03852
 - 14s - loss: 11.0940 - val_loss: 11.4670
Epoch 324/8000

Epoch 00324: val_loss did not improve from 11.03852
 - 14s - loss: 11.2579 - val_loss: 11.4657
Epoch 325/8000

Epoch 00325: val_loss did not improve from 11.03852
 - 14s - loss: 10.9863 - val_loss: 11.1793
Epoch 326/8000

Epoch 00326: val_loss did not improve from 11.03852
 - 14s - loss: 13.7803 - val_loss: 12.3325
Epoch 327/8000

Epoch 00327: val_loss improved from 11.03852 to 11.02021, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.5849 - val_loss: 11.0202
Epoch 328/8000

Epoch 00328: val_loss improved from 11.02021 to 10.97388, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 11.0795 - val_loss: 10.9739
Epoch 329/8000

Epoch 00329: val_loss did not improve from 10.97388
 - 14s - loss: 11.0366 - val_loss: 11.1812
Epoch 330/8000

Epoch 00330: val_loss did not improve from 10.97388
 - 14s - loss: 11.3300 - val_loss: 11.1488
Epoch 331/8000

Epoch 00331: val_loss did not improve from 10.97388
 - 14s - loss: 12.4294 - val_loss: 12.3321
Epoch 332/8000

Epoch 00332: val_loss did not improve from 10.97388
 - 14s - loss: 11.5432 - val_loss: 12.1246
Epoch 333/8000

Epoch 00333: val_loss did not improve from 10.97388
 - 14s - loss: 11.5172 - val_loss: 11.2098
Epoch 334/8000

Epoch 00334: val_loss did not improve from 10.97388
 - 14s - loss: 11.3720 - val_loss: 11.3195
Epoch 335/8000

Epoch 00335: val_loss did not improve from 10.97388
 - 14s - loss: 11.9644 - val_loss: 11.2908
Epoch 336/8000

Epoch 00336: val_loss did not improve from 10.97388
 - 14s - loss: 11.0334 - val_loss: 11.1550
Epoch 337/8000

Epoch 00337: val_loss did not improve from 10.97388
 - 14s - loss: 11.0212 - val_loss: 11.2187
Epoch 338/8000

Epoch 00338: val_loss did not improve from 10.97388
 - 14s - loss: 11.7354 - val_loss: 11.4242
Epoch 339/8000

Epoch 00339: val_loss did not improve from 10.97388
 - 14s - loss: 11.4093 - val_loss: 12.4216
Epoch 340/8000

Epoch 00340: val_loss did not improve from 10.97388
 - 14s - loss: 11.5447 - val_loss: 11.7959
Epoch 341/8000

Epoch 00341: val_loss did not improve from 10.97388
 - 14s - loss: 11.3382 - val_loss: 11.8019
Epoch 342/8000

Epoch 00342: val_loss did not improve from 10.97388
 - 14s - loss: 11.2350 - val_loss: 11.3911
Epoch 343/8000

Epoch 00343: val_loss did not improve from 10.97388
 - 14s - loss: 11.2096 - val_loss: 11.7506
Epoch 344/8000

Epoch 00344: val_loss did not improve from 10.97388
 - 14s - loss: 11.0371 - val_loss: 11.4003
Epoch 345/8000

Epoch 00345: val_loss improved from 10.97388 to 10.88348, saving model to model_weights/model_2020-01-27_12-52-37.h5
 - 14s - loss: 10.9610 - val_loss: 10.8835
Epoch 346/8000

Epoch 00346: val_loss did not improve from 10.88348
 - 14s - loss: 10.8346 - val_loss: 11.0035
Epoch 347/8000

Epoch 00347: val_loss did not improve from 10.88348
 - 14s - loss: 10.8145 - val_loss: 11.1557
Epoch 348/8000

Epoch 00348: val_loss did not improve from 10.88348
 - 14s - loss: 10.8945 - val_loss: 11.6391
Epoch 349/8000

Epoch 00349: val_loss did not improve from 10.88348
 - 14s - loss: 11.5060 - val_loss: 11.0202
Epoch 350/8000

Epoch 00350: val_loss did not improve from 10.88348
 - 14s - loss: 15.3699 - val_loss: 18.0003
Epoch 351/8000

Epoch 00351: val_loss did not improve from 10.88348
 - 14s - loss: 16.5234 - val_loss: 16.0250
Epoch 352/8000

Epoch 00352: val_loss did not improve from 10.88348
 - 14s - loss: 15.0418 - val_loss: 14.8139
Epoch 353/8000

Epoch 00353: val_loss did not improve from 10.88348
 - 14s - loss: 14.1871 - val_loss: 14.1928
Epoch 354/8000

Epoch 00354: val_loss did not improve from 10.88348
 - 14s - loss: 13.5916 - val_loss: 13.7824
Epoch 355/8000

Epoch 00355: val_loss did not improve from 10.88348
 - 14s - loss: 13.2319 - val_loss: 13.3943
Epoch 356/8000

Epoch 00356: val_loss did not improve from 10.88348
 - 14s - loss: 12.6220 - val_loss: 12.6111
Epoch 357/8000

Epoch 00357: val_loss did not improve from 10.88348
 - 14s - loss: 12.0505 - val_loss: 12.4907
Epoch 358/8000

Epoch 00358: val_loss did not improve from 10.88348
 - 14s - loss: 11.7959 - val_loss: 11.7539
Epoch 359/8000

Epoch 00359: val_loss did not improve from 10.88348
 - 14s - loss: 11.5434 - val_loss: 11.5195
Epoch 360/8000

Epoch 00360: val_loss did not improve from 10.88348
 - 14s - loss: 11.5136 - val_loss: 11.2981
Epoch 361/8000

Epoch 00361: val_loss did not improve from 10.88348
 - 14s - loss: 11.6546 - val_loss: 11.5005
Epoch 362/8000

Epoch 00362: val_loss did not improve from 10.88348
 - 14s - loss: 11.1572 - val_loss: 11.4295
Epoch 363/8000

Epoch 00363: val_loss did not improve from 10.88348
 - 14s - loss: 11.1212 - val_loss: 11.7424
Epoch 364/8000

Epoch 00364: val_loss did not improve from 10.88348
 - 14s - loss: 10.9546 - val_loss: 11.5200
Epoch 365/8000

Epoch 00365: val_loss did not improve from 10.88348
 - 14s - loss: 11.0400 - val_loss: 11.4090
Epoch 366/8000

Epoch 00366: val_loss did not improve from 10.88348
 - 14s - loss: 11.0790 - val_loss: 11.5285
Epoch 367/8000

Epoch 00367: val_loss did not improve from 10.88348
 - 14s - loss: 11.1143 - val_loss: 10.9879
Epoch 368/8000

Epoch 00368: val_loss did not improve from 10.88348
 - 14s - loss: 11.5220 - val_loss: 12.3677
Epoch 369/8000

Epoch 00369: val_loss did not improve from 10.88348
 - 14s - loss: 11.5140 - val_loss: 11.5413
Epoch 370/8000

Epoch 00370: val_loss did not improve from 10.88348
 - 14s - loss: 11.0460 - val_loss: 11.2301
Epoch 371/8000

Epoch 00371: val_loss did not improve from 10.88348
 - 14s - loss: 11.5012 - val_loss: 11.7720
Epoch 372/8000

Epoch 00372: val_loss did not improve from 10.88348
 - 14s - loss: 12.6351 - val_loss: 12.4783
Epoch 373/8000

Epoch 00373: val_loss did not improve from 10.88348
 - 14s - loss: 11.4199 - val_loss: 11.3883
Epoch 374/8000

Epoch 00374: val_loss did not improve from 10.88348
 - 14s - loss: 11.1344 - val_loss: 11.3501
Epoch 375/8000

Epoch 00375: val_loss did not improve from 10.88348
 - 14s - loss: 11.2689 - val_loss: 11.5751
Epoch 376/8000

Epoch 00376: val_loss did not improve from 10.88348
 - 14s - loss: 11.4804 - val_loss: 11.6587
Epoch 377/8000

Epoch 00377: val_loss did not improve from 10.88348
 - 14s - loss: 10.9518 - val_loss: 11.3135
Epoch 378/8000

Epoch 00378: val_loss did not improve from 10.88348
 - 14s - loss: 11.2043 - val_loss: 11.8894
Epoch 379/8000

Epoch 00379: val_loss did not improve from 10.88348
 - 14s - loss: 14.2076 - val_loss: 15.2005
Epoch 380/8000

Epoch 00380: val_loss did not improve from 10.88348
 - 14s - loss: 13.2798 - val_loss: 12.4533
Epoch 381/8000

Epoch 00381: val_loss did not improve from 10.88348
 - 14s - loss: 11.6190 - val_loss: 12.3978
Epoch 382/8000

Epoch 00382: val_loss did not improve from 10.88348
 - 14s - loss: 12.0023 - val_loss: 11.8940
Epoch 383/8000

Epoch 00383: val_loss did not improve from 10.88348
 - 14s - loss: 11.2643 - val_loss: 12.2223
Epoch 384/8000

Epoch 00384: val_loss did not improve from 10.88348
 - 14s - loss: 10.9395 - val_loss: 11.2262
Epoch 385/8000

Epoch 00385: val_loss did not improve from 10.88348
 - 14s - loss: 10.9547 - val_loss: 10.9710
Epoch 386/8000

Epoch 00386: val_loss did not improve from 10.88348
 - 14s - loss: 10.8626 - val_loss: 11.0920
Epoch 387/8000

Epoch 00387: val_loss did not improve from 10.88348
 - 14s - loss: 10.7426 - val_loss: 11.0548
Epoch 388/8000

Epoch 00388: val_loss did not improve from 10.88348
 - 14s - loss: 10.7283 - val_loss: 11.1734
Epoch 389/8000

Epoch 00389: val_loss did not improve from 10.88348
 - 14s - loss: 11.0878 - val_loss: 11.5905
Epoch 390/8000

Epoch 00390: val_loss did not improve from 10.88348
 - 14s - loss: 11.1048 - val_loss: 11.0626
Epoch 391/8000

Epoch 00391: val_loss did not improve from 10.88348
 - 14s - loss: 10.7737 - val_loss: 10.9147
Epoch 392/8000

Epoch 00392: val_loss did not improve from 10.88348
 - 14s - loss: 10.8491 - val_loss: 10.9426
Epoch 393/8000

Epoch 00393: val_loss did not improve from 10.88348
 - 14s - loss: 10.9705 - val_loss: 12.1804
Epoch 394/8000

Epoch 00394: val_loss did not improve from 10.88348
 - 14s - loss: 11.6232 - val_loss: 13.6795
Epoch 395/8000

Epoch 00395: val_loss did not improve from 10.88348
 - 14s - loss: 12.2313 - val_loss: 12.1306
Epoch 396/8000

Epoch 00396: val_loss did not improve from 10.88348
 - 14s - loss: 11.9513 - val_loss: 11.8721
Epoch 397/8000

Epoch 00397: val_loss did not improve from 10.88348
 - 14s - loss: 11.5942 - val_loss: 12.4852
Epoch 398/8000

Epoch 00398: val_loss did not improve from 10.88348
 - 14s - loss: 11.7648 - val_loss: 12.6931
Epoch 399/8000

Epoch 00399: val_loss did not improve from 10.88348
 - 14s - loss: 11.7013 - val_loss: 11.9152
Epoch 400/8000

Epoch 00400: val_loss did not improve from 10.88348
 - 14s - loss: 14.6275 - val_loss: 13.8730
Epoch 401/8000

Epoch 00401: val_loss did not improve from 10.88348
 - 14s - loss: 12.8787 - val_loss: 13.0363
Epoch 402/8000

Epoch 00402: val_loss did not improve from 10.88348
 - 14s - loss: 12.3194 - val_loss: 12.4296
Epoch 403/8000

Epoch 00403: val_loss did not improve from 10.88348
 - 14s - loss: 12.0995 - val_loss: 12.1197
Epoch 404/8000

Epoch 00404: val_loss did not improve from 10.88348
 - 14s - loss: 11.8395 - val_loss: 12.3206
Epoch 405/8000

Epoch 00405: val_loss did not improve from 10.88348
 - 14s - loss: 11.7552 - val_loss: 13.1763
Epoch 406/8000

Epoch 00406: val_loss did not improve from 10.88348
 - 14s - loss: 11.7167 - val_loss: 11.9615
Epoch 407/8000

Epoch 00407: val_loss did not improve from 10.88348
 - 14s - loss: 11.4667 - val_loss: 11.4642
Epoch 408/8000

Epoch 00408: val_loss did not improve from 10.88348
 - 14s - loss: 11.5790 - val_loss: 11.5818
Epoch 409/8000

Epoch 00409: val_loss did not improve from 10.88348
 - 14s - loss: 11.4459 - val_loss: 11.6676
Epoch 410/8000

Epoch 00410: val_loss did not improve from 10.88348
 - 14s - loss: 11.2468 - val_loss: 11.5589
Epoch 411/8000

Epoch 00411: val_loss did not improve from 10.88348
 - 14s - loss: 11.4946 - val_loss: 11.9576
Epoch 412/8000

Epoch 00412: val_loss did not improve from 10.88348
 - 14s - loss: 11.3270 - val_loss: 12.1038
Epoch 413/8000

Epoch 00413: val_loss did not improve from 10.88348
 - 14s - loss: 11.3070 - val_loss: 11.7510
Epoch 414/8000

Epoch 00414: val_loss did not improve from 10.88348
 - 14s - loss: 11.1207 - val_loss: 11.3376
Epoch 415/8000

Epoch 00415: val_loss did not improve from 10.88348
 - 14s - loss: 11.3603 - val_loss: 12.3191
Epoch 416/8000

Epoch 00416: val_loss did not improve from 10.88348
 - 14s - loss: 11.3889 - val_loss: 11.9382
Epoch 417/8000

Epoch 00417: val_loss did not improve from 10.88348
 - 14s - loss: 11.1863 - val_loss: 11.4240
Epoch 418/8000

Epoch 00418: val_loss did not improve from 10.88348
 - 14s - loss: 11.0700 - val_loss: 11.1932
Epoch 419/8000

Epoch 00419: val_loss did not improve from 10.88348
 - 14s - loss: 12.1694 - val_loss: 12.7184
Epoch 420/8000

Epoch 00420: val_loss did not improve from 10.88348
 - 14s - loss: 12.3896 - val_loss: 12.1822
Epoch 421/8000

Epoch 00421: val_loss did not improve from 10.88348
 - 14s - loss: 11.7614 - val_loss: 12.3185
Epoch 422/8000

Epoch 00422: val_loss did not improve from 10.88348
 - 14s - loss: 11.2649 - val_loss: 11.4084
Epoch 423/8000

Epoch 00423: val_loss did not improve from 10.88348
 - 14s - loss: 11.3830 - val_loss: 13.0096
Epoch 424/8000

Epoch 00424: val_loss did not improve from 10.88348
 - 14s - loss: 11.4412 - val_loss: 11.6953
Epoch 425/8000

Epoch 00425: val_loss did not improve from 10.88348
 - 14s - loss: 11.1379 - val_loss: 12.2515
Epoch 426/8000

Epoch 00426: val_loss did not improve from 10.88348
 - 14s - loss: 11.2429 - val_loss: 11.4398
Epoch 427/8000

Epoch 00427: val_loss did not improve from 10.88348
 - 14s - loss: 11.0990 - val_loss: 11.5041
Epoch 428/8000

Epoch 00428: val_loss did not improve from 10.88348
 - 14s - loss: 11.3210 - val_loss: 11.2034
Epoch 429/8000

Epoch 00429: val_loss did not improve from 10.88348
 - 14s - loss: 10.9539 - val_loss: 11.2677
Epoch 430/8000

Epoch 00430: val_loss did not improve from 10.88348
 - 14s - loss: 10.9430 - val_loss: 11.4041
Epoch 431/8000

Epoch 00431: val_loss did not improve from 10.88348
 - 14s - loss: 11.1895 - val_loss: 12.4529
Epoch 432/8000

Epoch 00432: val_loss did not improve from 10.88348
 - 14s - loss: 11.1525 - val_loss: 12.3229
Epoch 433/8000

Epoch 00433: val_loss did not improve from 10.88348
 - 14s - loss: 11.0814 - val_loss: 11.1868
Epoch 434/8000

Epoch 00434: val_loss did not improve from 10.88348
 - 14s - loss: 12.3238 - val_loss: 12.9169
Epoch 435/8000

Epoch 00435: val_loss did not improve from 10.88348
 - 14s - loss: 11.7746 - val_loss: 11.7359
Epoch 436/8000

Epoch 00436: val_loss did not improve from 10.88348
 - 14s - loss: 11.2524 - val_loss: 11.7966
Epoch 437/8000

Epoch 00437: val_loss did not improve from 10.88348
 - 14s - loss: 13.0544 - val_loss: 11.3093
Epoch 438/8000

Epoch 00438: val_loss did not improve from 10.88348
 - 14s - loss: 11.3076 - val_loss: 12.1830
Epoch 439/8000

Epoch 00439: val_loss did not improve from 10.88348
 - 14s - loss: 13.9478 - val_loss: 13.3509
Epoch 440/8000

Epoch 00440: val_loss did not improve from 10.88348
 - 14s - loss: 12.5745 - val_loss: 12.6952
Epoch 441/8000

Epoch 00441: val_loss did not improve from 10.88348
 - 14s - loss: 12.2211 - val_loss: 13.4978
Epoch 442/8000

Epoch 00442: val_loss did not improve from 10.88348
 - 14s - loss: 11.9456 - val_loss: 12.2789
Epoch 443/8000

Epoch 00443: val_loss did not improve from 10.88348
 - 14s - loss: 11.3866 - val_loss: 11.5911
Epoch 444/8000

Epoch 00444: val_loss did not improve from 10.88348
 - 14s - loss: 11.2282 - val_loss: 12.1473
Epoch 445/8000

Epoch 00445: val_loss did not improve from 10.88348
 - 14s - loss: 14.2319 - val_loss: 16.1384
Epoch 00445: early stopping
