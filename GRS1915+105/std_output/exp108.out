2020-04-09 09:37:22.180146: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-04-09 09:37:22.492170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-09 09:37:22.492705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2020-04-09 09:37:22.492721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-04-09 09:37:22.764546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-09 09:37:22.764593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-04-09 09:37:22.764603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-04-09 09:37:22.764850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-09 09:37:22.967262: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x564c95f469e0
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 6.46567, saving model to ../../model_weights/model_2020-04-09_09-37-23.h5
 - 41s - loss: 5.4606 - val_loss: 6.4657
Epoch 2/8000

Epoch 00002: val_loss improved from 6.46567 to 6.27003, saving model to ../../model_weights/model_2020-04-09_09-37-23.h5
 - 39s - loss: 5.4165 - val_loss: 6.2700
Epoch 3/8000

Epoch 00003: val_loss improved from 6.27003 to 6.19516, saving model to ../../model_weights/model_2020-04-09_09-37-23.h5
 - 39s - loss: 5.4042 - val_loss: 6.1952
Epoch 4/8000

Epoch 00004: val_loss did not improve from 6.19516
 - 40s - loss: 5.3955 - val_loss: 6.3164
Epoch 5/8000

Epoch 00005: val_loss did not improve from 6.19516
 - 40s - loss: 5.3944 - val_loss: 6.5207
Epoch 6/8000

Epoch 00006: val_loss did not improve from 6.19516
 - 40s - loss: 5.3848 - val_loss: 6.3573
Epoch 7/8000

Epoch 00007: val_loss did not improve from 6.19516
 - 40s - loss: 5.3832 - val_loss: 6.2950
Epoch 8/8000

Epoch 00008: val_loss did not improve from 6.19516
 - 40s - loss: 5.3824 - val_loss: 6.4451
Epoch 9/8000

Epoch 00009: val_loss did not improve from 6.19516
 - 40s - loss: 5.3770 - val_loss: 6.3691
Epoch 10/8000

Epoch 00010: val_loss did not improve from 6.19516
 - 40s - loss: 5.3688 - val_loss: 6.3185
Epoch 11/8000

Epoch 00011: val_loss did not improve from 6.19516
 - 40s - loss: 5.3732 - val_loss: 6.2911
Epoch 12/8000

Epoch 00012: val_loss did not improve from 6.19516
 - 40s - loss: 5.3634 - val_loss: 6.3509
Epoch 13/8000

Epoch 00013: val_loss did not improve from 6.19516
 - 40s - loss: 5.3706 - val_loss: 6.3363
Epoch 14/8000

Epoch 00014: val_loss did not improve from 6.19516
 - 40s - loss: 5.3685 - val_loss: 6.3165
Epoch 15/8000

Epoch 00015: val_loss improved from 6.19516 to 6.09884, saving model to ../../model_weights/model_2020-04-09_09-37-23.h5
 - 40s - loss: 5.3637 - val_loss: 6.0988
Epoch 16/8000

Epoch 00016: val_loss did not improve from 6.09884
 - 40s - loss: 5.3550 - val_loss: 6.3192
Epoch 17/8000

Epoch 00017: val_loss did not improve from 6.09884
 - 40s - loss: 5.3604 - val_loss: 6.4377
Epoch 18/8000

Epoch 00018: val_loss did not improve from 6.09884
 - 40s - loss: 5.3591 - val_loss: 6.3040
Epoch 19/8000

Epoch 00019: val_loss did not improve from 6.09884
 - 40s - loss: 5.3559 - val_loss: 6.3690
Epoch 20/8000

Epoch 00020: val_loss did not improve from 6.09884
 - 40s - loss: 5.3534 - val_loss: 6.2439
Epoch 21/8000

Epoch 00021: val_loss improved from 6.09884 to 6.03730, saving model to ../../model_weights/model_2020-04-09_09-37-23.h5
 - 40s - loss: 5.3554 - val_loss: 6.0373
Epoch 22/8000

Epoch 00022: val_loss did not improve from 6.03730
 - 40s - loss: 5.3525 - val_loss: 6.2058
Epoch 23/8000

Epoch 00023: val_loss did not improve from 6.03730
 - 40s - loss: 5.3360 - val_loss: 6.3575
Epoch 24/8000

Epoch 00024: val_loss did not improve from 6.03730
 - 40s - loss: 5.3455 - val_loss: 6.2603
Epoch 25/8000

Epoch 00025: val_loss did not improve from 6.03730
 - 40s - loss: 5.3386 - val_loss: 6.2985
Epoch 26/8000

Epoch 00026: val_loss did not improve from 6.03730
 - 40s - loss: 5.3418 - val_loss: 6.3131
Epoch 27/8000

Epoch 00027: val_loss did not improve from 6.03730
 - 40s - loss: 5.3461 - val_loss: 6.2892
Epoch 28/8000

Epoch 00028: val_loss did not improve from 6.03730
 - 40s - loss: 5.3482 - val_loss: 6.2638
Epoch 29/8000

Epoch 00029: val_loss did not improve from 6.03730
 - 40s - loss: 5.3572 - val_loss: 6.3551
Epoch 30/8000

Epoch 00030: val_loss did not improve from 6.03730
 - 40s - loss: 5.3594 - val_loss: 6.4635
Epoch 31/8000

Epoch 00031: val_loss did not improve from 6.03730
 - 40s - loss: 5.3571 - val_loss: 6.2686
Epoch 32/8000

Epoch 00032: val_loss did not improve from 6.03730
 - 40s - loss: 5.3512 - val_loss: 6.4792
Epoch 33/8000

Epoch 00033: val_loss did not improve from 6.03730
 - 40s - loss: 5.3602 - val_loss: 6.3378
Epoch 34/8000

Epoch 00034: val_loss did not improve from 6.03730
 - 40s - loss: 5.3586 - val_loss: 6.3033
Epoch 35/8000

Epoch 00035: val_loss did not improve from 6.03730
 - 40s - loss: 5.3647 - val_loss: 6.3013
Epoch 36/8000

Epoch 00036: val_loss did not improve from 6.03730
 - 40s - loss: 5.3393 - val_loss: 6.2672
Epoch 37/8000

Epoch 00037: val_loss did not improve from 6.03730
 - 40s - loss: 5.3463 - val_loss: 6.3778
Epoch 38/8000

Epoch 00038: val_loss did not improve from 6.03730
 - 40s - loss: 5.3320 - val_loss: 6.2152
Epoch 39/8000

Epoch 00039: val_loss did not improve from 6.03730
 - 40s - loss: 5.3295 - val_loss: 6.1247
Epoch 40/8000

Epoch 00040: val_loss did not improve from 6.03730
 - 40s - loss: 5.3206 - val_loss: 6.1586
Epoch 41/8000

Epoch 00041: val_loss did not improve from 6.03730
 - 40s - loss: 5.3327 - val_loss: 6.3489
Epoch 42/8000

Epoch 00042: val_loss did not improve from 6.03730
 - 40s - loss: 5.3495 - val_loss: 6.2983
Epoch 43/8000

Epoch 00043: val_loss did not improve from 6.03730
 - 40s - loss: 5.3460 - val_loss: 6.2998
Epoch 44/8000

Epoch 00044: val_loss did not improve from 6.03730
 - 40s - loss: 5.3385 - val_loss: 6.3169
Epoch 45/8000

Epoch 00045: val_loss did not improve from 6.03730
 - 40s - loss: 5.3425 - val_loss: 6.1243
Epoch 46/8000

Epoch 00046: val_loss did not improve from 6.03730
 - 40s - loss: 5.3276 - val_loss: 6.1955
Epoch 47/8000

Epoch 00047: val_loss did not improve from 6.03730
 - 40s - loss: 5.3287 - val_loss: 6.2016
Epoch 48/8000

Epoch 00048: val_loss did not improve from 6.03730
 - 40s - loss: 5.3426 - val_loss: 6.1602
Epoch 49/8000

Epoch 00049: val_loss did not improve from 6.03730
 - 40s - loss: 5.3436 - val_loss: 6.2850
Epoch 50/8000

Epoch 00050: val_loss did not improve from 6.03730
 - 40s - loss: 5.3657 - val_loss: 6.4114
Epoch 51/8000

Epoch 00051: val_loss did not improve from 6.03730
 - 40s - loss: 5.3607 - val_loss: 6.4308
Epoch 52/8000

Epoch 00052: val_loss did not improve from 6.03730
 - 40s - loss: 5.3465 - val_loss: 6.2166
Epoch 53/8000

Epoch 00053: val_loss did not improve from 6.03730
 - 40s - loss: 5.3374 - val_loss: 6.3527
Epoch 54/8000

Epoch 00054: val_loss did not improve from 6.03730
 - 40s - loss: 5.3516 - val_loss: 6.2887
Epoch 55/8000

Epoch 00055: val_loss did not improve from 6.03730
 - 40s - loss: 5.3478 - val_loss: 6.3382
Epoch 56/8000

Epoch 00056: val_loss did not improve from 6.03730
 - 40s - loss: 5.3423 - val_loss: 6.4431
Epoch 57/8000

Epoch 00057: val_loss did not improve from 6.03730
 - 40s - loss: 5.3321 - val_loss: 6.2228
Epoch 58/8000

Epoch 00058: val_loss did not improve from 6.03730
 - 40s - loss: 5.3330 - val_loss: 6.2745
Epoch 59/8000

Epoch 00059: val_loss did not improve from 6.03730
 - 40s - loss: 5.3270 - val_loss: 6.2328
Epoch 60/8000

Epoch 00060: val_loss did not improve from 6.03730
 - 40s - loss: 5.3282 - val_loss: 6.2537
Epoch 61/8000

Epoch 00061: val_loss did not improve from 6.03730
 - 40s - loss: 5.3400 - val_loss: 6.2604
Epoch 62/8000

Epoch 00062: val_loss did not improve from 6.03730
 - 40s - loss: 5.3538 - val_loss: 6.2003
Epoch 63/8000

Epoch 00063: val_loss did not improve from 6.03730
 - 40s - loss: 5.3369 - val_loss: 6.2778
Epoch 64/8000

Epoch 00064: val_loss did not improve from 6.03730
 - 41s - loss: 5.3432 - val_loss: 6.2146
Epoch 65/8000

Epoch 00065: val_loss did not improve from 6.03730
 - 40s - loss: 5.3319 - val_loss: 6.2515
Epoch 66/8000

Epoch 00066: val_loss did not improve from 6.03730
 - 40s - loss: 5.3277 - val_loss: 6.1726
Epoch 67/8000

Epoch 00067: val_loss did not improve from 6.03730
 - 40s - loss: 5.3287 - val_loss: 6.2264
Epoch 68/8000

Epoch 00068: val_loss did not improve from 6.03730
 - 40s - loss: 5.3231 - val_loss: 6.1858
Epoch 69/8000

Epoch 00069: val_loss did not improve from 6.03730
 - 40s - loss: 5.3392 - val_loss: 6.1253
Epoch 70/8000

Epoch 00070: val_loss did not improve from 6.03730
 - 41s - loss: 5.3361 - val_loss: 6.1862
Epoch 71/8000

Epoch 00071: val_loss did not improve from 6.03730
 - 41s - loss: 5.3230 - val_loss: 6.1874
Epoch 72/8000

Epoch 00072: val_loss did not improve from 6.03730
 - 40s - loss: 5.3243 - val_loss: 6.2677
Epoch 73/8000

Epoch 00073: val_loss did not improve from 6.03730
 - 40s - loss: 5.3120 - val_loss: 6.2517
Epoch 74/8000

Epoch 00074: val_loss did not improve from 6.03730
 - 40s - loss: 5.3094 - val_loss: 6.2740
Epoch 75/8000

Epoch 00075: val_loss did not improve from 6.03730
 - 40s - loss: 5.3114 - val_loss: 6.3592
Epoch 76/8000

Epoch 00076: val_loss did not improve from 6.03730
 - 40s - loss: 5.3044 - val_loss: 6.2541
Epoch 77/8000

Epoch 00077: val_loss did not improve from 6.03730
 - 41s - loss: 5.3109 - val_loss: 6.3119
Epoch 78/8000

Epoch 00078: val_loss did not improve from 6.03730
 - 41s - loss: 5.3083 - val_loss: 6.2039
Epoch 79/8000

Epoch 00079: val_loss did not improve from 6.03730
 - 40s - loss: 5.3029 - val_loss: 6.1618
Epoch 80/8000

Epoch 00080: val_loss did not improve from 6.03730
 - 41s - loss: 5.3037 - val_loss: 6.2045
Epoch 81/8000

Epoch 00081: val_loss did not improve from 6.03730
 - 40s - loss: 5.3147 - val_loss: 6.2744
Epoch 82/8000

Epoch 00082: val_loss did not improve from 6.03730
 - 40s - loss: 5.3069 - val_loss: 6.2973
Epoch 83/8000

Epoch 00083: val_loss did not improve from 6.03730
 - 40s - loss: 5.3048 - val_loss: 6.1965
Epoch 84/8000

Epoch 00084: val_loss did not improve from 6.03730
 - 41s - loss: 5.3051 - val_loss: 6.2210
Epoch 85/8000

Epoch 00085: val_loss did not improve from 6.03730
 - 41s - loss: 5.3018 - val_loss: 6.2280
Epoch 86/8000

Epoch 00086: val_loss did not improve from 6.03730
 - 40s - loss: 5.3064 - val_loss: 6.3448
Epoch 87/8000

Epoch 00087: val_loss did not improve from 6.03730
 - 41s - loss: 5.3195 - val_loss: 6.3051
Epoch 88/8000

Epoch 00088: val_loss did not improve from 6.03730
 - 40s - loss: 5.3262 - val_loss: 6.2750
Epoch 89/8000

Epoch 00089: val_loss did not improve from 6.03730
 - 40s - loss: 5.3477 - val_loss: 6.2283
Epoch 90/8000

Epoch 00090: val_loss did not improve from 6.03730
 - 41s - loss: 5.3543 - val_loss: 6.1813
Epoch 91/8000

Epoch 00091: val_loss did not improve from 6.03730
 - 41s - loss: 5.3394 - val_loss: 6.4144
Epoch 92/8000

Epoch 00092: val_loss did not improve from 6.03730
 - 41s - loss: 5.3297 - val_loss: 6.2462
Epoch 93/8000

Epoch 00093: val_loss did not improve from 6.03730
 - 40s - loss: 5.3419 - val_loss: 6.3382
Epoch 94/8000

Epoch 00094: val_loss did not improve from 6.03730
 - 40s - loss: 5.3310 - val_loss: 6.0872
Epoch 95/8000

Epoch 00095: val_loss did not improve from 6.03730
 - 40s - loss: 5.3174 - val_loss: 6.2295
Epoch 96/8000

Epoch 00096: val_loss did not improve from 6.03730
 - 40s - loss: 5.3191 - val_loss: 6.3564
Epoch 97/8000

Epoch 00097: val_loss did not improve from 6.03730
 - 41s - loss: 5.3563 - val_loss: 6.3015
Epoch 98/8000

Epoch 00098: val_loss did not improve from 6.03730
 - 41s - loss: 5.3794 - val_loss: 6.1464
Epoch 99/8000

Epoch 00099: val_loss did not improve from 6.03730
 - 41s - loss: 5.3626 - val_loss: 6.1890
Epoch 100/8000

Epoch 00100: val_loss did not improve from 6.03730
 - 40s - loss: 5.3529 - val_loss: 6.1885
Epoch 101/8000

Epoch 00101: val_loss did not improve from 6.03730
 - 41s - loss: 5.3451 - val_loss: 6.2302
Epoch 102/8000

Epoch 00102: val_loss did not improve from 6.03730
 - 40s - loss: 5.3691 - val_loss: 6.3185
Epoch 103/8000

Epoch 00103: val_loss did not improve from 6.03730
 - 40s - loss: 5.3655 - val_loss: 6.3426
Epoch 104/8000

Epoch 00104: val_loss did not improve from 6.03730
 - 40s - loss: 5.3668 - val_loss: 6.3711
Epoch 105/8000

Epoch 00105: val_loss did not improve from 6.03730
 - 40s - loss: 5.3542 - val_loss: 6.3561
Epoch 106/8000

Epoch 00106: val_loss did not improve from 6.03730
 - 40s - loss: 5.3391 - val_loss: 6.1837
Epoch 107/8000

Epoch 00107: val_loss did not improve from 6.03730
 - 40s - loss: 5.3498 - val_loss: 6.2234
Epoch 108/8000

Epoch 00108: val_loss did not improve from 6.03730
 - 41s - loss: 5.3520 - val_loss: 6.2182
Epoch 109/8000

Epoch 00109: val_loss did not improve from 6.03730
 - 40s - loss: 5.3572 - val_loss: 6.3895
Epoch 110/8000

Epoch 00110: val_loss did not improve from 6.03730
 - 40s - loss: 5.3878 - val_loss: 6.2323
Epoch 111/8000

Epoch 00111: val_loss did not improve from 6.03730
 - 41s - loss: 5.3850 - val_loss: 6.1856
Epoch 112/8000

Epoch 00112: val_loss did not improve from 6.03730
 - 41s - loss: 5.4043 - val_loss: 6.4317
Epoch 113/8000

Epoch 00113: val_loss did not improve from 6.03730
 - 41s - loss: 5.3918 - val_loss: 6.3721
Epoch 114/8000

Epoch 00114: val_loss did not improve from 6.03730
 - 41s - loss: 5.4126 - val_loss: 6.3580
Epoch 115/8000

Epoch 00115: val_loss did not improve from 6.03730
 - 41s - loss: 5.4102 - val_loss: 6.3122
Epoch 116/8000

Epoch 00116: val_loss did not improve from 6.03730
 - 40s - loss: 5.4141 - val_loss: 6.1900
Epoch 117/8000

Epoch 00117: val_loss did not improve from 6.03730
 - 41s - loss: 5.3984 - val_loss: 6.3990
Epoch 118/8000

Epoch 00118: val_loss did not improve from 6.03730
 - 40s - loss: 5.3740 - val_loss: 6.3488
Epoch 119/8000

Epoch 00119: val_loss did not improve from 6.03730
 - 41s - loss: 5.3624 - val_loss: 6.2249
Epoch 120/8000

Epoch 00120: val_loss did not improve from 6.03730
 - 41s - loss: 5.3698 - val_loss: 6.2903
Epoch 121/8000

Epoch 00121: val_loss did not improve from 6.03730
 - 40s - loss: 5.3827 - val_loss: 6.3643
Epoch 122/8000

Epoch 00122: val_loss did not improve from 6.03730
 - 41s - loss: 5.3745 - val_loss: 6.1822
Epoch 123/8000

Epoch 00123: val_loss did not improve from 6.03730
 - 40s - loss: 5.3770 - val_loss: 6.2194
Epoch 124/8000

Epoch 00124: val_loss did not improve from 6.03730
 - 41s - loss: 5.3822 - val_loss: 6.2126
Epoch 125/8000

Epoch 00125: val_loss did not improve from 6.03730
 - 40s - loss: 5.3680 - val_loss: 6.1403
Epoch 126/8000

Epoch 00126: val_loss did not improve from 6.03730
 - 40s - loss: 5.3690 - val_loss: 6.2932
Epoch 127/8000

Epoch 00127: val_loss did not improve from 6.03730
 - 40s - loss: 5.3867 - val_loss: 6.2774
Epoch 128/8000

Epoch 00128: val_loss did not improve from 6.03730
 - 40s - loss: 5.3812 - val_loss: 6.1724
Epoch 129/8000

Epoch 00129: val_loss did not improve from 6.03730
 - 40s - loss: 5.3905 - val_loss: 6.3489
Epoch 130/8000

Epoch 00130: val_loss improved from 6.03730 to 5.96353, saving model to ../../model_weights/model_2020-04-09_09-37-23.h5
 - 40s - loss: 5.4511 - val_loss: 5.9635
Epoch 131/8000

Epoch 00131: val_loss did not improve from 5.96353
 - 40s - loss: 5.4950 - val_loss: 6.3166
Epoch 132/8000

Epoch 00132: val_loss did not improve from 5.96353
 - 40s - loss: 5.4714 - val_loss: 6.4013
Epoch 133/8000

Epoch 00133: val_loss did not improve from 5.96353
 - 40s - loss: 5.4491 - val_loss: 6.2778
Epoch 134/8000

Epoch 00134: val_loss did not improve from 5.96353
 - 40s - loss: 5.4544 - val_loss: 6.4028
Epoch 135/8000

Epoch 00135: val_loss did not improve from 5.96353
 - 40s - loss: 5.4592 - val_loss: 6.2206
Epoch 136/8000

Epoch 00136: val_loss did not improve from 5.96353
 - 40s - loss: 5.5244 - val_loss: 6.3431
Epoch 137/8000

Epoch 00137: val_loss did not improve from 5.96353
 - 40s - loss: 5.5405 - val_loss: 6.3596
Epoch 138/8000

Epoch 00138: val_loss did not improve from 5.96353
 - 40s - loss: 5.5748 - val_loss: 6.4217
Epoch 139/8000

Epoch 00139: val_loss did not improve from 5.96353
 - 40s - loss: 5.6238 - val_loss: 6.3901
Epoch 140/8000

Epoch 00140: val_loss did not improve from 5.96353
 - 41s - loss: 5.6156 - val_loss: 6.3877
Epoch 141/8000

Epoch 00141: val_loss did not improve from 5.96353
 - 40s - loss: 5.6068 - val_loss: 6.4033
Epoch 142/8000

Epoch 00142: val_loss did not improve from 5.96353
 - 40s - loss: 5.5950 - val_loss: 6.4002
Epoch 143/8000

Epoch 00143: val_loss did not improve from 5.96353
 - 40s - loss: 5.5592 - val_loss: 6.2353
Epoch 144/8000

Epoch 00144: val_loss did not improve from 5.96353
 - 40s - loss: 5.5740 - val_loss: 6.3462
Epoch 145/8000

Epoch 00145: val_loss did not improve from 5.96353
 - 40s - loss: 5.5748 - val_loss: 6.3560
Epoch 146/8000

Epoch 00146: val_loss did not improve from 5.96353
 - 40s - loss: 5.5729 - val_loss: 6.3317
Epoch 147/8000

Epoch 00147: val_loss did not improve from 5.96353
 - 40s - loss: 5.5639 - val_loss: 6.5229
Epoch 148/8000

Epoch 00148: val_loss did not improve from 5.96353
 - 40s - loss: 5.5828 - val_loss: 6.2292
Epoch 149/8000

Epoch 00149: val_loss did not improve from 5.96353
 - 40s - loss: 5.5909 - val_loss: 6.4220
Epoch 150/8000

Epoch 00150: val_loss did not improve from 5.96353
 - 40s - loss: 5.5946 - val_loss: 6.2713
Epoch 151/8000

Epoch 00151: val_loss did not improve from 5.96353
 - 40s - loss: 5.5702 - val_loss: 6.3349
Epoch 152/8000

Epoch 00152: val_loss did not improve from 5.96353
 - 40s - loss: 5.5398 - val_loss: 6.3091
Epoch 153/8000

Epoch 00153: val_loss did not improve from 5.96353
 - 40s - loss: 5.5642 - val_loss: 6.3443
Epoch 154/8000

Epoch 00154: val_loss did not improve from 5.96353
 - 40s - loss: 5.6332 - val_loss: 6.5288
Epoch 155/8000

Epoch 00155: val_loss did not improve from 5.96353
 - 40s - loss: 5.6201 - val_loss: 6.3974
Epoch 156/8000

Epoch 00156: val_loss did not improve from 5.96353
 - 40s - loss: 5.6492 - val_loss: 6.4789
Epoch 157/8000

Epoch 00157: val_loss did not improve from 5.96353
 - 40s - loss: 5.6522 - val_loss: 6.4188
Epoch 158/8000

Epoch 00158: val_loss did not improve from 5.96353
 - 40s - loss: 5.6392 - val_loss: 6.4790
Epoch 159/8000

Epoch 00159: val_loss did not improve from 5.96353
 - 40s - loss: 5.6941 - val_loss: 6.5464
Epoch 160/8000

Epoch 00160: val_loss did not improve from 5.96353
 - 40s - loss: 5.7475 - val_loss: 6.5197
Epoch 161/8000

Epoch 00161: val_loss did not improve from 5.96353
 - 40s - loss: 5.7583 - val_loss: 6.4240
Epoch 162/8000

Epoch 00162: val_loss did not improve from 5.96353
 - 40s - loss: 5.7344 - val_loss: 6.3922
Epoch 163/8000

Epoch 00163: val_loss did not improve from 5.96353
 - 40s - loss: 5.7165 - val_loss: 6.3560
Epoch 164/8000

Epoch 00164: val_loss did not improve from 5.96353
 - 40s - loss: 5.7960 - val_loss: 6.6183
Epoch 165/8000

Epoch 00165: val_loss did not improve from 5.96353
 - 40s - loss: 5.8134 - val_loss: 6.5084
Epoch 166/8000

Epoch 00166: val_loss did not improve from 5.96353
 - 40s - loss: 5.8150 - val_loss: 6.6032
Epoch 167/8000

Epoch 00167: val_loss did not improve from 5.96353
 - 40s - loss: 5.8834 - val_loss: 6.6503
Epoch 168/8000

Epoch 00168: val_loss did not improve from 5.96353
 - 40s - loss: 5.9025 - val_loss: 6.4930
Epoch 169/8000

Epoch 00169: val_loss did not improve from 5.96353
 - 41s - loss: 5.9710 - val_loss: 6.7839
Epoch 170/8000

Epoch 00170: val_loss did not improve from 5.96353
 - 40s - loss: 5.9581 - val_loss: 6.7026
Epoch 171/8000

Epoch 00171: val_loss did not improve from 5.96353
 - 40s - loss: 5.9651 - val_loss: 6.6892
Epoch 172/8000

Epoch 00172: val_loss did not improve from 5.96353
 - 40s - loss: 5.9905 - val_loss: 6.5319
Epoch 173/8000

Epoch 00173: val_loss did not improve from 5.96353
 - 40s - loss: 6.0831 - val_loss: 7.0484
Epoch 174/8000

Epoch 00174: val_loss did not improve from 5.96353
 - 40s - loss: 6.0818 - val_loss: 6.7577
Epoch 175/8000

Epoch 00175: val_loss did not improve from 5.96353
 - 41s - loss: 6.0579 - val_loss: 6.8285
Epoch 176/8000

Epoch 00176: val_loss did not improve from 5.96353
 - 40s - loss: 6.0795 - val_loss: 6.6628
Epoch 177/8000

Epoch 00177: val_loss did not improve from 5.96353
 - 40s - loss: 6.1156 - val_loss: 6.8460
Epoch 178/8000

Epoch 00178: val_loss did not improve from 5.96353
 - 40s - loss: 6.4921 - val_loss: 6.9409
Epoch 179/8000

Epoch 00179: val_loss did not improve from 5.96353
 - 40s - loss: 6.6688 - val_loss: 7.4603
Epoch 180/8000

Epoch 00180: val_loss did not improve from 5.96353
 - 40s - loss: 6.6134 - val_loss: 7.0873
Epoch 181/8000

Epoch 00181: val_loss did not improve from 5.96353
 - 40s - loss: 6.4735 - val_loss: 7.2746
Epoch 182/8000

Epoch 00182: val_loss did not improve from 5.96353
 - 41s - loss: 6.6382 - val_loss: 7.4024
Epoch 183/8000

Epoch 00183: val_loss did not improve from 5.96353
 - 41s - loss: 6.7390 - val_loss: 7.2485
Epoch 184/8000

Epoch 00184: val_loss did not improve from 5.96353
 - 40s - loss: 6.7254 - val_loss: 7.5086
Epoch 185/8000

Epoch 00185: val_loss did not improve from 5.96353
 - 40s - loss: 6.9224 - val_loss: 7.4132
Epoch 186/8000

Epoch 00186: val_loss did not improve from 5.96353
 - 40s - loss: 6.9307 - val_loss: 7.3155
Epoch 187/8000

Epoch 00187: val_loss did not improve from 5.96353
 - 40s - loss: 6.8154 - val_loss: 7.3367
Epoch 188/8000

Epoch 00188: val_loss did not improve from 5.96353
 - 40s - loss: 6.7007 - val_loss: 7.4122
Epoch 189/8000

Epoch 00189: val_loss did not improve from 5.96353
 - 41s - loss: 6.6109 - val_loss: 7.0564
Epoch 190/8000

Epoch 00190: val_loss did not improve from 5.96353
 - 40s - loss: 6.6680 - val_loss: 7.2134
Epoch 191/8000

Epoch 00191: val_loss did not improve from 5.96353
 - 40s - loss: 6.7345 - val_loss: 7.7388
Epoch 192/8000

Epoch 00192: val_loss did not improve from 5.96353
 - 40s - loss: 6.9161 - val_loss: 7.5393
Epoch 193/8000

Epoch 00193: val_loss did not improve from 5.96353
 - 40s - loss: 6.7911 - val_loss: 7.3373
Epoch 194/8000

Epoch 00194: val_loss did not improve from 5.96353
 - 40s - loss: 6.5804 - val_loss: 7.1205
Epoch 195/8000

Epoch 00195: val_loss did not improve from 5.96353
 - 40s - loss: 6.5484 - val_loss: 7.2140
Epoch 196/8000

Epoch 00196: val_loss did not improve from 5.96353
 - 40s - loss: 6.6685 - val_loss: 7.4827
Epoch 197/8000

Epoch 00197: val_loss did not improve from 5.96353
 - 40s - loss: 6.6269 - val_loss: 7.4478
Epoch 198/8000

Epoch 00198: val_loss did not improve from 5.96353
 - 40s - loss: 6.6390 - val_loss: 7.6294
Epoch 199/8000

Epoch 00199: val_loss did not improve from 5.96353
 - 40s - loss: 6.8241 - val_loss: 7.5687
Epoch 200/8000

Epoch 00200: val_loss did not improve from 5.96353
 - 40s - loss: 6.9147 - val_loss: 7.6519
Epoch 201/8000

Epoch 00201: val_loss did not improve from 5.96353
 - 40s - loss: 7.1350 - val_loss: 7.9021
Epoch 202/8000

Epoch 00202: val_loss did not improve from 5.96353
 - 40s - loss: 7.3447 - val_loss: 7.9042
Epoch 203/8000

Epoch 00203: val_loss did not improve from 5.96353
 - 41s - loss: 7.1316 - val_loss: 7.4960
Epoch 204/8000

Epoch 00204: val_loss did not improve from 5.96353
 - 41s - loss: 7.0200 - val_loss: 7.5952
Epoch 205/8000

Epoch 00205: val_loss did not improve from 5.96353
 - 40s - loss: 7.0223 - val_loss: 7.5387
