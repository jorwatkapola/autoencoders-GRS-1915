2020-12-21 15:11:52.450231: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-12-21 15:11:52.757684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-21 15:11:52.758334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2020-12-21 15:11:52.758351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-12-21 15:11:53.044677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-21 15:11:53.044727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-12-21 15:11:53.044745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-12-21 15:11:53.045012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-12-21 15:11:53.259783: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x558ec0baf5f0
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 103.43886, saving model to ../../model_weights/model_2020-12-21_15-11-54.h5
 - 264s - loss: 70.0583 - kl_loss: 3.4968 - val_loss: 103.4389 - val_kl_loss: 3.6649
Epoch 2/8000

Epoch 00002: val_loss improved from 103.43886 to 103.16082, saving model to ../../model_weights/model_2020-12-21_15-11-54.h5
 - 263s - loss: 69.7658 - kl_loss: 3.5005 - val_loss: 103.1608 - val_kl_loss: 3.6739
Epoch 3/8000

Epoch 00003: val_loss improved from 103.16082 to 102.60892, saving model to ../../model_weights/model_2020-12-21_15-11-54.h5
 - 265s - loss: 69.4927 - kl_loss: 3.4688 - val_loss: 102.6089 - val_kl_loss: 3.6346
Epoch 4/8000

Epoch 00004: val_loss improved from 102.60892 to 102.54546, saving model to ../../model_weights/model_2020-12-21_15-11-54.h5
 - 266s - loss: 69.3030 - kl_loss: 3.4677 - val_loss: 102.5455 - val_kl_loss: 3.5836
Epoch 5/8000

Epoch 00005: val_loss did not improve from 102.54546
 - 265s - loss: 69.4555 - kl_loss: 3.4974 - val_loss: 102.6055 - val_kl_loss: 3.6370
Epoch 6/8000

Epoch 00006: val_loss did not improve from 102.54546
 - 265s - loss: 69.7935 - kl_loss: 3.5253 - val_loss: 103.3455 - val_kl_loss: 3.7119
Epoch 7/8000

Epoch 00007: val_loss did not improve from 102.54546
 - 265s - loss: 69.8024 - kl_loss: 3.5431 - val_loss: 104.0283 - val_kl_loss: 3.7226
Epoch 8/8000

Epoch 00008: val_loss did not improve from 102.54546
 - 268s - loss: 70.2371 - kl_loss: 3.5650 - val_loss: 105.7547 - val_kl_loss: 3.9577
Epoch 9/8000

Epoch 00009: val_loss did not improve from 102.54546
 - 265s - loss: 70.1713 - kl_loss: 3.6029 - val_loss: 104.9105 - val_kl_loss: 3.8716
Epoch 10/8000

Epoch 00010: val_loss did not improve from 102.54546
 - 265s - loss: 70.4369 - kl_loss: 3.6251 - val_loss: 105.6996 - val_kl_loss: 3.8996
Epoch 11/8000

Epoch 00011: val_loss did not improve from 102.54546
 - 265s - loss: 71.2320 - kl_loss: 3.7119 - val_loss: 105.0421 - val_kl_loss: 3.9216
Epoch 12/8000

Epoch 00012: val_loss did not improve from 102.54546
 - 265s - loss: 71.0056 - kl_loss: 3.7099 - val_loss: 104.9039 - val_kl_loss: 3.8871
Epoch 13/8000

Epoch 00013: val_loss did not improve from 102.54546
 - 266s - loss: 70.7046 - kl_loss: 3.6658 - val_loss: 105.0664 - val_kl_loss: 3.8408
Epoch 14/8000

Epoch 00014: val_loss did not improve from 102.54546
 - 265s - loss: 71.1747 - kl_loss: 3.7193 - val_loss: 104.9393 - val_kl_loss: 3.8482
Epoch 15/8000

Epoch 00015: val_loss did not improve from 102.54546
 - 267s - loss: 72.8124 - kl_loss: 3.8990 - val_loss: 106.1008 - val_kl_loss: 4.1107
Epoch 16/8000

Epoch 00016: val_loss did not improve from 102.54546
 - 264s - loss: 71.4767 - kl_loss: 3.8054 - val_loss: 105.3247 - val_kl_loss: 3.9129
Epoch 17/8000

Epoch 00017: val_loss did not improve from 102.54546
 - 266s - loss: 70.9293 - kl_loss: 3.7382 - val_loss: 104.6338 - val_kl_loss: 3.8851
Epoch 18/8000

Epoch 00018: val_loss did not improve from 102.54546
 - 267s - loss: 70.4939 - kl_loss: 3.6853 - val_loss: 104.9975 - val_kl_loss: 3.9191
Epoch 19/8000

Epoch 00019: val_loss did not improve from 102.54546
 - 265s - loss: 71.1565 - kl_loss: 3.7430 - val_loss: 105.5855 - val_kl_loss: 3.9171
Epoch 20/8000

Epoch 00020: val_loss did not improve from 102.54546
 - 265s - loss: 71.1743 - kl_loss: 3.7894 - val_loss: 105.1291 - val_kl_loss: 3.8917
Epoch 21/8000

Epoch 00021: val_loss did not improve from 102.54546
 - 266s - loss: 70.7776 - kl_loss: 3.7154 - val_loss: 105.2433 - val_kl_loss: 3.8972
Epoch 22/8000

Epoch 00022: val_loss did not improve from 102.54546
 - 269s - loss: 70.3514 - kl_loss: 3.6438 - val_loss: 105.0410 - val_kl_loss: 3.8185
Epoch 23/8000

Epoch 00023: val_loss did not improve from 102.54546
 - 265s - loss: 70.7298 - kl_loss: 3.6974 - val_loss: 106.5686 - val_kl_loss: 4.0225
Epoch 24/8000

Epoch 00024: val_loss did not improve from 102.54546
 - 265s - loss: 70.7940 - kl_loss: 3.7150 - val_loss: 106.1898 - val_kl_loss: 3.9940
Epoch 25/8000

Epoch 00025: val_loss did not improve from 102.54546
 - 266s - loss: 71.4062 - kl_loss: 3.8203 - val_loss: 106.0892 - val_kl_loss: 4.0831
Epoch 26/8000

Epoch 00026: val_loss did not improve from 102.54546
 - 266s - loss: 73.0733 - kl_loss: 4.0078 - val_loss: 108.5263 - val_kl_loss: 4.2691
Epoch 27/8000

Epoch 00027: val_loss did not improve from 102.54546
 - 267s - loss: 73.2791 - kl_loss: 4.0620 - val_loss: 107.0918 - val_kl_loss: 4.1913
Epoch 28/8000

Epoch 00028: val_loss did not improve from 102.54546
 - 265s - loss: 72.2579 - kl_loss: 3.9698 - val_loss: 107.0865 - val_kl_loss: 4.1468
Epoch 29/8000

Epoch 00029: val_loss did not improve from 102.54546
 - 268s - loss: 72.2987 - kl_loss: 3.9623 - val_loss: 105.6039 - val_kl_loss: 3.8996
Epoch 30/8000

Epoch 00030: val_loss did not improve from 102.54546
 - 266s - loss: 71.6777 - kl_loss: 3.8885 - val_loss: 107.8067 - val_kl_loss: 4.2062
Epoch 31/8000

Epoch 00031: val_loss did not improve from 102.54546
 - 267s - loss: 71.9563 - kl_loss: 3.9307 - val_loss: 106.4874 - val_kl_loss: 4.0384
Epoch 32/8000

Epoch 00032: val_loss did not improve from 102.54546
 - 265s - loss: 71.2886 - kl_loss: 3.8292 - val_loss: 104.9314 - val_kl_loss: 3.9111
Epoch 33/8000

Epoch 00033: val_loss did not improve from 102.54546
 - 264s - loss: 71.1805 - kl_loss: 3.8179 - val_loss: 106.0138 - val_kl_loss: 3.9387
Epoch 34/8000

Epoch 00034: val_loss did not improve from 102.54546
 - 267s - loss: 70.9788 - kl_loss: 3.7869 - val_loss: 106.0899 - val_kl_loss: 4.0062
Epoch 35/8000

Epoch 00035: val_loss did not improve from 102.54546
 - 267s - loss: 71.5888 - kl_loss: 3.8539 - val_loss: 105.8063 - val_kl_loss: 3.9841
Epoch 36/8000

Epoch 00036: val_loss did not improve from 102.54546
 - 267s - loss: 71.1929 - kl_loss: 3.8238 - val_loss: 107.6303 - val_kl_loss: 4.0779
Epoch 37/8000

Epoch 00037: val_loss did not improve from 102.54546
 - 264s - loss: 71.9327 - kl_loss: 3.9248 - val_loss: 107.1990 - val_kl_loss: 4.1488
Epoch 38/8000

Epoch 00038: val_loss did not improve from 102.54546
 - 266s - loss: 71.9977 - kl_loss: 3.9242 - val_loss: 106.4500 - val_kl_loss: 4.0229
Epoch 39/8000

Epoch 00039: val_loss did not improve from 102.54546
 - 267s - loss: 71.7201 - kl_loss: 3.8826 - val_loss: 107.4600 - val_kl_loss: 4.0848
Epoch 40/8000

Epoch 00040: val_loss did not improve from 102.54546
 - 264s - loss: 71.7237 - kl_loss: 3.8744 - val_loss: 107.8528 - val_kl_loss: 4.1678
Epoch 41/8000

Epoch 00041: val_loss did not improve from 102.54546
 - 266s - loss: 72.3374 - kl_loss: 3.9564 - val_loss: 107.3548 - val_kl_loss: 4.1144
Epoch 42/8000

Epoch 00042: val_loss did not improve from 102.54546
 - 266s - loss: 71.9120 - kl_loss: 3.8750 - val_loss: 107.3960 - val_kl_loss: 4.0588
Epoch 43/8000

Epoch 00043: val_loss did not improve from 102.54546
 - 269s - loss: 71.6439 - kl_loss: 3.8696 - val_loss: 107.6573 - val_kl_loss: 4.0929
Epoch 44/8000

Epoch 00044: val_loss did not improve from 102.54546
 - 264s - loss: 72.0017 - kl_loss: 3.9019 - val_loss: 106.7388 - val_kl_loss: 4.0195
Epoch 45/8000

Epoch 00045: val_loss did not improve from 102.54546
 - 265s - loss: 71.7825 - kl_loss: 3.8637 - val_loss: 107.4360 - val_kl_loss: 4.0614
Epoch 46/8000

Epoch 00046: val_loss did not improve from 102.54546
 - 266s - loss: 72.1931 - kl_loss: 3.8792 - val_loss: 106.7865 - val_kl_loss: 4.0551
Epoch 47/8000

Epoch 00047: val_loss did not improve from 102.54546
 - 264s - loss: 71.2363 - kl_loss: 3.7765 - val_loss: 105.4782 - val_kl_loss: 3.8451
Epoch 48/8000

Epoch 00048: val_loss did not improve from 102.54546
 - 267s - loss: 70.6227 - kl_loss: 3.6929 - val_loss: 106.4532 - val_kl_loss: 3.8861
Epoch 49/8000

Epoch 00049: val_loss did not improve from 102.54546
 - 267s - loss: 71.1240 - kl_loss: 3.7605 - val_loss: 106.7689 - val_kl_loss: 3.9929
Epoch 50/8000

Epoch 00050: val_loss did not improve from 102.54546
 - 267s - loss: 71.1681 - kl_loss: 3.7598 - val_loss: 106.0997 - val_kl_loss: 3.9571
Epoch 51/8000

Epoch 00051: val_loss did not improve from 102.54546
 - 265s - loss: 71.1819 - kl_loss: 3.7633 - val_loss: 106.6016 - val_kl_loss: 3.9768
Epoch 52/8000

Epoch 00052: val_loss did not improve from 102.54546
 - 267s - loss: 71.3531 - kl_loss: 3.7717 - val_loss: 106.9212 - val_kl_loss: 3.9852
Epoch 53/8000

Epoch 00053: val_loss did not improve from 102.54546
 - 267s - loss: 71.4216 - kl_loss: 3.7779 - val_loss: 105.6777 - val_kl_loss: 3.8987
Epoch 54/8000

Epoch 00054: val_loss did not improve from 102.54546
 - 264s - loss: 70.9818 - kl_loss: 3.7247 - val_loss: 106.3784 - val_kl_loss: 3.9088
Epoch 00054: early stopping
