2020-03-28 10:09:42.263574: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-03-28 10:09:42.573067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-28 10:09:42.573613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2020-03-28 10:09:42.573632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-03-28 10:09:42.845983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-28 10:09:42.846028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-03-28 10:09:42.846038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-03-28 10:09:42.846287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-03-28 10:09:43.338154: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x555e549da310
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 44.62576, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 77s - loss: 76.4797 - val_loss: 44.6258
Epoch 2/8000

Epoch 00002: val_loss improved from 44.62576 to 30.26417, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 39.5652 - val_loss: 30.2642
Epoch 3/8000

Epoch 00003: val_loss did not improve from 30.26417
 - 74s - loss: 32.6287 - val_loss: 48.5923
Epoch 4/8000

Epoch 00004: val_loss improved from 30.26417 to 28.70965, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 31.7483 - val_loss: 28.7097
Epoch 5/8000

Epoch 00005: val_loss improved from 28.70965 to 24.69579, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 27.6294 - val_loss: 24.6958
Epoch 6/8000

Epoch 00006: val_loss did not improve from 24.69579
 - 75s - loss: 28.8615 - val_loss: 31.6003
Epoch 7/8000

Epoch 00007: val_loss did not improve from 24.69579
 - 75s - loss: 35.1885 - val_loss: 53.4333
Epoch 8/8000

Epoch 00008: val_loss did not improve from 24.69579
 - 75s - loss: 43.0639 - val_loss: 38.7773
Epoch 9/8000

Epoch 00009: val_loss did not improve from 24.69579
 - 76s - loss: 30.0989 - val_loss: 27.5651
Epoch 10/8000

Epoch 00010: val_loss improved from 24.69579 to 24.48198, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 25.8503 - val_loss: 24.4820
Epoch 11/8000

Epoch 00011: val_loss improved from 24.48198 to 22.99149, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 24.3488 - val_loss: 22.9915
Epoch 12/8000

Epoch 00012: val_loss improved from 22.99149 to 22.24032, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 23.2856 - val_loss: 22.2403
Epoch 13/8000

Epoch 00013: val_loss did not improve from 22.24032
 - 75s - loss: 23.5921 - val_loss: 23.6004
Epoch 14/8000

Epoch 00014: val_loss did not improve from 22.24032
 - 75s - loss: 24.0747 - val_loss: 22.9691
Epoch 15/8000

Epoch 00015: val_loss did not improve from 22.24032
 - 75s - loss: 23.2126 - val_loss: 22.5494
Epoch 16/8000

Epoch 00016: val_loss did not improve from 22.24032
 - 75s - loss: 21826.1206 - val_loss: 47.6198
Epoch 17/8000

Epoch 00017: val_loss did not improve from 22.24032
 - 75s - loss: 28.8559 - val_loss: 24.3993
Epoch 18/8000

Epoch 00018: val_loss did not improve from 22.24032
 - 76s - loss: 23.9816 - val_loss: 22.8749
Epoch 19/8000

Epoch 00019: val_loss did not improve from 22.24032
 - 76s - loss: 23.0435 - val_loss: 22.3454
Epoch 20/8000

Epoch 00020: val_loss did not improve from 22.24032
 - 76s - loss: 23.7173 - val_loss: 23.3822
Epoch 21/8000

Epoch 00021: val_loss improved from 22.24032 to 21.70435, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 23.0928 - val_loss: 21.7043
Epoch 22/8000

Epoch 00022: val_loss did not improve from 21.70435
 - 75s - loss: 22.6379 - val_loss: 22.1118
Epoch 23/8000

Epoch 00023: val_loss did not improve from 21.70435
 - 76s - loss: 22.5276 - val_loss: 22.0990
Epoch 24/8000

Epoch 00024: val_loss did not improve from 21.70435
 - 75s - loss: 22.4281 - val_loss: 21.8283
Epoch 25/8000

Epoch 00025: val_loss did not improve from 21.70435
 - 76s - loss: 22.3887 - val_loss: 22.0040
Epoch 26/8000

Epoch 00026: val_loss did not improve from 21.70435
 - 76s - loss: 22.3326 - val_loss: 22.0998
Epoch 27/8000

Epoch 00027: val_loss improved from 21.70435 to 21.68255, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 22.3015 - val_loss: 21.6826
Epoch 28/8000

Epoch 00028: val_loss did not improve from 21.68255
 - 76s - loss: 22.2697 - val_loss: 21.8380
Epoch 29/8000

Epoch 00029: val_loss did not improve from 21.68255
 - 75s - loss: 22.2344 - val_loss: 21.7486
Epoch 30/8000

Epoch 00030: val_loss did not improve from 21.68255
 - 75s - loss: 22.2148 - val_loss: 21.8194
Epoch 31/8000

Epoch 00031: val_loss improved from 21.68255 to 21.57525, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 22.1909 - val_loss: 21.5752
Epoch 32/8000

Epoch 00032: val_loss did not improve from 21.57525
 - 76s - loss: 22.1599 - val_loss: 21.9045
Epoch 33/8000

Epoch 00033: val_loss did not improve from 21.57525
 - 76s - loss: 22.1725 - val_loss: 21.6444
Epoch 34/8000

Epoch 00034: val_loss did not improve from 21.57525
 - 76s - loss: 22.1460 - val_loss: 21.9343
Epoch 35/8000

Epoch 00035: val_loss did not improve from 21.57525
 - 76s - loss: 22.1279 - val_loss: 21.8181
Epoch 36/8000

Epoch 00036: val_loss did not improve from 21.57525
 - 75s - loss: 22.1288 - val_loss: 21.8951
Epoch 37/8000

Epoch 00037: val_loss improved from 21.57525 to 21.39572, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 22.1094 - val_loss: 21.3957
Epoch 38/8000

Epoch 00038: val_loss improved from 21.39572 to 21.37031, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 22.0964 - val_loss: 21.3703
Epoch 39/8000

Epoch 00039: val_loss did not improve from 21.37031
 - 76s - loss: 22.0904 - val_loss: 21.6135
Epoch 40/8000

Epoch 00040: val_loss did not improve from 21.37031
 - 76s - loss: 22.0932 - val_loss: 21.5752
Epoch 41/8000

Epoch 00041: val_loss did not improve from 21.37031
 - 76s - loss: 22.0840 - val_loss: 21.5719
Epoch 42/8000

Epoch 00042: val_loss did not improve from 21.37031
 - 76s - loss: 22.0512 - val_loss: 21.5779
Epoch 43/8000

Epoch 00043: val_loss did not improve from 21.37031
 - 75s - loss: 22.0469 - val_loss: 21.5523
Epoch 44/8000

Epoch 00044: val_loss did not improve from 21.37031
 - 76s - loss: 22.0387 - val_loss: 21.4274
Epoch 45/8000

Epoch 00045: val_loss did not improve from 21.37031
 - 75s - loss: 22.0364 - val_loss: 21.6080
Epoch 46/8000

Epoch 00046: val_loss did not improve from 21.37031
 - 76s - loss: 22.0255 - val_loss: 21.6514
Epoch 47/8000

Epoch 00047: val_loss did not improve from 21.37031
 - 76s - loss: 22.0448 - val_loss: 21.4030
Epoch 48/8000

Epoch 00048: val_loss did not improve from 21.37031
 - 76s - loss: 22.0238 - val_loss: 21.4919
Epoch 49/8000

Epoch 00049: val_loss did not improve from 21.37031
 - 76s - loss: 22.0305 - val_loss: 21.5727
Epoch 50/8000

Epoch 00050: val_loss did not improve from 21.37031
 - 76s - loss: 21.9976 - val_loss: 21.5113
Epoch 51/8000

Epoch 00051: val_loss did not improve from 21.37031
 - 76s - loss: 22.0016 - val_loss: 21.5566
Epoch 52/8000

Epoch 00052: val_loss did not improve from 21.37031
 - 76s - loss: 22.0012 - val_loss: 21.5383
Epoch 53/8000

Epoch 00053: val_loss did not improve from 21.37031
 - 76s - loss: 21.9883 - val_loss: 21.6790
Epoch 54/8000

Epoch 00054: val_loss did not improve from 21.37031
 - 76s - loss: 22.0128 - val_loss: 21.4547
Epoch 55/8000

Epoch 00055: val_loss did not improve from 21.37031
 - 76s - loss: 21.9754 - val_loss: 21.4652
Epoch 56/8000

Epoch 00056: val_loss did not improve from 21.37031
 - 76s - loss: 21.9763 - val_loss: 21.7488
Epoch 57/8000

Epoch 00057: val_loss did not improve from 21.37031
 - 75s - loss: 21.9638 - val_loss: 21.6503
Epoch 58/8000

Epoch 00058: val_loss improved from 21.37031 to 21.34776, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 21.8696 - val_loss: 21.3478
Epoch 59/8000

Epoch 00059: val_loss did not improve from 21.34776
 - 75s - loss: 23.5637 - val_loss: 80.4443
Epoch 60/8000

Epoch 00060: val_loss did not improve from 21.34776
 - 75s - loss: 32.6722 - val_loss: 25.9355
Epoch 61/8000

Epoch 00061: val_loss did not improve from 21.34776
 - 75s - loss: 23.6106 - val_loss: 22.0700
Epoch 62/8000

Epoch 00062: val_loss did not improve from 21.34776
 - 75s - loss: 22.4354 - val_loss: 21.6666
Epoch 63/8000

Epoch 00063: val_loss improved from 21.34776 to 21.26716, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 22.0992 - val_loss: 21.2672
Epoch 64/8000

Epoch 00064: val_loss improved from 21.26716 to 20.92469, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 21.9614 - val_loss: 20.9247
Epoch 65/8000

Epoch 00065: val_loss improved from 20.92469 to 20.44568, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 21.0567 - val_loss: 20.4457
Epoch 66/8000

Epoch 00066: val_loss improved from 20.44568 to 19.45132, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 20.2389 - val_loss: 19.4513
Epoch 67/8000

Epoch 00067: val_loss improved from 19.45132 to 19.42630, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 19.5229 - val_loss: 19.4263
Epoch 68/8000

Epoch 00068: val_loss improved from 19.42630 to 19.17755, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 19.2374 - val_loss: 19.1775
Epoch 69/8000

Epoch 00069: val_loss improved from 19.17755 to 18.53806, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 19.1392 - val_loss: 18.5381
Epoch 70/8000

Epoch 00070: val_loss did not improve from 18.53806
 - 76s - loss: 18.8690 - val_loss: 18.8001
Epoch 71/8000

Epoch 00071: val_loss did not improve from 18.53806
 - 75s - loss: 18.8018 - val_loss: 18.6520
Epoch 72/8000

Epoch 00072: val_loss did not improve from 18.53806
 - 75s - loss: 18.7277 - val_loss: 18.6595
Epoch 73/8000

Epoch 00073: val_loss improved from 18.53806 to 18.40329, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 18.7523 - val_loss: 18.4033
Epoch 74/8000

Epoch 00074: val_loss did not improve from 18.40329
 - 75s - loss: 18.5624 - val_loss: 18.5978
Epoch 75/8000

Epoch 00075: val_loss improved from 18.40329 to 18.24961, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 18.5115 - val_loss: 18.2496
Epoch 76/8000

Epoch 00076: val_loss did not improve from 18.24961
 - 75s - loss: 18.3672 - val_loss: 18.2776
Epoch 77/8000

Epoch 00077: val_loss improved from 18.24961 to 18.06600, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 18.1843 - val_loss: 18.0660
Epoch 78/8000

Epoch 00078: val_loss improved from 18.06600 to 17.96560, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 18.1088 - val_loss: 17.9656
Epoch 79/8000

Epoch 00079: val_loss improved from 17.96560 to 17.84975, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 17.9281 - val_loss: 17.8497
Epoch 80/8000

Epoch 00080: val_loss did not improve from 17.84975
 - 75s - loss: 18.0410 - val_loss: 18.3789
Epoch 81/8000

Epoch 00081: val_loss improved from 17.84975 to 17.59166, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 17.8776 - val_loss: 17.5917
Epoch 82/8000

Epoch 00082: val_loss improved from 17.59166 to 17.35056, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 17.5436 - val_loss: 17.3506
Epoch 83/8000

Epoch 00083: val_loss improved from 17.35056 to 17.24561, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 17.3476 - val_loss: 17.2456
Epoch 84/8000

Epoch 00084: val_loss did not improve from 17.24561
 - 75s - loss: 17.2847 - val_loss: 17.3414
Epoch 85/8000

Epoch 00085: val_loss improved from 17.24561 to 17.13956, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 17.2181 - val_loss: 17.1396
Epoch 86/8000

Epoch 00086: val_loss did not improve from 17.13956
 - 75s - loss: 17.2327 - val_loss: 17.2482
Epoch 87/8000

Epoch 00087: val_loss did not improve from 17.13956
 - 75s - loss: 17.2580 - val_loss: 18.9002
Epoch 88/8000

Epoch 00088: val_loss improved from 17.13956 to 17.01876, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 17.4697 - val_loss: 17.0188
Epoch 89/8000

Epoch 00089: val_loss improved from 17.01876 to 16.98960, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 16.8633 - val_loss: 16.9896
Epoch 90/8000

Epoch 00090: val_loss did not improve from 16.98960
 - 75s - loss: 17.1343 - val_loss: 20.0736
Epoch 91/8000

Epoch 00091: val_loss did not improve from 16.98960
 - 75s - loss: 18.7201 - val_loss: 17.1072
Epoch 92/8000

Epoch 00092: val_loss did not improve from 16.98960
 - 75s - loss: 17.0130 - val_loss: 17.0820
Epoch 93/8000

Epoch 00093: val_loss did not improve from 16.98960
 - 75s - loss: 16.8549 - val_loss: 17.3391
Epoch 94/8000

Epoch 00094: val_loss did not improve from 16.98960
 - 75s - loss: 16.7467 - val_loss: 17.1041
Epoch 95/8000

Epoch 00095: val_loss did not improve from 16.98960
 - 75s - loss: 17.0944 - val_loss: 19.1078
Epoch 96/8000

Epoch 00096: val_loss improved from 16.98960 to 16.61410, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 17.4857 - val_loss: 16.6141
Epoch 97/8000

Epoch 00097: val_loss did not improve from 16.61410
 - 75s - loss: 16.6990 - val_loss: 17.0297
Epoch 98/8000

Epoch 00098: val_loss improved from 16.61410 to 16.41866, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 16.5165 - val_loss: 16.4187
Epoch 99/8000

Epoch 00099: val_loss did not improve from 16.41866
 - 75s - loss: 16.2898 - val_loss: 16.5710
Epoch 100/8000

Epoch 00100: val_loss did not improve from 16.41866
 - 75s - loss: 16.2625 - val_loss: 17.0043
Epoch 101/8000

Epoch 00101: val_loss improved from 16.41866 to 16.35833, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 16.5544 - val_loss: 16.3583
Epoch 102/8000

Epoch 00102: val_loss improved from 16.35833 to 16.21393, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 16.2307 - val_loss: 16.2139
Epoch 103/8000

Epoch 00103: val_loss did not improve from 16.21393
 - 75s - loss: 16.2258 - val_loss: 16.3933
Epoch 104/8000

Epoch 00104: val_loss did not improve from 16.21393
 - 75s - loss: 16.4086 - val_loss: 16.4600
Epoch 105/8000

Epoch 00105: val_loss did not improve from 16.21393
 - 75s - loss: 16.2864 - val_loss: 16.2564
Epoch 106/8000

Epoch 00106: val_loss improved from 16.21393 to 16.09252, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 15.9604 - val_loss: 16.0925
Epoch 107/8000

Epoch 00107: val_loss did not improve from 16.09252
 - 75s - loss: 16.2953 - val_loss: 16.6200
Epoch 108/8000

Epoch 00108: val_loss did not improve from 16.09252
 - 74s - loss: 16.5237 - val_loss: 16.2197
Epoch 109/8000

Epoch 00109: val_loss did not improve from 16.09252
 - 75s - loss: 16.4680 - val_loss: 16.5343
Epoch 110/8000

Epoch 00110: val_loss improved from 16.09252 to 15.96894, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 16.1507 - val_loss: 15.9689
Epoch 111/8000

Epoch 00111: val_loss did not improve from 15.96894
 - 75s - loss: 16.2482 - val_loss: 16.1922
Epoch 112/8000

Epoch 00112: val_loss did not improve from 15.96894
 - 75s - loss: 16.2801 - val_loss: 16.0700
Epoch 113/8000

Epoch 00113: val_loss did not improve from 15.96894
 - 75s - loss: 16.2357 - val_loss: 16.0618
Epoch 114/8000

Epoch 00114: val_loss did not improve from 15.96894
 - 75s - loss: 16.2573 - val_loss: 16.2735
Epoch 115/8000

Epoch 00115: val_loss did not improve from 15.96894
 - 75s - loss: 16.7290 - val_loss: 16.2290
Epoch 116/8000

Epoch 00116: val_loss did not improve from 15.96894
 - 76s - loss: 15.9333 - val_loss: 16.1553
Epoch 117/8000

Epoch 00117: val_loss did not improve from 15.96894
 - 75s - loss: 15.9104 - val_loss: 16.4610
Epoch 118/8000

Epoch 00118: val_loss did not improve from 15.96894
 - 76s - loss: 16.8966 - val_loss: 18.0251
Epoch 119/8000

Epoch 00119: val_loss did not improve from 15.96894
 - 76s - loss: 16.4730 - val_loss: 16.9106
Epoch 120/8000

Epoch 00120: val_loss did not improve from 15.96894
 - 75s - loss: 16.6090 - val_loss: 16.8489
Epoch 121/8000

Epoch 00121: val_loss did not improve from 15.96894
 - 76s - loss: 16.3703 - val_loss: 16.4501
Epoch 122/8000

Epoch 00122: val_loss did not improve from 15.96894
 - 75s - loss: 16.4194 - val_loss: 16.2775
Epoch 123/8000

Epoch 00123: val_loss improved from 15.96894 to 15.64003, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 15.7978 - val_loss: 15.6400
Epoch 124/8000

Epoch 00124: val_loss improved from 15.64003 to 15.31033, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 15.6377 - val_loss: 15.3103
Epoch 125/8000

Epoch 00125: val_loss did not improve from 15.31033
 - 76s - loss: 15.6079 - val_loss: 15.3202
Epoch 126/8000

Epoch 00126: val_loss improved from 15.31033 to 15.10245, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 15.2338 - val_loss: 15.1025
Epoch 127/8000

Epoch 00127: val_loss did not improve from 15.10245
 - 75s - loss: 15.1184 - val_loss: 15.1398
Epoch 128/8000

Epoch 00128: val_loss did not improve from 15.10245
 - 75s - loss: 15.3899 - val_loss: 15.9950
Epoch 129/8000

Epoch 00129: val_loss did not improve from 15.10245
 - 75s - loss: 15.3488 - val_loss: 16.8956
Epoch 130/8000

Epoch 00130: val_loss improved from 15.10245 to 15.09888, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 15.4171 - val_loss: 15.0989
Epoch 131/8000

Epoch 00131: val_loss did not improve from 15.09888
 - 76s - loss: 15.4012 - val_loss: 17.5475
Epoch 132/8000

Epoch 00132: val_loss did not improve from 15.09888
 - 76s - loss: 15.2978 - val_loss: 15.1662
Epoch 133/8000

Epoch 00133: val_loss improved from 15.09888 to 14.98488, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 14.8676 - val_loss: 14.9849
Epoch 134/8000

Epoch 00134: val_loss improved from 14.98488 to 14.94992, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 15.2249 - val_loss: 14.9499
Epoch 135/8000

Epoch 00135: val_loss did not improve from 14.94992
 - 76s - loss: 15.0940 - val_loss: 15.4920
Epoch 136/8000

Epoch 00136: val_loss improved from 14.94992 to 14.55797, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 14.8711 - val_loss: 14.5580
Epoch 137/8000

Epoch 00137: val_loss did not improve from 14.55797
 - 76s - loss: 14.8603 - val_loss: 14.9602
Epoch 138/8000

Epoch 00138: val_loss did not improve from 14.55797
 - 76s - loss: 14.5101 - val_loss: 14.8195
Epoch 139/8000

Epoch 00139: val_loss did not improve from 14.55797
 - 76s - loss: 16.7352 - val_loss: 22.5093
Epoch 140/8000

Epoch 00140: val_loss did not improve from 14.55797
 - 76s - loss: 42.0849 - val_loss: 18.7674
Epoch 141/8000

Epoch 00141: val_loss did not improve from 14.55797
 - 75s - loss: 18.2122 - val_loss: 17.7311
Epoch 142/8000

Epoch 00142: val_loss did not improve from 14.55797
 - 76s - loss: 17.1309 - val_loss: 16.8001
Epoch 143/8000

Epoch 00143: val_loss did not improve from 14.55797
 - 75s - loss: 16.3753 - val_loss: 16.3998
Epoch 144/8000

Epoch 00144: val_loss did not improve from 14.55797
 - 76s - loss: 16.0805 - val_loss: 15.9093
Epoch 145/8000

Epoch 00145: val_loss did not improve from 14.55797
 - 75s - loss: 15.7075 - val_loss: 15.6320
Epoch 146/8000

Epoch 00146: val_loss did not improve from 14.55797
 - 75s - loss: 15.4374 - val_loss: 15.5513
Epoch 147/8000

Epoch 00147: val_loss did not improve from 14.55797
 - 75s - loss: 15.2068 - val_loss: 15.3107
Epoch 148/8000

Epoch 00148: val_loss did not improve from 14.55797
 - 75s - loss: 15.2145 - val_loss: 15.0890
Epoch 149/8000

Epoch 00149: val_loss did not improve from 14.55797
 - 75s - loss: 15.0045 - val_loss: 15.0318
Epoch 150/8000

Epoch 00150: val_loss did not improve from 14.55797
 - 75s - loss: 14.9940 - val_loss: 15.1113
Epoch 151/8000

Epoch 00151: val_loss did not improve from 14.55797
 - 76s - loss: 14.8988 - val_loss: 15.1970
Epoch 152/8000

Epoch 00152: val_loss did not improve from 14.55797
 - 76s - loss: 14.8221 - val_loss: 14.9856
Epoch 153/8000

Epoch 00153: val_loss did not improve from 14.55797
 - 76s - loss: 14.9809 - val_loss: 14.8549
Epoch 154/8000

Epoch 00154: val_loss did not improve from 14.55797
 - 76s - loss: 15.1660 - val_loss: 15.4028
Epoch 155/8000

Epoch 00155: val_loss did not improve from 14.55797
 - 75s - loss: 14.8040 - val_loss: 14.9179
Epoch 156/8000

Epoch 00156: val_loss did not improve from 14.55797
 - 76s - loss: 14.6827 - val_loss: 14.6375
Epoch 157/8000

Epoch 00157: val_loss did not improve from 14.55797
 - 76s - loss: 14.6313 - val_loss: 15.0195
Epoch 158/8000

Epoch 00158: val_loss did not improve from 14.55797
 - 76s - loss: 14.5964 - val_loss: 14.7060
Epoch 159/8000

Epoch 00159: val_loss did not improve from 14.55797
 - 76s - loss: 14.7967 - val_loss: 14.7405
Epoch 160/8000

Epoch 00160: val_loss did not improve from 14.55797
 - 76s - loss: 14.6922 - val_loss: 14.7989
Epoch 161/8000

Epoch 00161: val_loss did not improve from 14.55797
 - 76s - loss: 14.5527 - val_loss: 14.7684
Epoch 162/8000

Epoch 00162: val_loss improved from 14.55797 to 14.54316, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 14.6269 - val_loss: 14.5432
Epoch 163/8000

Epoch 00163: val_loss did not improve from 14.54316
 - 76s - loss: 14.5354 - val_loss: 14.7994
Epoch 164/8000

Epoch 00164: val_loss did not improve from 14.54316
 - 75s - loss: 14.6226 - val_loss: 14.7603
Epoch 165/8000

Epoch 00165: val_loss did not improve from 14.54316
 - 76s - loss: 14.8799 - val_loss: 15.3401
Epoch 166/8000

Epoch 00166: val_loss improved from 14.54316 to 14.40388, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 14.3792 - val_loss: 14.4039
Epoch 167/8000

Epoch 00167: val_loss did not improve from 14.40388
 - 76s - loss: 14.3079 - val_loss: 14.4873
Epoch 168/8000

Epoch 00168: val_loss improved from 14.40388 to 14.27014, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 14.2932 - val_loss: 14.2701
Epoch 169/8000

Epoch 00169: val_loss did not improve from 14.27014
 - 76s - loss: 14.4519 - val_loss: 14.7216
Epoch 170/8000

Epoch 00170: val_loss did not improve from 14.27014
 - 76s - loss: 14.3245 - val_loss: 14.5600
Epoch 171/8000

Epoch 00171: val_loss did not improve from 14.27014
 - 76s - loss: 16.9348 - val_loss: 21.9793
Epoch 172/8000

Epoch 00172: val_loss did not improve from 14.27014
 - 76s - loss: 18.5122 - val_loss: 16.6684
Epoch 173/8000

Epoch 00173: val_loss did not improve from 14.27014
 - 76s - loss: 15.7676 - val_loss: 15.2650
Epoch 174/8000

Epoch 00174: val_loss did not improve from 14.27014
 - 76s - loss: 15.1888 - val_loss: 15.3398
Epoch 175/8000

Epoch 00175: val_loss did not improve from 14.27014
 - 76s - loss: 14.8721 - val_loss: 14.6866
Epoch 176/8000

Epoch 00176: val_loss did not improve from 14.27014
 - 76s - loss: 14.6476 - val_loss: 14.5969
Epoch 177/8000

Epoch 00177: val_loss did not improve from 14.27014
 - 76s - loss: 14.5470 - val_loss: 15.0361
Epoch 178/8000

Epoch 00178: val_loss did not improve from 14.27014
 - 75s - loss: 14.4520 - val_loss: 14.3540
Epoch 179/8000

Epoch 00179: val_loss did not improve from 14.27014
 - 76s - loss: 14.5269 - val_loss: 14.7223
Epoch 180/8000

Epoch 00180: val_loss did not improve from 14.27014
 - 76s - loss: 14.2431 - val_loss: 14.6256
Epoch 181/8000

Epoch 00181: val_loss did not improve from 14.27014
 - 76s - loss: 14.2770 - val_loss: 14.4839
Epoch 182/8000

Epoch 00182: val_loss improved from 14.27014 to 14.14418, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 14.1740 - val_loss: 14.1442
Epoch 183/8000

Epoch 00183: val_loss did not improve from 14.14418
 - 75s - loss: 14.3129 - val_loss: 14.4231
Epoch 184/8000

Epoch 00184: val_loss did not improve from 14.14418
 - 76s - loss: 14.2388 - val_loss: 14.2567
Epoch 185/8000

Epoch 00185: val_loss did not improve from 14.14418
 - 75s - loss: 14.1539 - val_loss: 14.5179
Epoch 186/8000

Epoch 00186: val_loss did not improve from 14.14418
 - 76s - loss: 15.6410 - val_loss: 14.6777
Epoch 187/8000

Epoch 00187: val_loss did not improve from 14.14418
 - 76s - loss: 14.4542 - val_loss: 14.3842
Epoch 188/8000

Epoch 00188: val_loss did not improve from 14.14418
 - 76s - loss: 14.4906 - val_loss: 14.3277
Epoch 189/8000

Epoch 00189: val_loss improved from 14.14418 to 14.10324, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 14.1772 - val_loss: 14.1032
Epoch 190/8000

Epoch 00190: val_loss improved from 14.10324 to 14.02217, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 13.9059 - val_loss: 14.0222
Epoch 191/8000

Epoch 00191: val_loss did not improve from 14.02217
 - 76s - loss: 13.9433 - val_loss: 14.2157
Epoch 192/8000

Epoch 00192: val_loss did not improve from 14.02217
 - 75s - loss: 14.0081 - val_loss: 14.0409
Epoch 193/8000

Epoch 00193: val_loss improved from 14.02217 to 13.92436, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 13.9190 - val_loss: 13.9244
Epoch 194/8000

Epoch 00194: val_loss did not improve from 13.92436
 - 76s - loss: 13.9574 - val_loss: 14.1463
Epoch 195/8000

Epoch 00195: val_loss did not improve from 13.92436
 - 76s - loss: 13.7956 - val_loss: 14.0469
Epoch 196/8000

Epoch 00196: val_loss did not improve from 13.92436
 - 76s - loss: 13.9313 - val_loss: 14.0064
Epoch 197/8000

Epoch 00197: val_loss did not improve from 13.92436
 - 75s - loss: 14.0837 - val_loss: 13.9752
Epoch 198/8000

Epoch 00198: val_loss did not improve from 13.92436
 - 76s - loss: 13.7950 - val_loss: 13.9430
Epoch 199/8000

Epoch 00199: val_loss did not improve from 13.92436
 - 75s - loss: 13.7941 - val_loss: 14.4323
Epoch 200/8000

Epoch 00200: val_loss did not improve from 13.92436
 - 76s - loss: 13.9809 - val_loss: 14.0633
Epoch 201/8000

Epoch 00201: val_loss did not improve from 13.92436
 - 76s - loss: 13.9981 - val_loss: 14.0564
Epoch 202/8000

Epoch 00202: val_loss did not improve from 13.92436
 - 76s - loss: 13.7092 - val_loss: 14.2476
Epoch 203/8000

Epoch 00203: val_loss improved from 13.92436 to 13.55512, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 13.7885 - val_loss: 13.5551
Epoch 204/8000

Epoch 00204: val_loss did not improve from 13.55512
 - 75s - loss: 13.5592 - val_loss: 14.0170
Epoch 205/8000

Epoch 00205: val_loss did not improve from 13.55512
 - 76s - loss: 13.7675 - val_loss: 13.6521
Epoch 206/8000

Epoch 00206: val_loss did not improve from 13.55512
 - 76s - loss: 13.5816 - val_loss: 13.6496
Epoch 207/8000

Epoch 00207: val_loss did not improve from 13.55512
 - 76s - loss: 13.7045 - val_loss: 13.8138
Epoch 208/8000

Epoch 00208: val_loss did not improve from 13.55512
 - 76s - loss: 13.3771 - val_loss: 13.5579
Epoch 209/8000

Epoch 00209: val_loss did not improve from 13.55512
 - 75s - loss: 13.7147 - val_loss: 15.2797
Epoch 210/8000

Epoch 00210: val_loss did not improve from 13.55512
 - 76s - loss: 13.9602 - val_loss: 13.6274
Epoch 211/8000

Epoch 00211: val_loss did not improve from 13.55512
 - 75s - loss: 14.0711 - val_loss: 13.9251
Epoch 212/8000

Epoch 00212: val_loss did not improve from 13.55512
 - 76s - loss: 13.6630 - val_loss: 14.9821
Epoch 213/8000

Epoch 00213: val_loss did not improve from 13.55512
 - 75s - loss: 13.6616 - val_loss: 13.9049
Epoch 214/8000

Epoch 00214: val_loss did not improve from 13.55512
 - 76s - loss: 13.5169 - val_loss: 13.8116
Epoch 215/8000

Epoch 00215: val_loss improved from 13.55512 to 13.47148, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 13.3204 - val_loss: 13.4715
Epoch 216/8000

Epoch 00216: val_loss did not improve from 13.47148
 - 76s - loss: 14.1910 - val_loss: 14.0424
Epoch 217/8000

Epoch 00217: val_loss did not improve from 13.47148
 - 76s - loss: 13.4758 - val_loss: 13.7422
Epoch 218/8000

Epoch 00218: val_loss did not improve from 13.47148
 - 76s - loss: 13.2796 - val_loss: 13.8106
Epoch 219/8000

Epoch 00219: val_loss did not improve from 13.47148
 - 76s - loss: 13.4397 - val_loss: 14.0807
Epoch 220/8000

Epoch 00220: val_loss did not improve from 13.47148
 - 76s - loss: 13.5726 - val_loss: 13.4776
Epoch 221/8000

Epoch 00221: val_loss did not improve from 13.47148
 - 76s - loss: 13.6440 - val_loss: 15.8920
Epoch 222/8000

Epoch 00222: val_loss did not improve from 13.47148
 - 76s - loss: 16.3370 - val_loss: 15.5970
Epoch 223/8000

Epoch 00223: val_loss did not improve from 13.47148
 - 76s - loss: 14.6947 - val_loss: 14.1997
Epoch 224/8000

Epoch 00224: val_loss did not improve from 13.47148
 - 75s - loss: 13.6963 - val_loss: 13.9089
Epoch 225/8000

Epoch 00225: val_loss did not improve from 13.47148
 - 75s - loss: 13.5010 - val_loss: 13.4756
Epoch 226/8000

Epoch 00226: val_loss did not improve from 13.47148
 - 76s - loss: 13.3471 - val_loss: 13.6822
Epoch 227/8000

Epoch 00227: val_loss improved from 13.47148 to 13.32020, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 13.2445 - val_loss: 13.3202
Epoch 228/8000

Epoch 00228: val_loss did not improve from 13.32020
 - 76s - loss: 13.8608 - val_loss: 13.4244
Epoch 229/8000

Epoch 00229: val_loss did not improve from 13.32020
 - 76s - loss: 13.6420 - val_loss: 13.4858
Epoch 230/8000

Epoch 00230: val_loss did not improve from 13.32020
 - 76s - loss: 13.2859 - val_loss: 13.4578
Epoch 231/8000

Epoch 00231: val_loss did not improve from 13.32020
 - 76s - loss: 13.0038 - val_loss: 13.8800
Epoch 232/8000

Epoch 00232: val_loss did not improve from 13.32020
 - 76s - loss: 13.4372 - val_loss: 13.3249
Epoch 233/8000

Epoch 00233: val_loss improved from 13.32020 to 13.08585, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 13.0773 - val_loss: 13.0859
Epoch 234/8000

Epoch 00234: val_loss did not improve from 13.08585
 - 76s - loss: 12.8409 - val_loss: 13.1733
Epoch 235/8000

Epoch 00235: val_loss did not improve from 13.08585
 - 76s - loss: 12.8889 - val_loss: 13.1297
Epoch 236/8000

Epoch 00236: val_loss did not improve from 13.08585
 - 76s - loss: 12.8856 - val_loss: 13.3732
Epoch 237/8000

Epoch 00237: val_loss did not improve from 13.08585
 - 76s - loss: 12.8537 - val_loss: 13.3338
Epoch 238/8000

Epoch 00238: val_loss improved from 13.08585 to 12.93694, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.8654 - val_loss: 12.9369
Epoch 239/8000

Epoch 00239: val_loss did not improve from 12.93694
 - 75s - loss: 12.9948 - val_loss: 13.2176
Epoch 240/8000

Epoch 00240: val_loss did not improve from 12.93694
 - 76s - loss: 12.7103 - val_loss: 13.0279
Epoch 241/8000

Epoch 00241: val_loss did not improve from 12.93694
 - 75s - loss: 14.1441 - val_loss: 13.5379
Epoch 242/8000

Epoch 00242: val_loss did not improve from 12.93694
 - 76s - loss: 13.0326 - val_loss: 13.4279
Epoch 243/8000

Epoch 00243: val_loss did not improve from 12.93694
 - 76s - loss: 14.3944 - val_loss: 13.4349
Epoch 244/8000

Epoch 00244: val_loss did not improve from 12.93694
 - 76s - loss: 13.8786 - val_loss: 13.7221
Epoch 245/8000

Epoch 00245: val_loss did not improve from 12.93694
 - 76s - loss: 13.1577 - val_loss: 13.8586
Epoch 246/8000

Epoch 00246: val_loss did not improve from 12.93694
 - 76s - loss: 13.1817 - val_loss: 13.0409
Epoch 247/8000

Epoch 00247: val_loss did not improve from 12.93694
 - 76s - loss: 12.9058 - val_loss: 13.0495
Epoch 248/8000

Epoch 00248: val_loss did not improve from 12.93694
 - 75s - loss: 12.9784 - val_loss: 13.1447
Epoch 249/8000

Epoch 00249: val_loss improved from 12.93694 to 12.80756, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.7796 - val_loss: 12.8076
Epoch 250/8000

Epoch 00250: val_loss did not improve from 12.80756
 - 76s - loss: 12.7347 - val_loss: 12.8945
Epoch 251/8000

Epoch 00251: val_loss did not improve from 12.80756
 - 76s - loss: 12.7419 - val_loss: 12.8110
Epoch 252/8000

Epoch 00252: val_loss did not improve from 12.80756
 - 76s - loss: 12.7748 - val_loss: 13.2615
Epoch 253/8000

Epoch 00253: val_loss did not improve from 12.80756
 - 75s - loss: 12.8455 - val_loss: 12.8300
Epoch 254/8000

Epoch 00254: val_loss did not improve from 12.80756
 - 76s - loss: 12.7939 - val_loss: 12.8458
Epoch 255/8000

Epoch 00255: val_loss did not improve from 12.80756
 - 75s - loss: 12.6622 - val_loss: 12.8122
Epoch 256/8000

Epoch 00256: val_loss improved from 12.80756 to 12.73977, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.9056 - val_loss: 12.7398
Epoch 257/8000

Epoch 00257: val_loss did not improve from 12.73977
 - 75s - loss: 12.8250 - val_loss: 12.9567
Epoch 258/8000

Epoch 00258: val_loss did not improve from 12.73977
 - 75s - loss: 13.6380 - val_loss: 14.8659
Epoch 259/8000

Epoch 00259: val_loss did not improve from 12.73977
 - 75s - loss: 13.4877 - val_loss: 13.9518
Epoch 260/8000

Epoch 00260: val_loss did not improve from 12.73977
 - 75s - loss: 13.1029 - val_loss: 12.8788
Epoch 261/8000

Epoch 00261: val_loss did not improve from 12.73977
 - 76s - loss: 13.5913 - val_loss: 13.3481
Epoch 262/8000

Epoch 00262: val_loss did not improve from 12.73977
 - 75s - loss: 12.8918 - val_loss: 12.8012
Epoch 263/8000

Epoch 00263: val_loss did not improve from 12.73977
 - 76s - loss: 12.8488 - val_loss: 12.9829
Epoch 264/8000

Epoch 00264: val_loss did not improve from 12.73977
 - 76s - loss: 12.8337 - val_loss: 14.1463
Epoch 265/8000

Epoch 00265: val_loss did not improve from 12.73977
 - 76s - loss: 12.9991 - val_loss: 13.0100
Epoch 266/8000

Epoch 00266: val_loss did not improve from 12.73977
 - 76s - loss: 12.6985 - val_loss: 13.0317
Epoch 267/8000

Epoch 00267: val_loss did not improve from 12.73977
 - 75s - loss: 12.8268 - val_loss: 13.3176
Epoch 268/8000

Epoch 00268: val_loss did not improve from 12.73977
 - 76s - loss: 13.2690 - val_loss: 13.6610
Epoch 269/8000

Epoch 00269: val_loss did not improve from 12.73977
 - 75s - loss: 13.1154 - val_loss: 13.7808
Epoch 270/8000

Epoch 00270: val_loss improved from 12.73977 to 12.66247, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.9519 - val_loss: 12.6625
Epoch 271/8000

Epoch 00271: val_loss did not improve from 12.66247
 - 76s - loss: 12.7497 - val_loss: 12.9049
Epoch 272/8000

Epoch 00272: val_loss did not improve from 12.66247
 - 76s - loss: 12.5491 - val_loss: 13.0945
Epoch 273/8000

Epoch 00273: val_loss did not improve from 12.66247
 - 76s - loss: 12.6268 - val_loss: 13.0079
Epoch 274/8000

Epoch 00274: val_loss improved from 12.66247 to 12.51369, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.6174 - val_loss: 12.5137
Epoch 275/8000

Epoch 00275: val_loss did not improve from 12.51369
 - 76s - loss: 12.5702 - val_loss: 12.7966
Epoch 276/8000

Epoch 00276: val_loss did not improve from 12.51369
 - 75s - loss: 12.5473 - val_loss: 12.7351
Epoch 277/8000

Epoch 00277: val_loss did not improve from 12.51369
 - 76s - loss: 12.4191 - val_loss: 12.5233
Epoch 278/8000

Epoch 00278: val_loss improved from 12.51369 to 12.41249, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.6614 - val_loss: 12.4125
Epoch 279/8000

Epoch 00279: val_loss did not improve from 12.41249
 - 76s - loss: 12.3986 - val_loss: 12.7227
Epoch 280/8000

Epoch 00280: val_loss did not improve from 12.41249
 - 76s - loss: 12.5350 - val_loss: 12.6531
Epoch 281/8000

Epoch 00281: val_loss did not improve from 12.41249
 - 76s - loss: 12.5307 - val_loss: 12.9400
Epoch 282/8000

Epoch 00282: val_loss did not improve from 12.41249
 - 76s - loss: 12.8626 - val_loss: 12.9629
Epoch 283/8000

Epoch 00283: val_loss did not improve from 12.41249
 - 76s - loss: 12.5352 - val_loss: 12.7926
Epoch 284/8000

Epoch 00284: val_loss did not improve from 12.41249
 - 76s - loss: 12.6214 - val_loss: 13.0797
Epoch 285/8000

Epoch 00285: val_loss did not improve from 12.41249
 - 76s - loss: 12.9460 - val_loss: 12.5153
Epoch 286/8000

Epoch 00286: val_loss did not improve from 12.41249
 - 76s - loss: 12.5719 - val_loss: 12.6128
Epoch 287/8000

Epoch 00287: val_loss did not improve from 12.41249
 - 76s - loss: 12.5510 - val_loss: 14.1608
Epoch 288/8000

Epoch 00288: val_loss did not improve from 12.41249
 - 76s - loss: 12.3890 - val_loss: 12.6180
Epoch 289/8000

Epoch 00289: val_loss did not improve from 12.41249
 - 76s - loss: 12.3416 - val_loss: 12.7411
Epoch 290/8000

Epoch 00290: val_loss did not improve from 12.41249
 - 75s - loss: 12.3211 - val_loss: 12.5211
Epoch 291/8000

Epoch 00291: val_loss improved from 12.41249 to 12.29858, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.3651 - val_loss: 12.2986
Epoch 292/8000

Epoch 00292: val_loss did not improve from 12.29858
 - 75s - loss: 12.4309 - val_loss: 12.5079
Epoch 293/8000

Epoch 00293: val_loss did not improve from 12.29858
 - 76s - loss: 12.6005 - val_loss: 12.6316
Epoch 294/8000

Epoch 00294: val_loss did not improve from 12.29858
 - 76s - loss: 12.3575 - val_loss: 12.4995
Epoch 295/8000

Epoch 00295: val_loss did not improve from 12.29858
 - 75s - loss: 12.5220 - val_loss: 13.4624
Epoch 296/8000

Epoch 00296: val_loss did not improve from 12.29858
 - 76s - loss: 12.5142 - val_loss: 12.5040
Epoch 297/8000

Epoch 00297: val_loss improved from 12.29858 to 12.26030, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.3985 - val_loss: 12.2603
Epoch 298/8000

Epoch 00298: val_loss did not improve from 12.26030
 - 76s - loss: 12.1674 - val_loss: 12.3655
Epoch 299/8000

Epoch 00299: val_loss did not improve from 12.26030
 - 76s - loss: 12.3357 - val_loss: 12.5380
Epoch 300/8000

Epoch 00300: val_loss did not improve from 12.26030
 - 76s - loss: 12.4252 - val_loss: 12.9691
Epoch 301/8000

Epoch 00301: val_loss did not improve from 12.26030
 - 76s - loss: 12.4890 - val_loss: 12.6781
Epoch 302/8000

Epoch 00302: val_loss did not improve from 12.26030
 - 76s - loss: 12.5884 - val_loss: 12.4336
Epoch 303/8000

Epoch 00303: val_loss did not improve from 12.26030
 - 76s - loss: 12.3347 - val_loss: 12.5930
Epoch 304/8000

Epoch 00304: val_loss did not improve from 12.26030
 - 75s - loss: 12.2774 - val_loss: 12.2975
Epoch 305/8000

Epoch 00305: val_loss did not improve from 12.26030
 - 76s - loss: 12.1333 - val_loss: 12.3548
Epoch 306/8000

Epoch 00306: val_loss did not improve from 12.26030
 - 76s - loss: 12.0656 - val_loss: 12.3127
Epoch 307/8000

Epoch 00307: val_loss did not improve from 12.26030
 - 76s - loss: 12.1262 - val_loss: 12.8869
Epoch 308/8000

Epoch 00308: val_loss did not improve from 12.26030
 - 76s - loss: 13.1112 - val_loss: 13.7755
Epoch 309/8000

Epoch 00309: val_loss did not improve from 12.26030
 - 75s - loss: 12.4479 - val_loss: 12.7405
Epoch 310/8000

Epoch 00310: val_loss did not improve from 12.26030
 - 76s - loss: 12.6594 - val_loss: 12.8313
Epoch 311/8000

Epoch 00311: val_loss did not improve from 12.26030
 - 75s - loss: 12.6446 - val_loss: 13.1856
Epoch 312/8000

Epoch 00312: val_loss did not improve from 12.26030
 - 76s - loss: 12.4983 - val_loss: 12.6364
Epoch 313/8000

Epoch 00313: val_loss did not improve from 12.26030
 - 76s - loss: 12.4124 - val_loss: 13.0353
Epoch 314/8000

Epoch 00314: val_loss did not improve from 12.26030
 - 76s - loss: 12.5312 - val_loss: 12.7537
Epoch 315/8000

Epoch 00315: val_loss did not improve from 12.26030
 - 76s - loss: 12.4905 - val_loss: 12.4251
Epoch 316/8000

Epoch 00316: val_loss did not improve from 12.26030
 - 75s - loss: 12.4271 - val_loss: 12.5191
Epoch 317/8000

Epoch 00317: val_loss did not improve from 12.26030
 - 76s - loss: 12.1892 - val_loss: 12.5588
Epoch 318/8000

Epoch 00318: val_loss did not improve from 12.26030
 - 75s - loss: 12.5840 - val_loss: 13.9521
Epoch 319/8000

Epoch 00319: val_loss improved from 12.26030 to 12.22156, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 12.3778 - val_loss: 12.2216
Epoch 320/8000

Epoch 00320: val_loss did not improve from 12.22156
 - 75s - loss: 12.2181 - val_loss: 12.4826
Epoch 321/8000

Epoch 00321: val_loss did not improve from 12.22156
 - 76s - loss: 12.4946 - val_loss: 12.2570
Epoch 322/8000

Epoch 00322: val_loss did not improve from 12.22156
 - 76s - loss: 12.5581 - val_loss: 12.8589
Epoch 323/8000

Epoch 00323: val_loss did not improve from 12.22156
 - 75s - loss: 12.4003 - val_loss: 12.5165
Epoch 324/8000

Epoch 00324: val_loss did not improve from 12.22156
 - 76s - loss: 12.2041 - val_loss: 12.9039
Epoch 325/8000

Epoch 00325: val_loss did not improve from 12.22156
 - 75s - loss: 12.5258 - val_loss: 12.5629
Epoch 326/8000

Epoch 00326: val_loss did not improve from 12.22156
 - 76s - loss: 12.7087 - val_loss: 12.8902
Epoch 327/8000

Epoch 00327: val_loss did not improve from 12.22156
 - 76s - loss: 12.8145 - val_loss: 13.2324
Epoch 328/8000

Epoch 00328: val_loss did not improve from 12.22156
 - 76s - loss: 12.3508 - val_loss: 13.5593
Epoch 329/8000

Epoch 00329: val_loss did not improve from 12.22156
 - 76s - loss: 12.3223 - val_loss: 12.2462
Epoch 330/8000

Epoch 00330: val_loss did not improve from 12.22156
 - 75s - loss: 12.3803 - val_loss: 12.7755
Epoch 331/8000

Epoch 00331: val_loss did not improve from 12.22156
 - 76s - loss: 12.6591 - val_loss: 13.4808
Epoch 332/8000

Epoch 00332: val_loss did not improve from 12.22156
 - 75s - loss: 12.4616 - val_loss: 12.4901
Epoch 333/8000

Epoch 00333: val_loss did not improve from 12.22156
 - 76s - loss: 12.2487 - val_loss: 12.5478
Epoch 334/8000

Epoch 00334: val_loss did not improve from 12.22156
 - 76s - loss: 12.0496 - val_loss: 12.3664
Epoch 335/8000

Epoch 00335: val_loss did not improve from 12.22156
 - 76s - loss: 12.1180 - val_loss: 12.4191
Epoch 336/8000

Epoch 00336: val_loss did not improve from 12.22156
 - 76s - loss: 12.1184 - val_loss: 12.7376
Epoch 337/8000

Epoch 00337: val_loss improved from 12.22156 to 12.14628, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 12.0973 - val_loss: 12.1463
Epoch 338/8000

Epoch 00338: val_loss did not improve from 12.14628
 - 76s - loss: 12.2991 - val_loss: 12.5881
Epoch 339/8000

Epoch 00339: val_loss did not improve from 12.14628
 - 75s - loss: 12.1730 - val_loss: 12.5614
Epoch 340/8000

Epoch 00340: val_loss did not improve from 12.14628
 - 76s - loss: 11.9829 - val_loss: 12.7924
Epoch 341/8000

Epoch 00341: val_loss did not improve from 12.14628
 - 76s - loss: 12.1481 - val_loss: 12.5549
Epoch 342/8000

Epoch 00342: val_loss did not improve from 12.14628
 - 76s - loss: 12.4169 - val_loss: 13.4301
Epoch 343/8000

Epoch 00343: val_loss did not improve from 12.14628
 - 76s - loss: 12.4735 - val_loss: 12.8200
Epoch 344/8000

Epoch 00344: val_loss did not improve from 12.14628
 - 75s - loss: 12.4694 - val_loss: 12.5028
Epoch 345/8000

Epoch 00345: val_loss did not improve from 12.14628
 - 76s - loss: 11.9789 - val_loss: 12.6519
Epoch 346/8000

Epoch 00346: val_loss did not improve from 12.14628
 - 75s - loss: 12.1723 - val_loss: 12.2807
Epoch 347/8000

Epoch 00347: val_loss did not improve from 12.14628
 - 76s - loss: 12.2694 - val_loss: 12.3318
Epoch 348/8000

Epoch 00348: val_loss did not improve from 12.14628
 - 76s - loss: 12.1059 - val_loss: 12.4379
Epoch 349/8000

Epoch 00349: val_loss did not improve from 12.14628
 - 76s - loss: 12.3323 - val_loss: 12.4798
Epoch 350/8000

Epoch 00350: val_loss did not improve from 12.14628
 - 76s - loss: 12.0557 - val_loss: 12.3545
Epoch 351/8000

Epoch 00351: val_loss did not improve from 12.14628
 - 75s - loss: 12.0364 - val_loss: 12.4457
Epoch 352/8000

Epoch 00352: val_loss did not improve from 12.14628
 - 76s - loss: 11.8959 - val_loss: 12.6634
Epoch 353/8000

Epoch 00353: val_loss did not improve from 12.14628
 - 76s - loss: 12.1240 - val_loss: 12.4192
Epoch 354/8000

Epoch 00354: val_loss did not improve from 12.14628
 - 76s - loss: 12.1208 - val_loss: 12.8997
Epoch 355/8000

Epoch 00355: val_loss did not improve from 12.14628
 - 76s - loss: 11.9923 - val_loss: 12.4585
Epoch 356/8000

Epoch 00356: val_loss did not improve from 12.14628
 - 76s - loss: 11.9209 - val_loss: 12.3734
Epoch 357/8000

Epoch 00357: val_loss did not improve from 12.14628
 - 76s - loss: 11.9131 - val_loss: 12.2443
Epoch 358/8000

Epoch 00358: val_loss did not improve from 12.14628
 - 75s - loss: 11.8973 - val_loss: 12.3194
Epoch 359/8000

Epoch 00359: val_loss did not improve from 12.14628
 - 75s - loss: 11.9925 - val_loss: 12.2033
Epoch 360/8000

Epoch 00360: val_loss did not improve from 12.14628
 - 75s - loss: 12.1840 - val_loss: 12.2327
Epoch 361/8000

Epoch 00361: val_loss improved from 12.14628 to 12.11147, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 11.9181 - val_loss: 12.1115
Epoch 362/8000

Epoch 00362: val_loss did not improve from 12.11147
 - 75s - loss: 11.8151 - val_loss: 12.3179
Epoch 363/8000

Epoch 00363: val_loss did not improve from 12.11147
 - 76s - loss: 11.7583 - val_loss: 12.5892
Epoch 364/8000

Epoch 00364: val_loss did not improve from 12.11147
 - 76s - loss: 11.8232 - val_loss: 12.2339
Epoch 365/8000

Epoch 00365: val_loss improved from 12.11147 to 12.09112, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 11.7606 - val_loss: 12.0911
Epoch 366/8000

Epoch 00366: val_loss did not improve from 12.09112
 - 76s - loss: 11.9620 - val_loss: 12.1379
Epoch 367/8000

Epoch 00367: val_loss did not improve from 12.09112
 - 75s - loss: 11.7560 - val_loss: 12.2032
Epoch 368/8000

Epoch 00368: val_loss improved from 12.09112 to 11.92119, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.7391 - val_loss: 11.9212
Epoch 369/8000

Epoch 00369: val_loss did not improve from 11.92119
 - 76s - loss: 12.1714 - val_loss: 12.6488
Epoch 370/8000

Epoch 00370: val_loss did not improve from 11.92119
 - 76s - loss: 11.8020 - val_loss: 12.0101
Epoch 371/8000

Epoch 00371: val_loss did not improve from 11.92119
 - 76s - loss: 11.8081 - val_loss: 12.0715
Epoch 372/8000

Epoch 00372: val_loss did not improve from 11.92119
 - 75s - loss: 11.7924 - val_loss: 12.2694
Epoch 373/8000

Epoch 00373: val_loss did not improve from 11.92119
 - 76s - loss: 11.8856 - val_loss: 13.3346
Epoch 374/8000

Epoch 00374: val_loss did not improve from 11.92119
 - 75s - loss: 13.0517 - val_loss: 12.4913
Epoch 375/8000

Epoch 00375: val_loss did not improve from 11.92119
 - 76s - loss: 12.3082 - val_loss: 12.8201
Epoch 376/8000

Epoch 00376: val_loss did not improve from 11.92119
 - 76s - loss: 11.9843 - val_loss: 12.0203
Epoch 377/8000

Epoch 00377: val_loss did not improve from 11.92119
 - 76s - loss: 12.3594 - val_loss: 12.2942
Epoch 378/8000

Epoch 00378: val_loss did not improve from 11.92119
 - 76s - loss: 12.1500 - val_loss: 12.2789
Epoch 379/8000

Epoch 00379: val_loss did not improve from 11.92119
 - 75s - loss: 12.8051 - val_loss: 12.6238
Epoch 380/8000

Epoch 00380: val_loss did not improve from 11.92119
 - 75s - loss: 12.4789 - val_loss: 13.8303
Epoch 381/8000

Epoch 00381: val_loss did not improve from 11.92119
 - 75s - loss: 12.2552 - val_loss: 12.0536
Epoch 382/8000

Epoch 00382: val_loss did not improve from 11.92119
 - 76s - loss: 11.9377 - val_loss: 11.9478
Epoch 383/8000

Epoch 00383: val_loss did not improve from 11.92119
 - 76s - loss: 11.7611 - val_loss: 12.6257
Epoch 384/8000

Epoch 00384: val_loss did not improve from 11.92119
 - 76s - loss: 12.0177 - val_loss: 11.9567
Epoch 385/8000

Epoch 00385: val_loss did not improve from 11.92119
 - 76s - loss: 11.8239 - val_loss: 12.5068
Epoch 386/8000

Epoch 00386: val_loss did not improve from 11.92119
 - 75s - loss: 11.7717 - val_loss: 12.0915
Epoch 387/8000

Epoch 00387: val_loss did not improve from 11.92119
 - 76s - loss: 12.2656 - val_loss: 12.5771
Epoch 388/8000

Epoch 00388: val_loss did not improve from 11.92119
 - 75s - loss: 12.1284 - val_loss: 12.5867
Epoch 389/8000

Epoch 00389: val_loss did not improve from 11.92119
 - 76s - loss: 12.1104 - val_loss: 12.4116
Epoch 390/8000

Epoch 00390: val_loss did not improve from 11.92119
 - 76s - loss: 12.0962 - val_loss: 12.4295
Epoch 391/8000

Epoch 00391: val_loss did not improve from 11.92119
 - 76s - loss: 12.1248 - val_loss: 11.9779
Epoch 392/8000

Epoch 00392: val_loss did not improve from 11.92119
 - 76s - loss: 11.6247 - val_loss: 12.1152
Epoch 393/8000

Epoch 00393: val_loss did not improve from 11.92119
 - 75s - loss: 12.0289 - val_loss: 12.3961
Epoch 394/8000

Epoch 00394: val_loss did not improve from 11.92119
 - 76s - loss: 13.3758 - val_loss: 12.4466
Epoch 395/8000

Epoch 00395: val_loss did not improve from 11.92119
 - 75s - loss: 12.1336 - val_loss: 12.3168
Epoch 396/8000

Epoch 00396: val_loss did not improve from 11.92119
 - 76s - loss: 12.4645 - val_loss: 13.3158
Epoch 397/8000

Epoch 00397: val_loss did not improve from 11.92119
 - 76s - loss: 12.1661 - val_loss: 12.0190
Epoch 398/8000

Epoch 00398: val_loss did not improve from 11.92119
 - 76s - loss: 11.8256 - val_loss: 12.9694
Epoch 399/8000

Epoch 00399: val_loss did not improve from 11.92119
 - 76s - loss: 12.3508 - val_loss: 12.6189
Epoch 400/8000

Epoch 00400: val_loss did not improve from 11.92119
 - 75s - loss: 12.7612 - val_loss: 12.4382
Epoch 401/8000

Epoch 00401: val_loss did not improve from 11.92119
 - 76s - loss: 12.3119 - val_loss: 12.3029
Epoch 402/8000

Epoch 00402: val_loss did not improve from 11.92119
 - 75s - loss: 12.3541 - val_loss: 12.3761
Epoch 403/8000

Epoch 00403: val_loss did not improve from 11.92119
 - 76s - loss: 11.6999 - val_loss: 12.4378
Epoch 404/8000

Epoch 00404: val_loss did not improve from 11.92119
 - 76s - loss: 11.6212 - val_loss: 12.3071
Epoch 405/8000

Epoch 00405: val_loss improved from 11.92119 to 11.85713, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.5906 - val_loss: 11.8571
Epoch 406/8000

Epoch 00406: val_loss did not improve from 11.85713
 - 76s - loss: 11.5941 - val_loss: 11.9127
Epoch 407/8000

Epoch 00407: val_loss did not improve from 11.85713
 - 75s - loss: 11.7997 - val_loss: 12.1513
Epoch 408/8000

Epoch 00408: val_loss did not improve from 11.85713
 - 75s - loss: 11.5415 - val_loss: 11.9235
Epoch 409/8000

Epoch 00409: val_loss did not improve from 11.85713
 - 75s - loss: 11.7576 - val_loss: 12.1298
Epoch 410/8000

Epoch 00410: val_loss improved from 11.85713 to 11.84051, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.7281 - val_loss: 11.8405
Epoch 411/8000

Epoch 00411: val_loss did not improve from 11.84051
 - 76s - loss: 11.7724 - val_loss: 11.9923
Epoch 412/8000

Epoch 00412: val_loss improved from 11.84051 to 11.82788, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.7161 - val_loss: 11.8279
Epoch 413/8000

Epoch 00413: val_loss did not improve from 11.82788
 - 76s - loss: 11.5761 - val_loss: 11.8910
Epoch 414/8000

Epoch 00414: val_loss did not improve from 11.82788
 - 75s - loss: 11.6914 - val_loss: 11.8396
Epoch 415/8000

Epoch 00415: val_loss did not improve from 11.82788
 - 76s - loss: 11.4671 - val_loss: 11.9010
Epoch 416/8000

Epoch 00416: val_loss did not improve from 11.82788
 - 75s - loss: 11.6050 - val_loss: 12.0540
Epoch 417/8000

Epoch 00417: val_loss did not improve from 11.82788
 - 76s - loss: 11.4753 - val_loss: 11.9184
Epoch 418/8000

Epoch 00418: val_loss did not improve from 11.82788
 - 76s - loss: 11.6669 - val_loss: 12.2667
Epoch 419/8000

Epoch 00419: val_loss improved from 11.82788 to 11.78515, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.6884 - val_loss: 11.7852
Epoch 420/8000

Epoch 00420: val_loss did not improve from 11.78515
 - 76s - loss: 11.7750 - val_loss: 12.5519
Epoch 421/8000

Epoch 00421: val_loss did not improve from 11.78515
 - 75s - loss: 11.9029 - val_loss: 12.1465
Epoch 422/8000

Epoch 00422: val_loss did not improve from 11.78515
 - 76s - loss: 11.5473 - val_loss: 11.9634
Epoch 423/8000

Epoch 00423: val_loss did not improve from 11.78515
 - 75s - loss: 11.4743 - val_loss: 11.8308
Epoch 424/8000

Epoch 00424: val_loss improved from 11.78515 to 11.67234, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.4265 - val_loss: 11.6723
Epoch 425/8000

Epoch 00425: val_loss did not improve from 11.67234
 - 76s - loss: 11.7005 - val_loss: 12.4567
Epoch 426/8000

Epoch 00426: val_loss did not improve from 11.67234
 - 76s - loss: 12.0092 - val_loss: 12.2585
Epoch 427/8000

Epoch 00427: val_loss did not improve from 11.67234
 - 76s - loss: 11.5587 - val_loss: 11.8446
Epoch 428/8000

Epoch 00428: val_loss did not improve from 11.67234
 - 75s - loss: 11.9033 - val_loss: 12.4176
Epoch 429/8000

Epoch 00429: val_loss did not improve from 11.67234
 - 76s - loss: 11.6999 - val_loss: 11.8663
Epoch 430/8000

Epoch 00430: val_loss did not improve from 11.67234
 - 75s - loss: 11.4824 - val_loss: 12.2499
Epoch 431/8000

Epoch 00431: val_loss did not improve from 11.67234
 - 76s - loss: 11.5457 - val_loss: 12.7040
Epoch 432/8000

Epoch 00432: val_loss did not improve from 11.67234
 - 76s - loss: 11.4745 - val_loss: 11.7263
Epoch 433/8000

Epoch 00433: val_loss did not improve from 11.67234
 - 76s - loss: 11.9305 - val_loss: 11.9387
Epoch 434/8000

Epoch 00434: val_loss did not improve from 11.67234
 - 76s - loss: 11.3934 - val_loss: 11.7539
Epoch 435/8000

Epoch 00435: val_loss did not improve from 11.67234
 - 75s - loss: 11.5793 - val_loss: 12.0988
Epoch 436/8000

Epoch 00436: val_loss did not improve from 11.67234
 - 75s - loss: 11.8869 - val_loss: 11.9088
Epoch 437/8000

Epoch 00437: val_loss did not improve from 11.67234
 - 75s - loss: 11.6561 - val_loss: 12.0269
Epoch 438/8000

Epoch 00438: val_loss did not improve from 11.67234
 - 76s - loss: 11.5273 - val_loss: 12.1861
Epoch 439/8000

Epoch 00439: val_loss did not improve from 11.67234
 - 76s - loss: 12.0007 - val_loss: 11.9018
Epoch 440/8000

Epoch 00440: val_loss did not improve from 11.67234
 - 76s - loss: 11.3993 - val_loss: 11.7650
Epoch 441/8000

Epoch 00441: val_loss did not improve from 11.67234
 - 76s - loss: 11.5333 - val_loss: 12.2345
Epoch 442/8000

Epoch 00442: val_loss did not improve from 11.67234
 - 75s - loss: 11.5595 - val_loss: 11.7932
Epoch 443/8000

Epoch 00443: val_loss improved from 11.67234 to 11.62765, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.3163 - val_loss: 11.6277
Epoch 444/8000

Epoch 00444: val_loss did not improve from 11.62765
 - 75s - loss: 11.3256 - val_loss: 11.7816
Epoch 445/8000

Epoch 00445: val_loss did not improve from 11.62765
 - 76s - loss: 11.4208 - val_loss: 12.7701
Epoch 446/8000

Epoch 00446: val_loss did not improve from 11.62765
 - 76s - loss: 11.7663 - val_loss: 11.6408
Epoch 447/8000

Epoch 00447: val_loss did not improve from 11.62765
 - 76s - loss: 11.5303 - val_loss: 12.2545
Epoch 448/8000

Epoch 00448: val_loss did not improve from 11.62765
 - 76s - loss: 11.7956 - val_loss: 11.9582
Epoch 449/8000

Epoch 00449: val_loss did not improve from 11.62765
 - 75s - loss: 11.4172 - val_loss: 11.8087
Epoch 450/8000

Epoch 00450: val_loss did not improve from 11.62765
 - 75s - loss: 11.2034 - val_loss: 11.6795
Epoch 451/8000

Epoch 00451: val_loss did not improve from 11.62765
 - 75s - loss: 11.4475 - val_loss: 11.7394
Epoch 452/8000

Epoch 00452: val_loss did not improve from 11.62765
 - 76s - loss: 11.4568 - val_loss: 12.1057
Epoch 453/8000

Epoch 00453: val_loss did not improve from 11.62765
 - 76s - loss: 11.5290 - val_loss: 11.6445
Epoch 454/8000

Epoch 00454: val_loss did not improve from 11.62765
 - 76s - loss: 11.2942 - val_loss: 11.9369
Epoch 455/8000

Epoch 00455: val_loss improved from 11.62765 to 11.49762, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.1078 - val_loss: 11.4976
Epoch 456/8000

Epoch 00456: val_loss did not improve from 11.49762
 - 75s - loss: 11.4294 - val_loss: 11.7336
Epoch 457/8000

Epoch 00457: val_loss did not improve from 11.49762
 - 76s - loss: 11.5873 - val_loss: 12.0132
Epoch 458/8000

Epoch 00458: val_loss did not improve from 11.49762
 - 75s - loss: 11.1023 - val_loss: 11.8173
Epoch 459/8000

Epoch 00459: val_loss did not improve from 11.49762
 - 76s - loss: 11.1395 - val_loss: 12.0167
Epoch 460/8000

Epoch 00460: val_loss did not improve from 11.49762
 - 76s - loss: 11.2754 - val_loss: 11.6554
Epoch 461/8000

Epoch 00461: val_loss did not improve from 11.49762
 - 76s - loss: 11.5171 - val_loss: 12.2276
Epoch 462/8000

Epoch 00462: val_loss did not improve from 11.49762
 - 76s - loss: 11.4303 - val_loss: 12.6588
Epoch 463/8000

Epoch 00463: val_loss did not improve from 11.49762
 - 75s - loss: 12.2477 - val_loss: 12.2969
Epoch 464/8000

Epoch 00464: val_loss did not improve from 11.49762
 - 75s - loss: 11.8285 - val_loss: 12.8628
Epoch 465/8000

Epoch 00465: val_loss did not improve from 11.49762
 - 75s - loss: 11.6875 - val_loss: 12.3260
Epoch 466/8000

Epoch 00466: val_loss did not improve from 11.49762
 - 75s - loss: 11.3800 - val_loss: 11.6089
Epoch 467/8000

Epoch 00467: val_loss did not improve from 11.49762
 - 75s - loss: 11.2541 - val_loss: 11.6795
Epoch 468/8000

Epoch 00468: val_loss did not improve from 11.49762
 - 75s - loss: 11.0744 - val_loss: 11.5537
Epoch 469/8000

Epoch 00469: val_loss did not improve from 11.49762
 - 76s - loss: 11.4131 - val_loss: 11.8769
Epoch 470/8000

Epoch 00470: val_loss did not improve from 11.49762
 - 75s - loss: 11.1412 - val_loss: 12.0001
Epoch 471/8000

Epoch 00471: val_loss did not improve from 11.49762
 - 76s - loss: 11.4198 - val_loss: 11.7123
Epoch 472/8000

Epoch 00472: val_loss did not improve from 11.49762
 - 75s - loss: 11.2606 - val_loss: 12.0857
Epoch 473/8000

Epoch 00473: val_loss improved from 11.49762 to 11.49422, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.1447 - val_loss: 11.4942
Epoch 474/8000

Epoch 00474: val_loss improved from 11.49422 to 11.46425, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.6074 - val_loss: 11.4643
Epoch 475/8000

Epoch 00475: val_loss did not improve from 11.46425
 - 76s - loss: 11.2299 - val_loss: 12.1318
Epoch 476/8000

Epoch 00476: val_loss did not improve from 11.46425
 - 76s - loss: 11.2905 - val_loss: 11.8317
Epoch 477/8000

Epoch 00477: val_loss did not improve from 11.46425
 - 75s - loss: 11.7589 - val_loss: 12.6757
Epoch 478/8000

Epoch 00478: val_loss did not improve from 11.46425
 - 76s - loss: 11.7245 - val_loss: 11.8164
Epoch 479/8000

Epoch 00479: val_loss did not improve from 11.46425
 - 76s - loss: 11.2609 - val_loss: 11.6055
Epoch 480/8000

Epoch 00480: val_loss did not improve from 11.46425
 - 76s - loss: 10.9868 - val_loss: 11.9851
Epoch 481/8000

Epoch 00481: val_loss did not improve from 11.46425
 - 76s - loss: 11.4684 - val_loss: 11.7140
Epoch 482/8000

Epoch 00482: val_loss did not improve from 11.46425
 - 76s - loss: 11.2099 - val_loss: 11.5254
Epoch 483/8000

Epoch 00483: val_loss improved from 11.46425 to 11.45529, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 10.9954 - val_loss: 11.4553
Epoch 484/8000

Epoch 00484: val_loss did not improve from 11.45529
 - 75s - loss: 10.8536 - val_loss: 11.5313
Epoch 485/8000

Epoch 00485: val_loss did not improve from 11.45529
 - 75s - loss: 11.1496 - val_loss: 11.6433
Epoch 486/8000

Epoch 00486: val_loss did not improve from 11.45529
 - 75s - loss: 11.0251 - val_loss: 11.4614
Epoch 487/8000

Epoch 00487: val_loss did not improve from 11.45529
 - 76s - loss: 11.7066 - val_loss: 11.6074
Epoch 488/8000

Epoch 00488: val_loss did not improve from 11.45529
 - 76s - loss: 11.1238 - val_loss: 11.8399
Epoch 489/8000

Epoch 00489: val_loss did not improve from 11.45529
 - 76s - loss: 11.3339 - val_loss: 11.8120
Epoch 490/8000

Epoch 00490: val_loss did not improve from 11.45529
 - 76s - loss: 11.1719 - val_loss: 11.6430
Epoch 491/8000

Epoch 00491: val_loss did not improve from 11.45529
 - 75s - loss: 11.1613 - val_loss: 11.4564
Epoch 492/8000

Epoch 00492: val_loss improved from 11.45529 to 11.36361, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.1064 - val_loss: 11.3636
Epoch 493/8000

Epoch 00493: val_loss did not improve from 11.36361
 - 76s - loss: 10.9405 - val_loss: 11.9251
Epoch 494/8000

Epoch 00494: val_loss did not improve from 11.36361
 - 76s - loss: 11.0780 - val_loss: 11.4138
Epoch 495/8000

Epoch 00495: val_loss did not improve from 11.36361
 - 76s - loss: 11.4397 - val_loss: 11.8601
Epoch 496/8000

Epoch 00496: val_loss did not improve from 11.36361
 - 76s - loss: 11.4096 - val_loss: 11.6209
Epoch 497/8000

Epoch 00497: val_loss did not improve from 11.36361
 - 76s - loss: 11.3786 - val_loss: 12.3841
Epoch 498/8000

Epoch 00498: val_loss did not improve from 11.36361
 - 75s - loss: 11.3012 - val_loss: 11.9073
Epoch 499/8000

Epoch 00499: val_loss did not improve from 11.36361
 - 75s - loss: 11.1795 - val_loss: 11.9422
Epoch 500/8000

Epoch 00500: val_loss improved from 11.36361 to 11.35159, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 11.1215 - val_loss: 11.3516
Epoch 501/8000

Epoch 00501: val_loss did not improve from 11.35159
 - 76s - loss: 11.1613 - val_loss: 11.6396
Epoch 502/8000

Epoch 00502: val_loss did not improve from 11.35159
 - 76s - loss: 11.1608 - val_loss: 12.0581
Epoch 503/8000

Epoch 00503: val_loss improved from 11.35159 to 11.32877, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 11.1460 - val_loss: 11.3288
Epoch 504/8000

Epoch 00504: val_loss did not improve from 11.32877
 - 76s - loss: 11.0827 - val_loss: 11.3729
Epoch 505/8000

Epoch 00505: val_loss did not improve from 11.32877
 - 75s - loss: 10.8328 - val_loss: 11.7525
Epoch 506/8000

Epoch 00506: val_loss did not improve from 11.32877
 - 76s - loss: 10.8793 - val_loss: 11.6592
Epoch 507/8000

Epoch 00507: val_loss did not improve from 11.32877
 - 76s - loss: 10.7718 - val_loss: 11.5314
Epoch 508/8000

Epoch 00508: val_loss did not improve from 11.32877
 - 76s - loss: 11.2941 - val_loss: 11.5859
Epoch 509/8000

Epoch 00509: val_loss improved from 11.32877 to 11.13097, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 10.7923 - val_loss: 11.1310
Epoch 510/8000

Epoch 00510: val_loss did not improve from 11.13097
 - 76s - loss: 10.6508 - val_loss: 11.5582
Epoch 511/8000

Epoch 00511: val_loss did not improve from 11.13097
 - 76s - loss: 11.0047 - val_loss: 12.5456
Epoch 512/8000

Epoch 00512: val_loss did not improve from 11.13097
 - 75s - loss: 11.2970 - val_loss: 11.6853
Epoch 513/8000

Epoch 00513: val_loss did not improve from 11.13097
 - 75s - loss: 10.9628 - val_loss: 11.4335
Epoch 514/8000

Epoch 00514: val_loss did not improve from 11.13097
 - 75s - loss: 10.9331 - val_loss: 12.0998
Epoch 515/8000

Epoch 00515: val_loss did not improve from 11.13097
 - 76s - loss: 10.9413 - val_loss: 11.3014
Epoch 516/8000

Epoch 00516: val_loss did not improve from 11.13097
 - 76s - loss: 10.8497 - val_loss: 11.4518
Epoch 517/8000

Epoch 00517: val_loss did not improve from 11.13097
 - 76s - loss: 10.8239 - val_loss: 11.4620
Epoch 518/8000

Epoch 00518: val_loss did not improve from 11.13097
 - 76s - loss: 10.8362 - val_loss: 11.4845
Epoch 519/8000

Epoch 00519: val_loss did not improve from 11.13097
 - 75s - loss: 10.7167 - val_loss: 11.4181
Epoch 520/8000

Epoch 00520: val_loss did not improve from 11.13097
 - 76s - loss: 10.7587 - val_loss: 11.6215
Epoch 521/8000

Epoch 00521: val_loss did not improve from 11.13097
 - 76s - loss: 11.5408 - val_loss: 12.3322
Epoch 522/8000

Epoch 00522: val_loss did not improve from 11.13097
 - 76s - loss: 11.2094 - val_loss: 11.8839
Epoch 523/8000

Epoch 00523: val_loss did not improve from 11.13097
 - 76s - loss: 11.1325 - val_loss: 11.3704
Epoch 524/8000

Epoch 00524: val_loss did not improve from 11.13097
 - 76s - loss: 10.7514 - val_loss: 11.3933
Epoch 525/8000

Epoch 00525: val_loss did not improve from 11.13097
 - 76s - loss: 11.2570 - val_loss: 11.8821
Epoch 526/8000

Epoch 00526: val_loss did not improve from 11.13097
 - 75s - loss: 11.3284 - val_loss: 15.8410
Epoch 527/8000

Epoch 00527: val_loss did not improve from 11.13097
 - 75s - loss: 30.2997 - val_loss: 22.3016
Epoch 528/8000

Epoch 00528: val_loss did not improve from 11.13097
 - 75s - loss: 21.8172 - val_loss: 20.4870
Epoch 529/8000

Epoch 00529: val_loss did not improve from 11.13097
 - 76s - loss: 19.8857 - val_loss: 19.1632
Epoch 530/8000

Epoch 00530: val_loss did not improve from 11.13097
 - 76s - loss: 18.7701 - val_loss: 18.2309
Epoch 531/8000

Epoch 00531: val_loss did not improve from 11.13097
 - 76s - loss: 17.9143 - val_loss: 17.4381
Epoch 532/8000

Epoch 00532: val_loss did not improve from 11.13097
 - 76s - loss: 16.9352 - val_loss: 16.5803
Epoch 533/8000

Epoch 00533: val_loss did not improve from 11.13097
 - 75s - loss: 16.2389 - val_loss: 16.1528
Epoch 534/8000

Epoch 00534: val_loss did not improve from 11.13097
 - 76s - loss: 15.7624 - val_loss: 15.7158
Epoch 535/8000

Epoch 00535: val_loss did not improve from 11.13097
 - 75s - loss: 15.3813 - val_loss: 15.6251
Epoch 536/8000

Epoch 00536: val_loss did not improve from 11.13097
 - 76s - loss: 15.2100 - val_loss: 15.1341
Epoch 537/8000

Epoch 00537: val_loss did not improve from 11.13097
 - 76s - loss: 14.8858 - val_loss: 14.9082
Epoch 538/8000

Epoch 00538: val_loss did not improve from 11.13097
 - 76s - loss: 14.7403 - val_loss: 14.7769
Epoch 539/8000

Epoch 00539: val_loss did not improve from 11.13097
 - 76s - loss: 14.5641 - val_loss: 14.5955
Epoch 540/8000

Epoch 00540: val_loss did not improve from 11.13097
 - 75s - loss: 14.6516 - val_loss: 14.6610
Epoch 541/8000

Epoch 00541: val_loss did not improve from 11.13097
 - 76s - loss: 14.3033 - val_loss: 14.3359
Epoch 542/8000

Epoch 00542: val_loss did not improve from 11.13097
 - 75s - loss: 14.0379 - val_loss: 14.1815
Epoch 543/8000

Epoch 00543: val_loss did not improve from 11.13097
 - 76s - loss: 13.9528 - val_loss: 14.1188
Epoch 544/8000

Epoch 00544: val_loss did not improve from 11.13097
 - 76s - loss: 13.9261 - val_loss: 13.9258
Epoch 545/8000

Epoch 00545: val_loss did not improve from 11.13097
 - 76s - loss: 13.7614 - val_loss: 14.0984
Epoch 546/8000

Epoch 00546: val_loss did not improve from 11.13097
 - 76s - loss: 13.6411 - val_loss: 13.9740
Epoch 547/8000

Epoch 00547: val_loss did not improve from 11.13097
 - 75s - loss: 13.7528 - val_loss: 13.7711
Epoch 548/8000

Epoch 00548: val_loss did not improve from 11.13097
 - 76s - loss: 13.4517 - val_loss: 13.5187
Epoch 549/8000

Epoch 00549: val_loss did not improve from 11.13097
 - 76s - loss: 13.7740 - val_loss: 13.6074
Epoch 550/8000

Epoch 00550: val_loss did not improve from 11.13097
 - 76s - loss: 13.3097 - val_loss: 13.4220
Epoch 551/8000

Epoch 00551: val_loss did not improve from 11.13097
 - 76s - loss: 13.4471 - val_loss: 13.1900
Epoch 552/8000

Epoch 00552: val_loss did not improve from 11.13097
 - 76s - loss: 13.1322 - val_loss: 13.1094
Epoch 553/8000

Epoch 00553: val_loss did not improve from 11.13097
 - 76s - loss: 13.2227 - val_loss: 13.3148
Epoch 554/8000

Epoch 00554: val_loss did not improve from 11.13097
 - 75s - loss: 13.0602 - val_loss: 13.1380
Epoch 555/8000

Epoch 00555: val_loss did not improve from 11.13097
 - 76s - loss: 12.8888 - val_loss: 13.0328
Epoch 556/8000

Epoch 00556: val_loss did not improve from 11.13097
 - 75s - loss: 12.8949 - val_loss: 12.9071
Epoch 557/8000

Epoch 00557: val_loss did not improve from 11.13097
 - 76s - loss: 12.9739 - val_loss: 13.9582
Epoch 558/8000

Epoch 00558: val_loss did not improve from 11.13097
 - 76s - loss: 13.1291 - val_loss: 13.1248
Epoch 559/8000

Epoch 00559: val_loss did not improve from 11.13097
 - 76s - loss: 13.0711 - val_loss: 13.1944
Epoch 560/8000

Epoch 00560: val_loss did not improve from 11.13097
 - 76s - loss: 12.7857 - val_loss: 13.0071
Epoch 561/8000

Epoch 00561: val_loss did not improve from 11.13097
 - 75s - loss: 12.9385 - val_loss: 13.6714
Epoch 562/8000

Epoch 00562: val_loss did not improve from 11.13097
 - 76s - loss: 12.9305 - val_loss: 12.7337
Epoch 563/8000

Epoch 00563: val_loss did not improve from 11.13097
 - 75s - loss: 13.5494 - val_loss: 13.1793
Epoch 564/8000

Epoch 00564: val_loss did not improve from 11.13097
 - 76s - loss: 12.7616 - val_loss: 12.8093
Epoch 565/8000

Epoch 00565: val_loss did not improve from 11.13097
 - 76s - loss: 12.6879 - val_loss: 12.9193
Epoch 566/8000

Epoch 00566: val_loss did not improve from 11.13097
 - 76s - loss: 12.5756 - val_loss: 12.6958
Epoch 567/8000

Epoch 00567: val_loss did not improve from 11.13097
 - 76s - loss: 12.5713 - val_loss: 12.7973
Epoch 568/8000

Epoch 00568: val_loss did not improve from 11.13097
 - 75s - loss: 12.6865 - val_loss: 12.6567
Epoch 569/8000

Epoch 00569: val_loss did not improve from 11.13097
 - 76s - loss: 12.6630 - val_loss: 12.9511
Epoch 570/8000

Epoch 00570: val_loss did not improve from 11.13097
 - 75s - loss: 12.6971 - val_loss: 12.7258
Epoch 571/8000

Epoch 00571: val_loss did not improve from 11.13097
 - 75s - loss: 12.4228 - val_loss: 12.5304
Epoch 572/8000

Epoch 00572: val_loss did not improve from 11.13097
 - 75s - loss: 12.3796 - val_loss: 12.6893
Epoch 573/8000

Epoch 00573: val_loss did not improve from 11.13097
 - 75s - loss: 13.6629 - val_loss: 13.1209
Epoch 574/8000

Epoch 00574: val_loss did not improve from 11.13097
 - 76s - loss: 12.8572 - val_loss: 13.7270
Epoch 575/8000

Epoch 00575: val_loss did not improve from 11.13097
 - 75s - loss: 12.8750 - val_loss: 12.6521
Epoch 576/8000

Epoch 00576: val_loss did not improve from 11.13097
 - 76s - loss: 12.6747 - val_loss: 13.2553
Epoch 577/8000

Epoch 00577: val_loss did not improve from 11.13097
 - 75s - loss: 12.5783 - val_loss: 12.6863
Epoch 578/8000

Epoch 00578: val_loss did not improve from 11.13097
 - 76s - loss: 12.9908 - val_loss: 13.2592
Epoch 579/8000

Epoch 00579: val_loss did not improve from 11.13097
 - 76s - loss: 12.5217 - val_loss: 12.7590
Epoch 580/8000

Epoch 00580: val_loss did not improve from 11.13097
 - 76s - loss: 12.4129 - val_loss: 12.6068
Epoch 581/8000

Epoch 00581: val_loss did not improve from 11.13097
 - 76s - loss: 12.4033 - val_loss: 12.2163
Epoch 582/8000

Epoch 00582: val_loss did not improve from 11.13097
 - 75s - loss: 12.4461 - val_loss: 12.8890
Epoch 583/8000

Epoch 00583: val_loss did not improve from 11.13097
 - 76s - loss: 12.5939 - val_loss: 12.8847
Epoch 584/8000

Epoch 00584: val_loss did not improve from 11.13097
 - 75s - loss: 12.6253 - val_loss: 12.6778
Epoch 585/8000

Epoch 00585: val_loss did not improve from 11.13097
 - 76s - loss: 12.4195 - val_loss: 12.4631
Epoch 586/8000

Epoch 00586: val_loss did not improve from 11.13097
 - 76s - loss: 12.3425 - val_loss: 13.1082
Epoch 587/8000

Epoch 00587: val_loss did not improve from 11.13097
 - 76s - loss: 12.5786 - val_loss: 12.6820
Epoch 588/8000

Epoch 00588: val_loss did not improve from 11.13097
 - 76s - loss: 12.9317 - val_loss: 13.0390
Epoch 589/8000

Epoch 00589: val_loss did not improve from 11.13097
 - 75s - loss: 12.4484 - val_loss: 12.2342
Epoch 590/8000

Epoch 00590: val_loss did not improve from 11.13097
 - 75s - loss: 12.2587 - val_loss: 12.7359
Epoch 591/8000

Epoch 00591: val_loss did not improve from 11.13097
 - 75s - loss: 12.5555 - val_loss: 12.5293
Epoch 592/8000

Epoch 00592: val_loss did not improve from 11.13097
 - 76s - loss: 12.4092 - val_loss: 12.3468
Epoch 593/8000

Epoch 00593: val_loss did not improve from 11.13097
 - 76s - loss: 12.4679 - val_loss: 12.6129
Epoch 594/8000

Epoch 00594: val_loss did not improve from 11.13097
 - 76s - loss: 12.3966 - val_loss: 12.8001
Epoch 595/8000

Epoch 00595: val_loss did not improve from 11.13097
 - 76s - loss: 12.4055 - val_loss: 12.6734
Epoch 596/8000

Epoch 00596: val_loss did not improve from 11.13097
 - 75s - loss: 12.1554 - val_loss: 12.2024
Epoch 597/8000

Epoch 00597: val_loss did not improve from 11.13097
 - 76s - loss: 12.3708 - val_loss: 12.8582
Epoch 598/8000

Epoch 00598: val_loss did not improve from 11.13097
 - 75s - loss: 12.6831 - val_loss: 12.4804
Epoch 599/8000

Epoch 00599: val_loss did not improve from 11.13097
 - 76s - loss: 12.5071 - val_loss: 13.0963
Epoch 600/8000

Epoch 00600: val_loss did not improve from 11.13097
 - 76s - loss: 12.4881 - val_loss: 12.7848
Epoch 601/8000

Epoch 00601: val_loss did not improve from 11.13097
 - 76s - loss: 12.1989 - val_loss: 12.7203
Epoch 602/8000

Epoch 00602: val_loss did not improve from 11.13097
 - 76s - loss: 12.3323 - val_loss: 12.8434
Epoch 603/8000

Epoch 00603: val_loss did not improve from 11.13097
 - 75s - loss: 12.2745 - val_loss: 12.3967
Epoch 604/8000

Epoch 00604: val_loss did not improve from 11.13097
 - 75s - loss: 12.2476 - val_loss: 13.3527
Epoch 605/8000

Epoch 00605: val_loss did not improve from 11.13097
 - 75s - loss: 12.3159 - val_loss: 12.3185
Epoch 606/8000

Epoch 00606: val_loss did not improve from 11.13097
 - 76s - loss: 12.0831 - val_loss: 12.1114
Epoch 607/8000

Epoch 00607: val_loss did not improve from 11.13097
 - 76s - loss: 11.9701 - val_loss: 12.1612
Epoch 608/8000

Epoch 00608: val_loss did not improve from 11.13097
 - 76s - loss: 11.8937 - val_loss: 12.0624
Epoch 609/8000

Epoch 00609: val_loss did not improve from 11.13097
 - 76s - loss: 11.8083 - val_loss: 12.1638
Epoch 610/8000

Epoch 00610: val_loss did not improve from 11.13097
 - 75s - loss: 11.9692 - val_loss: 12.1000
Epoch 611/8000

Epoch 00611: val_loss did not improve from 11.13097
 - 76s - loss: 12.0580 - val_loss: 15.4840
Epoch 612/8000

Epoch 00612: val_loss did not improve from 11.13097
 - 75s - loss: 13.6954 - val_loss: 13.0831
Epoch 613/8000

Epoch 00613: val_loss did not improve from 11.13097
 - 76s - loss: 12.8185 - val_loss: 12.8989
Epoch 614/8000

Epoch 00614: val_loss did not improve from 11.13097
 - 76s - loss: 12.1427 - val_loss: 12.4504
Epoch 615/8000

Epoch 00615: val_loss did not improve from 11.13097
 - 76s - loss: 11.8312 - val_loss: 12.1055
Epoch 616/8000

Epoch 00616: val_loss did not improve from 11.13097
 - 76s - loss: 11.9711 - val_loss: 12.1120
Epoch 617/8000

Epoch 00617: val_loss did not improve from 11.13097
 - 75s - loss: 11.9657 - val_loss: 12.0486
Epoch 618/8000

Epoch 00618: val_loss did not improve from 11.13097
 - 75s - loss: 12.2227 - val_loss: 13.1432
Epoch 619/8000

Epoch 00619: val_loss did not improve from 11.13097
 - 75s - loss: 12.0555 - val_loss: 12.0690
Epoch 620/8000

Epoch 00620: val_loss did not improve from 11.13097
 - 76s - loss: 11.8954 - val_loss: 12.0568
Epoch 621/8000

Epoch 00621: val_loss did not improve from 11.13097
 - 76s - loss: 11.7505 - val_loss: 12.0215
Epoch 622/8000

Epoch 00622: val_loss did not improve from 11.13097
 - 76s - loss: 11.8623 - val_loss: 12.1097
Epoch 623/8000

Epoch 00623: val_loss did not improve from 11.13097
 - 76s - loss: 11.8803 - val_loss: 12.1844
Epoch 624/8000

Epoch 00624: val_loss did not improve from 11.13097
 - 75s - loss: 11.7286 - val_loss: 12.2884
Epoch 625/8000

Epoch 00625: val_loss did not improve from 11.13097
 - 76s - loss: 11.6296 - val_loss: 12.1171
Epoch 626/8000

Epoch 00626: val_loss did not improve from 11.13097
 - 76s - loss: 11.6485 - val_loss: 11.8961
Epoch 627/8000

Epoch 00627: val_loss did not improve from 11.13097
 - 76s - loss: 11.5973 - val_loss: 12.0790
Epoch 628/8000

Epoch 00628: val_loss did not improve from 11.13097
 - 76s - loss: 11.6459 - val_loss: 12.0431
Epoch 629/8000

Epoch 00629: val_loss did not improve from 11.13097
 - 76s - loss: 11.6077 - val_loss: 11.8545
Epoch 630/8000

Epoch 00630: val_loss did not improve from 11.13097
 - 76s - loss: 11.7159 - val_loss: 11.9968
Epoch 631/8000

Epoch 00631: val_loss did not improve from 11.13097
 - 75s - loss: 11.6415 - val_loss: 12.4131
Epoch 632/8000

Epoch 00632: val_loss did not improve from 11.13097
 - 76s - loss: 11.9268 - val_loss: 11.8448
Epoch 633/8000

Epoch 00633: val_loss did not improve from 11.13097
 - 75s - loss: 11.5829 - val_loss: 11.7271
Epoch 634/8000

Epoch 00634: val_loss did not improve from 11.13097
 - 76s - loss: 11.5349 - val_loss: 12.0034
Epoch 635/8000

Epoch 00635: val_loss did not improve from 11.13097
 - 76s - loss: 11.7170 - val_loss: 12.0866
Epoch 636/8000

Epoch 00636: val_loss did not improve from 11.13097
 - 76s - loss: 11.8282 - val_loss: 12.0595
Epoch 637/8000

Epoch 00637: val_loss did not improve from 11.13097
 - 76s - loss: 11.7157 - val_loss: 11.8563
Epoch 638/8000

Epoch 00638: val_loss did not improve from 11.13097
 - 75s - loss: 11.5008 - val_loss: 11.8020
Epoch 639/8000

Epoch 00639: val_loss did not improve from 11.13097
 - 76s - loss: 11.6093 - val_loss: 11.7082
Epoch 640/8000

Epoch 00640: val_loss did not improve from 11.13097
 - 75s - loss: 11.5214 - val_loss: 11.9130
Epoch 641/8000

Epoch 00641: val_loss did not improve from 11.13097
 - 76s - loss: 11.5830 - val_loss: 11.9753
Epoch 642/8000

Epoch 00642: val_loss did not improve from 11.13097
 - 76s - loss: 11.9525 - val_loss: 11.8926
Epoch 643/8000

Epoch 00643: val_loss did not improve from 11.13097
 - 76s - loss: 12.0356 - val_loss: 13.2035
Epoch 644/8000

Epoch 00644: val_loss did not improve from 11.13097
 - 76s - loss: 11.9924 - val_loss: 11.8847
Epoch 645/8000

Epoch 00645: val_loss did not improve from 11.13097
 - 75s - loss: 11.6990 - val_loss: 13.3785
Epoch 646/8000

Epoch 00646: val_loss did not improve from 11.13097
 - 76s - loss: 11.9397 - val_loss: 11.8121
Epoch 647/8000

Epoch 00647: val_loss did not improve from 11.13097
 - 75s - loss: 12.1730 - val_loss: 12.6737
Epoch 648/8000

Epoch 00648: val_loss did not improve from 11.13097
 - 76s - loss: 11.9300 - val_loss: 12.2453
Epoch 649/8000

Epoch 00649: val_loss did not improve from 11.13097
 - 76s - loss: 11.6064 - val_loss: 12.0031
Epoch 650/8000

Epoch 00650: val_loss did not improve from 11.13097
 - 76s - loss: 11.7338 - val_loss: 12.6286
Epoch 651/8000

Epoch 00651: val_loss did not improve from 11.13097
 - 76s - loss: 11.5579 - val_loss: 11.6463
Epoch 652/8000

Epoch 00652: val_loss did not improve from 11.13097
 - 75s - loss: 11.3960 - val_loss: 11.7965
Epoch 653/8000

Epoch 00653: val_loss did not improve from 11.13097
 - 76s - loss: 12.1816 - val_loss: 13.1336
Epoch 654/8000

Epoch 00654: val_loss did not improve from 11.13097
 - 75s - loss: 12.0535 - val_loss: 12.0363
Epoch 655/8000

Epoch 00655: val_loss did not improve from 11.13097
 - 76s - loss: 13.5630 - val_loss: 12.5987
Epoch 656/8000

Epoch 00656: val_loss did not improve from 11.13097
 - 76s - loss: 12.0200 - val_loss: 12.6646
Epoch 657/8000

Epoch 00657: val_loss did not improve from 11.13097
 - 76s - loss: 12.5041 - val_loss: 12.2756
Epoch 658/8000

Epoch 00658: val_loss did not improve from 11.13097
 - 76s - loss: 12.6502 - val_loss: 12.7845
Epoch 659/8000

Epoch 00659: val_loss did not improve from 11.13097
 - 75s - loss: 12.0204 - val_loss: 12.3756
Epoch 660/8000

Epoch 00660: val_loss did not improve from 11.13097
 - 76s - loss: 12.3919 - val_loss: 12.3888
Epoch 661/8000

Epoch 00661: val_loss did not improve from 11.13097
 - 75s - loss: 13.2190 - val_loss: 12.7719
Epoch 662/8000

Epoch 00662: val_loss did not improve from 11.13097
 - 76s - loss: 12.2345 - val_loss: 12.5914
Epoch 663/8000

Epoch 00663: val_loss did not improve from 11.13097
 - 76s - loss: 11.7774 - val_loss: 11.7375
Epoch 664/8000

Epoch 00664: val_loss did not improve from 11.13097
 - 76s - loss: 11.5085 - val_loss: 12.3969
Epoch 665/8000

Epoch 00665: val_loss did not improve from 11.13097
 - 76s - loss: 11.6221 - val_loss: 11.9316
Epoch 666/8000

Epoch 00666: val_loss did not improve from 11.13097
 - 75s - loss: 11.3949 - val_loss: 11.6573
Epoch 667/8000

Epoch 00667: val_loss did not improve from 11.13097
 - 76s - loss: 11.4057 - val_loss: 11.6638
Epoch 668/8000

Epoch 00668: val_loss did not improve from 11.13097
 - 75s - loss: 11.6622 - val_loss: 12.1656
Epoch 669/8000

Epoch 00669: val_loss did not improve from 11.13097
 - 76s - loss: 11.5483 - val_loss: 11.7547
Epoch 670/8000

Epoch 00670: val_loss did not improve from 11.13097
 - 76s - loss: 12.4616 - val_loss: 12.4186
Epoch 671/8000

Epoch 00671: val_loss did not improve from 11.13097
 - 76s - loss: 13.1641 - val_loss: 12.3330
Epoch 672/8000

Epoch 00672: val_loss did not improve from 11.13097
 - 75s - loss: 12.2239 - val_loss: 12.3083
Epoch 673/8000

Epoch 00673: val_loss did not improve from 11.13097
 - 75s - loss: 11.8745 - val_loss: 12.7357
Epoch 674/8000

Epoch 00674: val_loss did not improve from 11.13097
 - 75s - loss: 11.3714 - val_loss: 11.6649
Epoch 675/8000

Epoch 00675: val_loss did not improve from 11.13097
 - 75s - loss: 11.2870 - val_loss: 11.4884
Epoch 676/8000

Epoch 00676: val_loss did not improve from 11.13097
 - 75s - loss: 11.6747 - val_loss: 12.1019
Epoch 677/8000

Epoch 00677: val_loss did not improve from 11.13097
 - 75s - loss: 11.4843 - val_loss: 12.1703
Epoch 678/8000

Epoch 00678: val_loss did not improve from 11.13097
 - 75s - loss: 11.6172 - val_loss: 12.2557
Epoch 679/8000

Epoch 00679: val_loss did not improve from 11.13097
 - 76s - loss: 12.2886 - val_loss: 12.2343
Epoch 680/8000

Epoch 00680: val_loss did not improve from 11.13097
 - 75s - loss: 11.9336 - val_loss: 12.5154
Epoch 681/8000

Epoch 00681: val_loss did not improve from 11.13097
 - 76s - loss: 12.1207 - val_loss: 12.3005
Epoch 682/8000

Epoch 00682: val_loss did not improve from 11.13097
 - 75s - loss: 11.8742 - val_loss: 12.8205
Epoch 683/8000

Epoch 00683: val_loss did not improve from 11.13097
 - 76s - loss: 11.8449 - val_loss: 11.8312
Epoch 684/8000

Epoch 00684: val_loss did not improve from 11.13097
 - 76s - loss: 11.5998 - val_loss: 12.2454
Epoch 685/8000

Epoch 00685: val_loss did not improve from 11.13097
 - 76s - loss: 12.1047 - val_loss: 12.0483
Epoch 686/8000

Epoch 00686: val_loss did not improve from 11.13097
 - 76s - loss: 13.6946 - val_loss: 13.1251
Epoch 687/8000

Epoch 00687: val_loss did not improve from 11.13097
 - 75s - loss: 12.1920 - val_loss: 12.1781
Epoch 688/8000

Epoch 00688: val_loss did not improve from 11.13097
 - 76s - loss: 11.8823 - val_loss: 11.8954
Epoch 689/8000

Epoch 00689: val_loss did not improve from 11.13097
 - 76s - loss: 11.8321 - val_loss: 13.2448
Epoch 690/8000

Epoch 00690: val_loss did not improve from 11.13097
 - 76s - loss: 12.1202 - val_loss: 11.9733
Epoch 691/8000

Epoch 00691: val_loss did not improve from 11.13097
 - 76s - loss: 11.3287 - val_loss: 11.4277
Epoch 692/8000

Epoch 00692: val_loss did not improve from 11.13097
 - 76s - loss: 12.3569 - val_loss: 13.8700
Epoch 693/8000

Epoch 00693: val_loss did not improve from 11.13097
 - 76s - loss: 12.4212 - val_loss: 12.2792
Epoch 694/8000

Epoch 00694: val_loss did not improve from 11.13097
 - 75s - loss: 12.2096 - val_loss: 12.0033
Epoch 695/8000

Epoch 00695: val_loss did not improve from 11.13097
 - 76s - loss: 11.9393 - val_loss: 11.9394
Epoch 696/8000

Epoch 00696: val_loss did not improve from 11.13097
 - 75s - loss: 11.9278 - val_loss: 12.5273
Epoch 697/8000

Epoch 00697: val_loss did not improve from 11.13097
 - 76s - loss: 11.7339 - val_loss: 12.1163
Epoch 698/8000

Epoch 00698: val_loss did not improve from 11.13097
 - 76s - loss: 11.7391 - val_loss: 12.0083
Epoch 699/8000

Epoch 00699: val_loss did not improve from 11.13097
 - 76s - loss: 11.7878 - val_loss: 11.6577
Epoch 700/8000

Epoch 00700: val_loss did not improve from 11.13097
 - 76s - loss: 11.7919 - val_loss: 12.2919
Epoch 701/8000

Epoch 00701: val_loss did not improve from 11.13097
 - 75s - loss: 12.4890 - val_loss: 12.5262
Epoch 702/8000

Epoch 00702: val_loss did not improve from 11.13097
 - 76s - loss: 12.0148 - val_loss: 12.0213
Epoch 703/8000

Epoch 00703: val_loss did not improve from 11.13097
 - 76s - loss: 12.2896 - val_loss: 12.7864
Epoch 704/8000

Epoch 00704: val_loss did not improve from 11.13097
 - 76s - loss: 11.9046 - val_loss: 12.3413
Epoch 705/8000

Epoch 00705: val_loss did not improve from 11.13097
 - 76s - loss: 11.8553 - val_loss: 13.0188
Epoch 706/8000

Epoch 00706: val_loss did not improve from 11.13097
 - 76s - loss: 12.1702 - val_loss: 12.1516
Epoch 707/8000

Epoch 00707: val_loss did not improve from 11.13097
 - 76s - loss: 11.9313 - val_loss: 12.4408
Epoch 708/8000

Epoch 00708: val_loss did not improve from 11.13097
 - 75s - loss: 11.8295 - val_loss: 11.9344
Epoch 709/8000

Epoch 00709: val_loss did not improve from 11.13097
 - 75s - loss: 11.9983 - val_loss: 12.0339
Epoch 710/8000

Epoch 00710: val_loss did not improve from 11.13097
 - 75s - loss: 12.3566 - val_loss: 12.1033
Epoch 711/8000

Epoch 00711: val_loss did not improve from 11.13097
 - 76s - loss: 12.1038 - val_loss: 13.1523
Epoch 712/8000

Epoch 00712: val_loss did not improve from 11.13097
 - 76s - loss: 12.8049 - val_loss: 13.4413
Epoch 713/8000

Epoch 00713: val_loss did not improve from 11.13097
 - 76s - loss: 13.3823 - val_loss: 12.7952
Epoch 714/8000

Epoch 00714: val_loss did not improve from 11.13097
 - 76s - loss: 12.0416 - val_loss: 12.4160
Epoch 715/8000

Epoch 00715: val_loss did not improve from 11.13097
 - 75s - loss: 11.9290 - val_loss: 12.8200
Epoch 716/8000

Epoch 00716: val_loss did not improve from 11.13097
 - 76s - loss: 11.9066 - val_loss: 11.8672
Epoch 717/8000

Epoch 00717: val_loss did not improve from 11.13097
 - 75s - loss: 12.2480 - val_loss: 12.3809
Epoch 718/8000

Epoch 00718: val_loss did not improve from 11.13097
 - 76s - loss: 11.9625 - val_loss: 12.4738
Epoch 719/8000

Epoch 00719: val_loss did not improve from 11.13097
 - 76s - loss: 11.6115 - val_loss: 11.8139
Epoch 720/8000

Epoch 00720: val_loss did not improve from 11.13097
 - 76s - loss: 11.6896 - val_loss: 12.1043
Epoch 721/8000

Epoch 00721: val_loss did not improve from 11.13097
 - 75s - loss: 11.5496 - val_loss: 11.6054
Epoch 722/8000

Epoch 00722: val_loss did not improve from 11.13097
 - 75s - loss: 11.8765 - val_loss: 13.4342
Epoch 723/8000

Epoch 00723: val_loss did not improve from 11.13097
 - 75s - loss: 12.2964 - val_loss: 11.9633
Epoch 724/8000

Epoch 00724: val_loss did not improve from 11.13097
 - 75s - loss: 12.1108 - val_loss: 12.3624
Epoch 725/8000

Epoch 00725: val_loss did not improve from 11.13097
 - 76s - loss: 11.7253 - val_loss: 11.6347
Epoch 726/8000

Epoch 00726: val_loss did not improve from 11.13097
 - 76s - loss: 11.6747 - val_loss: 11.7695
Epoch 727/8000

Epoch 00727: val_loss did not improve from 11.13097
 - 76s - loss: 11.6132 - val_loss: 11.9650
Epoch 728/8000

Epoch 00728: val_loss did not improve from 11.13097
 - 76s - loss: 11.3152 - val_loss: 11.8495
Epoch 729/8000

Epoch 00729: val_loss did not improve from 11.13097
 - 75s - loss: 11.5600 - val_loss: 11.8155
Epoch 730/8000

Epoch 00730: val_loss did not improve from 11.13097
 - 76s - loss: 11.4118 - val_loss: 11.6784
Epoch 731/8000

Epoch 00731: val_loss did not improve from 11.13097
 - 75s - loss: 11.6209 - val_loss: 12.0413
Epoch 732/8000

Epoch 00732: val_loss did not improve from 11.13097
 - 76s - loss: 11.7168 - val_loss: 12.0578
Epoch 733/8000

Epoch 00733: val_loss did not improve from 11.13097
 - 76s - loss: 12.2239 - val_loss: 12.5242
Epoch 734/8000

Epoch 00734: val_loss did not improve from 11.13097
 - 76s - loss: 11.9830 - val_loss: 11.8430
Epoch 735/8000

Epoch 00735: val_loss did not improve from 11.13097
 - 76s - loss: 11.5741 - val_loss: 11.6988
Epoch 736/8000

Epoch 00736: val_loss did not improve from 11.13097
 - 75s - loss: 11.8366 - val_loss: 11.9635
Epoch 737/8000

Epoch 00737: val_loss did not improve from 11.13097
 - 75s - loss: 11.7692 - val_loss: 12.3157
Epoch 738/8000

Epoch 00738: val_loss did not improve from 11.13097
 - 75s - loss: 11.6863 - val_loss: 12.3911
Epoch 739/8000

Epoch 00739: val_loss did not improve from 11.13097
 - 76s - loss: 11.3695 - val_loss: 12.1540
Epoch 740/8000

Epoch 00740: val_loss did not improve from 11.13097
 - 76s - loss: 11.5029 - val_loss: 12.0106
Epoch 741/8000

Epoch 00741: val_loss did not improve from 11.13097
 - 76s - loss: 11.5746 - val_loss: 12.0883
Epoch 742/8000

Epoch 00742: val_loss did not improve from 11.13097
 - 76s - loss: 11.5894 - val_loss: 11.8986
Epoch 743/8000

Epoch 00743: val_loss did not improve from 11.13097
 - 75s - loss: 12.8826 - val_loss: 13.2772
Epoch 744/8000

Epoch 00744: val_loss did not improve from 11.13097
 - 76s - loss: 12.6942 - val_loss: 12.9878
Epoch 745/8000

Epoch 00745: val_loss did not improve from 11.13097
 - 75s - loss: 11.8741 - val_loss: 11.8709
Epoch 746/8000

Epoch 00746: val_loss did not improve from 11.13097
 - 76s - loss: 11.4752 - val_loss: 12.0021
Epoch 747/8000

Epoch 00747: val_loss did not improve from 11.13097
 - 76s - loss: 11.5874 - val_loss: 12.4509
Epoch 748/8000

Epoch 00748: val_loss did not improve from 11.13097
 - 76s - loss: 11.6029 - val_loss: 12.5721
Epoch 749/8000

Epoch 00749: val_loss did not improve from 11.13097
 - 76s - loss: 11.8473 - val_loss: 12.5428
Epoch 750/8000

Epoch 00750: val_loss did not improve from 11.13097
 - 75s - loss: 12.0048 - val_loss: 12.4181
Epoch 751/8000

Epoch 00751: val_loss did not improve from 11.13097
 - 76s - loss: 11.6956 - val_loss: 11.9846
Epoch 752/8000

Epoch 00752: val_loss did not improve from 11.13097
 - 75s - loss: 11.5533 - val_loss: 11.6492
Epoch 753/8000

Epoch 00753: val_loss did not improve from 11.13097
 - 76s - loss: 11.7084 - val_loss: 11.9223
Epoch 754/8000

Epoch 00754: val_loss did not improve from 11.13097
 - 76s - loss: 11.6035 - val_loss: 11.6730
Epoch 755/8000

Epoch 00755: val_loss did not improve from 11.13097
 - 76s - loss: 11.4143 - val_loss: 11.7836
Epoch 756/8000

Epoch 00756: val_loss did not improve from 11.13097
 - 76s - loss: 11.2934 - val_loss: 11.8946
Epoch 757/8000

Epoch 00757: val_loss did not improve from 11.13097
 - 75s - loss: 11.4114 - val_loss: 11.8385
Epoch 758/8000

Epoch 00758: val_loss did not improve from 11.13097
 - 76s - loss: 11.1418 - val_loss: 11.6250
Epoch 759/8000

Epoch 00759: val_loss did not improve from 11.13097
 - 76s - loss: 11.2055 - val_loss: 11.8756
Epoch 760/8000

Epoch 00760: val_loss did not improve from 11.13097
 - 76s - loss: 11.2736 - val_loss: 11.5382
Epoch 761/8000

Epoch 00761: val_loss did not improve from 11.13097
 - 76s - loss: 12.3032 - val_loss: 12.9965
Epoch 762/8000

Epoch 00762: val_loss did not improve from 11.13097
 - 76s - loss: 12.3441 - val_loss: 12.1387
Epoch 763/8000

Epoch 00763: val_loss did not improve from 11.13097
 - 75s - loss: 12.2028 - val_loss: 12.7413
Epoch 764/8000

Epoch 00764: val_loss did not improve from 11.13097
 - 75s - loss: 12.3460 - val_loss: 12.4255
Epoch 765/8000

Epoch 00765: val_loss did not improve from 11.13097
 - 76s - loss: 12.0775 - val_loss: 12.2628
Epoch 766/8000

Epoch 00766: val_loss did not improve from 11.13097
 - 75s - loss: 11.7954 - val_loss: 12.1760
Epoch 767/8000

Epoch 00767: val_loss did not improve from 11.13097
 - 76s - loss: 11.7931 - val_loss: 12.0908
Epoch 768/8000

Epoch 00768: val_loss did not improve from 11.13097
 - 76s - loss: 11.4893 - val_loss: 12.2816
Epoch 769/8000

Epoch 00769: val_loss did not improve from 11.13097
 - 76s - loss: 11.5721 - val_loss: 11.5423
Epoch 770/8000

Epoch 00770: val_loss did not improve from 11.13097
 - 76s - loss: 11.4626 - val_loss: 11.5566
Epoch 771/8000

Epoch 00771: val_loss did not improve from 11.13097
 - 75s - loss: 11.1397 - val_loss: 11.6237
Epoch 772/8000

Epoch 00772: val_loss did not improve from 11.13097
 - 76s - loss: 11.3106 - val_loss: 11.4992
Epoch 773/8000

Epoch 00773: val_loss did not improve from 11.13097
 - 75s - loss: 11.2655 - val_loss: 11.7992
Epoch 774/8000

Epoch 00774: val_loss did not improve from 11.13097
 - 76s - loss: 11.3317 - val_loss: 11.4756
Epoch 775/8000

Epoch 00775: val_loss did not improve from 11.13097
 - 76s - loss: 11.1828 - val_loss: 11.9018
Epoch 776/8000

Epoch 00776: val_loss did not improve from 11.13097
 - 76s - loss: 11.2623 - val_loss: 11.6285
Epoch 777/8000

Epoch 00777: val_loss did not improve from 11.13097
 - 76s - loss: 10.9208 - val_loss: 11.7693
Epoch 778/8000

Epoch 00778: val_loss did not improve from 11.13097
 - 75s - loss: 10.9962 - val_loss: 11.6158
Epoch 779/8000

Epoch 00779: val_loss did not improve from 11.13097
 - 75s - loss: 11.0006 - val_loss: 11.5070
Epoch 780/8000

Epoch 00780: val_loss did not improve from 11.13097
 - 75s - loss: 11.0819 - val_loss: 11.5129
Epoch 781/8000

Epoch 00781: val_loss did not improve from 11.13097
 - 75s - loss: 11.0074 - val_loss: 12.0686
Epoch 782/8000

Epoch 00782: val_loss did not improve from 11.13097
 - 75s - loss: 11.5424 - val_loss: 11.8033
Epoch 783/8000

Epoch 00783: val_loss did not improve from 11.13097
 - 76s - loss: 11.1571 - val_loss: 11.3925
Epoch 784/8000

Epoch 00784: val_loss did not improve from 11.13097
 - 76s - loss: 11.3446 - val_loss: 12.1669
Epoch 785/8000

Epoch 00785: val_loss did not improve from 11.13097
 - 75s - loss: 11.1978 - val_loss: 11.6408
Epoch 786/8000

Epoch 00786: val_loss did not improve from 11.13097
 - 76s - loss: 11.1679 - val_loss: 11.5970
Epoch 787/8000

Epoch 00787: val_loss did not improve from 11.13097
 - 75s - loss: 11.1974 - val_loss: 12.0239
Epoch 788/8000

Epoch 00788: val_loss did not improve from 11.13097
 - 76s - loss: 11.0868 - val_loss: 11.4556
Epoch 789/8000

Epoch 00789: val_loss did not improve from 11.13097
 - 76s - loss: 11.0325 - val_loss: 11.5051
Epoch 790/8000

Epoch 00790: val_loss did not improve from 11.13097
 - 76s - loss: 10.8467 - val_loss: 12.2047
Epoch 791/8000

Epoch 00791: val_loss did not improve from 11.13097
 - 76s - loss: 11.4982 - val_loss: 13.6938
Epoch 792/8000

Epoch 00792: val_loss did not improve from 11.13097
 - 75s - loss: 12.6129 - val_loss: 12.5147
Epoch 793/8000

Epoch 00793: val_loss did not improve from 11.13097
 - 76s - loss: 11.5933 - val_loss: 12.0965
Epoch 794/8000

Epoch 00794: val_loss did not improve from 11.13097
 - 75s - loss: 11.6701 - val_loss: 11.6371
Epoch 795/8000

Epoch 00795: val_loss did not improve from 11.13097
 - 76s - loss: 10.9704 - val_loss: 11.9272
Epoch 796/8000

Epoch 00796: val_loss did not improve from 11.13097
 - 76s - loss: 10.9730 - val_loss: 11.2953
Epoch 797/8000

Epoch 00797: val_loss did not improve from 11.13097
 - 76s - loss: 11.0230 - val_loss: 12.0833
Epoch 798/8000

Epoch 00798: val_loss did not improve from 11.13097
 - 76s - loss: 11.1614 - val_loss: 11.4405
Epoch 799/8000

Epoch 00799: val_loss did not improve from 11.13097
 - 75s - loss: 11.0455 - val_loss: 12.1349
Epoch 800/8000

Epoch 00800: val_loss did not improve from 11.13097
 - 76s - loss: 11.6037 - val_loss: 13.5599
Epoch 801/8000

Epoch 00801: val_loss did not improve from 11.13097
 - 75s - loss: 12.1358 - val_loss: 12.8978
Epoch 802/8000

Epoch 00802: val_loss did not improve from 11.13097
 - 76s - loss: 11.4436 - val_loss: 11.7327
Epoch 803/8000

Epoch 00803: val_loss did not improve from 11.13097
 - 76s - loss: 11.1184 - val_loss: 11.3632
Epoch 804/8000

Epoch 00804: val_loss did not improve from 11.13097
 - 76s - loss: 11.1957 - val_loss: 11.5853
Epoch 805/8000

Epoch 00805: val_loss did not improve from 11.13097
 - 76s - loss: 11.0148 - val_loss: 11.7835
Epoch 806/8000

Epoch 00806: val_loss did not improve from 11.13097
 - 75s - loss: 10.9649 - val_loss: 11.3863
Epoch 807/8000

Epoch 00807: val_loss did not improve from 11.13097
 - 76s - loss: 10.8833 - val_loss: 11.5785
Epoch 808/8000

Epoch 00808: val_loss did not improve from 11.13097
 - 75s - loss: 11.0031 - val_loss: 11.4461
Epoch 809/8000

Epoch 00809: val_loss did not improve from 11.13097
 - 76s - loss: 11.1328 - val_loss: 11.6093
Epoch 810/8000

Epoch 00810: val_loss did not improve from 11.13097
 - 76s - loss: 11.1260 - val_loss: 11.5580
Epoch 811/8000

Epoch 00811: val_loss did not improve from 11.13097
 - 76s - loss: 11.0075 - val_loss: 11.4752
Epoch 812/8000

Epoch 00812: val_loss did not improve from 11.13097
 - 76s - loss: 10.8758 - val_loss: 11.7581
Epoch 813/8000

Epoch 00813: val_loss did not improve from 11.13097
 - 75s - loss: 11.1063 - val_loss: 11.8188
Epoch 814/8000

Epoch 00814: val_loss did not improve from 11.13097
 - 76s - loss: 10.7531 - val_loss: 11.8807
Epoch 815/8000

Epoch 00815: val_loss did not improve from 11.13097
 - 75s - loss: 11.0791 - val_loss: 11.6563
Epoch 816/8000

Epoch 00816: val_loss did not improve from 11.13097
 - 76s - loss: 10.8691 - val_loss: 11.8029
Epoch 817/8000

Epoch 00817: val_loss did not improve from 11.13097
 - 76s - loss: 11.1174 - val_loss: 12.5833
Epoch 818/8000

Epoch 00818: val_loss did not improve from 11.13097
 - 76s - loss: 11.3511 - val_loss: 11.5159
Epoch 819/8000

Epoch 00819: val_loss did not improve from 11.13097
 - 76s - loss: 11.6993 - val_loss: 12.4458
Epoch 820/8000

Epoch 00820: val_loss did not improve from 11.13097
 - 75s - loss: 11.5350 - val_loss: 12.0516
Epoch 821/8000

Epoch 00821: val_loss did not improve from 11.13097
 - 76s - loss: 11.1533 - val_loss: 11.4954
Epoch 822/8000

Epoch 00822: val_loss did not improve from 11.13097
 - 76s - loss: 10.7808 - val_loss: 11.6036
Epoch 823/8000

Epoch 00823: val_loss did not improve from 11.13097
 - 76s - loss: 10.9786 - val_loss: 11.2175
Epoch 824/8000

Epoch 00824: val_loss did not improve from 11.13097
 - 76s - loss: 10.8879 - val_loss: 11.6210
Epoch 825/8000

Epoch 00825: val_loss did not improve from 11.13097
 - 76s - loss: 10.5532 - val_loss: 11.3346
Epoch 826/8000

Epoch 00826: val_loss did not improve from 11.13097
 - 76s - loss: 10.8091 - val_loss: 11.3465
Epoch 827/8000

Epoch 00827: val_loss did not improve from 11.13097
 - 75s - loss: 10.6744 - val_loss: 11.5541
Epoch 828/8000

Epoch 00828: val_loss did not improve from 11.13097
 - 76s - loss: 10.6711 - val_loss: 11.1579
Epoch 829/8000

Epoch 00829: val_loss did not improve from 11.13097
 - 75s - loss: 10.6724 - val_loss: 11.2617
Epoch 830/8000

Epoch 00830: val_loss improved from 11.13097 to 11.11506, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 10.6132 - val_loss: 11.1151
Epoch 831/8000

Epoch 00831: val_loss did not improve from 11.11506
 - 76s - loss: 10.5713 - val_loss: 11.3902
Epoch 832/8000

Epoch 00832: val_loss did not improve from 11.11506
 - 76s - loss: 10.7069 - val_loss: 11.5760
Epoch 833/8000

Epoch 00833: val_loss did not improve from 11.11506
 - 76s - loss: 10.9351 - val_loss: 11.3084
Epoch 834/8000

Epoch 00834: val_loss did not improve from 11.11506
 - 75s - loss: 10.7901 - val_loss: 11.8471
Epoch 835/8000

Epoch 00835: val_loss did not improve from 11.11506
 - 76s - loss: 10.8731 - val_loss: 12.0516
Epoch 836/8000

Epoch 00836: val_loss did not improve from 11.11506
 - 76s - loss: 10.7476 - val_loss: 11.3369
Epoch 837/8000

Epoch 00837: val_loss did not improve from 11.11506
 - 76s - loss: 11.0799 - val_loss: 11.9098
Epoch 838/8000

Epoch 00838: val_loss did not improve from 11.11506
 - 76s - loss: 10.8742 - val_loss: 11.1729
Epoch 839/8000

Epoch 00839: val_loss did not improve from 11.11506
 - 76s - loss: 10.8484 - val_loss: 11.4724
Epoch 840/8000

Epoch 00840: val_loss did not improve from 11.11506
 - 76s - loss: 10.7936 - val_loss: 11.6109
Epoch 841/8000

Epoch 00841: val_loss did not improve from 11.11506
 - 75s - loss: 10.6690 - val_loss: 11.6565
Epoch 842/8000

Epoch 00842: val_loss did not improve from 11.11506
 - 76s - loss: 10.6077 - val_loss: 11.2588
Epoch 843/8000

Epoch 00843: val_loss did not improve from 11.11506
 - 75s - loss: 10.4733 - val_loss: 11.2822
Epoch 844/8000

Epoch 00844: val_loss did not improve from 11.11506
 - 76s - loss: 11.0380 - val_loss: 11.7681
Epoch 845/8000

Epoch 00845: val_loss improved from 11.11506 to 11.02259, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 10.5547 - val_loss: 11.0226
Epoch 846/8000

Epoch 00846: val_loss did not improve from 11.02259
 - 76s - loss: 10.7191 - val_loss: 11.2558
Epoch 847/8000

Epoch 00847: val_loss did not improve from 11.02259
 - 76s - loss: 10.8736 - val_loss: 11.5643
Epoch 848/8000

Epoch 00848: val_loss did not improve from 11.02259
 - 75s - loss: 10.6377 - val_loss: 11.0802
Epoch 849/8000

Epoch 00849: val_loss did not improve from 11.02259
 - 76s - loss: 10.3889 - val_loss: 11.9272
Epoch 850/8000

Epoch 00850: val_loss did not improve from 11.02259
 - 75s - loss: 10.7270 - val_loss: 11.1347
Epoch 851/8000

Epoch 00851: val_loss did not improve from 11.02259
 - 76s - loss: 10.5048 - val_loss: 11.0315
Epoch 852/8000

Epoch 00852: val_loss did not improve from 11.02259
 - 76s - loss: 10.5318 - val_loss: 11.3096
Epoch 853/8000

Epoch 00853: val_loss did not improve from 11.02259
 - 76s - loss: 10.6328 - val_loss: 11.1595
Epoch 854/8000

Epoch 00854: val_loss did not improve from 11.02259
 - 76s - loss: 10.8667 - val_loss: 11.4272
Epoch 855/8000

Epoch 00855: val_loss did not improve from 11.02259
 - 75s - loss: 10.4441 - val_loss: 11.3245
Epoch 856/8000

Epoch 00856: val_loss did not improve from 11.02259
 - 76s - loss: 10.6912 - val_loss: 11.4631
Epoch 857/8000

Epoch 00857: val_loss did not improve from 11.02259
 - 75s - loss: 10.3888 - val_loss: 11.1526
Epoch 858/8000

Epoch 00858: val_loss did not improve from 11.02259
 - 76s - loss: 10.7000 - val_loss: 11.2132
Epoch 859/8000

Epoch 00859: val_loss did not improve from 11.02259
 - 76s - loss: 10.4694 - val_loss: 11.4522
Epoch 860/8000

Epoch 00860: val_loss did not improve from 11.02259
 - 76s - loss: 10.7625 - val_loss: 12.2980
Epoch 861/8000

Epoch 00861: val_loss did not improve from 11.02259
 - 76s - loss: 11.6108 - val_loss: 11.5719
Epoch 862/8000

Epoch 00862: val_loss did not improve from 11.02259
 - 75s - loss: 11.8829 - val_loss: 13.4111
Epoch 863/8000

Epoch 00863: val_loss did not improve from 11.02259
 - 76s - loss: 12.2236 - val_loss: 12.3520
Epoch 864/8000

Epoch 00864: val_loss did not improve from 11.02259
 - 75s - loss: 11.5976 - val_loss: 11.7943
Epoch 865/8000

Epoch 00865: val_loss did not improve from 11.02259
 - 76s - loss: 11.0343 - val_loss: 11.5200
Epoch 866/8000

Epoch 00866: val_loss did not improve from 11.02259
 - 76s - loss: 10.5956 - val_loss: 11.4213
Epoch 867/8000

Epoch 00867: val_loss did not improve from 11.02259
 - 76s - loss: 10.9117 - val_loss: 11.3441
Epoch 868/8000

Epoch 00868: val_loss did not improve from 11.02259
 - 76s - loss: 10.9303 - val_loss: 11.5019
Epoch 869/8000

Epoch 00869: val_loss did not improve from 11.02259
 - 75s - loss: 10.7859 - val_loss: 11.5155
Epoch 870/8000

Epoch 00870: val_loss did not improve from 11.02259
 - 76s - loss: 10.5071 - val_loss: 11.4747
Epoch 871/8000

Epoch 00871: val_loss did not improve from 11.02259
 - 75s - loss: 10.9138 - val_loss: 11.6663
Epoch 872/8000

Epoch 00872: val_loss did not improve from 11.02259
 - 76s - loss: 10.6920 - val_loss: 11.5998
Epoch 873/8000

Epoch 00873: val_loss did not improve from 11.02259
 - 76s - loss: 10.8094 - val_loss: 11.3831
Epoch 874/8000

Epoch 00874: val_loss did not improve from 11.02259
 - 76s - loss: 10.6041 - val_loss: 11.2502
Epoch 875/8000

Epoch 00875: val_loss did not improve from 11.02259
 - 76s - loss: 10.5782 - val_loss: 11.6625
Epoch 876/8000

Epoch 00876: val_loss did not improve from 11.02259
 - 75s - loss: 10.4798 - val_loss: 11.4866
Epoch 877/8000

Epoch 00877: val_loss did not improve from 11.02259
 - 76s - loss: 10.5539 - val_loss: 11.3489
Epoch 878/8000

Epoch 00878: val_loss did not improve from 11.02259
 - 75s - loss: 10.5050 - val_loss: 11.3112
Epoch 879/8000

Epoch 00879: val_loss did not improve from 11.02259
 - 76s - loss: 10.3898 - val_loss: 11.6863
Epoch 880/8000

Epoch 00880: val_loss did not improve from 11.02259
 - 76s - loss: 10.5996 - val_loss: 11.6264
Epoch 881/8000

Epoch 00881: val_loss did not improve from 11.02259
 - 76s - loss: 10.5779 - val_loss: 11.3697
Epoch 882/8000

Epoch 00882: val_loss did not improve from 11.02259
 - 76s - loss: 10.7516 - val_loss: 11.1707
Epoch 883/8000

Epoch 00883: val_loss did not improve from 11.02259
 - 75s - loss: 10.6064 - val_loss: 11.6637
Epoch 884/8000

Epoch 00884: val_loss did not improve from 11.02259
 - 76s - loss: 10.3505 - val_loss: 11.2256
Epoch 885/8000

Epoch 00885: val_loss did not improve from 11.02259
 - 75s - loss: 10.4862 - val_loss: 11.4381
Epoch 886/8000

Epoch 00886: val_loss did not improve from 11.02259
 - 75s - loss: 10.4202 - val_loss: 11.0771
Epoch 887/8000

Epoch 00887: val_loss did not improve from 11.02259
 - 75s - loss: 10.3773 - val_loss: 11.3567
Epoch 888/8000

Epoch 00888: val_loss did not improve from 11.02259
 - 75s - loss: 10.7433 - val_loss: 11.6695
Epoch 889/8000

Epoch 00889: val_loss did not improve from 11.02259
 - 76s - loss: 10.4982 - val_loss: 11.2269
Epoch 890/8000

Epoch 00890: val_loss did not improve from 11.02259
 - 75s - loss: 10.7204 - val_loss: 11.5253
Epoch 891/8000

Epoch 00891: val_loss did not improve from 11.02259
 - 76s - loss: 10.5755 - val_loss: 11.1843
Epoch 892/8000

Epoch 00892: val_loss did not improve from 11.02259
 - 75s - loss: 10.8237 - val_loss: 11.3226
Epoch 893/8000

Epoch 00893: val_loss improved from 11.02259 to 10.96244, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 10.4098 - val_loss: 10.9624
Epoch 894/8000

Epoch 00894: val_loss did not improve from 10.96244
 - 76s - loss: 10.2599 - val_loss: 11.6359
Epoch 895/8000

Epoch 00895: val_loss did not improve from 10.96244
 - 76s - loss: 10.2706 - val_loss: 11.1707
Epoch 896/8000

Epoch 00896: val_loss did not improve from 10.96244
 - 76s - loss: 10.1692 - val_loss: 11.2165
Epoch 897/8000

Epoch 00897: val_loss did not improve from 10.96244
 - 75s - loss: 10.4873 - val_loss: 11.2566
Epoch 898/8000

Epoch 00898: val_loss did not improve from 10.96244
 - 76s - loss: 10.5930 - val_loss: 11.0599
Epoch 899/8000

Epoch 00899: val_loss did not improve from 10.96244
 - 75s - loss: 10.4309 - val_loss: 11.1468
Epoch 900/8000

Epoch 00900: val_loss did not improve from 10.96244
 - 76s - loss: 10.4747 - val_loss: 11.6633
Epoch 901/8000

Epoch 00901: val_loss improved from 10.96244 to 10.95601, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 10.9464 - val_loss: 10.9560
Epoch 902/8000

Epoch 00902: val_loss did not improve from 10.95601
 - 76s - loss: 10.3050 - val_loss: 11.0597
Epoch 903/8000

Epoch 00903: val_loss did not improve from 10.95601
 - 76s - loss: 10.3894 - val_loss: 11.4925
Epoch 904/8000

Epoch 00904: val_loss did not improve from 10.95601
 - 75s - loss: 10.3490 - val_loss: 11.0376
Epoch 905/8000

Epoch 00905: val_loss did not improve from 10.95601
 - 75s - loss: 10.2060 - val_loss: 11.2689
Epoch 906/8000

Epoch 00906: val_loss did not improve from 10.95601
 - 75s - loss: 10.1598 - val_loss: 11.2564
Epoch 907/8000

Epoch 00907: val_loss did not improve from 10.95601
 - 76s - loss: 10.3096 - val_loss: 11.2784
Epoch 908/8000

Epoch 00908: val_loss did not improve from 10.95601
 - 76s - loss: 10.2653 - val_loss: 11.1171
Epoch 909/8000

Epoch 00909: val_loss did not improve from 10.95601
 - 76s - loss: 10.0302 - val_loss: 11.2638
Epoch 910/8000

Epoch 00910: val_loss did not improve from 10.95601
 - 76s - loss: 10.3275 - val_loss: 11.2805
Epoch 911/8000

Epoch 00911: val_loss did not improve from 10.95601
 - 75s - loss: 10.3433 - val_loss: 11.2534
Epoch 912/8000

Epoch 00912: val_loss did not improve from 10.95601
 - 76s - loss: 10.2761 - val_loss: 11.1244
Epoch 913/8000

Epoch 00913: val_loss did not improve from 10.95601
 - 75s - loss: 10.1624 - val_loss: 11.2758
Epoch 914/8000

Epoch 00914: val_loss did not improve from 10.95601
 - 76s - loss: 10.1826 - val_loss: 11.1360
Epoch 915/8000

Epoch 00915: val_loss did not improve from 10.95601
 - 76s - loss: 10.1002 - val_loss: 12.0212
Epoch 916/8000

Epoch 00916: val_loss did not improve from 10.95601
 - 76s - loss: 10.3798 - val_loss: 11.1119
Epoch 917/8000

Epoch 00917: val_loss did not improve from 10.95601
 - 76s - loss: 10.2458 - val_loss: 11.5509
Epoch 918/8000

Epoch 00918: val_loss did not improve from 10.95601
 - 75s - loss: 10.5304 - val_loss: 11.1668
Epoch 919/8000

Epoch 00919: val_loss did not improve from 10.95601
 - 76s - loss: 10.4332 - val_loss: 11.1872
Epoch 920/8000

Epoch 00920: val_loss did not improve from 10.95601
 - 75s - loss: 10.1556 - val_loss: 11.1184
Epoch 921/8000

Epoch 00921: val_loss did not improve from 10.95601
 - 76s - loss: 10.3719 - val_loss: 10.9691
Epoch 922/8000

Epoch 00922: val_loss did not improve from 10.95601
 - 76s - loss: 10.1104 - val_loss: 11.4311
Epoch 923/8000

Epoch 00923: val_loss did not improve from 10.95601
 - 76s - loss: 10.2891 - val_loss: 10.9825
Epoch 924/8000

Epoch 00924: val_loss did not improve from 10.95601
 - 76s - loss: 10.3831 - val_loss: 11.8762
Epoch 925/8000

Epoch 00925: val_loss did not improve from 10.95601
 - 75s - loss: 10.3098 - val_loss: 11.3565
Epoch 926/8000

Epoch 00926: val_loss did not improve from 10.95601
 - 76s - loss: 10.2119 - val_loss: 11.3637
Epoch 927/8000

Epoch 00927: val_loss did not improve from 10.95601
 - 75s - loss: 10.2830 - val_loss: 11.1152
Epoch 928/8000

Epoch 00928: val_loss did not improve from 10.95601
 - 76s - loss: 10.6020 - val_loss: 11.5091
Epoch 929/8000

Epoch 00929: val_loss did not improve from 10.95601
 - 76s - loss: 10.3778 - val_loss: 11.3505
Epoch 930/8000

Epoch 00930: val_loss did not improve from 10.95601
 - 76s - loss: 10.2147 - val_loss: 11.1042
Epoch 931/8000

Epoch 00931: val_loss did not improve from 10.95601
 - 76s - loss: 10.2111 - val_loss: 11.1932
Epoch 932/8000

Epoch 00932: val_loss did not improve from 10.95601
 - 75s - loss: 10.1698 - val_loss: 11.2003
Epoch 933/8000

Epoch 00933: val_loss did not improve from 10.95601
 - 76s - loss: 10.6495 - val_loss: 11.0744
Epoch 934/8000

Epoch 00934: val_loss did not improve from 10.95601
 - 75s - loss: 10.2083 - val_loss: 11.2282
Epoch 935/8000

Epoch 00935: val_loss did not improve from 10.95601
 - 76s - loss: 10.4527 - val_loss: 11.2051
Epoch 936/8000

Epoch 00936: val_loss did not improve from 10.95601
 - 76s - loss: 10.3883 - val_loss: 11.7793
Epoch 937/8000

Epoch 00937: val_loss did not improve from 10.95601
 - 76s - loss: 10.5791 - val_loss: 11.2724
Epoch 938/8000

Epoch 00938: val_loss did not improve from 10.95601
 - 76s - loss: 10.2194 - val_loss: 11.3570
Epoch 939/8000

Epoch 00939: val_loss did not improve from 10.95601
 - 75s - loss: 10.0596 - val_loss: 11.5983
Epoch 940/8000

Epoch 00940: val_loss did not improve from 10.95601
 - 76s - loss: 10.0831 - val_loss: 11.2635
Epoch 941/8000

Epoch 00941: val_loss did not improve from 10.95601
 - 75s - loss: 10.0580 - val_loss: 11.5493
Epoch 942/8000

Epoch 00942: val_loss did not improve from 10.95601
 - 76s - loss: 10.3883 - val_loss: 11.1430
Epoch 943/8000

Epoch 00943: val_loss did not improve from 10.95601
 - 76s - loss: 10.2938 - val_loss: 11.0141
Epoch 944/8000

Epoch 00944: val_loss did not improve from 10.95601
 - 76s - loss: 10.0303 - val_loss: 11.0067
Epoch 945/8000

Epoch 00945: val_loss did not improve from 10.95601
 - 76s - loss: 10.2801 - val_loss: 11.1999
Epoch 946/8000

Epoch 00946: val_loss did not improve from 10.95601
 - 75s - loss: 10.1413 - val_loss: 11.3450
Epoch 947/8000

Epoch 00947: val_loss did not improve from 10.95601
 - 76s - loss: 10.4401 - val_loss: 11.1946
Epoch 948/8000

Epoch 00948: val_loss did not improve from 10.95601
 - 75s - loss: 10.2245 - val_loss: 11.2300
Epoch 949/8000

Epoch 00949: val_loss did not improve from 10.95601
 - 76s - loss: 9.9520 - val_loss: 11.2568
Epoch 950/8000

Epoch 00950: val_loss did not improve from 10.95601
 - 76s - loss: 9.9567 - val_loss: 11.1983
Epoch 951/8000

Epoch 00951: val_loss did not improve from 10.95601
 - 76s - loss: 9.9076 - val_loss: 11.1530
Epoch 952/8000

Epoch 00952: val_loss did not improve from 10.95601
 - 76s - loss: 9.8904 - val_loss: 11.0572
Epoch 953/8000

Epoch 00953: val_loss did not improve from 10.95601
 - 75s - loss: 10.7776 - val_loss: 11.6869
Epoch 954/8000

Epoch 00954: val_loss did not improve from 10.95601
 - 76s - loss: 10.6868 - val_loss: 11.2817
Epoch 955/8000

Epoch 00955: val_loss did not improve from 10.95601
 - 75s - loss: 10.1997 - val_loss: 11.1406
Epoch 956/8000

Epoch 00956: val_loss did not improve from 10.95601
 - 76s - loss: 9.9726 - val_loss: 11.0027
Epoch 957/8000

Epoch 00957: val_loss did not improve from 10.95601
 - 76s - loss: 10.1931 - val_loss: 12.0983
Epoch 958/8000

Epoch 00958: val_loss did not improve from 10.95601
 - 76s - loss: 10.4877 - val_loss: 11.0004
Epoch 959/8000

Epoch 00959: val_loss did not improve from 10.95601
 - 76s - loss: 10.1208 - val_loss: 11.1475
Epoch 960/8000

Epoch 00960: val_loss did not improve from 10.95601
 - 75s - loss: 10.4562 - val_loss: 11.7808
Epoch 961/8000

Epoch 00961: val_loss did not improve from 10.95601
 - 76s - loss: 10.3476 - val_loss: 11.4151
Epoch 962/8000

Epoch 00962: val_loss did not improve from 10.95601
 - 75s - loss: 10.4041 - val_loss: 11.1821
Epoch 963/8000

Epoch 00963: val_loss did not improve from 10.95601
 - 76s - loss: 10.0864 - val_loss: 11.7594
Epoch 964/8000

Epoch 00964: val_loss improved from 10.95601 to 10.94801, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 10.1554 - val_loss: 10.9480
Epoch 965/8000

Epoch 00965: val_loss did not improve from 10.94801
 - 76s - loss: 9.9690 - val_loss: 10.9601
Epoch 966/8000

Epoch 00966: val_loss improved from 10.94801 to 10.83189, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 10.0702 - val_loss: 10.8319
Epoch 967/8000

Epoch 00967: val_loss did not improve from 10.83189
 - 75s - loss: 9.9673 - val_loss: 11.0660
Epoch 968/8000

Epoch 00968: val_loss did not improve from 10.83189
 - 76s - loss: 9.7449 - val_loss: 10.9149
Epoch 969/8000

Epoch 00969: val_loss did not improve from 10.83189
 - 75s - loss: 9.9526 - val_loss: 11.0248
Epoch 970/8000

Epoch 00970: val_loss did not improve from 10.83189
 - 76s - loss: 10.0474 - val_loss: 11.0194
Epoch 971/8000

Epoch 00971: val_loss did not improve from 10.83189
 - 76s - loss: 10.0748 - val_loss: 11.0852
Epoch 972/8000

Epoch 00972: val_loss did not improve from 10.83189
 - 76s - loss: 9.7791 - val_loss: 10.8902
Epoch 973/8000

Epoch 00973: val_loss improved from 10.83189 to 10.72113, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 9.8745 - val_loss: 10.7211
Epoch 974/8000

Epoch 00974: val_loss improved from 10.72113 to 10.71775, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 9.8470 - val_loss: 10.7177
Epoch 975/8000

Epoch 00975: val_loss did not improve from 10.71775
 - 76s - loss: 9.9923 - val_loss: 11.2278
Epoch 976/8000

Epoch 00976: val_loss improved from 10.71775 to 10.69473, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 10.0901 - val_loss: 10.6947
Epoch 977/8000

Epoch 00977: val_loss did not improve from 10.69473
 - 75s - loss: 9.7726 - val_loss: 11.2112
Epoch 978/8000

Epoch 00978: val_loss did not improve from 10.69473
 - 76s - loss: 10.1133 - val_loss: 11.3773
Epoch 979/8000

Epoch 00979: val_loss did not improve from 10.69473
 - 76s - loss: 10.4298 - val_loss: 11.6129
Epoch 980/8000

Epoch 00980: val_loss did not improve from 10.69473
 - 76s - loss: 10.4787 - val_loss: 11.1629
Epoch 981/8000

Epoch 00981: val_loss did not improve from 10.69473
 - 75s - loss: 10.1430 - val_loss: 10.8778
Epoch 982/8000

Epoch 00982: val_loss did not improve from 10.69473
 - 76s - loss: 10.0085 - val_loss: 10.8660
Epoch 983/8000

Epoch 00983: val_loss did not improve from 10.69473
 - 75s - loss: 9.9530 - val_loss: 10.8015
Epoch 984/8000

Epoch 00984: val_loss did not improve from 10.69473
 - 76s - loss: 9.9681 - val_loss: 11.2999
Epoch 985/8000

Epoch 00985: val_loss did not improve from 10.69473
 - 76s - loss: 9.7341 - val_loss: 10.8704
Epoch 986/8000

Epoch 00986: val_loss did not improve from 10.69473
 - 76s - loss: 10.0990 - val_loss: 10.9543
Epoch 987/8000

Epoch 00987: val_loss did not improve from 10.69473
 - 76s - loss: 10.4616 - val_loss: 11.2920
Epoch 988/8000

Epoch 00988: val_loss did not improve from 10.69473
 - 75s - loss: 10.1277 - val_loss: 11.7640
Epoch 989/8000

Epoch 00989: val_loss did not improve from 10.69473
 - 76s - loss: 10.1081 - val_loss: 11.3977
Epoch 990/8000

Epoch 00990: val_loss did not improve from 10.69473
 - 75s - loss: 10.1671 - val_loss: 10.9732
Epoch 991/8000

Epoch 00991: val_loss did not improve from 10.69473
 - 76s - loss: 10.0263 - val_loss: 10.9296
Epoch 992/8000

Epoch 00992: val_loss did not improve from 10.69473
 - 76s - loss: 10.0928 - val_loss: 11.2401
Epoch 993/8000

Epoch 00993: val_loss did not improve from 10.69473
 - 76s - loss: 10.0217 - val_loss: 10.8631
Epoch 994/8000

Epoch 00994: val_loss did not improve from 10.69473
 - 76s - loss: 9.8511 - val_loss: 10.9576
Epoch 995/8000

Epoch 00995: val_loss did not improve from 10.69473
 - 75s - loss: 10.3351 - val_loss: 11.5749
Epoch 996/8000

Epoch 00996: val_loss did not improve from 10.69473
 - 75s - loss: 10.0899 - val_loss: 11.2615
Epoch 997/8000

Epoch 00997: val_loss improved from 10.69473 to 10.66061, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 9.7087 - val_loss: 10.6606
Epoch 998/8000

Epoch 00998: val_loss did not improve from 10.66061
 - 75s - loss: 9.7786 - val_loss: 10.9009
Epoch 999/8000

Epoch 00999: val_loss did not improve from 10.66061
 - 75s - loss: 9.9074 - val_loss: 11.0673
Epoch 1000/8000

Epoch 01000: val_loss did not improve from 10.66061
 - 75s - loss: 9.7804 - val_loss: 11.5200
Epoch 1001/8000

Epoch 01001: val_loss did not improve from 10.66061
 - 76s - loss: 9.8678 - val_loss: 10.7428
Epoch 1002/8000

Epoch 01002: val_loss did not improve from 10.66061
 - 75s - loss: 9.7695 - val_loss: 10.8482
Epoch 1003/8000

Epoch 01003: val_loss did not improve from 10.66061
 - 76s - loss: 9.6712 - val_loss: 10.7752
Epoch 1004/8000

Epoch 01004: val_loss did not improve from 10.66061
 - 75s - loss: 9.9826 - val_loss: 11.1226
Epoch 1005/8000

Epoch 01005: val_loss did not improve from 10.66061
 - 76s - loss: 9.8867 - val_loss: 11.1136
Epoch 1006/8000

Epoch 01006: val_loss did not improve from 10.66061
 - 76s - loss: 9.8767 - val_loss: 10.7500
Epoch 1007/8000

Epoch 01007: val_loss did not improve from 10.66061
 - 76s - loss: 9.5909 - val_loss: 10.7249
Epoch 1008/8000

Epoch 01008: val_loss did not improve from 10.66061
 - 76s - loss: 9.8124 - val_loss: 11.6429
Epoch 1009/8000

Epoch 01009: val_loss did not improve from 10.66061
 - 75s - loss: 9.7999 - val_loss: 11.1384
Epoch 1010/8000

Epoch 01010: val_loss did not improve from 10.66061
 - 76s - loss: 10.2425 - val_loss: 10.8149
Epoch 1011/8000

Epoch 01011: val_loss did not improve from 10.66061
 - 75s - loss: 10.0411 - val_loss: 11.1551
Epoch 1012/8000

Epoch 01012: val_loss did not improve from 10.66061
 - 76s - loss: 10.3960 - val_loss: 11.0099
Epoch 1013/8000

Epoch 01013: val_loss did not improve from 10.66061
 - 76s - loss: 9.7924 - val_loss: 10.8966
Epoch 1014/8000

Epoch 01014: val_loss did not improve from 10.66061
 - 76s - loss: 9.8647 - val_loss: 11.6427
Epoch 1015/8000

Epoch 01015: val_loss did not improve from 10.66061
 - 76s - loss: 10.1893 - val_loss: 11.1516
Epoch 1016/8000

Epoch 01016: val_loss did not improve from 10.66061
 - 75s - loss: 9.8157 - val_loss: 11.1784
Epoch 1017/8000

Epoch 01017: val_loss did not improve from 10.66061
 - 76s - loss: 9.8718 - val_loss: 10.9560
Epoch 1018/8000

Epoch 01018: val_loss did not improve from 10.66061
 - 75s - loss: 9.7885 - val_loss: 10.8773
Epoch 1019/8000

Epoch 01019: val_loss did not improve from 10.66061
 - 76s - loss: 10.0564 - val_loss: 11.8393
Epoch 1020/8000

Epoch 01020: val_loss did not improve from 10.66061
 - 76s - loss: 10.0247 - val_loss: 10.8337
Epoch 1021/8000

Epoch 01021: val_loss did not improve from 10.66061
 - 76s - loss: 9.7381 - val_loss: 10.9021
Epoch 1022/8000

Epoch 01022: val_loss did not improve from 10.66061
 - 76s - loss: 12.2504 - val_loss: 12.8256
Epoch 1023/8000

Epoch 01023: val_loss did not improve from 10.66061
 - 75s - loss: 11.1987 - val_loss: 10.7038
Epoch 1024/8000

Epoch 01024: val_loss did not improve from 10.66061
 - 76s - loss: 9.8564 - val_loss: 10.8988
Epoch 1025/8000

Epoch 01025: val_loss did not improve from 10.66061
 - 75s - loss: 9.7804 - val_loss: 10.8100
Epoch 1026/8000

Epoch 01026: val_loss improved from 10.66061 to 10.65626, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 9.8245 - val_loss: 10.6563
Epoch 1027/8000

Epoch 01027: val_loss did not improve from 10.65626
 - 76s - loss: 9.9329 - val_loss: 10.8047
Epoch 1028/8000

Epoch 01028: val_loss did not improve from 10.65626
 - 76s - loss: 11.5712 - val_loss: 12.1340
Epoch 1029/8000

Epoch 01029: val_loss did not improve from 10.65626
 - 76s - loss: 10.8843 - val_loss: 12.6025
Epoch 1030/8000

Epoch 01030: val_loss did not improve from 10.65626
 - 75s - loss: 11.0202 - val_loss: 11.4018
Epoch 1031/8000

Epoch 01031: val_loss did not improve from 10.65626
 - 76s - loss: 10.0405 - val_loss: 10.8333
Epoch 1032/8000

Epoch 01032: val_loss improved from 10.65626 to 10.61946, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 9.8902 - val_loss: 10.6195
Epoch 1033/8000

Epoch 01033: val_loss did not improve from 10.61946
 - 76s - loss: 9.8774 - val_loss: 11.0846
Epoch 1034/8000

Epoch 01034: val_loss did not improve from 10.61946
 - 76s - loss: 9.7736 - val_loss: 10.6414
Epoch 1035/8000

Epoch 01035: val_loss did not improve from 10.61946
 - 76s - loss: 9.6333 - val_loss: 11.4719
Epoch 1036/8000

Epoch 01036: val_loss did not improve from 10.61946
 - 76s - loss: 9.8236 - val_loss: 11.7424
Epoch 1037/8000

Epoch 01037: val_loss did not improve from 10.61946
 - 75s - loss: 9.9188 - val_loss: 10.8302
Epoch 1038/8000

Epoch 01038: val_loss improved from 10.61946 to 10.58345, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 9.7789 - val_loss: 10.5835
Epoch 1039/8000

Epoch 01039: val_loss did not improve from 10.58345
 - 76s - loss: 9.5031 - val_loss: 11.0649
Epoch 1040/8000

Epoch 01040: val_loss did not improve from 10.58345
 - 76s - loss: 9.6288 - val_loss: 10.8882
Epoch 1041/8000

Epoch 01041: val_loss improved from 10.58345 to 10.43213, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 9.7362 - val_loss: 10.4321
Epoch 1042/8000

Epoch 01042: val_loss did not improve from 10.43213
 - 76s - loss: 9.8357 - val_loss: 11.3065
Epoch 1043/8000

Epoch 01043: val_loss did not improve from 10.43213
 - 76s - loss: 9.9167 - val_loss: 10.6789
Epoch 1044/8000

Epoch 01044: val_loss did not improve from 10.43213
 - 75s - loss: 9.5465 - val_loss: 11.2221
Epoch 1045/8000

Epoch 01045: val_loss did not improve from 10.43213
 - 76s - loss: 9.6419 - val_loss: 11.2803
Epoch 1046/8000

Epoch 01046: val_loss did not improve from 10.43213
 - 75s - loss: 9.4750 - val_loss: 10.7105
Epoch 1047/8000

Epoch 01047: val_loss did not improve from 10.43213
 - 76s - loss: 9.4297 - val_loss: 11.7673
Epoch 1048/8000

Epoch 01048: val_loss did not improve from 10.43213
 - 76s - loss: 9.5976 - val_loss: 10.8416
Epoch 1049/8000

Epoch 01049: val_loss did not improve from 10.43213
 - 76s - loss: 9.8513 - val_loss: 11.0482
Epoch 1050/8000

Epoch 01050: val_loss did not improve from 10.43213
 - 76s - loss: 9.7038 - val_loss: 11.2542
Epoch 1051/8000

Epoch 01051: val_loss did not improve from 10.43213
 - 75s - loss: 9.9957 - val_loss: 11.4826
Epoch 1052/8000

Epoch 01052: val_loss did not improve from 10.43213
 - 76s - loss: 10.0417 - val_loss: 11.0874
Epoch 1053/8000

Epoch 01053: val_loss did not improve from 10.43213
 - 75s - loss: 9.7078 - val_loss: 10.9408
Epoch 1054/8000

Epoch 01054: val_loss did not improve from 10.43213
 - 76s - loss: 10.8463 - val_loss: 11.5030
Epoch 1055/8000

Epoch 01055: val_loss did not improve from 10.43213
 - 76s - loss: 10.4239 - val_loss: 10.9345
Epoch 1056/8000

Epoch 01056: val_loss did not improve from 10.43213
 - 76s - loss: 10.0240 - val_loss: 10.7148
Epoch 1057/8000

Epoch 01057: val_loss did not improve from 10.43213
 - 76s - loss: 9.6536 - val_loss: 10.5083
Epoch 1058/8000

Epoch 01058: val_loss did not improve from 10.43213
 - 75s - loss: 9.5352 - val_loss: 11.0740
Epoch 1059/8000

Epoch 01059: val_loss did not improve from 10.43213
 - 76s - loss: 9.3648 - val_loss: 11.8185
Epoch 1060/8000

Epoch 01060: val_loss did not improve from 10.43213
 - 75s - loss: 9.8139 - val_loss: 10.6444
Epoch 1061/8000

Epoch 01061: val_loss did not improve from 10.43213
 - 76s - loss: 9.5280 - val_loss: 10.9113
Epoch 1062/8000

Epoch 01062: val_loss did not improve from 10.43213
 - 76s - loss: 9.9179 - val_loss: 12.0477
Epoch 1063/8000

Epoch 01063: val_loss did not improve from 10.43213
 - 76s - loss: 9.8288 - val_loss: 10.7417
Epoch 1064/8000

Epoch 01064: val_loss did not improve from 10.43213
 - 76s - loss: 11.5730 - val_loss: 11.0430
Epoch 1065/8000

Epoch 01065: val_loss did not improve from 10.43213
 - 75s - loss: 10.0910 - val_loss: 10.7737
Epoch 1066/8000

Epoch 01066: val_loss did not improve from 10.43213
 - 76s - loss: 10.1850 - val_loss: 11.4016
Epoch 1067/8000

Epoch 01067: val_loss did not improve from 10.43213
 - 75s - loss: 10.1668 - val_loss: 11.1289
Epoch 1068/8000

Epoch 01068: val_loss did not improve from 10.43213
 - 76s - loss: 9.6142 - val_loss: 11.7893
Epoch 1069/8000

Epoch 01069: val_loss did not improve from 10.43213
 - 76s - loss: 9.9224 - val_loss: 10.9073
Epoch 1070/8000

Epoch 01070: val_loss did not improve from 10.43213
 - 76s - loss: 9.7403 - val_loss: 10.8668
Epoch 1071/8000

Epoch 01071: val_loss did not improve from 10.43213
 - 76s - loss: 9.6714 - val_loss: 11.1294
Epoch 1072/8000

Epoch 01072: val_loss did not improve from 10.43213
 - 75s - loss: 9.8874 - val_loss: 10.9273
Epoch 1073/8000

Epoch 01073: val_loss did not improve from 10.43213
 - 76s - loss: 9.7625 - val_loss: 10.6551
Epoch 1074/8000

Epoch 01074: val_loss did not improve from 10.43213
 - 75s - loss: 9.9413 - val_loss: 10.7832
Epoch 1075/8000

Epoch 01075: val_loss did not improve from 10.43213
 - 76s - loss: 9.5786 - val_loss: 10.7008
Epoch 1076/8000

Epoch 01076: val_loss did not improve from 10.43213
 - 76s - loss: 9.6008 - val_loss: 10.7275
Epoch 1077/8000

Epoch 01077: val_loss did not improve from 10.43213
 - 76s - loss: 9.6887 - val_loss: 10.8823
Epoch 1078/8000

Epoch 01078: val_loss did not improve from 10.43213
 - 76s - loss: 9.6449 - val_loss: 11.0746
Epoch 1079/8000

Epoch 01079: val_loss did not improve from 10.43213
 - 75s - loss: 10.0131 - val_loss: 11.7115
Epoch 1080/8000

Epoch 01080: val_loss did not improve from 10.43213
 - 76s - loss: 9.6323 - val_loss: 11.0077
Epoch 1081/8000

Epoch 01081: val_loss did not improve from 10.43213
 - 75s - loss: 9.6926 - val_loss: 10.8357
Epoch 1082/8000

Epoch 01082: val_loss did not improve from 10.43213
 - 76s - loss: 9.6105 - val_loss: 10.6663
Epoch 1083/8000

Epoch 01083: val_loss did not improve from 10.43213
 - 76s - loss: 9.4483 - val_loss: 10.6586
Epoch 1084/8000

Epoch 01084: val_loss did not improve from 10.43213
 - 76s - loss: 9.4997 - val_loss: 10.5744
Epoch 1085/8000

Epoch 01085: val_loss did not improve from 10.43213
 - 76s - loss: 9.6217 - val_loss: 10.9276
Epoch 1086/8000

Epoch 01086: val_loss did not improve from 10.43213
 - 75s - loss: 9.6138 - val_loss: 11.3466
Epoch 1087/8000

Epoch 01087: val_loss did not improve from 10.43213
 - 76s - loss: 9.6584 - val_loss: 10.9909
Epoch 1088/8000

Epoch 01088: val_loss did not improve from 10.43213
 - 75s - loss: 9.6632 - val_loss: 11.9188
Epoch 1089/8000

Epoch 01089: val_loss did not improve from 10.43213
 - 76s - loss: 10.1581 - val_loss: 11.0340
Epoch 1090/8000

Epoch 01090: val_loss did not improve from 10.43213
 - 76s - loss: 9.7032 - val_loss: 11.1819
Epoch 1091/8000

Epoch 01091: val_loss did not improve from 10.43213
 - 76s - loss: 9.8476 - val_loss: 11.1601
Epoch 1092/8000

Epoch 01092: val_loss did not improve from 10.43213
 - 76s - loss: 10.5131 - val_loss: 11.5404
Epoch 1093/8000

Epoch 01093: val_loss did not improve from 10.43213
 - 75s - loss: 10.9955 - val_loss: 11.9708
Epoch 1094/8000

Epoch 01094: val_loss did not improve from 10.43213
 - 76s - loss: 10.9901 - val_loss: 12.1105
Epoch 1095/8000

Epoch 01095: val_loss did not improve from 10.43213
 - 75s - loss: 10.6667 - val_loss: 11.0850
Epoch 1096/8000

Epoch 01096: val_loss did not improve from 10.43213
 - 76s - loss: 10.4156 - val_loss: 12.0538
Epoch 1097/8000

Epoch 01097: val_loss did not improve from 10.43213
 - 76s - loss: 10.2075 - val_loss: 11.2672
Epoch 1098/8000

Epoch 01098: val_loss did not improve from 10.43213
 - 76s - loss: 10.0456 - val_loss: 11.8615
Epoch 1099/8000

Epoch 01099: val_loss did not improve from 10.43213
 - 76s - loss: 9.9571 - val_loss: 11.4336
Epoch 1100/8000

Epoch 01100: val_loss did not improve from 10.43213
 - 75s - loss: 10.1111 - val_loss: 11.1214
Epoch 1101/8000

Epoch 01101: val_loss did not improve from 10.43213
 - 76s - loss: 10.4356 - val_loss: 11.6952
Epoch 1102/8000

Epoch 01102: val_loss did not improve from 10.43213
 - 75s - loss: 10.3620 - val_loss: 11.5070
Epoch 1103/8000

Epoch 01103: val_loss did not improve from 10.43213
 - 75s - loss: 10.3467 - val_loss: 11.5826
Epoch 1104/8000

Epoch 01104: val_loss did not improve from 10.43213
 - 75s - loss: 10.4895 - val_loss: 11.9365
Epoch 1105/8000

Epoch 01105: val_loss did not improve from 10.43213
 - 75s - loss: 10.4160 - val_loss: 11.1045
Epoch 1106/8000

Epoch 01106: val_loss did not improve from 10.43213
 - 75s - loss: 10.3877 - val_loss: 11.5895
Epoch 1107/8000

Epoch 01107: val_loss did not improve from 10.43213
 - 75s - loss: 10.2444 - val_loss: 11.5573
Epoch 1108/8000

Epoch 01108: val_loss did not improve from 10.43213
 - 76s - loss: 9.8242 - val_loss: 11.1569
Epoch 1109/8000

Epoch 01109: val_loss did not improve from 10.43213
 - 75s - loss: 10.1588 - val_loss: 11.4511
Epoch 1110/8000

Epoch 01110: val_loss did not improve from 10.43213
 - 76s - loss: 9.8718 - val_loss: 10.9784
Epoch 1111/8000

Epoch 01111: val_loss did not improve from 10.43213
 - 76s - loss: 9.8872 - val_loss: 11.6263
Epoch 1112/8000

Epoch 01112: val_loss did not improve from 10.43213
 - 76s - loss: 9.8067 - val_loss: 11.1332
Epoch 1113/8000

Epoch 01113: val_loss did not improve from 10.43213
 - 76s - loss: 10.0233 - val_loss: 11.5822
Epoch 1114/8000

Epoch 01114: val_loss did not improve from 10.43213
 - 75s - loss: 9.8744 - val_loss: 11.7395
Epoch 1115/8000

Epoch 01115: val_loss did not improve from 10.43213
 - 76s - loss: 10.4138 - val_loss: 11.5095
Epoch 1116/8000

Epoch 01116: val_loss did not improve from 10.43213
 - 75s - loss: 10.0287 - val_loss: 10.9046
Epoch 1117/8000

Epoch 01117: val_loss did not improve from 10.43213
 - 76s - loss: 10.0248 - val_loss: 11.7428
Epoch 1118/8000

Epoch 01118: val_loss did not improve from 10.43213
 - 76s - loss: 10.4298 - val_loss: 11.6063
Epoch 1119/8000

Epoch 01119: val_loss did not improve from 10.43213
 - 76s - loss: 10.3433 - val_loss: 11.8878
Epoch 1120/8000

Epoch 01120: val_loss did not improve from 10.43213
 - 76s - loss: 10.2505 - val_loss: 11.7002
Epoch 1121/8000

Epoch 01121: val_loss did not improve from 10.43213
 - 75s - loss: 10.2418 - val_loss: 11.4919
Epoch 1122/8000

Epoch 01122: val_loss did not improve from 10.43213
 - 76s - loss: 9.6457 - val_loss: 10.8620
Epoch 1123/8000

Epoch 01123: val_loss did not improve from 10.43213
 - 75s - loss: 10.0914 - val_loss: 10.9604
Epoch 1124/8000

Epoch 01124: val_loss did not improve from 10.43213
 - 75s - loss: 9.6140 - val_loss: 11.1200
Epoch 1125/8000

Epoch 01125: val_loss did not improve from 10.43213
 - 75s - loss: 9.9201 - val_loss: 10.9147
Epoch 1126/8000

Epoch 01126: val_loss did not improve from 10.43213
 - 76s - loss: 9.6817 - val_loss: 11.4025
Epoch 1127/8000

Epoch 01127: val_loss did not improve from 10.43213
 - 76s - loss: 9.9395 - val_loss: 10.9579
Epoch 1128/8000

Epoch 01128: val_loss did not improve from 10.43213
 - 75s - loss: 10.0481 - val_loss: 11.5293
Epoch 1129/8000

Epoch 01129: val_loss did not improve from 10.43213
 - 76s - loss: 9.9396 - val_loss: 11.9916
Epoch 1130/8000

Epoch 01130: val_loss did not improve from 10.43213
 - 75s - loss: 9.8826 - val_loss: 10.9864
Epoch 1131/8000

Epoch 01131: val_loss did not improve from 10.43213
 - 76s - loss: 9.9911 - val_loss: 12.1964
Epoch 1132/8000

Epoch 01132: val_loss did not improve from 10.43213
 - 76s - loss: 10.3302 - val_loss: 11.2383
Epoch 1133/8000

Epoch 01133: val_loss did not improve from 10.43213
 - 76s - loss: 10.0265 - val_loss: 11.0604
Epoch 1134/8000

Epoch 01134: val_loss did not improve from 10.43213
 - 76s - loss: 10.0635 - val_loss: 11.0603
Epoch 1135/8000

Epoch 01135: val_loss did not improve from 10.43213
 - 75s - loss: 10.0364 - val_loss: 10.8471
Epoch 1136/8000

Epoch 01136: val_loss did not improve from 10.43213
 - 76s - loss: 9.9465 - val_loss: 12.0131
Epoch 1137/8000

Epoch 01137: val_loss did not improve from 10.43213
 - 75s - loss: 9.9644 - val_loss: 11.4867
Epoch 1138/8000

Epoch 01138: val_loss did not improve from 10.43213
 - 75s - loss: 9.9422 - val_loss: 11.2527
Epoch 1139/8000

Epoch 01139: val_loss did not improve from 10.43213
 - 76s - loss: 10.1929 - val_loss: 11.3499
Epoch 1140/8000

Epoch 01140: val_loss did not improve from 10.43213
 - 76s - loss: 10.1239 - val_loss: 11.5829
Epoch 1141/8000

Epoch 01141: val_loss did not improve from 10.43213
 - 76s - loss: 10.1022 - val_loss: 11.4563
Epoch 1142/8000

Epoch 01142: val_loss did not improve from 10.43213
 - 75s - loss: 10.1435 - val_loss: 11.7955
Epoch 1143/8000

Epoch 01143: val_loss did not improve from 10.43213
 - 76s - loss: 10.2505 - val_loss: 11.4037
Epoch 1144/8000

Epoch 01144: val_loss did not improve from 10.43213
 - 75s - loss: 9.9823 - val_loss: 11.2184
Epoch 1145/8000

Epoch 01145: val_loss did not improve from 10.43213
 - 76s - loss: 10.3200 - val_loss: 12.3877
Epoch 1146/8000

Epoch 01146: val_loss did not improve from 10.43213
 - 76s - loss: 10.4768 - val_loss: 11.5699
Epoch 1147/8000

Epoch 01147: val_loss did not improve from 10.43213
 - 76s - loss: 9.9973 - val_loss: 10.9506
Epoch 1148/8000

Epoch 01148: val_loss did not improve from 10.43213
 - 76s - loss: 10.2804 - val_loss: 11.3951
Epoch 1149/8000

Epoch 01149: val_loss did not improve from 10.43213
 - 75s - loss: 10.3149 - val_loss: 11.2567
Epoch 1150/8000

Epoch 01150: val_loss did not improve from 10.43213
 - 76s - loss: 10.2425 - val_loss: 11.4025
Epoch 1151/8000

Epoch 01151: val_loss did not improve from 10.43213
 - 75s - loss: 9.9638 - val_loss: 11.2988
Epoch 1152/8000

Epoch 01152: val_loss did not improve from 10.43213
 - 76s - loss: 9.8147 - val_loss: 11.3286
Epoch 1153/8000

Epoch 01153: val_loss did not improve from 10.43213
 - 76s - loss: 10.1060 - val_loss: 11.2576
Epoch 1154/8000

Epoch 01154: val_loss did not improve from 10.43213
 - 76s - loss: 10.0040 - val_loss: 11.3013
Epoch 1155/8000

Epoch 01155: val_loss did not improve from 10.43213
 - 76s - loss: 9.9150 - val_loss: 10.9473
Epoch 1156/8000

Epoch 01156: val_loss did not improve from 10.43213
 - 75s - loss: 9.5926 - val_loss: 10.8206
Epoch 1157/8000

Epoch 01157: val_loss did not improve from 10.43213
 - 76s - loss: 9.6975 - val_loss: 10.7336
Epoch 1158/8000

Epoch 01158: val_loss did not improve from 10.43213
 - 75s - loss: 9.6880 - val_loss: 11.0754
Epoch 1159/8000

Epoch 01159: val_loss did not improve from 10.43213
 - 76s - loss: 9.9108 - val_loss: 11.4036
Epoch 1160/8000

Epoch 01160: val_loss did not improve from 10.43213
 - 76s - loss: 9.9516 - val_loss: 11.4231
Epoch 1161/8000

Epoch 01161: val_loss did not improve from 10.43213
 - 76s - loss: 9.7184 - val_loss: 12.1015
Epoch 1162/8000

Epoch 01162: val_loss did not improve from 10.43213
 - 76s - loss: 9.6385 - val_loss: 10.9743
Epoch 1163/8000

Epoch 01163: val_loss did not improve from 10.43213
 - 75s - loss: 11.1605 - val_loss: 11.8768
Epoch 1164/8000

Epoch 01164: val_loss did not improve from 10.43213
 - 76s - loss: 10.3899 - val_loss: 11.1384
Epoch 1165/8000

Epoch 01165: val_loss did not improve from 10.43213
 - 75s - loss: 9.8410 - val_loss: 11.4177
Epoch 1166/8000

Epoch 01166: val_loss did not improve from 10.43213
 - 75s - loss: 10.0099 - val_loss: 10.8201
Epoch 1167/8000

Epoch 01167: val_loss did not improve from 10.43213
 - 75s - loss: 9.8226 - val_loss: 10.9771
Epoch 1168/8000

Epoch 01168: val_loss did not improve from 10.43213
 - 76s - loss: 9.8484 - val_loss: 12.2613
Epoch 1169/8000

Epoch 01169: val_loss did not improve from 10.43213
 - 76s - loss: 9.8132 - val_loss: 11.3258
Epoch 1170/8000

Epoch 01170: val_loss did not improve from 10.43213
 - 75s - loss: 10.8117 - val_loss: 11.8337
Epoch 1171/8000

Epoch 01171: val_loss did not improve from 10.43213
 - 76s - loss: 10.0972 - val_loss: 11.1112
Epoch 1172/8000

Epoch 01172: val_loss did not improve from 10.43213
 - 75s - loss: 10.0224 - val_loss: 12.3897
Epoch 1173/8000

Epoch 01173: val_loss did not improve from 10.43213
 - 76s - loss: 10.1517 - val_loss: 11.3689
Epoch 1174/8000

Epoch 01174: val_loss did not improve from 10.43213
 - 76s - loss: 9.7980 - val_loss: 11.1429
Epoch 1175/8000

Epoch 01175: val_loss did not improve from 10.43213
 - 76s - loss: 9.9232 - val_loss: 11.5193
Epoch 1176/8000

Epoch 01176: val_loss did not improve from 10.43213
 - 76s - loss: 9.7605 - val_loss: 10.9760
Epoch 1177/8000

Epoch 01177: val_loss did not improve from 10.43213
 - 75s - loss: 9.9952 - val_loss: 10.8791
Epoch 1178/8000

Epoch 01178: val_loss did not improve from 10.43213
 - 76s - loss: 9.9924 - val_loss: 11.0729
Epoch 1179/8000

Epoch 01179: val_loss did not improve from 10.43213
 - 75s - loss: 9.7000 - val_loss: 10.9991
Epoch 1180/8000

Epoch 01180: val_loss did not improve from 10.43213
 - 76s - loss: 9.7185 - val_loss: 11.4766
Epoch 1181/8000

Epoch 01181: val_loss did not improve from 10.43213
 - 75s - loss: 9.7017 - val_loss: 11.0608
Epoch 1182/8000

Epoch 01182: val_loss did not improve from 10.43213
 - 76s - loss: 9.8056 - val_loss: 11.5877
Epoch 1183/8000

Epoch 01183: val_loss did not improve from 10.43213
 - 76s - loss: 9.8845 - val_loss: 11.9287
Epoch 1184/8000

Epoch 01184: val_loss did not improve from 10.43213
 - 75s - loss: 10.3557 - val_loss: 11.8835
Epoch 1185/8000

Epoch 01185: val_loss did not improve from 10.43213
 - 76s - loss: 9.8678 - val_loss: 10.8111
Epoch 1186/8000

Epoch 01186: val_loss did not improve from 10.43213
 - 75s - loss: 9.7281 - val_loss: 11.0606
Epoch 1187/8000

Epoch 01187: val_loss did not improve from 10.43213
 - 76s - loss: 10.0006 - val_loss: 12.3047
Epoch 1188/8000

Epoch 01188: val_loss did not improve from 10.43213
 - 76s - loss: 11.4553 - val_loss: 11.6436
Epoch 1189/8000

Epoch 01189: val_loss did not improve from 10.43213
 - 76s - loss: 10.4011 - val_loss: 11.1034
Epoch 1190/8000

Epoch 01190: val_loss did not improve from 10.43213
 - 76s - loss: 10.1205 - val_loss: 11.1824
Epoch 1191/8000

Epoch 01191: val_loss did not improve from 10.43213
 - 75s - loss: 9.8193 - val_loss: 11.8576
Epoch 1192/8000

Epoch 01192: val_loss did not improve from 10.43213
 - 76s - loss: 9.7412 - val_loss: 10.8651
Epoch 1193/8000

Epoch 01193: val_loss did not improve from 10.43213
 - 75s - loss: 9.3251 - val_loss: 10.8604
Epoch 1194/8000

Epoch 01194: val_loss did not improve from 10.43213
 - 76s - loss: 9.3387 - val_loss: 10.6997
Epoch 1195/8000

Epoch 01195: val_loss did not improve from 10.43213
 - 75s - loss: 9.7057 - val_loss: 11.6213
Epoch 1196/8000

Epoch 01196: val_loss did not improve from 10.43213
 - 76s - loss: 9.6761 - val_loss: 10.9038
Epoch 1197/8000

Epoch 01197: val_loss did not improve from 10.43213
 - 76s - loss: 9.7638 - val_loss: 11.7090
Epoch 1198/8000

Epoch 01198: val_loss did not improve from 10.43213
 - 75s - loss: 10.1045 - val_loss: 11.2323
Epoch 1199/8000

Epoch 01199: val_loss did not improve from 10.43213
 - 76s - loss: 9.7472 - val_loss: 11.6047
Epoch 1200/8000

Epoch 01200: val_loss did not improve from 10.43213
 - 75s - loss: 9.7935 - val_loss: 11.3234
Epoch 1201/8000

Epoch 01201: val_loss did not improve from 10.43213
 - 76s - loss: 10.0668 - val_loss: 11.3224
Epoch 1202/8000

Epoch 01202: val_loss did not improve from 10.43213
 - 76s - loss: 10.1101 - val_loss: 10.8627
Epoch 1203/8000

Epoch 01203: val_loss did not improve from 10.43213
 - 76s - loss: 9.5140 - val_loss: 11.3322
Epoch 1204/8000

Epoch 01204: val_loss did not improve from 10.43213
 - 76s - loss: 9.6085 - val_loss: 10.7943
Epoch 1205/8000

Epoch 01205: val_loss did not improve from 10.43213
 - 75s - loss: 9.8128 - val_loss: 10.9223
Epoch 1206/8000

Epoch 01206: val_loss did not improve from 10.43213
 - 76s - loss: 9.4393 - val_loss: 10.9809
Epoch 1207/8000

Epoch 01207: val_loss did not improve from 10.43213
 - 75s - loss: 10.4350 - val_loss: 11.1109
Epoch 1208/8000

Epoch 01208: val_loss did not improve from 10.43213
 - 76s - loss: 10.5263 - val_loss: 12.9648
Epoch 1209/8000

Epoch 01209: val_loss did not improve from 10.43213
 - 75s - loss: 10.5833 - val_loss: 11.7141
Epoch 1210/8000

Epoch 01210: val_loss did not improve from 10.43213
 - 75s - loss: 9.7496 - val_loss: 11.2651
Epoch 1211/8000

Epoch 01211: val_loss did not improve from 10.43213
 - 76s - loss: 9.4792 - val_loss: 10.6872
Epoch 1212/8000

Epoch 01212: val_loss did not improve from 10.43213
 - 75s - loss: 9.5899 - val_loss: 10.8437
Epoch 1213/8000

Epoch 01213: val_loss did not improve from 10.43213
 - 76s - loss: 9.4975 - val_loss: 10.7923
Epoch 1214/8000

Epoch 01214: val_loss did not improve from 10.43213
 - 75s - loss: 9.8282 - val_loss: 11.8309
Epoch 1215/8000

Epoch 01215: val_loss did not improve from 10.43213
 - 76s - loss: 9.5200 - val_loss: 10.8032
Epoch 1216/8000

Epoch 01216: val_loss did not improve from 10.43213
 - 76s - loss: 9.7260 - val_loss: 11.2038
Epoch 1217/8000

Epoch 01217: val_loss did not improve from 10.43213
 - 76s - loss: 9.5473 - val_loss: 11.0940
Epoch 1218/8000

Epoch 01218: val_loss did not improve from 10.43213
 - 76s - loss: 9.9168 - val_loss: 10.6651
Epoch 1219/8000

Epoch 01219: val_loss did not improve from 10.43213
 - 76s - loss: 9.7727 - val_loss: 11.1279
Epoch 1220/8000

Epoch 01220: val_loss did not improve from 10.43213
 - 76s - loss: 10.3647 - val_loss: 11.2988
Epoch 1221/8000

Epoch 01221: val_loss did not improve from 10.43213
 - 75s - loss: 9.6318 - val_loss: 10.9363
Epoch 1222/8000

Epoch 01222: val_loss did not improve from 10.43213
 - 76s - loss: 10.0112 - val_loss: 11.1072
Epoch 1223/8000

Epoch 01223: val_loss did not improve from 10.43213
 - 76s - loss: 9.7699 - val_loss: 11.5403
Epoch 1224/8000

Epoch 01224: val_loss did not improve from 10.43213
 - 76s - loss: 9.7966 - val_loss: 10.8669
Epoch 1225/8000

Epoch 01225: val_loss did not improve from 10.43213
 - 75s - loss: 9.6336 - val_loss: 10.8390
Epoch 1226/8000

Epoch 01226: val_loss did not improve from 10.43213
 - 75s - loss: 9.6228 - val_loss: 11.0605
Epoch 1227/8000

Epoch 01227: val_loss did not improve from 10.43213
 - 75s - loss: 9.5820 - val_loss: 10.9960
Epoch 1228/8000

Epoch 01228: val_loss did not improve from 10.43213
 - 75s - loss: 9.9159 - val_loss: 11.3845
Epoch 1229/8000

Epoch 01229: val_loss did not improve from 10.43213
 - 76s - loss: 9.7888 - val_loss: 11.5801
Epoch 1230/8000

Epoch 01230: val_loss did not improve from 10.43213
 - 76s - loss: 9.8769 - val_loss: 11.3718
Epoch 1231/8000

Epoch 01231: val_loss did not improve from 10.43213
 - 76s - loss: 9.8495 - val_loss: 10.9052
Epoch 1232/8000

Epoch 01232: val_loss did not improve from 10.43213
 - 76s - loss: 9.6894 - val_loss: 11.1490
Epoch 1233/8000

Epoch 01233: val_loss did not improve from 10.43213
 - 75s - loss: 10.1492 - val_loss: 11.3741
Epoch 1234/8000

Epoch 01234: val_loss did not improve from 10.43213
 - 76s - loss: 9.8000 - val_loss: 11.1931
Epoch 1235/8000

Epoch 01235: val_loss did not improve from 10.43213
 - 75s - loss: 9.8703 - val_loss: 11.2787
Epoch 1236/8000

Epoch 01236: val_loss did not improve from 10.43213
 - 76s - loss: 9.7641 - val_loss: 11.4077
Epoch 1237/8000

Epoch 01237: val_loss did not improve from 10.43213
 - 76s - loss: 9.9874 - val_loss: 11.8016
Epoch 1238/8000

Epoch 01238: val_loss did not improve from 10.43213
 - 76s - loss: 9.8150 - val_loss: 11.3773
Epoch 1239/8000

Epoch 01239: val_loss did not improve from 10.43213
 - 76s - loss: 9.5690 - val_loss: 11.0255
Epoch 1240/8000

Epoch 01240: val_loss did not improve from 10.43213
 - 75s - loss: 9.8169 - val_loss: 11.2738
Epoch 1241/8000

Epoch 01241: val_loss did not improve from 10.43213
 - 76s - loss: 9.6787 - val_loss: 11.2534
Epoch 1242/8000

Epoch 01242: val_loss did not improve from 10.43213
 - 75s - loss: 9.7721 - val_loss: 11.4618
Epoch 1243/8000

Epoch 01243: val_loss did not improve from 10.43213
 - 76s - loss: 9.9547 - val_loss: 11.3797
Epoch 1244/8000

Epoch 01244: val_loss did not improve from 10.43213
 - 76s - loss: 9.8978 - val_loss: 11.5152
Epoch 1245/8000

Epoch 01245: val_loss did not improve from 10.43213
 - 76s - loss: 9.7681 - val_loss: 11.0081
Epoch 1246/8000

Epoch 01246: val_loss did not improve from 10.43213
 - 76s - loss: 9.7874 - val_loss: 11.7570
Epoch 1247/8000

Epoch 01247: val_loss did not improve from 10.43213
 - 75s - loss: 9.6669 - val_loss: 11.0924
Epoch 1248/8000

Epoch 01248: val_loss did not improve from 10.43213
 - 76s - loss: 9.6576 - val_loss: 11.3233
Epoch 1249/8000

Epoch 01249: val_loss did not improve from 10.43213
 - 75s - loss: 9.7680 - val_loss: 11.1071
Epoch 1250/8000

Epoch 01250: val_loss did not improve from 10.43213
 - 75s - loss: 9.7640 - val_loss: 11.1935
Epoch 1251/8000

Epoch 01251: val_loss did not improve from 10.43213
 - 75s - loss: 9.8119 - val_loss: 11.5160
Epoch 1252/8000

Epoch 01252: val_loss did not improve from 10.43213
 - 75s - loss: 9.6472 - val_loss: 11.8463
Epoch 1253/8000

Epoch 01253: val_loss did not improve from 10.43213
 - 75s - loss: 9.4671 - val_loss: 10.8814
Epoch 1254/8000

Epoch 01254: val_loss did not improve from 10.43213
 - 75s - loss: 9.7913 - val_loss: 11.8563
Epoch 1255/8000

Epoch 01255: val_loss did not improve from 10.43213
 - 76s - loss: 9.8769 - val_loss: 11.5450
Epoch 1256/8000

Epoch 01256: val_loss did not improve from 10.43213
 - 75s - loss: 10.0631 - val_loss: 11.3216
Epoch 1257/8000

Epoch 01257: val_loss did not improve from 10.43213
 - 76s - loss: 9.7385 - val_loss: 11.2878
Epoch 1258/8000

Epoch 01258: val_loss did not improve from 10.43213
 - 76s - loss: 10.4187 - val_loss: 11.3126
Epoch 1259/8000

Epoch 01259: val_loss did not improve from 10.43213
 - 76s - loss: 10.9035 - val_loss: 11.4302
Epoch 1260/8000

Epoch 01260: val_loss did not improve from 10.43213
 - 76s - loss: 11.3229 - val_loss: 12.3373
Epoch 1261/8000

Epoch 01261: val_loss did not improve from 10.43213
 - 75s - loss: 10.9314 - val_loss: 12.1064
Epoch 1262/8000

Epoch 01262: val_loss did not improve from 10.43213
 - 76s - loss: 10.5394 - val_loss: 12.0065
Epoch 1263/8000

Epoch 01263: val_loss did not improve from 10.43213
 - 75s - loss: 10.2290 - val_loss: 11.6716
Epoch 1264/8000

Epoch 01264: val_loss did not improve from 10.43213
 - 76s - loss: 10.0647 - val_loss: 11.0994
Epoch 1265/8000

Epoch 01265: val_loss did not improve from 10.43213
 - 76s - loss: 9.6673 - val_loss: 11.1582
Epoch 1266/8000

Epoch 01266: val_loss did not improve from 10.43213
 - 76s - loss: 9.7265 - val_loss: 11.0117
Epoch 1267/8000

Epoch 01267: val_loss did not improve from 10.43213
 - 76s - loss: 9.9483 - val_loss: 11.5579
Epoch 1268/8000

Epoch 01268: val_loss did not improve from 10.43213
 - 76s - loss: 9.8506 - val_loss: 11.5406
Epoch 1269/8000

Epoch 01269: val_loss did not improve from 10.43213
 - 76s - loss: 10.1086 - val_loss: 11.1415
Epoch 1270/8000

Epoch 01270: val_loss did not improve from 10.43213
 - 75s - loss: 9.8774 - val_loss: 11.9893
Epoch 1271/8000

Epoch 01271: val_loss did not improve from 10.43213
 - 76s - loss: 9.9345 - val_loss: 12.0472
Epoch 1272/8000

Epoch 01272: val_loss did not improve from 10.43213
 - 75s - loss: 10.0608 - val_loss: 11.4662
Epoch 1273/8000

Epoch 01273: val_loss did not improve from 10.43213
 - 76s - loss: 10.1252 - val_loss: 11.9266
Epoch 1274/8000

Epoch 01274: val_loss did not improve from 10.43213
 - 76s - loss: 10.5010 - val_loss: 11.9754
Epoch 1275/8000

Epoch 01275: val_loss did not improve from 10.43213
 - 75s - loss: 10.1971 - val_loss: 11.2798
Epoch 1276/8000

Epoch 01276: val_loss did not improve from 10.43213
 - 76s - loss: 10.0929 - val_loss: 11.8012
Epoch 1277/8000

Epoch 01277: val_loss did not improve from 10.43213
 - 75s - loss: 10.0120 - val_loss: 11.4599
Epoch 1278/8000

Epoch 01278: val_loss did not improve from 10.43213
 - 76s - loss: 10.3456 - val_loss: 11.3843
Epoch 1279/8000

Epoch 01279: val_loss did not improve from 10.43213
 - 76s - loss: 9.8954 - val_loss: 11.9581
Epoch 1280/8000

Epoch 01280: val_loss did not improve from 10.43213
 - 76s - loss: 9.9400 - val_loss: 11.7355
Epoch 1281/8000

Epoch 01281: val_loss did not improve from 10.43213
 - 76s - loss: 10.6966 - val_loss: 11.6440
Epoch 1282/8000

Epoch 01282: val_loss did not improve from 10.43213
 - 75s - loss: 10.3217 - val_loss: 11.5446
Epoch 1283/8000

Epoch 01283: val_loss did not improve from 10.43213
 - 76s - loss: 9.9306 - val_loss: 11.1437
Epoch 1284/8000

Epoch 01284: val_loss did not improve from 10.43213
 - 75s - loss: 9.9260 - val_loss: 11.2386
Epoch 1285/8000

Epoch 01285: val_loss did not improve from 10.43213
 - 76s - loss: 9.9250 - val_loss: 11.5687
Epoch 1286/8000

Epoch 01286: val_loss did not improve from 10.43213
 - 76s - loss: 10.0602 - val_loss: 12.2093
Epoch 1287/8000

Epoch 01287: val_loss did not improve from 10.43213
 - 76s - loss: 9.8615 - val_loss: 11.1723
Epoch 1288/8000

Epoch 01288: val_loss did not improve from 10.43213
 - 76s - loss: 9.7144 - val_loss: 11.2619
Epoch 1289/8000

Epoch 01289: val_loss did not improve from 10.43213
 - 75s - loss: 9.3922 - val_loss: 11.1427
Epoch 1290/8000

Epoch 01290: val_loss did not improve from 10.43213
 - 76s - loss: 9.8598 - val_loss: 11.5529
Epoch 1291/8000

Epoch 01291: val_loss did not improve from 10.43213
 - 75s - loss: 9.8306 - val_loss: 11.1569
Epoch 1292/8000

Epoch 01292: val_loss did not improve from 10.43213
 - 76s - loss: 12.6552 - val_loss: 13.0977
Epoch 1293/8000

Epoch 01293: val_loss did not improve from 10.43213
 - 76s - loss: 11.4784 - val_loss: 11.8560
Epoch 1294/8000

Epoch 01294: val_loss did not improve from 10.43213
 - 76s - loss: 10.6875 - val_loss: 12.2642
Epoch 1295/8000

Epoch 01295: val_loss did not improve from 10.43213
 - 76s - loss: 11.5171 - val_loss: 13.5256
Epoch 1296/8000

Epoch 01296: val_loss did not improve from 10.43213
 - 75s - loss: 11.8351 - val_loss: 11.3964
Epoch 1297/8000

Epoch 01297: val_loss did not improve from 10.43213
 - 76s - loss: 10.7868 - val_loss: 11.7274
Epoch 1298/8000

Epoch 01298: val_loss did not improve from 10.43213
 - 75s - loss: 11.5122 - val_loss: 14.9055
Epoch 1299/8000

Epoch 01299: val_loss did not improve from 10.43213
 - 76s - loss: 12.1561 - val_loss: 12.0231
Epoch 1300/8000

Epoch 01300: val_loss did not improve from 10.43213
 - 76s - loss: 10.7451 - val_loss: 11.5056
Epoch 1301/8000

Epoch 01301: val_loss did not improve from 10.43213
 - 76s - loss: 10.6903 - val_loss: 11.5894
Epoch 1302/8000

Epoch 01302: val_loss did not improve from 10.43213
 - 75s - loss: 10.3657 - val_loss: 11.1232
Epoch 1303/8000

Epoch 01303: val_loss did not improve from 10.43213
 - 75s - loss: 9.8309 - val_loss: 11.6422
Epoch 1304/8000

Epoch 01304: val_loss did not improve from 10.43213
 - 76s - loss: 10.0780 - val_loss: 11.5981
Epoch 1305/8000

Epoch 01305: val_loss did not improve from 10.43213
 - 75s - loss: 9.8023 - val_loss: 11.4954
Epoch 1306/8000

Epoch 01306: val_loss did not improve from 10.43213
 - 76s - loss: 10.0251 - val_loss: 11.3577
Epoch 1307/8000

Epoch 01307: val_loss did not improve from 10.43213
 - 76s - loss: 9.6732 - val_loss: 11.3027
Epoch 1308/8000

Epoch 01308: val_loss did not improve from 10.43213
 - 76s - loss: 9.8546 - val_loss: 11.0423
Epoch 1309/8000

Epoch 01309: val_loss did not improve from 10.43213
 - 76s - loss: 9.8790 - val_loss: 11.4090
Epoch 1310/8000

Epoch 01310: val_loss did not improve from 10.43213
 - 75s - loss: 9.7002 - val_loss: 11.4604
Epoch 1311/8000

Epoch 01311: val_loss did not improve from 10.43213
 - 76s - loss: 10.6614 - val_loss: 11.4598
Epoch 1312/8000

Epoch 01312: val_loss did not improve from 10.43213
 - 75s - loss: 10.3726 - val_loss: 11.8364
Epoch 1313/8000

Epoch 01313: val_loss did not improve from 10.43213
 - 76s - loss: 10.4829 - val_loss: 12.6541
Epoch 1314/8000

Epoch 01314: val_loss did not improve from 10.43213
 - 76s - loss: 10.5173 - val_loss: 11.6717
Epoch 1315/8000

Epoch 01315: val_loss did not improve from 10.43213
 - 76s - loss: 9.6737 - val_loss: 11.4440
Epoch 1316/8000

Epoch 01316: val_loss did not improve from 10.43213
 - 76s - loss: 9.7139 - val_loss: 10.7249
Epoch 1317/8000

Epoch 01317: val_loss did not improve from 10.43213
 - 75s - loss: 11.2221 - val_loss: 12.0699
Epoch 1318/8000

Epoch 01318: val_loss did not improve from 10.43213
 - 76s - loss: 10.4126 - val_loss: 11.7327
Epoch 1319/8000

Epoch 01319: val_loss did not improve from 10.43213
 - 75s - loss: 10.1137 - val_loss: 12.1154
Epoch 1320/8000

Epoch 01320: val_loss did not improve from 10.43213
 - 76s - loss: 11.5106 - val_loss: 14.2315
Epoch 1321/8000

Epoch 01321: val_loss did not improve from 10.43213
 - 76s - loss: 11.7578 - val_loss: 11.9328
Epoch 1322/8000

Epoch 01322: val_loss did not improve from 10.43213
 - 76s - loss: 10.7687 - val_loss: 11.4031
Epoch 1323/8000

Epoch 01323: val_loss did not improve from 10.43213
 - 76s - loss: 10.7346 - val_loss: 12.8693
Epoch 1324/8000

Epoch 01324: val_loss did not improve from 10.43213
 - 76s - loss: 10.7614 - val_loss: 11.6966
Epoch 1325/8000

Epoch 01325: val_loss did not improve from 10.43213
 - 76s - loss: 10.7143 - val_loss: 12.0571
Epoch 1326/8000

Epoch 01326: val_loss did not improve from 10.43213
 - 75s - loss: 10.1456 - val_loss: 11.0994
Epoch 1327/8000

Epoch 01327: val_loss did not improve from 10.43213
 - 76s - loss: 10.5595 - val_loss: 11.3952
Epoch 1328/8000

Epoch 01328: val_loss did not improve from 10.43213
 - 76s - loss: 10.3164 - val_loss: 11.1539
Epoch 1329/8000

Epoch 01329: val_loss did not improve from 10.43213
 - 76s - loss: 10.1488 - val_loss: 11.0661
Epoch 1330/8000

Epoch 01330: val_loss did not improve from 10.43213
 - 76s - loss: 9.9983 - val_loss: 11.2575
Epoch 1331/8000

Epoch 01331: val_loss did not improve from 10.43213
 - 75s - loss: 9.9771 - val_loss: 11.8163
Epoch 1332/8000

Epoch 01332: val_loss did not improve from 10.43213
 - 76s - loss: 9.9833 - val_loss: 11.6710
Epoch 1333/8000

Epoch 01333: val_loss did not improve from 10.43213
 - 75s - loss: 10.1741 - val_loss: 12.0478
Epoch 1334/8000

Epoch 01334: val_loss did not improve from 10.43213
 - 76s - loss: 11.2669 - val_loss: 11.3201
Epoch 1335/8000

Epoch 01335: val_loss did not improve from 10.43213
 - 76s - loss: 10.1069 - val_loss: 11.1787
Epoch 1336/8000

Epoch 01336: val_loss did not improve from 10.43213
 - 76s - loss: 9.9772 - val_loss: 12.1241
Epoch 1337/8000

Epoch 01337: val_loss did not improve from 10.43213
 - 76s - loss: 10.5059 - val_loss: 12.3745
Epoch 1338/8000

Epoch 01338: val_loss did not improve from 10.43213
 - 75s - loss: 11.1452 - val_loss: 12.4842
Epoch 1339/8000

Epoch 01339: val_loss did not improve from 10.43213
 - 76s - loss: 11.2155 - val_loss: 12.1338
Epoch 1340/8000

Epoch 01340: val_loss did not improve from 10.43213
 - 75s - loss: 11.3473 - val_loss: 12.1574
Epoch 1341/8000

Epoch 01341: val_loss did not improve from 10.43213
 - 76s - loss: 10.6408 - val_loss: 11.3015
Epoch 1342/8000

Epoch 01342: val_loss did not improve from 10.43213
 - 76s - loss: 10.2225 - val_loss: 11.0568
Epoch 1343/8000

Epoch 01343: val_loss did not improve from 10.43213
 - 76s - loss: 10.4770 - val_loss: 11.4758
Epoch 1344/8000

Epoch 01344: val_loss did not improve from 10.43213
 - 76s - loss: 10.0537 - val_loss: 11.5558
Epoch 1345/8000

Epoch 01345: val_loss did not improve from 10.43213
 - 75s - loss: 10.0336 - val_loss: 11.7902
Epoch 1346/8000

Epoch 01346: val_loss did not improve from 10.43213
 - 76s - loss: 10.0659 - val_loss: 10.9983
Epoch 1347/8000

Epoch 01347: val_loss did not improve from 10.43213
 - 75s - loss: 9.6002 - val_loss: 11.3228
Epoch 1348/8000

Epoch 01348: val_loss did not improve from 10.43213
 - 76s - loss: 9.7191 - val_loss: 11.3388
Epoch 1349/8000

Epoch 01349: val_loss did not improve from 10.43213
 - 76s - loss: 10.1800 - val_loss: 11.1136
Epoch 1350/8000

Epoch 01350: val_loss did not improve from 10.43213
 - 76s - loss: 11.4542 - val_loss: 12.2924
Epoch 1351/8000

Epoch 01351: val_loss did not improve from 10.43213
 - 76s - loss: 10.4573 - val_loss: 12.3211
Epoch 1352/8000

Epoch 01352: val_loss did not improve from 10.43213
 - 75s - loss: 10.2842 - val_loss: 11.8287
Epoch 1353/8000

Epoch 01353: val_loss did not improve from 10.43213
 - 76s - loss: 10.6597 - val_loss: 11.4435
Epoch 1354/8000

Epoch 01354: val_loss did not improve from 10.43213
 - 75s - loss: 10.7027 - val_loss: 11.8869
Epoch 1355/8000

Epoch 01355: val_loss did not improve from 10.43213
 - 76s - loss: 10.1812 - val_loss: 12.0850
Epoch 1356/8000

Epoch 01356: val_loss did not improve from 10.43213
 - 76s - loss: 10.5529 - val_loss: 13.2928
Epoch 1357/8000

Epoch 01357: val_loss did not improve from 10.43213
 - 76s - loss: 10.5702 - val_loss: 11.5859
Epoch 1358/8000

Epoch 01358: val_loss did not improve from 10.43213
 - 76s - loss: 10.6530 - val_loss: 11.3672
Epoch 1359/8000

Epoch 01359: val_loss did not improve from 10.43213
 - 75s - loss: 10.6678 - val_loss: 11.5121
Epoch 1360/8000

Epoch 01360: val_loss did not improve from 10.43213
 - 76s - loss: 10.3768 - val_loss: 12.3474
Epoch 1361/8000

Epoch 01361: val_loss did not improve from 10.43213
 - 75s - loss: 10.8717 - val_loss: 12.3976
Epoch 1362/8000

Epoch 01362: val_loss did not improve from 10.43213
 - 76s - loss: 11.4774 - val_loss: 11.1535
Epoch 1363/8000

Epoch 01363: val_loss did not improve from 10.43213
 - 75s - loss: 10.0359 - val_loss: 11.1151
Epoch 1364/8000

Epoch 01364: val_loss did not improve from 10.43213
 - 75s - loss: 10.2552 - val_loss: 11.2147
Epoch 1365/8000

Epoch 01365: val_loss did not improve from 10.43213
 - 75s - loss: 11.0059 - val_loss: 14.1767
Epoch 1366/8000

Epoch 01366: val_loss did not improve from 10.43213
 - 75s - loss: 12.3956 - val_loss: 12.5794
Epoch 1367/8000

Epoch 01367: val_loss did not improve from 10.43213
 - 76s - loss: 11.7914 - val_loss: 11.6885
Epoch 1368/8000

Epoch 01368: val_loss did not improve from 10.43213
 - 75s - loss: 11.3664 - val_loss: 12.0412
Epoch 1369/8000

Epoch 01369: val_loss did not improve from 10.43213
 - 76s - loss: 10.8258 - val_loss: 11.3199
Epoch 1370/8000

Epoch 01370: val_loss did not improve from 10.43213
 - 76s - loss: 10.8575 - val_loss: 11.2865
Epoch 1371/8000

Epoch 01371: val_loss did not improve from 10.43213
 - 76s - loss: 10.4782 - val_loss: 11.7734
Epoch 1372/8000

Epoch 01372: val_loss did not improve from 10.43213
 - 76s - loss: 10.9784 - val_loss: 12.0501
Epoch 1373/8000

Epoch 01373: val_loss did not improve from 10.43213
 - 75s - loss: 10.8692 - val_loss: 11.7362
Epoch 1374/8000

Epoch 01374: val_loss did not improve from 10.43213
 - 76s - loss: 10.5393 - val_loss: 11.6581
Epoch 1375/8000

Epoch 01375: val_loss did not improve from 10.43213
 - 75s - loss: 10.6218 - val_loss: 11.5218
Epoch 1376/8000

Epoch 01376: val_loss did not improve from 10.43213
 - 76s - loss: 10.1924 - val_loss: 11.1259
Epoch 1377/8000

Epoch 01377: val_loss did not improve from 10.43213
 - 76s - loss: 10.7003 - val_loss: 11.4940
Epoch 1378/8000

Epoch 01378: val_loss did not improve from 10.43213
 - 76s - loss: 11.0793 - val_loss: 12.8494
Epoch 1379/8000

Epoch 01379: val_loss did not improve from 10.43213
 - 76s - loss: 12.6082 - val_loss: 12.1652
Epoch 1380/8000

Epoch 01380: val_loss did not improve from 10.43213
 - 75s - loss: 11.1498 - val_loss: 11.5625
Epoch 1381/8000

Epoch 01381: val_loss did not improve from 10.43213
 - 76s - loss: 11.1152 - val_loss: 11.4510
Epoch 1382/8000

Epoch 01382: val_loss did not improve from 10.43213
 - 75s - loss: 10.8069 - val_loss: 12.6477
Epoch 1383/8000

Epoch 01383: val_loss did not improve from 10.43213
 - 76s - loss: 11.0200 - val_loss: 12.9032
Epoch 1384/8000

Epoch 01384: val_loss did not improve from 10.43213
 - 76s - loss: 11.2552 - val_loss: 12.5797
Epoch 1385/8000

Epoch 01385: val_loss did not improve from 10.43213
 - 76s - loss: 10.9712 - val_loss: 11.2962
Epoch 1386/8000

Epoch 01386: val_loss did not improve from 10.43213
 - 76s - loss: 11.4008 - val_loss: 11.9004
Epoch 1387/8000

Epoch 01387: val_loss did not improve from 10.43213
 - 75s - loss: 11.4985 - val_loss: 11.2044
Epoch 1388/8000

Epoch 01388: val_loss did not improve from 10.43213
 - 76s - loss: 12.4085 - val_loss: 12.0167
Epoch 1389/8000

Epoch 01389: val_loss did not improve from 10.43213
 - 76s - loss: 11.0891 - val_loss: 11.5367
Epoch 1390/8000

Epoch 01390: val_loss did not improve from 10.43213
 - 76s - loss: 11.3007 - val_loss: 11.8606
Epoch 1391/8000

Epoch 01391: val_loss did not improve from 10.43213
 - 76s - loss: 10.8623 - val_loss: 11.5419
Epoch 1392/8000

Epoch 01392: val_loss did not improve from 10.43213
 - 76s - loss: 10.7639 - val_loss: 12.2797
Epoch 1393/8000

Epoch 01393: val_loss did not improve from 10.43213
 - 76s - loss: 10.8057 - val_loss: 11.2778
Epoch 1394/8000

Epoch 01394: val_loss did not improve from 10.43213
 - 75s - loss: 10.4040 - val_loss: 11.3137
Epoch 1395/8000

Epoch 01395: val_loss did not improve from 10.43213
 - 76s - loss: 10.6511 - val_loss: 12.9195
Epoch 1396/8000

Epoch 01396: val_loss did not improve from 10.43213
 - 75s - loss: 11.5844 - val_loss: 11.7694
Epoch 1397/8000

Epoch 01397: val_loss did not improve from 10.43213
 - 76s - loss: 10.9463 - val_loss: 11.2116
Epoch 1398/8000

Epoch 01398: val_loss did not improve from 10.43213
 - 76s - loss: 16.0821 - val_loss: 14.5272
Epoch 1399/8000

Epoch 01399: val_loss did not improve from 10.43213
 - 76s - loss: 12.9766 - val_loss: 12.5905
Epoch 1400/8000

Epoch 01400: val_loss did not improve from 10.43213
 - 76s - loss: 12.3699 - val_loss: 12.2675
Epoch 1401/8000

Epoch 01401: val_loss did not improve from 10.43213
 - 75s - loss: 11.5502 - val_loss: 12.7183
Epoch 1402/8000

Epoch 01402: val_loss did not improve from 10.43213
 - 76s - loss: 12.0954 - val_loss: 11.6162
Epoch 1403/8000

Epoch 01403: val_loss did not improve from 10.43213
 - 76s - loss: 11.2928 - val_loss: 12.1710
Epoch 1404/8000

Epoch 01404: val_loss did not improve from 10.43213
 - 76s - loss: 11.0933 - val_loss: 11.7077
Epoch 1405/8000

Epoch 01405: val_loss did not improve from 10.43213
 - 76s - loss: 11.1252 - val_loss: 11.6018
Epoch 1406/8000

Epoch 01406: val_loss did not improve from 10.43213
 - 76s - loss: 10.8282 - val_loss: 11.5975
Epoch 1407/8000

Epoch 01407: val_loss did not improve from 10.43213
 - 76s - loss: 10.7439 - val_loss: 11.3362
Epoch 1408/8000

Epoch 01408: val_loss did not improve from 10.43213
 - 75s - loss: 10.7493 - val_loss: 11.2777
Epoch 1409/8000

Epoch 01409: val_loss did not improve from 10.43213
 - 76s - loss: 10.6163 - val_loss: 11.6393
Epoch 1410/8000

Epoch 01410: val_loss did not improve from 10.43213
 - 75s - loss: 10.5941 - val_loss: 11.5125
Epoch 1411/8000

Epoch 01411: val_loss did not improve from 10.43213
 - 76s - loss: 10.6534 - val_loss: 11.5693
Epoch 1412/8000

Epoch 01412: val_loss did not improve from 10.43213
 - 76s - loss: 10.7000 - val_loss: 12.0504
Epoch 1413/8000

Epoch 01413: val_loss did not improve from 10.43213
 - 76s - loss: 10.5361 - val_loss: 12.1303
Epoch 1414/8000

Epoch 01414: val_loss did not improve from 10.43213
 - 76s - loss: 10.4256 - val_loss: 11.4118
Epoch 1415/8000

Epoch 01415: val_loss did not improve from 10.43213
 - 75s - loss: 10.4595 - val_loss: 11.7480
Epoch 1416/8000

Epoch 01416: val_loss did not improve from 10.43213
 - 76s - loss: 10.1315 - val_loss: 10.9649
Epoch 1417/8000

Epoch 01417: val_loss did not improve from 10.43213
 - 76s - loss: 10.1096 - val_loss: 11.0053
Epoch 1418/8000

Epoch 01418: val_loss did not improve from 10.43213
 - 76s - loss: 9.8479 - val_loss: 10.8346
Epoch 1419/8000

Epoch 01419: val_loss did not improve from 10.43213
 - 76s - loss: 10.2402 - val_loss: 11.1429
Epoch 1420/8000

Epoch 01420: val_loss did not improve from 10.43213
 - 76s - loss: 10.2231 - val_loss: 11.7683
Epoch 1421/8000

Epoch 01421: val_loss did not improve from 10.43213
 - 76s - loss: 10.3775 - val_loss: 11.2192
Epoch 1422/8000

Epoch 01422: val_loss did not improve from 10.43213
 - 75s - loss: 10.1496 - val_loss: 10.8430
Epoch 1423/8000

Epoch 01423: val_loss did not improve from 10.43213
 - 76s - loss: 9.9794 - val_loss: 11.4935
Epoch 1424/8000

Epoch 01424: val_loss did not improve from 10.43213
 - 75s - loss: 10.6175 - val_loss: 11.9426
Epoch 1425/8000

Epoch 01425: val_loss did not improve from 10.43213
 - 76s - loss: 9.7330 - val_loss: 10.7870
Epoch 1426/8000

Epoch 01426: val_loss did not improve from 10.43213
 - 76s - loss: 10.0870 - val_loss: 11.0884
Epoch 1427/8000

Epoch 01427: val_loss did not improve from 10.43213
 - 76s - loss: 9.9383 - val_loss: 12.2533
Epoch 1428/8000

Epoch 01428: val_loss did not improve from 10.43213
 - 76s - loss: 10.3567 - val_loss: 10.9186
Epoch 1429/8000

Epoch 01429: val_loss did not improve from 10.43213
 - 75s - loss: 10.3850 - val_loss: 10.9241
Epoch 1430/8000

Epoch 01430: val_loss did not improve from 10.43213
 - 76s - loss: 11.2887 - val_loss: 10.9856
Epoch 1431/8000

Epoch 01431: val_loss did not improve from 10.43213
 - 76s - loss: 10.3583 - val_loss: 11.9527
Epoch 1432/8000

Epoch 01432: val_loss did not improve from 10.43213
 - 76s - loss: 10.0745 - val_loss: 11.1242
Epoch 1433/8000

Epoch 01433: val_loss did not improve from 10.43213
 - 76s - loss: 9.6104 - val_loss: 10.9657
Epoch 1434/8000

Epoch 01434: val_loss did not improve from 10.43213
 - 76s - loss: 9.8355 - val_loss: 10.6248
Epoch 1435/8000

Epoch 01435: val_loss did not improve from 10.43213
 - 76s - loss: 9.7790 - val_loss: 10.7349
Epoch 1436/8000

Epoch 01436: val_loss did not improve from 10.43213
 - 75s - loss: 9.7989 - val_loss: 12.2909
Epoch 1437/8000

Epoch 01437: val_loss did not improve from 10.43213
 - 76s - loss: 9.8647 - val_loss: 11.3109
Epoch 1438/8000

Epoch 01438: val_loss did not improve from 10.43213
 - 75s - loss: 9.7704 - val_loss: 10.9017
Epoch 1439/8000

Epoch 01439: val_loss did not improve from 10.43213
 - 75s - loss: 10.0935 - val_loss: 11.3036
Epoch 1440/8000

Epoch 01440: val_loss did not improve from 10.43213
 - 76s - loss: 10.0217 - val_loss: 10.7770
Epoch 1441/8000

Epoch 01441: val_loss did not improve from 10.43213
 - 76s - loss: 10.1791 - val_loss: 11.4003
Epoch 1442/8000

Epoch 01442: val_loss did not improve from 10.43213
 - 76s - loss: 10.0419 - val_loss: 11.0147
Epoch 1443/8000

Epoch 01443: val_loss did not improve from 10.43213
 - 75s - loss: 10.5019 - val_loss: 11.2593
Epoch 1444/8000

Epoch 01444: val_loss did not improve from 10.43213
 - 76s - loss: 9.5773 - val_loss: 11.4372
Epoch 1445/8000

Epoch 01445: val_loss did not improve from 10.43213
 - 75s - loss: 11.4440 - val_loss: 11.9608
Epoch 1446/8000

Epoch 01446: val_loss did not improve from 10.43213
 - 76s - loss: 10.4824 - val_loss: 11.5609
Epoch 1447/8000

Epoch 01447: val_loss did not improve from 10.43213
 - 76s - loss: 10.3786 - val_loss: 12.5959
Epoch 1448/8000

Epoch 01448: val_loss did not improve from 10.43213
 - 76s - loss: 10.5565 - val_loss: 11.8391
Epoch 1449/8000

Epoch 01449: val_loss did not improve from 10.43213
 - 76s - loss: 10.7355 - val_loss: 12.5260
Epoch 1450/8000

Epoch 01450: val_loss did not improve from 10.43213
 - 75s - loss: 11.3510 - val_loss: 11.7093
Epoch 1451/8000

Epoch 01451: val_loss did not improve from 10.43213
 - 76s - loss: 10.6382 - val_loss: 10.7624
Epoch 1452/8000

Epoch 01452: val_loss did not improve from 10.43213
 - 75s - loss: 10.6100 - val_loss: 11.6659
Epoch 1453/8000

Epoch 01453: val_loss did not improve from 10.43213
 - 76s - loss: 10.2352 - val_loss: 12.2999
Epoch 1454/8000

Epoch 01454: val_loss did not improve from 10.43213
 - 76s - loss: 10.9718 - val_loss: 11.5292
Epoch 1455/8000

Epoch 01455: val_loss did not improve from 10.43213
 - 76s - loss: 10.3747 - val_loss: 11.7131
Epoch 1456/8000

Epoch 01456: val_loss did not improve from 10.43213
 - 76s - loss: 251.5463 - val_loss: 20.5569
Epoch 1457/8000

Epoch 01457: val_loss did not improve from 10.43213
 - 75s - loss: 16.3141 - val_loss: 13.7770
Epoch 1458/8000

Epoch 01458: val_loss did not improve from 10.43213
 - 76s - loss: 13.1196 - val_loss: 13.0815
Epoch 1459/8000

Epoch 01459: val_loss did not improve from 10.43213
 - 76s - loss: 11.7308 - val_loss: 11.9155
Epoch 1460/8000

Epoch 01460: val_loss did not improve from 10.43213
 - 76s - loss: 11.6489 - val_loss: 13.4725
Epoch 1461/8000

Epoch 01461: val_loss did not improve from 10.43213
 - 76s - loss: 12.2264 - val_loss: 12.5332
Epoch 1462/8000

Epoch 01462: val_loss did not improve from 10.43213
 - 76s - loss: 10.9705 - val_loss: 12.0153
Epoch 1463/8000

Epoch 01463: val_loss did not improve from 10.43213
 - 76s - loss: 10.8148 - val_loss: 11.5477
Epoch 1464/8000

Epoch 01464: val_loss did not improve from 10.43213
 - 75s - loss: 10.8336 - val_loss: 11.6096
Epoch 1465/8000

Epoch 01465: val_loss did not improve from 10.43213
 - 76s - loss: 10.7046 - val_loss: 11.7282
Epoch 1466/8000

Epoch 01466: val_loss did not improve from 10.43213
 - 75s - loss: 10.5519 - val_loss: 11.2706
Epoch 1467/8000

Epoch 01467: val_loss did not improve from 10.43213
 - 76s - loss: 10.5565 - val_loss: 11.3430
Epoch 1468/8000

Epoch 01468: val_loss did not improve from 10.43213
 - 75s - loss: 11.0312 - val_loss: 12.6039
Epoch 1469/8000

Epoch 01469: val_loss did not improve from 10.43213
 - 75s - loss: 11.2285 - val_loss: 11.9750
Epoch 1470/8000

Epoch 01470: val_loss did not improve from 10.43213
 - 75s - loss: 10.7643 - val_loss: 11.4039
Epoch 1471/8000

Epoch 01471: val_loss did not improve from 10.43213
 - 75s - loss: 10.3643 - val_loss: 11.1367
Epoch 1472/8000

Epoch 01472: val_loss did not improve from 10.43213
 - 76s - loss: 10.2651 - val_loss: 11.3498
Epoch 1473/8000

Epoch 01473: val_loss did not improve from 10.43213
 - 75s - loss: 10.0703 - val_loss: 11.3955
Epoch 1474/8000

Epoch 01474: val_loss did not improve from 10.43213
 - 76s - loss: 10.3660 - val_loss: 11.5164
Epoch 1475/8000

Epoch 01475: val_loss did not improve from 10.43213
 - 76s - loss: 10.3506 - val_loss: 11.0195
Epoch 1476/8000

Epoch 01476: val_loss did not improve from 10.43213
 - 76s - loss: 10.1265 - val_loss: 12.1189
Epoch 1477/8000

Epoch 01477: val_loss did not improve from 10.43213
 - 76s - loss: 10.1454 - val_loss: 11.7191
Epoch 1478/8000

Epoch 01478: val_loss did not improve from 10.43213
 - 75s - loss: 10.1859 - val_loss: 11.4142
Epoch 1479/8000

Epoch 01479: val_loss did not improve from 10.43213
 - 76s - loss: 10.1567 - val_loss: 11.3365
Epoch 1480/8000

Epoch 01480: val_loss did not improve from 10.43213
 - 75s - loss: 10.1108 - val_loss: 11.6297
Epoch 1481/8000

Epoch 01481: val_loss did not improve from 10.43213
 - 76s - loss: 10.6220 - val_loss: 11.5084
Epoch 1482/8000

Epoch 01482: val_loss did not improve from 10.43213
 - 76s - loss: 10.3968 - val_loss: 11.3326
Epoch 1483/8000

Epoch 01483: val_loss did not improve from 10.43213
 - 76s - loss: 10.1576 - val_loss: 10.9918
Epoch 1484/8000

Epoch 01484: val_loss did not improve from 10.43213
 - 76s - loss: 10.2381 - val_loss: 11.3516
Epoch 1485/8000

Epoch 01485: val_loss did not improve from 10.43213
 - 76s - loss: 9.9571 - val_loss: 11.0739
Epoch 1486/8000

Epoch 01486: val_loss did not improve from 10.43213
 - 76s - loss: 10.1072 - val_loss: 11.0813
Epoch 1487/8000

Epoch 01487: val_loss did not improve from 10.43213
 - 75s - loss: 9.9867 - val_loss: 12.3239
Epoch 1488/8000

Epoch 01488: val_loss did not improve from 10.43213
 - 76s - loss: 11.0083 - val_loss: 11.3405
Epoch 1489/8000

Epoch 01489: val_loss did not improve from 10.43213
 - 75s - loss: 10.3064 - val_loss: 11.4487
Epoch 1490/8000

Epoch 01490: val_loss did not improve from 10.43213
 - 76s - loss: 10.4892 - val_loss: 11.1343
Epoch 1491/8000

Epoch 01491: val_loss did not improve from 10.43213
 - 76s - loss: 10.1216 - val_loss: 11.3834
Epoch 1492/8000

Epoch 01492: val_loss did not improve from 10.43213
 - 75s - loss: 10.1488 - val_loss: 10.9372
Epoch 1493/8000

Epoch 01493: val_loss did not improve from 10.43213
 - 76s - loss: 11.1625 - val_loss: 12.8976
Epoch 1494/8000

Epoch 01494: val_loss did not improve from 10.43213
 - 75s - loss: 11.1477 - val_loss: 11.4470
Epoch 1495/8000

Epoch 01495: val_loss did not improve from 10.43213
 - 76s - loss: 10.9196 - val_loss: 13.4397
Epoch 1496/8000

Epoch 01496: val_loss did not improve from 10.43213
 - 76s - loss: 12.2658 - val_loss: 12.1947
Epoch 1497/8000

Epoch 01497: val_loss did not improve from 10.43213
 - 76s - loss: 11.2226 - val_loss: 11.1475
Epoch 1498/8000

Epoch 01498: val_loss did not improve from 10.43213
 - 76s - loss: 10.6636 - val_loss: 10.8346
Epoch 1499/8000

Epoch 01499: val_loss did not improve from 10.43213
 - 76s - loss: 10.4550 - val_loss: 10.9083
Epoch 1500/8000

Epoch 01500: val_loss did not improve from 10.43213
 - 76s - loss: 11.1362 - val_loss: 12.6610
Epoch 1501/8000

Epoch 01501: val_loss did not improve from 10.43213
 - 75s - loss: 12.1222 - val_loss: 11.8765
Epoch 1502/8000

Epoch 01502: val_loss did not improve from 10.43213
 - 76s - loss: 11.5314 - val_loss: 11.2685
Epoch 1503/8000

Epoch 01503: val_loss did not improve from 10.43213
 - 76s - loss: 10.6354 - val_loss: 11.0977
Epoch 1504/8000

Epoch 01504: val_loss did not improve from 10.43213
 - 75s - loss: 10.2280 - val_loss: 11.4852
Epoch 1505/8000

Epoch 01505: val_loss did not improve from 10.43213
 - 76s - loss: 10.4427 - val_loss: 12.0550
Epoch 1506/8000

Epoch 01506: val_loss did not improve from 10.43213
 - 75s - loss: 10.0649 - val_loss: 11.0655
Epoch 1507/8000

Epoch 01507: val_loss did not improve from 10.43213
 - 76s - loss: 10.0738 - val_loss: 11.0490
Epoch 1508/8000

Epoch 01508: val_loss did not improve from 10.43213
 - 75s - loss: 10.0836 - val_loss: 11.0848
Epoch 1509/8000

Epoch 01509: val_loss did not improve from 10.43213
 - 76s - loss: 9.8142 - val_loss: 11.1103
Epoch 1510/8000

Epoch 01510: val_loss did not improve from 10.43213
 - 76s - loss: 9.7329 - val_loss: 11.2060
Epoch 1511/8000

Epoch 01511: val_loss did not improve from 10.43213
 - 76s - loss: 10.7284 - val_loss: 12.3259
Epoch 1512/8000

Epoch 01512: val_loss did not improve from 10.43213
 - 76s - loss: 12.7215 - val_loss: 16.0764
Epoch 1513/8000

Epoch 01513: val_loss did not improve from 10.43213
 - 75s - loss: 12.4716 - val_loss: 12.1038
Epoch 1514/8000

Epoch 01514: val_loss did not improve from 10.43213
 - 76s - loss: 11.5714 - val_loss: 11.6381
Epoch 1515/8000

Epoch 01515: val_loss did not improve from 10.43213
 - 75s - loss: 10.8353 - val_loss: 12.2144
Epoch 1516/8000

Epoch 01516: val_loss did not improve from 10.43213
 - 76s - loss: 9.9554 - val_loss: 11.7971
Epoch 1517/8000

Epoch 01517: val_loss did not improve from 10.43213
 - 76s - loss: 10.2396 - val_loss: 11.4876
Epoch 1518/8000

Epoch 01518: val_loss did not improve from 10.43213
 - 76s - loss: 10.7405 - val_loss: 11.2885
Epoch 1519/8000

Epoch 01519: val_loss did not improve from 10.43213
 - 76s - loss: 10.8888 - val_loss: 11.6144
Epoch 1520/8000

Epoch 01520: val_loss did not improve from 10.43213
 - 75s - loss: 10.5241 - val_loss: 11.2770
Epoch 1521/8000

Epoch 01521: val_loss did not improve from 10.43213
 - 76s - loss: 10.4434 - val_loss: 10.8684
Epoch 1522/8000

Epoch 01522: val_loss did not improve from 10.43213
 - 75s - loss: 10.5062 - val_loss: 10.6795
Epoch 1523/8000

Epoch 01523: val_loss did not improve from 10.43213
 - 76s - loss: 10.1475 - val_loss: 10.6787
Epoch 1524/8000

Epoch 01524: val_loss did not improve from 10.43213
 - 76s - loss: 10.2862 - val_loss: 12.7427
Epoch 1525/8000

Epoch 01525: val_loss did not improve from 10.43213
 - 76s - loss: 11.1247 - val_loss: 11.0887
Epoch 1526/8000

Epoch 01526: val_loss did not improve from 10.43213
 - 76s - loss: 10.0279 - val_loss: 10.6503
Epoch 1527/8000

Epoch 01527: val_loss did not improve from 10.43213
 - 75s - loss: 9.8836 - val_loss: 10.7038
Epoch 1528/8000

Epoch 01528: val_loss did not improve from 10.43213
 - 76s - loss: 9.8905 - val_loss: 11.1270
Epoch 1529/8000

Epoch 01529: val_loss did not improve from 10.43213
 - 75s - loss: 10.3982 - val_loss: 11.9075
Epoch 1530/8000

Epoch 01530: val_loss did not improve from 10.43213
 - 76s - loss: 10.5147 - val_loss: 13.3765
Epoch 1531/8000

Epoch 01531: val_loss did not improve from 10.43213
 - 76s - loss: 11.8180 - val_loss: 11.3244
Epoch 1532/8000

Epoch 01532: val_loss did not improve from 10.43213
 - 76s - loss: 10.3978 - val_loss: 11.0047
Epoch 1533/8000

Epoch 01533: val_loss did not improve from 10.43213
 - 76s - loss: 10.0990 - val_loss: 12.3465
Epoch 1534/8000

Epoch 01534: val_loss did not improve from 10.43213
 - 75s - loss: 10.7022 - val_loss: 11.3262
Epoch 1535/8000

Epoch 01535: val_loss did not improve from 10.43213
 - 76s - loss: 10.1193 - val_loss: 11.2895
Epoch 1536/8000

Epoch 01536: val_loss did not improve from 10.43213
 - 75s - loss: 10.3682 - val_loss: 11.4454
Epoch 1537/8000

Epoch 01537: val_loss did not improve from 10.43213
 - 76s - loss: 11.0061 - val_loss: 12.2630
Epoch 1538/8000

Epoch 01538: val_loss did not improve from 10.43213
 - 76s - loss: 11.7365 - val_loss: 12.0588
Epoch 1539/8000

Epoch 01539: val_loss did not improve from 10.43213
 - 76s - loss: 11.2018 - val_loss: 11.3437
Epoch 1540/8000

Epoch 01540: val_loss did not improve from 10.43213
 - 76s - loss: 10.7724 - val_loss: 11.2426
Epoch 1541/8000

Epoch 01541: val_loss did not improve from 10.43213
 - 75s - loss: 10.3578 - val_loss: 11.7830
Epoch 1542/8000

Epoch 01542: val_loss did not improve from 10.43213
 - 76s - loss: 10.5377 - val_loss: 11.4362
Epoch 1543/8000

Epoch 01543: val_loss did not improve from 10.43213
 - 75s - loss: 12.0102 - val_loss: 13.5147
Epoch 1544/8000

Epoch 01544: val_loss did not improve from 10.43213
 - 76s - loss: 12.2514 - val_loss: 11.9167
Epoch 1545/8000

Epoch 01545: val_loss did not improve from 10.43213
 - 76s - loss: 11.1237 - val_loss: 12.4100
Epoch 1546/8000

Epoch 01546: val_loss did not improve from 10.43213
 - 76s - loss: 11.4777 - val_loss: 11.5339
Epoch 1547/8000

Epoch 01547: val_loss did not improve from 10.43213
 - 76s - loss: 10.6954 - val_loss: 11.9214
Epoch 1548/8000

Epoch 01548: val_loss did not improve from 10.43213
 - 75s - loss: 10.8867 - val_loss: 12.1295
Epoch 1549/8000

Epoch 01549: val_loss did not improve from 10.43213
 - 76s - loss: 11.5267 - val_loss: 11.8766
Epoch 1550/8000

Epoch 01550: val_loss did not improve from 10.43213
 - 75s - loss: 11.2467 - val_loss: 11.6131
Epoch 1551/8000

Epoch 01551: val_loss did not improve from 10.43213
 - 76s - loss: 11.7474 - val_loss: 11.6779
Epoch 1552/8000

Epoch 01552: val_loss did not improve from 10.43213
 - 75s - loss: 11.0233 - val_loss: 12.2078
Epoch 1553/8000

Epoch 01553: val_loss did not improve from 10.43213
 - 76s - loss: 11.1242 - val_loss: 12.5144
Epoch 1554/8000

Epoch 01554: val_loss did not improve from 10.43213
 - 76s - loss: 11.7779 - val_loss: 12.3303
Epoch 1555/8000

Epoch 01555: val_loss did not improve from 10.43213
 - 75s - loss: 12.5085 - val_loss: 12.8033
Epoch 1556/8000

Epoch 01556: val_loss did not improve from 10.43213
 - 76s - loss: 13.0977 - val_loss: 12.9935
Epoch 1557/8000

Epoch 01557: val_loss did not improve from 10.43213
 - 75s - loss: 11.5867 - val_loss: 11.5764
Epoch 1558/8000

Epoch 01558: val_loss did not improve from 10.43213
 - 76s - loss: 10.8823 - val_loss: 11.2740
Epoch 1559/8000

Epoch 01559: val_loss did not improve from 10.43213
 - 76s - loss: 10.8093 - val_loss: 11.3129
Epoch 1560/8000

Epoch 01560: val_loss did not improve from 10.43213
 - 76s - loss: 10.9172 - val_loss: 12.1069
Epoch 1561/8000

Epoch 01561: val_loss did not improve from 10.43213
 - 76s - loss: 11.4647 - val_loss: 11.4976
Epoch 1562/8000

Epoch 01562: val_loss did not improve from 10.43213
 - 75s - loss: 10.6533 - val_loss: 10.9488
Epoch 1563/8000

Epoch 01563: val_loss did not improve from 10.43213
 - 76s - loss: 10.6495 - val_loss: 11.4315
Epoch 1564/8000

Epoch 01564: val_loss did not improve from 10.43213
 - 75s - loss: 10.7946 - val_loss: 11.1425
Epoch 1565/8000

Epoch 01565: val_loss did not improve from 10.43213
 - 76s - loss: 10.5361 - val_loss: 10.9043
Epoch 1566/8000

Epoch 01566: val_loss did not improve from 10.43213
 - 75s - loss: 10.5534 - val_loss: 10.9902
Epoch 1567/8000

Epoch 01567: val_loss did not improve from 10.43213
 - 75s - loss: 10.3158 - val_loss: 10.6048
Epoch 1568/8000

Epoch 01568: val_loss did not improve from 10.43213
 - 76s - loss: 10.8058 - val_loss: 11.7108
Epoch 1569/8000

Epoch 01569: val_loss did not improve from 10.43213
 - 75s - loss: 11.7377 - val_loss: 11.6425
Epoch 1570/8000

Epoch 01570: val_loss did not improve from 10.43213
 - 76s - loss: 11.0529 - val_loss: 11.4204
Epoch 1571/8000

Epoch 01571: val_loss did not improve from 10.43213
 - 75s - loss: 10.7319 - val_loss: 10.8145
Epoch 1572/8000

Epoch 01572: val_loss did not improve from 10.43213
 - 76s - loss: 10.9059 - val_loss: 11.3024
Epoch 1573/8000

Epoch 01573: val_loss did not improve from 10.43213
 - 76s - loss: 10.8055 - val_loss: 11.6307
Epoch 1574/8000

Epoch 01574: val_loss did not improve from 10.43213
 - 76s - loss: 10.6717 - val_loss: 11.0100
Epoch 1575/8000

Epoch 01575: val_loss did not improve from 10.43213
 - 76s - loss: 10.5648 - val_loss: 10.9096
Epoch 1576/8000

Epoch 01576: val_loss did not improve from 10.43213
 - 75s - loss: 10.6963 - val_loss: 10.9887
Epoch 1577/8000

Epoch 01577: val_loss did not improve from 10.43213
 - 76s - loss: 10.2164 - val_loss: 11.9385
Epoch 1578/8000

Epoch 01578: val_loss did not improve from 10.43213
 - 75s - loss: 10.6197 - val_loss: 11.5010
Epoch 1579/8000

Epoch 01579: val_loss did not improve from 10.43213
 - 76s - loss: 10.2649 - val_loss: 10.9287
Epoch 1580/8000

Epoch 01580: val_loss did not improve from 10.43213
 - 76s - loss: 9.9325 - val_loss: 11.0629
Epoch 1581/8000

Epoch 01581: val_loss did not improve from 10.43213
 - 75s - loss: 9.9832 - val_loss: 10.8768
Epoch 1582/8000

Epoch 01582: val_loss did not improve from 10.43213
 - 75s - loss: 10.2304 - val_loss: 10.8140
Epoch 1583/8000

Epoch 01583: val_loss did not improve from 10.43213
 - 75s - loss: 10.9644 - val_loss: 12.0516
Epoch 1584/8000

Epoch 01584: val_loss did not improve from 10.43213
 - 75s - loss: 10.8088 - val_loss: 10.9699
Epoch 1585/8000

Epoch 01585: val_loss improved from 10.43213 to 10.38035, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 10.1594 - val_loss: 10.3803
Epoch 1586/8000

Epoch 01586: val_loss did not improve from 10.38035
 - 76s - loss: 10.3253 - val_loss: 11.7045
Epoch 1587/8000

Epoch 01587: val_loss did not improve from 10.38035
 - 76s - loss: 11.4493 - val_loss: 12.1071
Epoch 1588/8000

Epoch 01588: val_loss did not improve from 10.38035
 - 76s - loss: 11.1682 - val_loss: 11.3272
Epoch 1589/8000

Epoch 01589: val_loss did not improve from 10.38035
 - 76s - loss: 10.3790 - val_loss: 10.7860
Epoch 1590/8000

Epoch 01590: val_loss did not improve from 10.38035
 - 75s - loss: 10.1209 - val_loss: 11.0322
Epoch 1591/8000

Epoch 01591: val_loss did not improve from 10.38035
 - 76s - loss: 10.3316 - val_loss: 12.2328
Epoch 1592/8000

Epoch 01592: val_loss did not improve from 10.38035
 - 75s - loss: 10.4152 - val_loss: 11.6061
Epoch 1593/8000

Epoch 01593: val_loss did not improve from 10.38035
 - 76s - loss: 10.8556 - val_loss: 11.3101
Epoch 1594/8000

Epoch 01594: val_loss did not improve from 10.38035
 - 76s - loss: 10.3428 - val_loss: 11.0023
Epoch 1595/8000

Epoch 01595: val_loss did not improve from 10.38035
 - 76s - loss: 10.2840 - val_loss: 11.8623
Epoch 1596/8000

Epoch 01596: val_loss did not improve from 10.38035
 - 76s - loss: 10.5865 - val_loss: 10.7788
Epoch 1597/8000

Epoch 01597: val_loss did not improve from 10.38035
 - 76s - loss: 10.7317 - val_loss: 11.1615
Epoch 1598/8000

Epoch 01598: val_loss did not improve from 10.38035
 - 76s - loss: 10.3485 - val_loss: 11.0813
Epoch 1599/8000

Epoch 01599: val_loss did not improve from 10.38035
 - 75s - loss: 10.7450 - val_loss: 11.7187
Epoch 1600/8000

Epoch 01600: val_loss did not improve from 10.38035
 - 76s - loss: 10.5006 - val_loss: 11.4388
Epoch 1601/8000

Epoch 01601: val_loss did not improve from 10.38035
 - 76s - loss: 10.3347 - val_loss: 12.5229
Epoch 1602/8000

Epoch 01602: val_loss did not improve from 10.38035
 - 76s - loss: 10.6181 - val_loss: 10.8258
Epoch 1603/8000

Epoch 01603: val_loss did not improve from 10.38035
 - 76s - loss: 10.2515 - val_loss: 11.4756
Epoch 1604/8000

Epoch 01604: val_loss did not improve from 10.38035
 - 75s - loss: 10.3539 - val_loss: 11.7391
Epoch 1605/8000

Epoch 01605: val_loss did not improve from 10.38035
 - 76s - loss: 10.3361 - val_loss: 11.7288
Epoch 1606/8000

Epoch 01606: val_loss did not improve from 10.38035
 - 75s - loss: 10.6493 - val_loss: 11.3612
Epoch 1607/8000

Epoch 01607: val_loss did not improve from 10.38035
 - 76s - loss: 10.6742 - val_loss: 11.4438
Epoch 1608/8000

Epoch 01608: val_loss did not improve from 10.38035
 - 76s - loss: 10.1095 - val_loss: 10.8133
Epoch 1609/8000

Epoch 01609: val_loss did not improve from 10.38035
 - 76s - loss: 10.0152 - val_loss: 11.0168
Epoch 1610/8000

Epoch 01610: val_loss did not improve from 10.38035
 - 76s - loss: 9.8387 - val_loss: 10.7011
Epoch 1611/8000

Epoch 01611: val_loss did not improve from 10.38035
 - 76s - loss: 9.8637 - val_loss: 11.0261
Epoch 1612/8000

Epoch 01612: val_loss did not improve from 10.38035
 - 76s - loss: 9.6447 - val_loss: 10.9315
Epoch 1613/8000

Epoch 01613: val_loss did not improve from 10.38035
 - 75s - loss: 10.1538 - val_loss: 11.2740
Epoch 1614/8000

Epoch 01614: val_loss did not improve from 10.38035
 - 76s - loss: 9.9757 - val_loss: 10.9668
Epoch 1615/8000

Epoch 01615: val_loss did not improve from 10.38035
 - 75s - loss: 10.0269 - val_loss: 11.3779
Epoch 1616/8000

Epoch 01616: val_loss did not improve from 10.38035
 - 76s - loss: 9.8496 - val_loss: 10.9839
Epoch 1617/8000

Epoch 01617: val_loss did not improve from 10.38035
 - 76s - loss: 10.0789 - val_loss: 10.9508
Epoch 1618/8000

Epoch 01618: val_loss improved from 10.38035 to 10.36283, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 9.5198 - val_loss: 10.3628
Epoch 1619/8000

Epoch 01619: val_loss did not improve from 10.36283
 - 76s - loss: 9.4781 - val_loss: 10.8470
Epoch 1620/8000

Epoch 01620: val_loss did not improve from 10.36283
 - 75s - loss: 9.7192 - val_loss: 10.9745
Epoch 1621/8000

Epoch 01621: val_loss did not improve from 10.36283
 - 76s - loss: 9.6726 - val_loss: 10.7243
Epoch 1622/8000

Epoch 01622: val_loss did not improve from 10.36283
 - 76s - loss: 9.9901 - val_loss: 11.3717
Epoch 1623/8000

Epoch 01623: val_loss did not improve from 10.36283
 - 76s - loss: 10.1587 - val_loss: 10.8835
Epoch 1624/8000

Epoch 01624: val_loss did not improve from 10.36283
 - 76s - loss: 10.0704 - val_loss: 11.0010
Epoch 1625/8000

Epoch 01625: val_loss did not improve from 10.36283
 - 75s - loss: 9.7651 - val_loss: 11.1921
Epoch 1626/8000

Epoch 01626: val_loss did not improve from 10.36283
 - 76s - loss: 9.7460 - val_loss: 11.0523
Epoch 1627/8000

Epoch 01627: val_loss did not improve from 10.36283
 - 75s - loss: 9.7560 - val_loss: 10.9167
Epoch 1628/8000

Epoch 01628: val_loss did not improve from 10.36283
 - 76s - loss: 9.4016 - val_loss: 10.4488
Epoch 1629/8000

Epoch 01629: val_loss did not improve from 10.36283
 - 75s - loss: 9.9285 - val_loss: 11.6708
Epoch 1630/8000

Epoch 01630: val_loss did not improve from 10.36283
 - 76s - loss: 10.1265 - val_loss: 11.2273
Epoch 1631/8000

Epoch 01631: val_loss did not improve from 10.36283
 - 76s - loss: 9.9767 - val_loss: 12.0416
Epoch 1632/8000

Epoch 01632: val_loss did not improve from 10.36283
 - 75s - loss: 10.1941 - val_loss: 10.8148
Epoch 1633/8000

Epoch 01633: val_loss did not improve from 10.36283
 - 76s - loss: 10.2170 - val_loss: 13.4090
Epoch 1634/8000

Epoch 01634: val_loss did not improve from 10.36283
 - 75s - loss: 10.4085 - val_loss: 12.6414
Epoch 1635/8000

Epoch 01635: val_loss did not improve from 10.36283
 - 76s - loss: 10.1778 - val_loss: 11.7650
Epoch 1636/8000

Epoch 01636: val_loss did not improve from 10.36283
 - 76s - loss: 9.8853 - val_loss: 11.0820
Epoch 1637/8000

Epoch 01637: val_loss did not improve from 10.36283
 - 76s - loss: 9.8247 - val_loss: 10.6270
Epoch 1638/8000

Epoch 01638: val_loss did not improve from 10.36283
 - 76s - loss: 10.3388 - val_loss: 11.4671
Epoch 1639/8000

Epoch 01639: val_loss did not improve from 10.36283
 - 76s - loss: 10.0391 - val_loss: 11.0026
Epoch 1640/8000

Epoch 01640: val_loss did not improve from 10.36283
 - 76s - loss: 10.5819 - val_loss: 11.8029
Epoch 1641/8000

Epoch 01641: val_loss did not improve from 10.36283
 - 75s - loss: 10.8335 - val_loss: 12.3117
Epoch 1642/8000

Epoch 01642: val_loss did not improve from 10.36283
 - 76s - loss: 10.5205 - val_loss: 11.6231
Epoch 1643/8000

Epoch 01643: val_loss did not improve from 10.36283
 - 75s - loss: 12.1271 - val_loss: 11.9141
Epoch 1644/8000

Epoch 01644: val_loss did not improve from 10.36283
 - 75s - loss: 11.3597 - val_loss: 11.8160
Epoch 1645/8000

Epoch 01645: val_loss did not improve from 10.36283
 - 76s - loss: 11.2911 - val_loss: 11.3851
Epoch 1646/8000

Epoch 01646: val_loss did not improve from 10.36283
 - 75s - loss: 10.9341 - val_loss: 11.5080
Epoch 1647/8000

Epoch 01647: val_loss did not improve from 10.36283
 - 76s - loss: 11.5560 - val_loss: 11.4982
Epoch 1648/8000

Epoch 01648: val_loss did not improve from 10.36283
 - 75s - loss: 11.1020 - val_loss: 11.7683
Epoch 1649/8000

Epoch 01649: val_loss did not improve from 10.36283
 - 76s - loss: 11.1297 - val_loss: 11.4904
Epoch 1650/8000

Epoch 01650: val_loss did not improve from 10.36283
 - 76s - loss: 12.9303 - val_loss: 14.9330
Epoch 1651/8000

Epoch 01651: val_loss did not improve from 10.36283
 - 76s - loss: 12.2530 - val_loss: 12.0005
Epoch 1652/8000

Epoch 01652: val_loss did not improve from 10.36283
 - 76s - loss: 11.1416 - val_loss: 11.4987
Epoch 1653/8000

Epoch 01653: val_loss did not improve from 10.36283
 - 75s - loss: 10.6588 - val_loss: 11.8841
Epoch 1654/8000

Epoch 01654: val_loss did not improve from 10.36283
 - 76s - loss: 10.9120 - val_loss: 12.0717
Epoch 1655/8000

Epoch 01655: val_loss did not improve from 10.36283
 - 75s - loss: 11.3198 - val_loss: 11.1661
Epoch 1656/8000

Epoch 01656: val_loss did not improve from 10.36283
 - 76s - loss: 10.7141 - val_loss: 11.1023
Epoch 1657/8000

Epoch 01657: val_loss did not improve from 10.36283
 - 75s - loss: 10.2322 - val_loss: 11.9777
Epoch 1658/8000

Epoch 01658: val_loss did not improve from 10.36283
 - 76s - loss: 10.4919 - val_loss: 11.4691
Epoch 1659/8000

Epoch 01659: val_loss did not improve from 10.36283
 - 76s - loss: 10.6268 - val_loss: 11.4416
Epoch 1660/8000

Epoch 01660: val_loss did not improve from 10.36283
 - 75s - loss: 10.3667 - val_loss: 12.4355
Epoch 1661/8000

Epoch 01661: val_loss did not improve from 10.36283
 - 76s - loss: 10.4987 - val_loss: 11.2858
Epoch 1662/8000

Epoch 01662: val_loss did not improve from 10.36283
 - 75s - loss: 10.1855 - val_loss: 11.0681
Epoch 1663/8000

Epoch 01663: val_loss did not improve from 10.36283
 - 76s - loss: 10.3912 - val_loss: 11.2379
Epoch 1664/8000

Epoch 01664: val_loss did not improve from 10.36283
 - 76s - loss: 10.0731 - val_loss: 12.0461
Epoch 1665/8000

Epoch 01665: val_loss did not improve from 10.36283
 - 76s - loss: 10.7346 - val_loss: 11.4101
Epoch 1666/8000

Epoch 01666: val_loss did not improve from 10.36283
 - 76s - loss: 10.0129 - val_loss: 10.7187
Epoch 1667/8000

Epoch 01667: val_loss did not improve from 10.36283
 - 75s - loss: 10.0611 - val_loss: 11.5714
Epoch 1668/8000

Epoch 01668: val_loss did not improve from 10.36283
 - 76s - loss: 10.3914 - val_loss: 10.9100
Epoch 1669/8000

Epoch 01669: val_loss did not improve from 10.36283
 - 75s - loss: 10.1178 - val_loss: 11.0785
Epoch 1670/8000

Epoch 01670: val_loss did not improve from 10.36283
 - 76s - loss: 9.8965 - val_loss: 11.1126
Epoch 1671/8000

Epoch 01671: val_loss did not improve from 10.36283
 - 75s - loss: 10.5267 - val_loss: 10.8733
Epoch 1672/8000

Epoch 01672: val_loss did not improve from 10.36283
 - 75s - loss: 9.7153 - val_loss: 10.8231
Epoch 1673/8000

Epoch 01673: val_loss did not improve from 10.36283
 - 76s - loss: 10.2740 - val_loss: 10.9786
Epoch 1674/8000

Epoch 01674: val_loss did not improve from 10.36283
 - 75s - loss: 10.0488 - val_loss: 11.9819
Epoch 1675/8000

Epoch 01675: val_loss did not improve from 10.36283
 - 76s - loss: 10.4194 - val_loss: 11.1527
Epoch 1676/8000

Epoch 01676: val_loss did not improve from 10.36283
 - 75s - loss: 10.0670 - val_loss: 10.7636
Epoch 1677/8000

Epoch 01677: val_loss did not improve from 10.36283
 - 76s - loss: 9.6280 - val_loss: 10.5250
Epoch 1678/8000

Epoch 01678: val_loss did not improve from 10.36283
 - 76s - loss: 9.8374 - val_loss: 10.6737
Epoch 1679/8000

Epoch 01679: val_loss did not improve from 10.36283
 - 76s - loss: 9.7325 - val_loss: 10.7073
Epoch 1680/8000

Epoch 01680: val_loss did not improve from 10.36283
 - 76s - loss: 9.9284 - val_loss: 10.7747
Epoch 1681/8000

Epoch 01681: val_loss did not improve from 10.36283
 - 75s - loss: 9.7017 - val_loss: 10.8808
Epoch 1682/8000

Epoch 01682: val_loss did not improve from 10.36283
 - 76s - loss: 9.9895 - val_loss: 10.6811
Epoch 1683/8000

Epoch 01683: val_loss improved from 10.36283 to 10.21025, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 9.7607 - val_loss: 10.2103
Epoch 1684/8000

Epoch 01684: val_loss did not improve from 10.21025
 - 76s - loss: 9.2749 - val_loss: 11.3673
Epoch 1685/8000

Epoch 01685: val_loss improved from 10.21025 to 10.13729, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 9.2408 - val_loss: 10.1373
Epoch 1686/8000

Epoch 01686: val_loss did not improve from 10.13729
 - 75s - loss: 9.6140 - val_loss: 10.7647
Epoch 1687/8000

Epoch 01687: val_loss did not improve from 10.13729
 - 75s - loss: 10.1194 - val_loss: 11.9038
Epoch 1688/8000

Epoch 01688: val_loss did not improve from 10.13729
 - 75s - loss: 10.0670 - val_loss: 10.4218
Epoch 1689/8000

Epoch 01689: val_loss did not improve from 10.13729
 - 75s - loss: 9.5190 - val_loss: 10.3758
Epoch 1690/8000

Epoch 01690: val_loss did not improve from 10.13729
 - 75s - loss: 9.5635 - val_loss: 10.3840
Epoch 1691/8000

Epoch 01691: val_loss did not improve from 10.13729
 - 76s - loss: 9.7095 - val_loss: 11.2943
Epoch 1692/8000

Epoch 01692: val_loss did not improve from 10.13729
 - 76s - loss: 9.7520 - val_loss: 10.8853
Epoch 1693/8000

Epoch 01693: val_loss did not improve from 10.13729
 - 76s - loss: 9.2548 - val_loss: 10.6403
Epoch 1694/8000

Epoch 01694: val_loss did not improve from 10.13729
 - 76s - loss: 9.4110 - val_loss: 11.3049
Epoch 1695/8000

Epoch 01695: val_loss did not improve from 10.13729
 - 75s - loss: 9.6023 - val_loss: 10.7830
Epoch 1696/8000

Epoch 01696: val_loss did not improve from 10.13729
 - 76s - loss: 9.7853 - val_loss: 10.5831
Epoch 1697/8000

Epoch 01697: val_loss did not improve from 10.13729
 - 75s - loss: 9.5938 - val_loss: 10.8087
Epoch 1698/8000

Epoch 01698: val_loss did not improve from 10.13729
 - 76s - loss: 9.5029 - val_loss: 11.3804
Epoch 1699/8000

Epoch 01699: val_loss did not improve from 10.13729
 - 76s - loss: 9.9688 - val_loss: 10.6556
Epoch 1700/8000

Epoch 01700: val_loss did not improve from 10.13729
 - 76s - loss: 9.9431 - val_loss: 10.6638
Epoch 1701/8000

Epoch 01701: val_loss did not improve from 10.13729
 - 76s - loss: 9.7811 - val_loss: 11.3709
Epoch 1702/8000

Epoch 01702: val_loss did not improve from 10.13729
 - 75s - loss: 9.5650 - val_loss: 10.7632
Epoch 1703/8000

Epoch 01703: val_loss did not improve from 10.13729
 - 76s - loss: 9.7795 - val_loss: 10.7606
Epoch 1704/8000

Epoch 01704: val_loss did not improve from 10.13729
 - 75s - loss: 9.3157 - val_loss: 10.6758
Epoch 1705/8000

Epoch 01705: val_loss did not improve from 10.13729
 - 76s - loss: 9.4077 - val_loss: 10.8298
Epoch 1706/8000

Epoch 01706: val_loss did not improve from 10.13729
 - 75s - loss: 10.0369 - val_loss: 11.9314
Epoch 1707/8000

Epoch 01707: val_loss did not improve from 10.13729
 - 75s - loss: 9.9458 - val_loss: 10.9511
Epoch 1708/8000

Epoch 01708: val_loss did not improve from 10.13729
 - 75s - loss: 9.6365 - val_loss: 10.8484
Epoch 1709/8000

Epoch 01709: val_loss did not improve from 10.13729
 - 75s - loss: 9.9468 - val_loss: 10.8331
Epoch 1710/8000

Epoch 01710: val_loss did not improve from 10.13729
 - 76s - loss: 9.6059 - val_loss: 10.7468
Epoch 1711/8000

Epoch 01711: val_loss did not improve from 10.13729
 - 75s - loss: 9.7853 - val_loss: 10.7545
Epoch 1712/8000

Epoch 01712: val_loss did not improve from 10.13729
 - 76s - loss: 10.1060 - val_loss: 11.8893
Epoch 1713/8000

Epoch 01713: val_loss did not improve from 10.13729
 - 76s - loss: 9.7675 - val_loss: 10.8112
Epoch 1714/8000

Epoch 01714: val_loss did not improve from 10.13729
 - 76s - loss: 9.6636 - val_loss: 10.7201
Epoch 1715/8000

Epoch 01715: val_loss did not improve from 10.13729
 - 76s - loss: 9.3829 - val_loss: 11.4000
Epoch 1716/8000

Epoch 01716: val_loss did not improve from 10.13729
 - 75s - loss: 9.5633 - val_loss: 10.6537
Epoch 1717/8000

Epoch 01717: val_loss did not improve from 10.13729
 - 76s - loss: 9.6631 - val_loss: 10.6842
Epoch 1718/8000

Epoch 01718: val_loss did not improve from 10.13729
 - 75s - loss: 9.3405 - val_loss: 10.4416
Epoch 1719/8000

Epoch 01719: val_loss did not improve from 10.13729
 - 76s - loss: 9.3444 - val_loss: 11.9083
Epoch 1720/8000

Epoch 01720: val_loss did not improve from 10.13729
 - 76s - loss: 9.2508 - val_loss: 10.6348
Epoch 1721/8000

Epoch 01721: val_loss did not improve from 10.13729
 - 76s - loss: 9.9739 - val_loss: 10.7899
Epoch 1722/8000

Epoch 01722: val_loss did not improve from 10.13729
 - 75s - loss: 10.2435 - val_loss: 12.7098
Epoch 1723/8000

Epoch 01723: val_loss did not improve from 10.13729
 - 75s - loss: 11.0365 - val_loss: 11.2879
Epoch 1724/8000

Epoch 01724: val_loss did not improve from 10.13729
 - 76s - loss: 10.5332 - val_loss: 11.2081
Epoch 1725/8000

Epoch 01725: val_loss did not improve from 10.13729
 - 75s - loss: 10.4910 - val_loss: 11.4961
Epoch 1726/8000

Epoch 01726: val_loss did not improve from 10.13729
 - 76s - loss: 10.3218 - val_loss: 10.5884
Epoch 1727/8000

Epoch 01727: val_loss did not improve from 10.13729
 - 76s - loss: 9.9254 - val_loss: 10.9686
Epoch 1728/8000

Epoch 01728: val_loss did not improve from 10.13729
 - 76s - loss: 9.8513 - val_loss: 10.7898
Epoch 1729/8000

Epoch 01729: val_loss did not improve from 10.13729
 - 76s - loss: 9.8767 - val_loss: 11.2606
Epoch 1730/8000

Epoch 01730: val_loss did not improve from 10.13729
 - 75s - loss: 9.4305 - val_loss: 10.1420
Epoch 1731/8000

Epoch 01731: val_loss did not improve from 10.13729
 - 76s - loss: 9.5387 - val_loss: 10.3801
Epoch 1732/8000

Epoch 01732: val_loss did not improve from 10.13729
 - 75s - loss: 9.5651 - val_loss: 11.0890
Epoch 1733/8000

Epoch 01733: val_loss did not improve from 10.13729
 - 76s - loss: 9.3896 - val_loss: 10.4563
Epoch 1734/8000

Epoch 01734: val_loss did not improve from 10.13729
 - 76s - loss: 9.5821 - val_loss: 10.2824
Epoch 1735/8000

Epoch 01735: val_loss did not improve from 10.13729
 - 76s - loss: 9.4356 - val_loss: 10.7184
Epoch 1736/8000

Epoch 01736: val_loss did not improve from 10.13729
 - 75s - loss: 9.5984 - val_loss: 11.7692
Epoch 1737/8000

Epoch 01737: val_loss did not improve from 10.13729
 - 75s - loss: 9.6308 - val_loss: 11.2212
Epoch 1738/8000

Epoch 01738: val_loss did not improve from 10.13729
 - 76s - loss: 9.7081 - val_loss: 11.1023
Epoch 1739/8000

Epoch 01739: val_loss did not improve from 10.13729
 - 75s - loss: 9.7244 - val_loss: 11.0074
Epoch 1740/8000

Epoch 01740: val_loss did not improve from 10.13729
 - 76s - loss: 9.9993 - val_loss: 10.7621
Epoch 1741/8000

Epoch 01741: val_loss did not improve from 10.13729
 - 76s - loss: 9.7534 - val_loss: 11.2554
Epoch 1742/8000

Epoch 01742: val_loss did not improve from 10.13729
 - 76s - loss: 10.2914 - val_loss: 11.6193
Epoch 1743/8000

Epoch 01743: val_loss did not improve from 10.13729
 - 76s - loss: 9.6672 - val_loss: 11.4646
Epoch 1744/8000

Epoch 01744: val_loss did not improve from 10.13729
 - 75s - loss: 9.9990 - val_loss: 11.6624
Epoch 1745/8000

Epoch 01745: val_loss did not improve from 10.13729
 - 76s - loss: 9.8819 - val_loss: 10.8272
Epoch 1746/8000

Epoch 01746: val_loss did not improve from 10.13729
 - 75s - loss: 9.5344 - val_loss: 10.9889
Epoch 1747/8000

Epoch 01747: val_loss did not improve from 10.13729
 - 76s - loss: 9.4758 - val_loss: 10.7467
Epoch 1748/8000

Epoch 01748: val_loss did not improve from 10.13729
 - 76s - loss: 9.4960 - val_loss: 10.9418
Epoch 1749/8000

Epoch 01749: val_loss did not improve from 10.13729
 - 76s - loss: 9.6625 - val_loss: 12.0585
Epoch 1750/8000

Epoch 01750: val_loss did not improve from 10.13729
 - 75s - loss: 9.8660 - val_loss: 11.0857
Epoch 1751/8000

Epoch 01751: val_loss did not improve from 10.13729
 - 75s - loss: 9.4609 - val_loss: 10.9455
Epoch 1752/8000

Epoch 01752: val_loss did not improve from 10.13729
 - 76s - loss: 9.5425 - val_loss: 12.2898
Epoch 1753/8000

Epoch 01753: val_loss did not improve from 10.13729
 - 75s - loss: 10.3578 - val_loss: 12.0004
Epoch 1754/8000

Epoch 01754: val_loss did not improve from 10.13729
 - 76s - loss: 10.2737 - val_loss: 10.9196
Epoch 1755/8000

Epoch 01755: val_loss did not improve from 10.13729
 - 76s - loss: 9.7008 - val_loss: 10.7971
Epoch 1756/8000

Epoch 01756: val_loss did not improve from 10.13729
 - 76s - loss: 10.3714 - val_loss: 11.4294
Epoch 1757/8000

Epoch 01757: val_loss did not improve from 10.13729
 - 76s - loss: 10.2323 - val_loss: 11.7109
Epoch 1758/8000

Epoch 01758: val_loss did not improve from 10.13729
 - 75s - loss: 10.3616 - val_loss: 11.5185
Epoch 1759/8000

Epoch 01759: val_loss did not improve from 10.13729
 - 76s - loss: 10.3883 - val_loss: 11.3090
Epoch 1760/8000

Epoch 01760: val_loss did not improve from 10.13729
 - 75s - loss: 9.9295 - val_loss: 10.6582
Epoch 1761/8000

Epoch 01761: val_loss did not improve from 10.13729
 - 76s - loss: 9.7786 - val_loss: 11.3886
Epoch 1762/8000

Epoch 01762: val_loss did not improve from 10.13729
 - 76s - loss: 10.6470 - val_loss: 11.5616
Epoch 1763/8000

Epoch 01763: val_loss did not improve from 10.13729
 - 76s - loss: 10.4604 - val_loss: 11.2847
Epoch 1764/8000

Epoch 01764: val_loss did not improve from 10.13729
 - 76s - loss: 10.1205 - val_loss: 10.7093
Epoch 1765/8000

Epoch 01765: val_loss did not improve from 10.13729
 - 75s - loss: 9.7633 - val_loss: 11.0365
Epoch 1766/8000

Epoch 01766: val_loss did not improve from 10.13729
 - 76s - loss: 10.0547 - val_loss: 12.1618
Epoch 1767/8000

Epoch 01767: val_loss did not improve from 10.13729
 - 75s - loss: 10.5057 - val_loss: 11.1368
Epoch 1768/8000

Epoch 01768: val_loss did not improve from 10.13729
 - 76s - loss: 10.0241 - val_loss: 11.1091
Epoch 1769/8000

Epoch 01769: val_loss did not improve from 10.13729
 - 76s - loss: 9.8419 - val_loss: 10.9378
Epoch 1770/8000

Epoch 01770: val_loss did not improve from 10.13729
 - 76s - loss: 9.8635 - val_loss: 11.0349
Epoch 1771/8000

Epoch 01771: val_loss did not improve from 10.13729
 - 76s - loss: 9.7740 - val_loss: 12.0358
Epoch 1772/8000

Epoch 01772: val_loss did not improve from 10.13729
 - 75s - loss: 10.2193 - val_loss: 11.7656
Epoch 1773/8000

Epoch 01773: val_loss did not improve from 10.13729
 - 76s - loss: 10.4907 - val_loss: 11.5093
Epoch 1774/8000

Epoch 01774: val_loss did not improve from 10.13729
 - 75s - loss: 11.2558 - val_loss: 12.0485
Epoch 1775/8000

Epoch 01775: val_loss did not improve from 10.13729
 - 76s - loss: 10.6081 - val_loss: 11.7247
Epoch 1776/8000

Epoch 01776: val_loss did not improve from 10.13729
 - 76s - loss: 10.8520 - val_loss: 11.5065
Epoch 1777/8000

Epoch 01777: val_loss did not improve from 10.13729
 - 75s - loss: 10.8252 - val_loss: 11.4015
Epoch 1778/8000

Epoch 01778: val_loss did not improve from 10.13729
 - 75s - loss: 11.2315 - val_loss: 12.0988
Epoch 1779/8000

Epoch 01779: val_loss did not improve from 10.13729
 - 75s - loss: 10.6764 - val_loss: 11.2133
Epoch 1780/8000

Epoch 01780: val_loss did not improve from 10.13729
 - 76s - loss: 10.4990 - val_loss: 12.2372
Epoch 1781/8000

Epoch 01781: val_loss did not improve from 10.13729
 - 75s - loss: 10.9863 - val_loss: 12.2941
Epoch 1782/8000

Epoch 01782: val_loss did not improve from 10.13729
 - 76s - loss: 10.2060 - val_loss: 10.9261
Epoch 1783/8000

Epoch 01783: val_loss did not improve from 10.13729
 - 76s - loss: 10.3270 - val_loss: 13.2156
Epoch 1784/8000

Epoch 01784: val_loss did not improve from 10.13729
 - 76s - loss: 11.0578 - val_loss: 12.4912
Epoch 1785/8000

Epoch 01785: val_loss did not improve from 10.13729
 - 76s - loss: 10.4921 - val_loss: 11.2667
Epoch 1786/8000

Epoch 01786: val_loss did not improve from 10.13729
 - 75s - loss: 10.3866 - val_loss: 11.5540
Epoch 1787/8000

Epoch 01787: val_loss did not improve from 10.13729
 - 76s - loss: 10.2249 - val_loss: 11.1210
Epoch 1788/8000

Epoch 01788: val_loss did not improve from 10.13729
 - 75s - loss: 9.8352 - val_loss: 11.0133
Epoch 1789/8000

Epoch 01789: val_loss did not improve from 10.13729
 - 76s - loss: 10.1586 - val_loss: 11.6940
Epoch 1790/8000

Epoch 01790: val_loss did not improve from 10.13729
 - 75s - loss: 10.0844 - val_loss: 11.6790
Epoch 1791/8000

Epoch 01791: val_loss did not improve from 10.13729
 - 76s - loss: 12.0490 - val_loss: 12.9649
Epoch 1792/8000

Epoch 01792: val_loss did not improve from 10.13729
 - 75s - loss: 10.9959 - val_loss: 12.0461
Epoch 1793/8000

Epoch 01793: val_loss did not improve from 10.13729
 - 75s - loss: 10.2371 - val_loss: 10.9670
Epoch 1794/8000

Epoch 01794: val_loss did not improve from 10.13729
 - 75s - loss: 10.3320 - val_loss: 11.6878
Epoch 1795/8000

Epoch 01795: val_loss did not improve from 10.13729
 - 75s - loss: 10.1722 - val_loss: 10.9116
Epoch 1796/8000

Epoch 01796: val_loss did not improve from 10.13729
 - 76s - loss: 10.0481 - val_loss: 10.9144
Epoch 1797/8000

Epoch 01797: val_loss did not improve from 10.13729
 - 76s - loss: 10.0234 - val_loss: 11.4517
Epoch 1798/8000

Epoch 01798: val_loss did not improve from 10.13729
 - 76s - loss: 10.1985 - val_loss: 11.1995
Epoch 1799/8000

Epoch 01799: val_loss did not improve from 10.13729
 - 76s - loss: 10.1854 - val_loss: 13.8206
Epoch 1800/8000

Epoch 01800: val_loss did not improve from 10.13729
 - 75s - loss: 11.2911 - val_loss: 12.5010
Epoch 1801/8000

Epoch 01801: val_loss did not improve from 10.13729
 - 76s - loss: 11.2714 - val_loss: 11.9749
Epoch 1802/8000

Epoch 01802: val_loss did not improve from 10.13729
 - 75s - loss: 10.7191 - val_loss: 11.7042
Epoch 1803/8000

Epoch 01803: val_loss did not improve from 10.13729
 - 76s - loss: 11.1599 - val_loss: 12.0691
Epoch 1804/8000

Epoch 01804: val_loss did not improve from 10.13729
 - 76s - loss: 11.0996 - val_loss: 11.3773
Epoch 1805/8000

Epoch 01805: val_loss did not improve from 10.13729
 - 76s - loss: 9.8647 - val_loss: 11.4325
Epoch 1806/8000

Epoch 01806: val_loss did not improve from 10.13729
 - 76s - loss: 10.4046 - val_loss: 11.1431
Epoch 1807/8000

Epoch 01807: val_loss did not improve from 10.13729
 - 75s - loss: 11.2885 - val_loss: 11.4520
Epoch 1808/8000

Epoch 01808: val_loss did not improve from 10.13729
 - 76s - loss: 11.2606 - val_loss: 13.0327
Epoch 1809/8000

Epoch 01809: val_loss did not improve from 10.13729
 - 75s - loss: 10.6344 - val_loss: 11.4527
Epoch 1810/8000

Epoch 01810: val_loss did not improve from 10.13729
 - 76s - loss: 11.4187 - val_loss: 12.7272
Epoch 1811/8000

Epoch 01811: val_loss did not improve from 10.13729
 - 76s - loss: 11.6212 - val_loss: 11.8723
Epoch 1812/8000

Epoch 01812: val_loss did not improve from 10.13729
 - 75s - loss: 11.3686 - val_loss: 11.9237
Epoch 1813/8000

Epoch 01813: val_loss did not improve from 10.13729
 - 76s - loss: 11.1936 - val_loss: 11.7942
Epoch 1814/8000

Epoch 01814: val_loss did not improve from 10.13729
 - 75s - loss: 10.7502 - val_loss: 11.7972
Epoch 1815/8000

Epoch 01815: val_loss did not improve from 10.13729
 - 76s - loss: 10.6074 - val_loss: 12.0343
Epoch 1816/8000

Epoch 01816: val_loss did not improve from 10.13729
 - 75s - loss: 10.6898 - val_loss: 11.0521
Epoch 1817/8000

Epoch 01817: val_loss did not improve from 10.13729
 - 76s - loss: 10.1297 - val_loss: 11.4159
Epoch 1818/8000

Epoch 01818: val_loss did not improve from 10.13729
 - 76s - loss: 10.4511 - val_loss: 12.2574
Epoch 1819/8000

Epoch 01819: val_loss did not improve from 10.13729
 - 76s - loss: 10.1516 - val_loss: 12.1551
Epoch 1820/8000

Epoch 01820: val_loss did not improve from 10.13729
 - 76s - loss: 11.5050 - val_loss: 12.1537
Epoch 1821/8000

Epoch 01821: val_loss did not improve from 10.13729
 - 76s - loss: 11.1523 - val_loss: 11.8386
Epoch 1822/8000

Epoch 01822: val_loss did not improve from 10.13729
 - 76s - loss: 9.9504 - val_loss: 10.8046
Epoch 1823/8000

Epoch 01823: val_loss did not improve from 10.13729
 - 75s - loss: 10.0736 - val_loss: 10.6727
Epoch 1824/8000

Epoch 01824: val_loss did not improve from 10.13729
 - 76s - loss: 10.2345 - val_loss: 11.5658
Epoch 1825/8000

Epoch 01825: val_loss did not improve from 10.13729
 - 75s - loss: 9.8869 - val_loss: 11.8757
Epoch 1826/8000

Epoch 01826: val_loss did not improve from 10.13729
 - 75s - loss: 9.8571 - val_loss: 10.6830
Epoch 1827/8000

Epoch 01827: val_loss did not improve from 10.13729
 - 76s - loss: 10.5634 - val_loss: 11.6133
Epoch 1828/8000

Epoch 01828: val_loss did not improve from 10.13729
 - 75s - loss: 10.3500 - val_loss: 11.9315
Epoch 1829/8000

Epoch 01829: val_loss did not improve from 10.13729
 - 76s - loss: 11.0935 - val_loss: 12.5719
Epoch 1830/8000

Epoch 01830: val_loss did not improve from 10.13729
 - 75s - loss: 10.4873 - val_loss: 11.3575
Epoch 1831/8000

Epoch 01831: val_loss did not improve from 10.13729
 - 76s - loss: 10.3650 - val_loss: 11.6678
Epoch 1832/8000

Epoch 01832: val_loss did not improve from 10.13729
 - 76s - loss: 10.5850 - val_loss: 11.8270
Epoch 1833/8000

Epoch 01833: val_loss did not improve from 10.13729
 - 76s - loss: 10.8195 - val_loss: 12.0628
Epoch 1834/8000

Epoch 01834: val_loss did not improve from 10.13729
 - 76s - loss: 10.7849 - val_loss: 11.4155
Epoch 1835/8000

Epoch 01835: val_loss did not improve from 10.13729
 - 75s - loss: 10.3835 - val_loss: 11.6097
Epoch 1836/8000

Epoch 01836: val_loss did not improve from 10.13729
 - 76s - loss: 10.3843 - val_loss: 11.6185
Epoch 1837/8000

Epoch 01837: val_loss did not improve from 10.13729
 - 75s - loss: 10.3701 - val_loss: 12.1251
Epoch 1838/8000

Epoch 01838: val_loss did not improve from 10.13729
 - 76s - loss: 10.3611 - val_loss: 10.6498
Epoch 1839/8000

Epoch 01839: val_loss did not improve from 10.13729
 - 75s - loss: 9.9595 - val_loss: 11.7198
Epoch 1840/8000

Epoch 01840: val_loss did not improve from 10.13729
 - 75s - loss: 10.7694 - val_loss: 11.5704
Epoch 1841/8000

Epoch 01841: val_loss did not improve from 10.13729
 - 76s - loss: 10.3935 - val_loss: 11.3653
Epoch 1842/8000

Epoch 01842: val_loss did not improve from 10.13729
 - 75s - loss: 10.1879 - val_loss: 11.3403
Epoch 1843/8000

Epoch 01843: val_loss did not improve from 10.13729
 - 76s - loss: 10.4711 - val_loss: 11.3368
Epoch 1844/8000

Epoch 01844: val_loss did not improve from 10.13729
 - 75s - loss: 10.5401 - val_loss: 11.3018
Epoch 1845/8000

Epoch 01845: val_loss did not improve from 10.13729
 - 76s - loss: 10.4310 - val_loss: 11.4700
Epoch 1846/8000

Epoch 01846: val_loss did not improve from 10.13729
 - 76s - loss: 10.2468 - val_loss: 11.5709
Epoch 1847/8000

Epoch 01847: val_loss did not improve from 10.13729
 - 76s - loss: 10.0530 - val_loss: 11.8213
Epoch 1848/8000

Epoch 01848: val_loss did not improve from 10.13729
 - 76s - loss: 10.2048 - val_loss: 12.5486
Epoch 1849/8000

Epoch 01849: val_loss did not improve from 10.13729
 - 75s - loss: 10.6126 - val_loss: 11.5683
Epoch 1850/8000

Epoch 01850: val_loss did not improve from 10.13729
 - 76s - loss: 10.2801 - val_loss: 11.4614
Epoch 1851/8000

Epoch 01851: val_loss did not improve from 10.13729
 - 75s - loss: 10.1978 - val_loss: 11.1534
Epoch 1852/8000

Epoch 01852: val_loss did not improve from 10.13729
 - 76s - loss: 10.1728 - val_loss: 11.4130
Epoch 1853/8000

Epoch 01853: val_loss did not improve from 10.13729
 - 75s - loss: 10.2551 - val_loss: 11.3051
Epoch 1854/8000

Epoch 01854: val_loss did not improve from 10.13729
 - 76s - loss: 10.1865 - val_loss: 11.3828
Epoch 1855/8000

Epoch 01855: val_loss did not improve from 10.13729
 - 76s - loss: 10.7754 - val_loss: 12.0232
Epoch 1856/8000

Epoch 01856: val_loss did not improve from 10.13729
 - 75s - loss: 10.0975 - val_loss: 10.7208
Epoch 1857/8000

Epoch 01857: val_loss did not improve from 10.13729
 - 76s - loss: 9.8800 - val_loss: 10.5258
Epoch 1858/8000

Epoch 01858: val_loss did not improve from 10.13729
 - 75s - loss: 10.8683 - val_loss: 11.6002
Epoch 1859/8000

Epoch 01859: val_loss did not improve from 10.13729
 - 76s - loss: 10.9099 - val_loss: 11.5366
Epoch 1860/8000

Epoch 01860: val_loss did not improve from 10.13729
 - 76s - loss: 10.5125 - val_loss: 12.1504
Epoch 1861/8000

Epoch 01861: val_loss did not improve from 10.13729
 - 76s - loss: 10.2398 - val_loss: 11.8971
Epoch 1862/8000

Epoch 01862: val_loss did not improve from 10.13729
 - 76s - loss: 10.2192 - val_loss: 11.4589
Epoch 1863/8000

Epoch 01863: val_loss did not improve from 10.13729
 - 75s - loss: 10.3849 - val_loss: 11.4379
Epoch 1864/8000

Epoch 01864: val_loss did not improve from 10.13729
 - 76s - loss: 10.4207 - val_loss: 11.6384
Epoch 1865/8000

Epoch 01865: val_loss did not improve from 10.13729
 - 75s - loss: 10.0968 - val_loss: 10.8542
Epoch 1866/8000

Epoch 01866: val_loss did not improve from 10.13729
 - 76s - loss: 10.8318 - val_loss: 11.5767
Epoch 1867/8000

Epoch 01867: val_loss did not improve from 10.13729
 - 75s - loss: 10.2911 - val_loss: 11.8741
Epoch 1868/8000

Epoch 01868: val_loss did not improve from 10.13729
 - 76s - loss: 10.4061 - val_loss: 11.5904
Epoch 1869/8000

Epoch 01869: val_loss did not improve from 10.13729
 - 76s - loss: 10.2711 - val_loss: 11.6561
Epoch 1870/8000

Epoch 01870: val_loss did not improve from 10.13729
 - 75s - loss: 10.2790 - val_loss: 11.3735
Epoch 1871/8000

Epoch 01871: val_loss did not improve from 10.13729
 - 76s - loss: 9.9669 - val_loss: 11.1143
Epoch 1872/8000

Epoch 01872: val_loss did not improve from 10.13729
 - 75s - loss: 9.9311 - val_loss: 11.6351
Epoch 1873/8000

Epoch 01873: val_loss did not improve from 10.13729
 - 76s - loss: 10.3683 - val_loss: 11.3419
Epoch 1874/8000

Epoch 01874: val_loss did not improve from 10.13729
 - 76s - loss: 10.0773 - val_loss: 11.2084
Epoch 1875/8000

Epoch 01875: val_loss did not improve from 10.13729
 - 76s - loss: 9.9037 - val_loss: 10.8668
Epoch 1876/8000

Epoch 01876: val_loss did not improve from 10.13729
 - 76s - loss: 10.4050 - val_loss: 11.3092
Epoch 1877/8000

Epoch 01877: val_loss did not improve from 10.13729
 - 75s - loss: 10.3191 - val_loss: 11.5316
Epoch 1878/8000

Epoch 01878: val_loss did not improve from 10.13729
 - 76s - loss: 9.9767 - val_loss: 12.7518
Epoch 1879/8000

Epoch 01879: val_loss did not improve from 10.13729
 - 75s - loss: 9.9377 - val_loss: 11.6893
Epoch 1880/8000

Epoch 01880: val_loss did not improve from 10.13729
 - 76s - loss: 10.1956 - val_loss: 11.3039
Epoch 1881/8000

Epoch 01881: val_loss did not improve from 10.13729
 - 75s - loss: 10.5638 - val_loss: 12.4337
Epoch 1882/8000

Epoch 01882: val_loss did not improve from 10.13729
 - 75s - loss: 10.6513 - val_loss: 12.2482
Epoch 1883/8000

Epoch 01883: val_loss did not improve from 10.13729
 - 76s - loss: 10.2209 - val_loss: 11.7820
Epoch 1884/8000

Epoch 01884: val_loss did not improve from 10.13729
 - 75s - loss: 10.2393 - val_loss: 11.6655
Epoch 1885/8000

Epoch 01885: val_loss did not improve from 10.13729
 - 76s - loss: 10.9930 - val_loss: 12.0810
Epoch 1886/8000

Epoch 01886: val_loss did not improve from 10.13729
 - 75s - loss: 11.0192 - val_loss: 11.6195
Epoch 1887/8000

Epoch 01887: val_loss did not improve from 10.13729
 - 76s - loss: 10.2968 - val_loss: 11.4169
Epoch 1888/8000

Epoch 01888: val_loss did not improve from 10.13729
 - 76s - loss: 10.1404 - val_loss: 12.0225
Epoch 1889/8000

Epoch 01889: val_loss did not improve from 10.13729
 - 76s - loss: 10.1647 - val_loss: 12.5070
Epoch 1890/8000

Epoch 01890: val_loss did not improve from 10.13729
 - 76s - loss: 10.4246 - val_loss: 11.9208
Epoch 1891/8000

Epoch 01891: val_loss did not improve from 10.13729
 - 75s - loss: 9.8768 - val_loss: 10.7240
Epoch 1892/8000

Epoch 01892: val_loss did not improve from 10.13729
 - 76s - loss: 10.4247 - val_loss: 11.2420
Epoch 1893/8000

Epoch 01893: val_loss did not improve from 10.13729
 - 75s - loss: 10.2430 - val_loss: 11.4458
Epoch 1894/8000

Epoch 01894: val_loss did not improve from 10.13729
 - 76s - loss: 10.2323 - val_loss: 11.4723
Epoch 1895/8000

Epoch 01895: val_loss did not improve from 10.13729
 - 75s - loss: 10.2383 - val_loss: 11.4314
Epoch 1896/8000

Epoch 01896: val_loss did not improve from 10.13729
 - 75s - loss: 10.2470 - val_loss: 11.2944
Epoch 1897/8000

Epoch 01897: val_loss did not improve from 10.13729
 - 75s - loss: 10.2173 - val_loss: 11.6357
Epoch 1898/8000

Epoch 01898: val_loss did not improve from 10.13729
 - 75s - loss: 10.5474 - val_loss: 11.4646
Epoch 1899/8000

Epoch 01899: val_loss did not improve from 10.13729
 - 76s - loss: 10.3672 - val_loss: 11.2473
Epoch 1900/8000

Epoch 01900: val_loss did not improve from 10.13729
 - 75s - loss: 10.2212 - val_loss: 11.6433
Epoch 1901/8000

Epoch 01901: val_loss did not improve from 10.13729
 - 76s - loss: 10.8211 - val_loss: 11.6836
Epoch 1902/8000

Epoch 01902: val_loss did not improve from 10.13729
 - 76s - loss: 11.3215 - val_loss: 13.3769
Epoch 1903/8000

Epoch 01903: val_loss did not improve from 10.13729
 - 76s - loss: 11.0642 - val_loss: 11.8803
Epoch 1904/8000

Epoch 01904: val_loss did not improve from 10.13729
 - 76s - loss: 10.2344 - val_loss: 11.3648
Epoch 1905/8000

Epoch 01905: val_loss did not improve from 10.13729
 - 75s - loss: 10.1550 - val_loss: 11.4844
Epoch 1906/8000

Epoch 01906: val_loss did not improve from 10.13729
 - 76s - loss: 10.7969 - val_loss: 12.1010
Epoch 1907/8000

Epoch 01907: val_loss did not improve from 10.13729
 - 75s - loss: 11.0161 - val_loss: 11.7846
Epoch 1908/8000

Epoch 01908: val_loss did not improve from 10.13729
 - 76s - loss: 10.8856 - val_loss: 12.0368
Epoch 1909/8000

Epoch 01909: val_loss did not improve from 10.13729
 - 76s - loss: 10.6417 - val_loss: 11.5683
Epoch 1910/8000

Epoch 01910: val_loss did not improve from 10.13729
 - 76s - loss: 10.4002 - val_loss: 11.3864
Epoch 1911/8000

Epoch 01911: val_loss did not improve from 10.13729
 - 76s - loss: 10.1093 - val_loss: 11.6430
Epoch 1912/8000

Epoch 01912: val_loss did not improve from 10.13729
 - 75s - loss: 10.0618 - val_loss: 11.3591
Epoch 1913/8000

Epoch 01913: val_loss did not improve from 10.13729
 - 76s - loss: 10.0561 - val_loss: 11.8528
Epoch 1914/8000

Epoch 01914: val_loss did not improve from 10.13729
 - 75s - loss: 10.0791 - val_loss: 11.1862
Epoch 1915/8000

Epoch 01915: val_loss did not improve from 10.13729
 - 76s - loss: 10.1871 - val_loss: 11.1791
Epoch 1916/8000

Epoch 01916: val_loss did not improve from 10.13729
 - 76s - loss: 10.0637 - val_loss: 11.6042
Epoch 1917/8000

Epoch 01917: val_loss did not improve from 10.13729
 - 76s - loss: 9.8671 - val_loss: 11.4165
Epoch 1918/8000

Epoch 01918: val_loss did not improve from 10.13729
 - 76s - loss: 10.2896 - val_loss: 11.3257
Epoch 1919/8000

Epoch 01919: val_loss did not improve from 10.13729
 - 75s - loss: 10.2522 - val_loss: 11.7343
Epoch 1920/8000

Epoch 01920: val_loss did not improve from 10.13729
 - 76s - loss: 10.1474 - val_loss: 11.5782
Epoch 1921/8000

Epoch 01921: val_loss did not improve from 10.13729
 - 75s - loss: 10.0910 - val_loss: 11.3304
Epoch 1922/8000

Epoch 01922: val_loss did not improve from 10.13729
 - 76s - loss: 9.7728 - val_loss: 11.3395
Epoch 1923/8000

Epoch 01923: val_loss did not improve from 10.13729
 - 76s - loss: 9.8599 - val_loss: 11.1415
Epoch 1924/8000

Epoch 01924: val_loss did not improve from 10.13729
 - 76s - loss: 9.8757 - val_loss: 11.2782
Epoch 1925/8000

Epoch 01925: val_loss did not improve from 10.13729
 - 76s - loss: 9.9657 - val_loss: 11.0118
Epoch 1926/8000

Epoch 01926: val_loss did not improve from 10.13729
 - 75s - loss: 10.4216 - val_loss: 11.3782
Epoch 1927/8000

Epoch 01927: val_loss did not improve from 10.13729
 - 76s - loss: 10.6386 - val_loss: 11.4790
Epoch 1928/8000

Epoch 01928: val_loss did not improve from 10.13729
 - 75s - loss: 10.1362 - val_loss: 11.7152
Epoch 1929/8000

Epoch 01929: val_loss did not improve from 10.13729
 - 76s - loss: 9.9409 - val_loss: 11.0858
Epoch 1930/8000

Epoch 01930: val_loss did not improve from 10.13729
 - 76s - loss: 10.1245 - val_loss: 11.2991
Epoch 1931/8000

Epoch 01931: val_loss did not improve from 10.13729
 - 76s - loss: 10.0403 - val_loss: 11.3534
Epoch 1932/8000

Epoch 01932: val_loss did not improve from 10.13729
 - 76s - loss: 10.2089 - val_loss: 11.1919
Epoch 1933/8000

Epoch 01933: val_loss did not improve from 10.13729
 - 75s - loss: 9.9688 - val_loss: 10.9957
Epoch 1934/8000

Epoch 01934: val_loss did not improve from 10.13729
 - 76s - loss: 10.3492 - val_loss: 11.6093
Epoch 1935/8000

Epoch 01935: val_loss did not improve from 10.13729
 - 75s - loss: 11.1869 - val_loss: 11.5541
Epoch 1936/8000

Epoch 01936: val_loss did not improve from 10.13729
 - 76s - loss: 10.4622 - val_loss: 11.3493
Epoch 1937/8000

Epoch 01937: val_loss did not improve from 10.13729
 - 76s - loss: 10.0602 - val_loss: 11.2943
Epoch 1938/8000

Epoch 01938: val_loss did not improve from 10.13729
 - 76s - loss: 9.8999 - val_loss: 11.0241
Epoch 1939/8000

Epoch 01939: val_loss did not improve from 10.13729
 - 76s - loss: 9.5978 - val_loss: 11.2042
Epoch 1940/8000

Epoch 01940: val_loss did not improve from 10.13729
 - 75s - loss: 9.9975 - val_loss: 12.0250
Epoch 1941/8000

Epoch 01941: val_loss did not improve from 10.13729
 - 76s - loss: 10.1606 - val_loss: 11.6047
Epoch 1942/8000

Epoch 01942: val_loss did not improve from 10.13729
 - 75s - loss: 10.0654 - val_loss: 11.2548
Epoch 1943/8000

Epoch 01943: val_loss did not improve from 10.13729
 - 76s - loss: 9.7936 - val_loss: 11.1712
Epoch 1944/8000

Epoch 01944: val_loss did not improve from 10.13729
 - 76s - loss: 9.6717 - val_loss: 11.2343
Epoch 1945/8000

Epoch 01945: val_loss did not improve from 10.13729
 - 76s - loss: 9.6783 - val_loss: 11.3217
Epoch 1946/8000

Epoch 01946: val_loss did not improve from 10.13729
 - 76s - loss: 10.3271 - val_loss: 12.0391
Epoch 1947/8000

Epoch 01947: val_loss did not improve from 10.13729
 - 75s - loss: 10.2284 - val_loss: 11.9233
Epoch 1948/8000

Epoch 01948: val_loss did not improve from 10.13729
 - 76s - loss: 9.8131 - val_loss: 11.0472
Epoch 1949/8000

Epoch 01949: val_loss did not improve from 10.13729
 - 75s - loss: 9.7268 - val_loss: 10.8581
Epoch 1950/8000

Epoch 01950: val_loss improved from 10.13729 to 10.09131, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 9.3613 - val_loss: 10.0913
Epoch 1951/8000

Epoch 01951: val_loss did not improve from 10.09131
 - 76s - loss: 9.6230 - val_loss: 10.6284
Epoch 1952/8000

Epoch 01952: val_loss did not improve from 10.09131
 - 76s - loss: 9.8159 - val_loss: 11.7322
Epoch 1953/8000

Epoch 01953: val_loss did not improve from 10.09131
 - 76s - loss: 9.4142 - val_loss: 10.3629
Epoch 1954/8000

Epoch 01954: val_loss did not improve from 10.09131
 - 75s - loss: 9.6667 - val_loss: 11.0112
Epoch 1955/8000

Epoch 01955: val_loss did not improve from 10.09131
 - 76s - loss: 10.0012 - val_loss: 11.6497
Epoch 1956/8000

Epoch 01956: val_loss did not improve from 10.09131
 - 75s - loss: 10.2772 - val_loss: 11.6911
Epoch 1957/8000

Epoch 01957: val_loss did not improve from 10.09131
 - 76s - loss: 10.1776 - val_loss: 11.2721
Epoch 1958/8000

Epoch 01958: val_loss did not improve from 10.09131
 - 76s - loss: 10.1831 - val_loss: 11.5884
Epoch 1959/8000

Epoch 01959: val_loss did not improve from 10.09131
 - 76s - loss: 10.4652 - val_loss: 11.4021
Epoch 1960/8000

Epoch 01960: val_loss did not improve from 10.09131
 - 76s - loss: 10.0282 - val_loss: 11.2101
Epoch 1961/8000

Epoch 01961: val_loss did not improve from 10.09131
 - 75s - loss: 10.0076 - val_loss: 11.4821
Epoch 1962/8000

Epoch 01962: val_loss did not improve from 10.09131
 - 76s - loss: 10.1672 - val_loss: 11.8092
Epoch 1963/8000

Epoch 01963: val_loss did not improve from 10.09131
 - 75s - loss: 10.1446 - val_loss: 11.2558
Epoch 1964/8000

Epoch 01964: val_loss did not improve from 10.09131
 - 76s - loss: 9.7915 - val_loss: 11.5944
Epoch 1965/8000

Epoch 01965: val_loss did not improve from 10.09131
 - 76s - loss: 9.9814 - val_loss: 11.4086
Epoch 1966/8000

Epoch 01966: val_loss did not improve from 10.09131
 - 76s - loss: 9.9505 - val_loss: 11.9821
Epoch 1967/8000

Epoch 01967: val_loss did not improve from 10.09131
 - 76s - loss: 10.1736 - val_loss: 11.5955
Epoch 1968/8000

Epoch 01968: val_loss did not improve from 10.09131
 - 75s - loss: 9.9235 - val_loss: 11.4004
Epoch 1969/8000

Epoch 01969: val_loss did not improve from 10.09131
 - 76s - loss: 9.7985 - val_loss: 11.5223
Epoch 1970/8000

Epoch 01970: val_loss did not improve from 10.09131
 - 75s - loss: 10.2831 - val_loss: 11.6537
Epoch 1971/8000

Epoch 01971: val_loss did not improve from 10.09131
 - 76s - loss: 9.8373 - val_loss: 11.1163
Epoch 1972/8000

Epoch 01972: val_loss did not improve from 10.09131
 - 76s - loss: 9.6747 - val_loss: 11.1313
Epoch 1973/8000

Epoch 01973: val_loss did not improve from 10.09131
 - 76s - loss: 9.6956 - val_loss: 11.2044
Epoch 1974/8000

Epoch 01974: val_loss did not improve from 10.09131
 - 76s - loss: 9.6878 - val_loss: 10.4399
Epoch 1975/8000

Epoch 01975: val_loss did not improve from 10.09131
 - 75s - loss: 9.4872 - val_loss: 11.1128
Epoch 1976/8000

Epoch 01976: val_loss did not improve from 10.09131
 - 76s - loss: 9.5284 - val_loss: 10.9154
Epoch 1977/8000

Epoch 01977: val_loss did not improve from 10.09131
 - 75s - loss: 9.3070 - val_loss: 11.1301
Epoch 1978/8000

Epoch 01978: val_loss did not improve from 10.09131
 - 76s - loss: 9.4535 - val_loss: 10.7279
Epoch 1979/8000

Epoch 01979: val_loss did not improve from 10.09131
 - 76s - loss: 9.4862 - val_loss: 11.0119
Epoch 1980/8000

Epoch 01980: val_loss did not improve from 10.09131
 - 76s - loss: 9.9116 - val_loss: 10.9624
Epoch 1981/8000

Epoch 01981: val_loss did not improve from 10.09131
 - 76s - loss: 9.5491 - val_loss: 11.2720
Epoch 1982/8000

Epoch 01982: val_loss did not improve from 10.09131
 - 75s - loss: 9.0756 - val_loss: 10.0933
Epoch 1983/8000

Epoch 01983: val_loss did not improve from 10.09131
 - 76s - loss: 9.2457 - val_loss: 11.2902
Epoch 1984/8000

Epoch 01984: val_loss did not improve from 10.09131
 - 75s - loss: 9.5393 - val_loss: 10.6389
Epoch 1985/8000

Epoch 01985: val_loss did not improve from 10.09131
 - 76s - loss: 9.1196 - val_loss: 10.9358
Epoch 1986/8000

Epoch 01986: val_loss did not improve from 10.09131
 - 75s - loss: 9.0763 - val_loss: 10.5499
Epoch 1987/8000

Epoch 01987: val_loss did not improve from 10.09131
 - 76s - loss: 9.0552 - val_loss: 10.9668
Epoch 1988/8000

Epoch 01988: val_loss did not improve from 10.09131
 - 76s - loss: 9.1519 - val_loss: 10.9171
Epoch 1989/8000

Epoch 01989: val_loss did not improve from 10.09131
 - 75s - loss: 9.5133 - val_loss: 11.5061
Epoch 1990/8000

Epoch 01990: val_loss did not improve from 10.09131
 - 76s - loss: 9.4859 - val_loss: 10.9196
Epoch 1991/8000

Epoch 01991: val_loss did not improve from 10.09131
 - 75s - loss: 9.7471 - val_loss: 10.5460
Epoch 1992/8000

Epoch 01992: val_loss did not improve from 10.09131
 - 76s - loss: 9.5661 - val_loss: 10.8817
Epoch 1993/8000

Epoch 01993: val_loss did not improve from 10.09131
 - 76s - loss: 9.3571 - val_loss: 11.3343
Epoch 1994/8000

Epoch 01994: val_loss did not improve from 10.09131
 - 76s - loss: 9.6682 - val_loss: 10.9894
Epoch 1995/8000

Epoch 01995: val_loss did not improve from 10.09131
 - 76s - loss: 9.3063 - val_loss: 10.9347
Epoch 1996/8000

Epoch 01996: val_loss did not improve from 10.09131
 - 75s - loss: 9.1845 - val_loss: 10.6675
Epoch 1997/8000

Epoch 01997: val_loss did not improve from 10.09131
 - 76s - loss: 9.3898 - val_loss: 10.7941
Epoch 1998/8000

Epoch 01998: val_loss did not improve from 10.09131
 - 75s - loss: 9.3892 - val_loss: 11.4138
Epoch 1999/8000

Epoch 01999: val_loss did not improve from 10.09131
 - 76s - loss: 10.5682 - val_loss: 11.5885
Epoch 2000/8000

Epoch 02000: val_loss did not improve from 10.09131
 - 75s - loss: 9.6784 - val_loss: 11.3520
Epoch 2001/8000

Epoch 02001: val_loss did not improve from 10.09131
 - 75s - loss: 9.9370 - val_loss: 11.3180
Epoch 2002/8000

Epoch 02002: val_loss did not improve from 10.09131
 - 75s - loss: 9.6510 - val_loss: 12.0782
Epoch 2003/8000

Epoch 02003: val_loss did not improve from 10.09131
 - 75s - loss: 9.6558 - val_loss: 11.2061
Epoch 2004/8000

Epoch 02004: val_loss did not improve from 10.09131
 - 76s - loss: 10.0689 - val_loss: 10.9845
Epoch 2005/8000

Epoch 02005: val_loss did not improve from 10.09131
 - 75s - loss: 10.0202 - val_loss: 11.2462
Epoch 2006/8000

Epoch 02006: val_loss did not improve from 10.09131
 - 76s - loss: 9.8196 - val_loss: 11.0803
Epoch 2007/8000

Epoch 02007: val_loss did not improve from 10.09131
 - 76s - loss: 9.5133 - val_loss: 10.4569
Epoch 2008/8000

Epoch 02008: val_loss did not improve from 10.09131
 - 76s - loss: 9.2022 - val_loss: 10.5931
Epoch 2009/8000

Epoch 02009: val_loss did not improve from 10.09131
 - 76s - loss: 9.0771 - val_loss: 10.4589
Epoch 2010/8000

Epoch 02010: val_loss did not improve from 10.09131
 - 75s - loss: 8.9925 - val_loss: 10.8632
Epoch 2011/8000

Epoch 02011: val_loss did not improve from 10.09131
 - 76s - loss: 9.4353 - val_loss: 11.2199
Epoch 2012/8000

Epoch 02012: val_loss did not improve from 10.09131
 - 75s - loss: 9.5197 - val_loss: 11.1041
Epoch 2013/8000

Epoch 02013: val_loss did not improve from 10.09131
 - 76s - loss: 9.2666 - val_loss: 10.5112
Epoch 2014/8000

Epoch 02014: val_loss did not improve from 10.09131
 - 76s - loss: 9.3171 - val_loss: 11.4310
Epoch 2015/8000

Epoch 02015: val_loss did not improve from 10.09131
 - 76s - loss: 9.4498 - val_loss: 10.9506
Epoch 2016/8000

Epoch 02016: val_loss did not improve from 10.09131
 - 76s - loss: 10.3603 - val_loss: 11.1127
Epoch 2017/8000

Epoch 02017: val_loss did not improve from 10.09131
 - 75s - loss: 9.4737 - val_loss: 10.6006
Epoch 2018/8000

Epoch 02018: val_loss did not improve from 10.09131
 - 76s - loss: 9.2365 - val_loss: 10.6541
Epoch 2019/8000

Epoch 02019: val_loss did not improve from 10.09131
 - 75s - loss: 9.0430 - val_loss: 11.1439
Epoch 2020/8000

Epoch 02020: val_loss did not improve from 10.09131
 - 76s - loss: 9.4552 - val_loss: 11.3599
Epoch 2021/8000

Epoch 02021: val_loss did not improve from 10.09131
 - 76s - loss: 9.0173 - val_loss: 10.4671
Epoch 2022/8000

Epoch 02022: val_loss did not improve from 10.09131
 - 76s - loss: 8.6516 - val_loss: 11.1234
Epoch 2023/8000

Epoch 02023: val_loss did not improve from 10.09131
 - 76s - loss: 8.9839 - val_loss: 11.6163
Epoch 2024/8000

Epoch 02024: val_loss did not improve from 10.09131
 - 75s - loss: 9.2213 - val_loss: 10.9709
Epoch 2025/8000

Epoch 02025: val_loss did not improve from 10.09131
 - 76s - loss: 9.1107 - val_loss: 11.5830
Epoch 2026/8000

Epoch 02026: val_loss did not improve from 10.09131
 - 76s - loss: 10.3186 - val_loss: 11.0940
Epoch 2027/8000

Epoch 02027: val_loss did not improve from 10.09131
 - 76s - loss: 10.0160 - val_loss: 11.9849
Epoch 2028/8000

Epoch 02028: val_loss did not improve from 10.09131
 - 76s - loss: 9.6583 - val_loss: 10.6791
Epoch 2029/8000

Epoch 02029: val_loss did not improve from 10.09131
 - 76s - loss: 9.7168 - val_loss: 11.4844
Epoch 2030/8000

Epoch 02030: val_loss did not improve from 10.09131
 - 76s - loss: 10.1057 - val_loss: 11.0164
Epoch 2031/8000

Epoch 02031: val_loss did not improve from 10.09131
 - 75s - loss: 10.1008 - val_loss: 11.2988
Epoch 2032/8000

Epoch 02032: val_loss did not improve from 10.09131
 - 76s - loss: 9.9538 - val_loss: 10.9638
Epoch 2033/8000

Epoch 02033: val_loss did not improve from 10.09131
 - 75s - loss: 9.7430 - val_loss: 10.9329
Epoch 2034/8000

Epoch 02034: val_loss did not improve from 10.09131
 - 76s - loss: 9.4147 - val_loss: 10.8636
Epoch 2035/8000

Epoch 02035: val_loss did not improve from 10.09131
 - 76s - loss: 9.5897 - val_loss: 11.2750
Epoch 2036/8000

Epoch 02036: val_loss did not improve from 10.09131
 - 76s - loss: 9.4590 - val_loss: 10.6389
Epoch 2037/8000

Epoch 02037: val_loss did not improve from 10.09131
 - 76s - loss: 9.2846 - val_loss: 10.8068
Epoch 2038/8000

Epoch 02038: val_loss did not improve from 10.09131
 - 75s - loss: 9.1070 - val_loss: 10.8703
Epoch 2039/8000

Epoch 02039: val_loss did not improve from 10.09131
 - 76s - loss: 9.6625 - val_loss: 10.8403
Epoch 2040/8000

Epoch 02040: val_loss did not improve from 10.09131
 - 75s - loss: 9.4418 - val_loss: 10.9402
Epoch 2041/8000

Epoch 02041: val_loss did not improve from 10.09131
 - 76s - loss: 9.2209 - val_loss: 11.4178
Epoch 2042/8000

Epoch 02042: val_loss did not improve from 10.09131
 - 76s - loss: 9.5056 - val_loss: 10.5592
Epoch 2043/8000

Epoch 02043: val_loss did not improve from 10.09131
 - 76s - loss: 9.3586 - val_loss: 11.5991
Epoch 2044/8000

Epoch 02044: val_loss did not improve from 10.09131
 - 76s - loss: 10.3689 - val_loss: 11.9055
Epoch 2045/8000

Epoch 02045: val_loss did not improve from 10.09131
 - 75s - loss: 10.1633 - val_loss: 11.5596
Epoch 2046/8000

Epoch 02046: val_loss did not improve from 10.09131
 - 76s - loss: 10.0771 - val_loss: 11.1767
Epoch 2047/8000

Epoch 02047: val_loss did not improve from 10.09131
 - 75s - loss: 12.4676 - val_loss: 17.1072
Epoch 2048/8000

Epoch 02048: val_loss did not improve from 10.09131
 - 76s - loss: 13.8837 - val_loss: 13.1558
Epoch 2049/8000

Epoch 02049: val_loss did not improve from 10.09131
 - 76s - loss: 12.2268 - val_loss: 12.8737
Epoch 2050/8000

Epoch 02050: val_loss did not improve from 10.09131
 - 76s - loss: 11.2802 - val_loss: 12.2671
Epoch 2051/8000

Epoch 02051: val_loss did not improve from 10.09131
 - 76s - loss: 10.9823 - val_loss: 12.3275
Epoch 2052/8000

Epoch 02052: val_loss did not improve from 10.09131
 - 75s - loss: 10.5055 - val_loss: 13.0113
Epoch 2053/8000

Epoch 02053: val_loss did not improve from 10.09131
 - 76s - loss: 10.1204 - val_loss: 11.3713
Epoch 2054/8000

Epoch 02054: val_loss did not improve from 10.09131
 - 75s - loss: 9.8775 - val_loss: 11.2774
Epoch 2055/8000

Epoch 02055: val_loss did not improve from 10.09131
 - 76s - loss: 10.2338 - val_loss: 11.7399
Epoch 2056/8000

Epoch 02056: val_loss did not improve from 10.09131
 - 76s - loss: 10.1864 - val_loss: 11.9132
Epoch 2057/8000

Epoch 02057: val_loss did not improve from 10.09131
 - 76s - loss: 9.7158 - val_loss: 11.0665
Epoch 2058/8000

Epoch 02058: val_loss did not improve from 10.09131
 - 76s - loss: 9.4842 - val_loss: 10.8539
Epoch 2059/8000

Epoch 02059: val_loss did not improve from 10.09131
 - 75s - loss: 9.7255 - val_loss: 11.2622
Epoch 2060/8000

Epoch 02060: val_loss did not improve from 10.09131
 - 76s - loss: 9.8026 - val_loss: 11.0711
Epoch 2061/8000

Epoch 02061: val_loss did not improve from 10.09131
 - 75s - loss: 9.8495 - val_loss: 11.2861
Epoch 2062/8000

Epoch 02062: val_loss did not improve from 10.09131
 - 76s - loss: 9.5891 - val_loss: 11.0895
Epoch 2063/8000

Epoch 02063: val_loss did not improve from 10.09131
 - 76s - loss: 9.5010 - val_loss: 11.3152
Epoch 2064/8000

Epoch 02064: val_loss did not improve from 10.09131
 - 76s - loss: 9.4644 - val_loss: 11.2158
Epoch 2065/8000

Epoch 02065: val_loss did not improve from 10.09131
 - 76s - loss: 9.8968 - val_loss: 12.1988
Epoch 2066/8000

Epoch 02066: val_loss did not improve from 10.09131
 - 75s - loss: 10.2785 - val_loss: 11.6101
Epoch 2067/8000

Epoch 02067: val_loss did not improve from 10.09131
 - 76s - loss: 10.5086 - val_loss: 11.3194
Epoch 2068/8000

Epoch 02068: val_loss did not improve from 10.09131
 - 76s - loss: 9.9872 - val_loss: 11.4382
Epoch 2069/8000

Epoch 02069: val_loss did not improve from 10.09131
 - 76s - loss: 10.3653 - val_loss: 11.9546
Epoch 2070/8000

Epoch 02070: val_loss did not improve from 10.09131
 - 76s - loss: 10.3617 - val_loss: 11.4802
Epoch 2071/8000

Epoch 02071: val_loss did not improve from 10.09131
 - 76s - loss: 10.1540 - val_loss: 11.4361
Epoch 2072/8000

Epoch 02072: val_loss did not improve from 10.09131
 - 76s - loss: 10.0337 - val_loss: 11.3174
Epoch 2073/8000

Epoch 02073: val_loss did not improve from 10.09131
 - 75s - loss: 10.0456 - val_loss: 11.4823
Epoch 2074/8000

Epoch 02074: val_loss did not improve from 10.09131
 - 76s - loss: 9.6996 - val_loss: 11.1737
Epoch 2075/8000

Epoch 02075: val_loss did not improve from 10.09131
 - 75s - loss: 9.8126 - val_loss: 11.1380
Epoch 2076/8000

Epoch 02076: val_loss did not improve from 10.09131
 - 76s - loss: 9.9727 - val_loss: 11.7992
Epoch 2077/8000

Epoch 02077: val_loss did not improve from 10.09131
 - 76s - loss: 10.0546 - val_loss: 11.5929
Epoch 2078/8000

Epoch 02078: val_loss did not improve from 10.09131
 - 76s - loss: 10.0919 - val_loss: 11.4682
Epoch 2079/8000

Epoch 02079: val_loss did not improve from 10.09131
 - 76s - loss: 10.2914 - val_loss: 11.1918
Epoch 2080/8000

Epoch 02080: val_loss did not improve from 10.09131
 - 75s - loss: 9.8965 - val_loss: 11.2280
Epoch 2081/8000

Epoch 02081: val_loss did not improve from 10.09131
 - 76s - loss: 9.6340 - val_loss: 11.8797
Epoch 2082/8000

Epoch 02082: val_loss did not improve from 10.09131
 - 75s - loss: 26.5659 - val_loss: 29.6477
Epoch 2083/8000

Epoch 02083: val_loss did not improve from 10.09131
 - 76s - loss: 17.4532 - val_loss: 14.8390
Epoch 2084/8000

Epoch 02084: val_loss did not improve from 10.09131
 - 76s - loss: 13.3257 - val_loss: 13.1680
Epoch 2085/8000

Epoch 02085: val_loss did not improve from 10.09131
 - 76s - loss: 11.5371 - val_loss: 12.5615
Epoch 2086/8000

Epoch 02086: val_loss did not improve from 10.09131
 - 76s - loss: 10.7970 - val_loss: 11.9130
Epoch 2087/8000

Epoch 02087: val_loss did not improve from 10.09131
 - 75s - loss: 10.5308 - val_loss: 11.7048
Epoch 2088/8000

Epoch 02088: val_loss did not improve from 10.09131
 - 76s - loss: 10.3219 - val_loss: 11.6547
Epoch 2089/8000

Epoch 02089: val_loss did not improve from 10.09131
 - 75s - loss: 10.0198 - val_loss: 11.5016
Epoch 2090/8000

Epoch 02090: val_loss did not improve from 10.09131
 - 76s - loss: 10.0480 - val_loss: 11.5469
Epoch 2091/8000

Epoch 02091: val_loss did not improve from 10.09131
 - 76s - loss: 10.0748 - val_loss: 12.3700
Epoch 2092/8000

Epoch 02092: val_loss did not improve from 10.09131
 - 76s - loss: 10.3294 - val_loss: 11.4196
Epoch 2093/8000

Epoch 02093: val_loss did not improve from 10.09131
 - 76s - loss: 10.8672 - val_loss: 13.1438
Epoch 2094/8000

Epoch 02094: val_loss did not improve from 10.09131
 - 75s - loss: 11.4229 - val_loss: 11.7438
Epoch 2095/8000

Epoch 02095: val_loss did not improve from 10.09131
 - 76s - loss: 11.4682 - val_loss: 12.9559
Epoch 2096/8000

Epoch 02096: val_loss did not improve from 10.09131
 - 75s - loss: 11.3315 - val_loss: 11.6625
Epoch 2097/8000

Epoch 02097: val_loss did not improve from 10.09131
 - 76s - loss: 10.4462 - val_loss: 11.1325
Epoch 2098/8000

Epoch 02098: val_loss did not improve from 10.09131
 - 76s - loss: 10.2414 - val_loss: 11.5268
Epoch 2099/8000

Epoch 02099: val_loss did not improve from 10.09131
 - 76s - loss: 10.0380 - val_loss: 11.5742
Epoch 2100/8000

Epoch 02100: val_loss did not improve from 10.09131
 - 76s - loss: 10.0110 - val_loss: 12.1602
Epoch 2101/8000

Epoch 02101: val_loss did not improve from 10.09131
 - 75s - loss: 9.9057 - val_loss: 11.6223
Epoch 2102/8000

Epoch 02102: val_loss did not improve from 10.09131
 - 76s - loss: 10.1003 - val_loss: 11.1974
Epoch 2103/8000

Epoch 02103: val_loss did not improve from 10.09131
 - 75s - loss: 10.0115 - val_loss: 11.1043
Epoch 2104/8000

Epoch 02104: val_loss did not improve from 10.09131
 - 76s - loss: 9.8726 - val_loss: 11.2871
Epoch 2105/8000

Epoch 02105: val_loss did not improve from 10.09131
 - 75s - loss: 9.6362 - val_loss: 13.2416
Epoch 2106/8000

Epoch 02106: val_loss did not improve from 10.09131
 - 75s - loss: 10.4758 - val_loss: 11.5572
Epoch 2107/8000

Epoch 02107: val_loss did not improve from 10.09131
 - 76s - loss: 10.2484 - val_loss: 11.9270
Epoch 2108/8000

Epoch 02108: val_loss did not improve from 10.09131
 - 75s - loss: 9.9177 - val_loss: 11.3513
Epoch 2109/8000

Epoch 02109: val_loss did not improve from 10.09131
 - 76s - loss: 10.0577 - val_loss: 11.5191
Epoch 2110/8000

Epoch 02110: val_loss did not improve from 10.09131
 - 75s - loss: 9.9452 - val_loss: 11.8890
Epoch 2111/8000

Epoch 02111: val_loss did not improve from 10.09131
 - 76s - loss: 10.1550 - val_loss: 11.6723
Epoch 2112/8000

Epoch 02112: val_loss did not improve from 10.09131
 - 76s - loss: 10.1286 - val_loss: 11.3810
Epoch 2113/8000

Epoch 02113: val_loss did not improve from 10.09131
 - 76s - loss: 10.0663 - val_loss: 12.1757
Epoch 2114/8000

Epoch 02114: val_loss did not improve from 10.09131
 - 76s - loss: 10.3543 - val_loss: 11.5768
Epoch 2115/8000

Epoch 02115: val_loss did not improve from 10.09131
 - 75s - loss: 10.3025 - val_loss: 11.4940
Epoch 2116/8000

Epoch 02116: val_loss did not improve from 10.09131
 - 76s - loss: 9.9611 - val_loss: 11.0479
Epoch 2117/8000

Epoch 02117: val_loss did not improve from 10.09131
 - 75s - loss: 9.9827 - val_loss: 10.9201
Epoch 2118/8000

Epoch 02118: val_loss did not improve from 10.09131
 - 76s - loss: 10.1835 - val_loss: 12.1755
Epoch 2119/8000

Epoch 02119: val_loss did not improve from 10.09131
 - 76s - loss: 10.2414 - val_loss: 11.9086
Epoch 2120/8000

Epoch 02120: val_loss did not improve from 10.09131
 - 76s - loss: 11.8869 - val_loss: 14.2321
Epoch 2121/8000

Epoch 02121: val_loss did not improve from 10.09131
 - 76s - loss: 19.4853 - val_loss: 15.9679
Epoch 2122/8000

Epoch 02122: val_loss did not improve from 10.09131
 - 75s - loss: 14.2436 - val_loss: 14.0613
Epoch 2123/8000

Epoch 02123: val_loss did not improve from 10.09131
 - 76s - loss: 12.3734 - val_loss: 12.8138
Epoch 2124/8000

Epoch 02124: val_loss did not improve from 10.09131
 - 75s - loss: 11.1516 - val_loss: 12.0230
Epoch 2125/8000

Epoch 02125: val_loss did not improve from 10.09131
 - 76s - loss: 10.4335 - val_loss: 11.8704
Epoch 2126/8000

Epoch 02126: val_loss did not improve from 10.09131
 - 76s - loss: 10.4909 - val_loss: 12.7926
Epoch 2127/8000

Epoch 02127: val_loss did not improve from 10.09131
 - 76s - loss: 10.3077 - val_loss: 11.6679
Epoch 2128/8000

Epoch 02128: val_loss did not improve from 10.09131
 - 76s - loss: 10.0881 - val_loss: 11.4227
Epoch 2129/8000

Epoch 02129: val_loss did not improve from 10.09131
 - 75s - loss: 9.9186 - val_loss: 11.2262
Epoch 2130/8000

Epoch 02130: val_loss did not improve from 10.09131
 - 76s - loss: 9.8868 - val_loss: 11.8894
Epoch 2131/8000

Epoch 02131: val_loss did not improve from 10.09131
 - 75s - loss: 9.7654 - val_loss: 11.0098
Epoch 2132/8000

Epoch 02132: val_loss did not improve from 10.09131
 - 76s - loss: 9.5381 - val_loss: 10.7244
Epoch 2133/8000

Epoch 02133: val_loss did not improve from 10.09131
 - 76s - loss: 9.7087 - val_loss: 11.1526
Epoch 2134/8000

Epoch 02134: val_loss did not improve from 10.09131
 - 76s - loss: 9.8075 - val_loss: 11.4245
Epoch 2135/8000

Epoch 02135: val_loss did not improve from 10.09131
 - 76s - loss: 9.9223 - val_loss: 12.1002
Epoch 2136/8000

Epoch 02136: val_loss did not improve from 10.09131
 - 75s - loss: 9.7128 - val_loss: 13.0379
Epoch 2137/8000

Epoch 02137: val_loss did not improve from 10.09131
 - 76s - loss: 10.2888 - val_loss: 11.1327
Epoch 2138/8000

Epoch 02138: val_loss did not improve from 10.09131
 - 75s - loss: 9.8998 - val_loss: 11.1556
Epoch 2139/8000

Epoch 02139: val_loss did not improve from 10.09131
 - 76s - loss: 9.8891 - val_loss: 11.6549
Epoch 2140/8000

Epoch 02140: val_loss did not improve from 10.09131
 - 76s - loss: 10.2835 - val_loss: 11.7232
Epoch 2141/8000

Epoch 02141: val_loss did not improve from 10.09131
 - 76s - loss: 10.1057 - val_loss: 11.4167
Epoch 2142/8000

Epoch 02142: val_loss did not improve from 10.09131
 - 76s - loss: 9.7471 - val_loss: 11.4084
Epoch 2143/8000

Epoch 02143: val_loss did not improve from 10.09131
 - 75s - loss: 10.1538 - val_loss: 11.3114
Epoch 2144/8000

Epoch 02144: val_loss did not improve from 10.09131
 - 76s - loss: 9.8512 - val_loss: 11.5243
Epoch 2145/8000

Epoch 02145: val_loss did not improve from 10.09131
 - 76s - loss: 9.5946 - val_loss: 10.9484
Epoch 2146/8000

Epoch 02146: val_loss did not improve from 10.09131
 - 76s - loss: 9.4399 - val_loss: 11.0285
Epoch 2147/8000

Epoch 02147: val_loss did not improve from 10.09131
 - 76s - loss: 9.5595 - val_loss: 12.3943
Epoch 2148/8000

Epoch 02148: val_loss did not improve from 10.09131
 - 76s - loss: 9.8695 - val_loss: 11.6049
Epoch 2149/8000

Epoch 02149: val_loss did not improve from 10.09131
 - 76s - loss: 9.4123 - val_loss: 10.9414
Epoch 2150/8000

Epoch 02150: val_loss did not improve from 10.09131
 - 75s - loss: 9.5181 - val_loss: 11.3535
Epoch 2151/8000

Epoch 02151: val_loss did not improve from 10.09131
 - 76s - loss: 9.6532 - val_loss: 10.9325
Epoch 2152/8000

Epoch 02152: val_loss did not improve from 10.09131
 - 75s - loss: 9.3295 - val_loss: 11.3346
Epoch 2153/8000

Epoch 02153: val_loss did not improve from 10.09131
 - 76s - loss: 9.5096 - val_loss: 11.6197
Epoch 2154/8000

Epoch 02154: val_loss did not improve from 10.09131
 - 76s - loss: 9.7128 - val_loss: 11.8391
Epoch 2155/8000

Epoch 02155: val_loss did not improve from 10.09131
 - 76s - loss: 9.5457 - val_loss: 11.5356
Epoch 2156/8000

Epoch 02156: val_loss did not improve from 10.09131
 - 76s - loss: 9.3687 - val_loss: 11.3681
Epoch 2157/8000

Epoch 02157: val_loss did not improve from 10.09131
 - 75s - loss: 10.0107 - val_loss: 11.6582
Epoch 2158/8000

Epoch 02158: val_loss did not improve from 10.09131
 - 76s - loss: 9.5232 - val_loss: 11.2342
Epoch 2159/8000

Epoch 02159: val_loss did not improve from 10.09131
 - 75s - loss: 9.9202 - val_loss: 11.4075
Epoch 2160/8000

Epoch 02160: val_loss did not improve from 10.09131
 - 76s - loss: 9.5735 - val_loss: 11.9630
Epoch 2161/8000

Epoch 02161: val_loss did not improve from 10.09131
 - 76s - loss: 10.1249 - val_loss: 11.3581
Epoch 2162/8000

Epoch 02162: val_loss did not improve from 10.09131
 - 76s - loss: 10.0942 - val_loss: 11.2887
Epoch 2163/8000

Epoch 02163: val_loss did not improve from 10.09131
 - 76s - loss: 10.0208 - val_loss: 11.0590
Epoch 2164/8000

Epoch 02164: val_loss did not improve from 10.09131
 - 75s - loss: 9.4615 - val_loss: 10.5478
Epoch 2165/8000

Epoch 02165: val_loss did not improve from 10.09131
 - 76s - loss: 9.3952 - val_loss: 11.3202
Epoch 2166/8000

Epoch 02166: val_loss did not improve from 10.09131
 - 75s - loss: 9.5025 - val_loss: 11.1994
Epoch 2167/8000

Epoch 02167: val_loss did not improve from 10.09131
 - 76s - loss: 9.4778 - val_loss: 12.8616
Epoch 2168/8000

Epoch 02168: val_loss did not improve from 10.09131
 - 76s - loss: 11.7173 - val_loss: 11.9051
Epoch 2169/8000

Epoch 02169: val_loss did not improve from 10.09131
 - 76s - loss: 11.4350 - val_loss: 11.8895
Epoch 2170/8000

Epoch 02170: val_loss did not improve from 10.09131
 - 76s - loss: 10.6179 - val_loss: 11.1010
Epoch 2171/8000

Epoch 02171: val_loss did not improve from 10.09131
 - 75s - loss: 10.1285 - val_loss: 11.9576
Epoch 2172/8000

Epoch 02172: val_loss did not improve from 10.09131
 - 76s - loss: 10.7054 - val_loss: 12.3402
Epoch 2173/8000

Epoch 02173: val_loss did not improve from 10.09131
 - 76s - loss: 10.3742 - val_loss: 10.7710
Epoch 2174/8000

Epoch 02174: val_loss did not improve from 10.09131
 - 76s - loss: 9.7980 - val_loss: 10.8805
Epoch 2175/8000

Epoch 02175: val_loss did not improve from 10.09131
 - 76s - loss: 9.4440 - val_loss: 11.6602
Epoch 2176/8000

Epoch 02176: val_loss did not improve from 10.09131
 - 76s - loss: 9.3892 - val_loss: 10.7059
Epoch 2177/8000

Epoch 02177: val_loss did not improve from 10.09131
 - 76s - loss: 9.4357 - val_loss: 10.6589
Epoch 2178/8000

Epoch 02178: val_loss did not improve from 10.09131
 - 75s - loss: 9.0741 - val_loss: 10.9048
Epoch 2179/8000

Epoch 02179: val_loss did not improve from 10.09131
 - 76s - loss: 9.5992 - val_loss: 11.3137
Epoch 2180/8000

Epoch 02180: val_loss did not improve from 10.09131
 - 75s - loss: 9.2606 - val_loss: 10.9810
Epoch 2181/8000

Epoch 02181: val_loss did not improve from 10.09131
 - 76s - loss: 9.6436 - val_loss: 10.7228
Epoch 2182/8000

Epoch 02182: val_loss did not improve from 10.09131
 - 76s - loss: 9.6084 - val_loss: 11.3847
Epoch 2183/8000

Epoch 02183: val_loss did not improve from 10.09131
 - 76s - loss: 9.6168 - val_loss: 11.0057
Epoch 2184/8000

Epoch 02184: val_loss did not improve from 10.09131
 - 76s - loss: 9.5403 - val_loss: 11.2749
Epoch 2185/8000

Epoch 02185: val_loss did not improve from 10.09131
 - 75s - loss: 9.6281 - val_loss: 11.5428
Epoch 2186/8000

Epoch 02186: val_loss did not improve from 10.09131
 - 76s - loss: 10.1939 - val_loss: 11.1905
Epoch 2187/8000

Epoch 02187: val_loss did not improve from 10.09131
 - 75s - loss: 9.4135 - val_loss: 10.9874
Epoch 2188/8000

Epoch 02188: val_loss did not improve from 10.09131
 - 76s - loss: 9.1505 - val_loss: 10.8183
Epoch 2189/8000

Epoch 02189: val_loss did not improve from 10.09131
 - 76s - loss: 9.2498 - val_loss: 10.7008
Epoch 2190/8000

Epoch 02190: val_loss did not improve from 10.09131
 - 76s - loss: 9.4061 - val_loss: 10.9925
Epoch 2191/8000

Epoch 02191: val_loss did not improve from 10.09131
 - 76s - loss: 9.2949 - val_loss: 11.1147
Epoch 2192/8000

Epoch 02192: val_loss did not improve from 10.09131
 - 75s - loss: 9.5819 - val_loss: 11.6467
Epoch 2193/8000

Epoch 02193: val_loss did not improve from 10.09131
 - 76s - loss: 9.3234 - val_loss: 10.8580
Epoch 2194/8000

Epoch 02194: val_loss did not improve from 10.09131
 - 75s - loss: 9.5427 - val_loss: 11.4197
Epoch 2195/8000

Epoch 02195: val_loss did not improve from 10.09131
 - 76s - loss: 9.3296 - val_loss: 11.0471
Epoch 2196/8000

Epoch 02196: val_loss did not improve from 10.09131
 - 76s - loss: 9.6964 - val_loss: 10.7726
Epoch 2197/8000

Epoch 02197: val_loss did not improve from 10.09131
 - 76s - loss: 9.3137 - val_loss: 11.8543
Epoch 2198/8000

Epoch 02198: val_loss did not improve from 10.09131
 - 76s - loss: 9.9830 - val_loss: 10.7078
Epoch 2199/8000

Epoch 02199: val_loss did not improve from 10.09131
 - 76s - loss: 9.3061 - val_loss: 11.5620
Epoch 2200/8000

Epoch 02200: val_loss did not improve from 10.09131
 - 76s - loss: 9.0257 - val_loss: 10.5849
Epoch 2201/8000

Epoch 02201: val_loss did not improve from 10.09131
 - 75s - loss: 9.3803 - val_loss: 11.0648
Epoch 2202/8000

Epoch 02202: val_loss did not improve from 10.09131
 - 76s - loss: 10.3615 - val_loss: 12.9890
Epoch 2203/8000

Epoch 02203: val_loss did not improve from 10.09131
 - 76s - loss: 10.3942 - val_loss: 11.1088
Epoch 2204/8000

Epoch 02204: val_loss did not improve from 10.09131
 - 76s - loss: 9.7930 - val_loss: 11.2743
Epoch 2205/8000

Epoch 02205: val_loss did not improve from 10.09131
 - 76s - loss: 10.1258 - val_loss: 11.1824
Epoch 2206/8000

Epoch 02206: val_loss did not improve from 10.09131
 - 75s - loss: 10.1510 - val_loss: 11.1506
Epoch 2207/8000

Epoch 02207: val_loss did not improve from 10.09131
 - 76s - loss: 9.9147 - val_loss: 11.2770
Epoch 2208/8000

Epoch 02208: val_loss did not improve from 10.09131
 - 75s - loss: 9.7148 - val_loss: 11.5130
Epoch 2209/8000

Epoch 02209: val_loss did not improve from 10.09131
 - 75s - loss: 9.4613 - val_loss: 10.4674
Epoch 2210/8000

Epoch 02210: val_loss did not improve from 10.09131
 - 75s - loss: 9.1673 - val_loss: 10.7318
Epoch 2211/8000

Epoch 02211: val_loss did not improve from 10.09131
 - 76s - loss: 8.9297 - val_loss: 10.8171
Epoch 2212/8000

Epoch 02212: val_loss did not improve from 10.09131
 - 76s - loss: 9.7413 - val_loss: 11.6875
Epoch 2213/8000

Epoch 02213: val_loss did not improve from 10.09131
 - 75s - loss: 9.6693 - val_loss: 11.5758
Epoch 2214/8000

Epoch 02214: val_loss did not improve from 10.09131
 - 76s - loss: 10.3372 - val_loss: 12.1748
Epoch 2215/8000

Epoch 02215: val_loss did not improve from 10.09131
 - 75s - loss: 10.0340 - val_loss: 10.6811
Epoch 2216/8000

Epoch 02216: val_loss did not improve from 10.09131
 - 76s - loss: 9.2995 - val_loss: 11.3667
Epoch 2217/8000

Epoch 02217: val_loss did not improve from 10.09131
 - 76s - loss: 9.4807 - val_loss: 11.7103
Epoch 2218/8000

Epoch 02218: val_loss did not improve from 10.09131
 - 76s - loss: 10.2976 - val_loss: 12.5037
Epoch 2219/8000

Epoch 02219: val_loss did not improve from 10.09131
 - 76s - loss: 10.1787 - val_loss: 10.8043
Epoch 2220/8000

Epoch 02220: val_loss did not improve from 10.09131
 - 75s - loss: 9.6320 - val_loss: 10.6462
Epoch 2221/8000

Epoch 02221: val_loss did not improve from 10.09131
 - 76s - loss: 9.6459 - val_loss: 11.9263
Epoch 2222/8000

Epoch 02222: val_loss did not improve from 10.09131
 - 76s - loss: 9.6734 - val_loss: 11.3618
Epoch 2223/8000

Epoch 02223: val_loss did not improve from 10.09131
 - 76s - loss: 10.2814 - val_loss: 12.8242
Epoch 2224/8000

Epoch 02224: val_loss did not improve from 10.09131
 - 76s - loss: 10.8702 - val_loss: 10.8056
Epoch 2225/8000

Epoch 02225: val_loss did not improve from 10.09131
 - 76s - loss: 10.5404 - val_loss: 11.6165
Epoch 2226/8000

Epoch 02226: val_loss did not improve from 10.09131
 - 76s - loss: 10.4397 - val_loss: 11.2694
Epoch 2227/8000

Epoch 02227: val_loss did not improve from 10.09131
 - 75s - loss: 10.0808 - val_loss: 10.9868
Epoch 2228/8000

Epoch 02228: val_loss did not improve from 10.09131
 - 76s - loss: 9.9518 - val_loss: 10.8652
Epoch 2229/8000

Epoch 02229: val_loss did not improve from 10.09131
 - 75s - loss: 9.4994 - val_loss: 11.0543
Epoch 2230/8000

Epoch 02230: val_loss did not improve from 10.09131
 - 76s - loss: 9.3836 - val_loss: 11.8278
Epoch 2231/8000

Epoch 02231: val_loss did not improve from 10.09131
 - 76s - loss: 10.5366 - val_loss: 12.0308
Epoch 2232/8000

Epoch 02232: val_loss did not improve from 10.09131
 - 76s - loss: 11.1829 - val_loss: 11.0676
Epoch 2233/8000

Epoch 02233: val_loss did not improve from 10.09131
 - 76s - loss: 10.3194 - val_loss: 11.1558
Epoch 2234/8000

Epoch 02234: val_loss did not improve from 10.09131
 - 75s - loss: 9.9490 - val_loss: 11.4371
Epoch 2235/8000

Epoch 02235: val_loss did not improve from 10.09131
 - 76s - loss: 9.5217 - val_loss: 10.7401
Epoch 2236/8000

Epoch 02236: val_loss did not improve from 10.09131
 - 76s - loss: 9.5126 - val_loss: 11.2145
Epoch 2237/8000

Epoch 02237: val_loss did not improve from 10.09131
 - 76s - loss: 9.4320 - val_loss: 11.0488
Epoch 2238/8000

Epoch 02238: val_loss did not improve from 10.09131
 - 76s - loss: 9.5235 - val_loss: 11.3495
Epoch 2239/8000

Epoch 02239: val_loss did not improve from 10.09131
 - 76s - loss: 9.8084 - val_loss: 11.7028
Epoch 2240/8000

Epoch 02240: val_loss did not improve from 10.09131
 - 76s - loss: 9.9453 - val_loss: 11.6356
Epoch 2241/8000

Epoch 02241: val_loss did not improve from 10.09131
 - 75s - loss: 10.0241 - val_loss: 11.6976
Epoch 2242/8000

Epoch 02242: val_loss did not improve from 10.09131
 - 76s - loss: 9.8001 - val_loss: 10.8609
Epoch 2243/8000

Epoch 02243: val_loss did not improve from 10.09131
 - 75s - loss: 9.2814 - val_loss: 11.0162
Epoch 2244/8000

Epoch 02244: val_loss did not improve from 10.09131
 - 76s - loss: 9.3784 - val_loss: 11.0047
Epoch 2245/8000

Epoch 02245: val_loss did not improve from 10.09131
 - 76s - loss: 9.2617 - val_loss: 11.0342
Epoch 2246/8000

Epoch 02246: val_loss did not improve from 10.09131
 - 76s - loss: 9.0844 - val_loss: 11.1662
Epoch 2247/8000

Epoch 02247: val_loss did not improve from 10.09131
 - 76s - loss: 9.6122 - val_loss: 10.9004
Epoch 2248/8000

Epoch 02248: val_loss did not improve from 10.09131
 - 75s - loss: 9.4015 - val_loss: 10.9521
Epoch 2249/8000

Epoch 02249: val_loss did not improve from 10.09131
 - 76s - loss: 9.1776 - val_loss: 11.0290
Epoch 2250/8000

Epoch 02250: val_loss did not improve from 10.09131
 - 76s - loss: 8.9922 - val_loss: 10.8839
Epoch 2251/8000

Epoch 02251: val_loss did not improve from 10.09131
 - 76s - loss: 8.9246 - val_loss: 10.7502
Epoch 2252/8000

Epoch 02252: val_loss did not improve from 10.09131
 - 76s - loss: 9.0265 - val_loss: 12.0459
Epoch 2253/8000

Epoch 02253: val_loss did not improve from 10.09131
 - 76s - loss: 9.2793 - val_loss: 10.5885
Epoch 2254/8000

Epoch 02254: val_loss did not improve from 10.09131
 - 75s - loss: 9.3916 - val_loss: 10.8747
Epoch 2255/8000

Epoch 02255: val_loss did not improve from 10.09131
 - 75s - loss: 8.7402 - val_loss: 10.6391
Epoch 2256/8000

Epoch 02256: val_loss did not improve from 10.09131
 - 76s - loss: 9.0747 - val_loss: 10.6372
Epoch 2257/8000

Epoch 02257: val_loss did not improve from 10.09131
 - 75s - loss: 8.7854 - val_loss: 11.2202
Epoch 2258/8000

Epoch 02258: val_loss did not improve from 10.09131
 - 76s - loss: 9.0688 - val_loss: 10.4079
Epoch 2259/8000

Epoch 02259: val_loss did not improve from 10.09131
 - 76s - loss: 9.0578 - val_loss: 10.8947
Epoch 2260/8000

Epoch 02260: val_loss did not improve from 10.09131
 - 76s - loss: 9.0498 - val_loss: 10.2102
Epoch 2261/8000

Epoch 02261: val_loss did not improve from 10.09131
 - 76s - loss: 8.8687 - val_loss: 11.4607
Epoch 2262/8000

Epoch 02262: val_loss improved from 10.09131 to 10.08735, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 8.6710 - val_loss: 10.0874
Epoch 2263/8000

Epoch 02263: val_loss did not improve from 10.08735
 - 76s - loss: 8.9185 - val_loss: 10.2437
Epoch 2264/8000

Epoch 02264: val_loss did not improve from 10.08735
 - 75s - loss: 9.3323 - val_loss: 12.2317
Epoch 2265/8000

Epoch 02265: val_loss did not improve from 10.08735
 - 76s - loss: 10.5275 - val_loss: 10.8937
Epoch 2266/8000

Epoch 02266: val_loss did not improve from 10.08735
 - 76s - loss: 9.1473 - val_loss: 10.1872
Epoch 2267/8000

Epoch 02267: val_loss did not improve from 10.08735
 - 76s - loss: 9.6715 - val_loss: 11.5043
Epoch 2268/8000

Epoch 02268: val_loss did not improve from 10.08735
 - 76s - loss: 9.4026 - val_loss: 10.4940
Epoch 2269/8000

Epoch 02269: val_loss did not improve from 10.08735
 - 75s - loss: 9.4629 - val_loss: 11.2594
Epoch 2270/8000

Epoch 02270: val_loss did not improve from 10.08735
 - 76s - loss: 9.4827 - val_loss: 10.9241
Epoch 2271/8000

Epoch 02271: val_loss did not improve from 10.08735
 - 75s - loss: 9.1260 - val_loss: 11.3417
Epoch 2272/8000

Epoch 02272: val_loss did not improve from 10.08735
 - 76s - loss: 9.1301 - val_loss: 11.0461
Epoch 2273/8000

Epoch 02273: val_loss did not improve from 10.08735
 - 76s - loss: 9.1369 - val_loss: 10.8662
Epoch 2274/8000

Epoch 02274: val_loss did not improve from 10.08735
 - 76s - loss: 8.5449 - val_loss: 10.6064
Epoch 2275/8000

Epoch 02275: val_loss did not improve from 10.08735
 - 76s - loss: 8.9166 - val_loss: 10.3273
Epoch 2276/8000

Epoch 02276: val_loss did not improve from 10.08735
 - 75s - loss: 8.8746 - val_loss: 10.7053
Epoch 2277/8000

Epoch 02277: val_loss did not improve from 10.08735
 - 76s - loss: 8.8222 - val_loss: 10.6493
Epoch 2278/8000

Epoch 02278: val_loss did not improve from 10.08735
 - 76s - loss: 9.4641 - val_loss: 11.3546
Epoch 2279/8000

Epoch 02279: val_loss did not improve from 10.08735
 - 76s - loss: 10.4421 - val_loss: 10.8827
Epoch 2280/8000

Epoch 02280: val_loss did not improve from 10.08735
 - 76s - loss: 9.8187 - val_loss: 10.6891
Epoch 2281/8000

Epoch 02281: val_loss did not improve from 10.08735
 - 76s - loss: 9.5198 - val_loss: 10.5170
Epoch 2282/8000

Epoch 02282: val_loss did not improve from 10.08735
 - 76s - loss: 9.2554 - val_loss: 11.3754
Epoch 2283/8000

Epoch 02283: val_loss did not improve from 10.08735
 - 75s - loss: 10.0567 - val_loss: 11.2543
Epoch 2284/8000

Epoch 02284: val_loss did not improve from 10.08735
 - 76s - loss: 9.6078 - val_loss: 11.2821
Epoch 2285/8000

Epoch 02285: val_loss did not improve from 10.08735
 - 75s - loss: 9.6994 - val_loss: 10.8698
Epoch 2286/8000

Epoch 02286: val_loss did not improve from 10.08735
 - 76s - loss: 9.2456 - val_loss: 10.4573
Epoch 2287/8000

Epoch 02287: val_loss did not improve from 10.08735
 - 76s - loss: 8.9603 - val_loss: 11.1187
Epoch 2288/8000

Epoch 02288: val_loss did not improve from 10.08735
 - 76s - loss: 8.8631 - val_loss: 10.3598
Epoch 2289/8000

Epoch 02289: val_loss did not improve from 10.08735
 - 76s - loss: 8.9335 - val_loss: 10.5203
Epoch 2290/8000

Epoch 02290: val_loss did not improve from 10.08735
 - 75s - loss: 8.9731 - val_loss: 10.4997
Epoch 2291/8000

Epoch 02291: val_loss did not improve from 10.08735
 - 76s - loss: 8.6708 - val_loss: 10.9574
Epoch 2292/8000

Epoch 02292: val_loss did not improve from 10.08735
 - 76s - loss: 9.5206 - val_loss: 10.8845
Epoch 2293/8000

Epoch 02293: val_loss did not improve from 10.08735
 - 76s - loss: 9.8455 - val_loss: 12.0405
Epoch 2294/8000

Epoch 02294: val_loss did not improve from 10.08735
 - 76s - loss: 9.6882 - val_loss: 11.3098
Epoch 2295/8000

Epoch 02295: val_loss did not improve from 10.08735
 - 76s - loss: 9.3841 - val_loss: 10.8778
Epoch 2296/8000

Epoch 02296: val_loss did not improve from 10.08735
 - 76s - loss: 8.9789 - val_loss: 10.6841
Epoch 2297/8000

Epoch 02297: val_loss did not improve from 10.08735
 - 75s - loss: 10.0095 - val_loss: 11.4246
Epoch 2298/8000

Epoch 02298: val_loss did not improve from 10.08735
 - 76s - loss: 9.7349 - val_loss: 11.1361
Epoch 2299/8000

Epoch 02299: val_loss did not improve from 10.08735
 - 75s - loss: 9.6404 - val_loss: 11.1521
Epoch 2300/8000

Epoch 02300: val_loss did not improve from 10.08735
 - 76s - loss: 9.0439 - val_loss: 11.4804
Epoch 2301/8000

Epoch 02301: val_loss did not improve from 10.08735
 - 76s - loss: 9.2985 - val_loss: 10.8293
Epoch 2302/8000

Epoch 02302: val_loss did not improve from 10.08735
 - 76s - loss: 8.8720 - val_loss: 10.6780
Epoch 2303/8000

Epoch 02303: val_loss did not improve from 10.08735
 - 76s - loss: 8.7740 - val_loss: 10.6269
Epoch 2304/8000

Epoch 02304: val_loss did not improve from 10.08735
 - 76s - loss: 9.5847 - val_loss: 11.3024
Epoch 2305/8000

Epoch 02305: val_loss did not improve from 10.08735
 - 76s - loss: 9.6141 - val_loss: 11.5955
Epoch 2306/8000

Epoch 02306: val_loss did not improve from 10.08735
 - 76s - loss: 9.7685 - val_loss: 11.1857
Epoch 2307/8000

Epoch 02307: val_loss did not improve from 10.08735
 - 76s - loss: 9.6307 - val_loss: 11.1511
Epoch 2308/8000

Epoch 02308: val_loss did not improve from 10.08735
 - 76s - loss: 9.2530 - val_loss: 11.6732
Epoch 2309/8000

Epoch 02309: val_loss did not improve from 10.08735
 - 76s - loss: 9.1035 - val_loss: 11.5367
Epoch 2310/8000

Epoch 02310: val_loss did not improve from 10.08735
 - 76s - loss: 9.5664 - val_loss: 10.9784
Epoch 2311/8000

Epoch 02311: val_loss did not improve from 10.08735
 - 75s - loss: 9.5428 - val_loss: 11.3214
Epoch 2312/8000

Epoch 02312: val_loss did not improve from 10.08735
 - 75s - loss: 9.4429 - val_loss: 11.4843
Epoch 2313/8000

Epoch 02313: val_loss did not improve from 10.08735
 - 75s - loss: 9.6762 - val_loss: 10.7714
Epoch 2314/8000

Epoch 02314: val_loss did not improve from 10.08735
 - 76s - loss: 9.3608 - val_loss: 11.1469
Epoch 2315/8000

Epoch 02315: val_loss did not improve from 10.08735
 - 76s - loss: 9.9878 - val_loss: 11.4382
Epoch 2316/8000

Epoch 02316: val_loss did not improve from 10.08735
 - 76s - loss: 9.9210 - val_loss: 11.4055
Epoch 2317/8000

Epoch 02317: val_loss did not improve from 10.08735
 - 76s - loss: 9.7839 - val_loss: 10.9576
Epoch 2318/8000

Epoch 02318: val_loss did not improve from 10.08735
 - 75s - loss: 9.6828 - val_loss: 11.4030
Epoch 2319/8000

Epoch 02319: val_loss did not improve from 10.08735
 - 76s - loss: 9.5835 - val_loss: 11.4500
Epoch 2320/8000

Epoch 02320: val_loss did not improve from 10.08735
 - 75s - loss: 9.5656 - val_loss: 11.0041
Epoch 2321/8000

Epoch 02321: val_loss did not improve from 10.08735
 - 76s - loss: 9.3973 - val_loss: 11.6711
Epoch 2322/8000

Epoch 02322: val_loss did not improve from 10.08735
 - 76s - loss: 9.5810 - val_loss: 11.6866
Epoch 2323/8000

Epoch 02323: val_loss did not improve from 10.08735
 - 76s - loss: 9.3742 - val_loss: 11.0065
Epoch 2324/8000

Epoch 02324: val_loss did not improve from 10.08735
 - 76s - loss: 9.5370 - val_loss: 11.5665
Epoch 2325/8000

Epoch 02325: val_loss did not improve from 10.08735
 - 75s - loss: 9.5441 - val_loss: 10.8902
Epoch 2326/8000

Epoch 02326: val_loss did not improve from 10.08735
 - 76s - loss: 9.5546 - val_loss: 11.2083
Epoch 2327/8000

Epoch 02327: val_loss did not improve from 10.08735
 - 75s - loss: 9.3498 - val_loss: 11.3789
Epoch 2328/8000

Epoch 02328: val_loss did not improve from 10.08735
 - 76s - loss: 9.1892 - val_loss: 11.5709
Epoch 2329/8000

Epoch 02329: val_loss did not improve from 10.08735
 - 76s - loss: 9.6933 - val_loss: 10.6548
Epoch 2330/8000

Epoch 02330: val_loss did not improve from 10.08735
 - 75s - loss: 9.8562 - val_loss: 10.9659
Epoch 2331/8000

Epoch 02331: val_loss did not improve from 10.08735
 - 76s - loss: 9.5488 - val_loss: 10.4678
Epoch 2332/8000

Epoch 02332: val_loss did not improve from 10.08735
 - 75s - loss: 9.6098 - val_loss: 10.8652
Epoch 2333/8000

Epoch 02333: val_loss did not improve from 10.08735
 - 76s - loss: 9.5194 - val_loss: 10.7568
Epoch 2334/8000

Epoch 02334: val_loss did not improve from 10.08735
 - 75s - loss: 9.8954 - val_loss: 11.1287
Epoch 2335/8000

Epoch 02335: val_loss did not improve from 10.08735
 - 76s - loss: 9.8247 - val_loss: 11.3159
Epoch 2336/8000

Epoch 02336: val_loss did not improve from 10.08735
 - 76s - loss: 9.6442 - val_loss: 10.9189
Epoch 2337/8000

Epoch 02337: val_loss did not improve from 10.08735
 - 76s - loss: 9.2593 - val_loss: 10.5047
Epoch 2338/8000

Epoch 02338: val_loss did not improve from 10.08735
 - 76s - loss: 9.1345 - val_loss: 10.7702
Epoch 2339/8000

Epoch 02339: val_loss did not improve from 10.08735
 - 75s - loss: 9.5582 - val_loss: 11.0968
Epoch 2340/8000

Epoch 02340: val_loss did not improve from 10.08735
 - 76s - loss: 9.7573 - val_loss: 11.1975
Epoch 2341/8000

Epoch 02341: val_loss did not improve from 10.08735
 - 75s - loss: 9.4357 - val_loss: 11.2706
Epoch 2342/8000

Epoch 02342: val_loss did not improve from 10.08735
 - 76s - loss: 9.6777 - val_loss: 11.3400
Epoch 2343/8000

Epoch 02343: val_loss did not improve from 10.08735
 - 75s - loss: 9.7539 - val_loss: 10.9487
Epoch 2344/8000

Epoch 02344: val_loss did not improve from 10.08735
 - 76s - loss: 9.5078 - val_loss: 10.7610
Epoch 2345/8000

Epoch 02345: val_loss did not improve from 10.08735
 - 76s - loss: 9.5325 - val_loss: 11.1511
Epoch 2346/8000

Epoch 02346: val_loss did not improve from 10.08735
 - 75s - loss: 9.6013 - val_loss: 10.3238
Epoch 2347/8000

Epoch 02347: val_loss did not improve from 10.08735
 - 76s - loss: 9.7897 - val_loss: 11.6259
Epoch 2348/8000

Epoch 02348: val_loss did not improve from 10.08735
 - 75s - loss: 10.4799 - val_loss: 11.2506
Epoch 2349/8000

Epoch 02349: val_loss did not improve from 10.08735
 - 76s - loss: 9.5197 - val_loss: 10.4264
Epoch 2350/8000

Epoch 02350: val_loss did not improve from 10.08735
 - 76s - loss: 10.4328 - val_loss: 10.9399
Epoch 2351/8000

Epoch 02351: val_loss did not improve from 10.08735
 - 76s - loss: 10.3241 - val_loss: 10.8675
Epoch 2352/8000

Epoch 02352: val_loss did not improve from 10.08735
 - 76s - loss: 10.6357 - val_loss: 11.1641
Epoch 2353/8000

Epoch 02353: val_loss did not improve from 10.08735
 - 75s - loss: 11.9209 - val_loss: 13.9291
Epoch 2354/8000

Epoch 02354: val_loss did not improve from 10.08735
 - 76s - loss: 12.1946 - val_loss: 11.9748
Epoch 2355/8000

Epoch 02355: val_loss did not improve from 10.08735
 - 75s - loss: 11.0046 - val_loss: 11.0358
Epoch 2356/8000

Epoch 02356: val_loss did not improve from 10.08735
 - 76s - loss: 10.7486 - val_loss: 12.0711
Epoch 2357/8000

Epoch 02357: val_loss did not improve from 10.08735
 - 75s - loss: 10.8334 - val_loss: 11.6289
Epoch 2358/8000

Epoch 02358: val_loss did not improve from 10.08735
 - 76s - loss: 10.7221 - val_loss: 11.3430
Epoch 2359/8000

Epoch 02359: val_loss did not improve from 10.08735
 - 76s - loss: 10.2115 - val_loss: 11.1244
Epoch 2360/8000

Epoch 02360: val_loss did not improve from 10.08735
 - 75s - loss: 10.0114 - val_loss: 11.5824
Epoch 2361/8000

Epoch 02361: val_loss did not improve from 10.08735
 - 76s - loss: 9.9466 - val_loss: 11.0235
Epoch 2362/8000

Epoch 02362: val_loss did not improve from 10.08735
 - 75s - loss: 9.7614 - val_loss: 11.4581
Epoch 2363/8000

Epoch 02363: val_loss did not improve from 10.08735
 - 76s - loss: 10.1350 - val_loss: 10.7857
Epoch 2364/8000

Epoch 02364: val_loss did not improve from 10.08735
 - 76s - loss: 10.4311 - val_loss: 11.7528
Epoch 2365/8000

Epoch 02365: val_loss did not improve from 10.08735
 - 76s - loss: 10.2333 - val_loss: 10.7889
Epoch 2366/8000

Epoch 02366: val_loss did not improve from 10.08735
 - 76s - loss: 10.5192 - val_loss: 11.2442
Epoch 2367/8000

Epoch 02367: val_loss did not improve from 10.08735
 - 75s - loss: 9.4130 - val_loss: 10.9319
Epoch 2368/8000

Epoch 02368: val_loss did not improve from 10.08735
 - 76s - loss: 10.3857 - val_loss: 12.0369
Epoch 2369/8000

Epoch 02369: val_loss did not improve from 10.08735
 - 75s - loss: 10.2179 - val_loss: 11.6330
Epoch 2370/8000

Epoch 02370: val_loss did not improve from 10.08735
 - 76s - loss: 10.2332 - val_loss: 11.9025
Epoch 2371/8000

Epoch 02371: val_loss did not improve from 10.08735
 - 75s - loss: 10.3246 - val_loss: 11.1510
Epoch 2372/8000

Epoch 02372: val_loss did not improve from 10.08735
 - 76s - loss: 9.9321 - val_loss: 11.0212
Epoch 2373/8000

Epoch 02373: val_loss did not improve from 10.08735
 - 76s - loss: 9.9628 - val_loss: 11.4037
Epoch 2374/8000

Epoch 02374: val_loss did not improve from 10.08735
 - 75s - loss: 10.1478 - val_loss: 11.8672
Epoch 2375/8000

Epoch 02375: val_loss did not improve from 10.08735
 - 76s - loss: 9.8402 - val_loss: 11.0438
Epoch 2376/8000

Epoch 02376: val_loss did not improve from 10.08735
 - 75s - loss: 9.8404 - val_loss: 11.0496
Epoch 2377/8000

Epoch 02377: val_loss did not improve from 10.08735
 - 76s - loss: 9.9138 - val_loss: 11.3549
Epoch 2378/8000

Epoch 02378: val_loss did not improve from 10.08735
 - 76s - loss: 9.8160 - val_loss: 11.2915
Epoch 2379/8000

Epoch 02379: val_loss did not improve from 10.08735
 - 76s - loss: 9.5768 - val_loss: 10.6725
Epoch 2380/8000

Epoch 02380: val_loss did not improve from 10.08735
 - 76s - loss: 9.6438 - val_loss: 10.8973
Epoch 2381/8000

Epoch 02381: val_loss did not improve from 10.08735
 - 75s - loss: 9.6616 - val_loss: 11.5320
Epoch 2382/8000

Epoch 02382: val_loss did not improve from 10.08735
 - 76s - loss: 9.4294 - val_loss: 10.9259
Epoch 2383/8000

Epoch 02383: val_loss did not improve from 10.08735
 - 75s - loss: 9.3242 - val_loss: 10.5274
Epoch 2384/8000

Epoch 02384: val_loss did not improve from 10.08735
 - 76s - loss: 9.2650 - val_loss: 11.5358
Epoch 2385/8000

Epoch 02385: val_loss did not improve from 10.08735
 - 75s - loss: 10.2601 - val_loss: 11.8604
Epoch 2386/8000

Epoch 02386: val_loss did not improve from 10.08735
 - 76s - loss: 9.8378 - val_loss: 11.4243
Epoch 2387/8000

Epoch 02387: val_loss did not improve from 10.08735
 - 76s - loss: 9.8933 - val_loss: 11.1731
Epoch 2388/8000

Epoch 02388: val_loss did not improve from 10.08735
 - 75s - loss: 9.7787 - val_loss: 11.3372
Epoch 2389/8000

Epoch 02389: val_loss did not improve from 10.08735
 - 76s - loss: 9.9675 - val_loss: 11.3888
Epoch 2390/8000

Epoch 02390: val_loss did not improve from 10.08735
 - 75s - loss: 9.5258 - val_loss: 10.9434
Epoch 2391/8000

Epoch 02391: val_loss did not improve from 10.08735
 - 76s - loss: 9.7278 - val_loss: 11.5178
Epoch 2392/8000

Epoch 02392: val_loss did not improve from 10.08735
 - 76s - loss: 10.9609 - val_loss: 12.3990
Epoch 2393/8000

Epoch 02393: val_loss did not improve from 10.08735
 - 76s - loss: 10.6862 - val_loss: 11.7423
Epoch 2394/8000

Epoch 02394: val_loss did not improve from 10.08735
 - 76s - loss: 10.6322 - val_loss: 11.0704
Epoch 2395/8000

Epoch 02395: val_loss did not improve from 10.08735
 - 75s - loss: 10.7027 - val_loss: 11.1953
Epoch 2396/8000

Epoch 02396: val_loss did not improve from 10.08735
 - 76s - loss: 9.9722 - val_loss: 11.3864
Epoch 2397/8000

Epoch 02397: val_loss did not improve from 10.08735
 - 75s - loss: 11.0243 - val_loss: 11.2226
Epoch 2398/8000

Epoch 02398: val_loss did not improve from 10.08735
 - 76s - loss: 10.8381 - val_loss: 11.6881
Epoch 2399/8000

Epoch 02399: val_loss did not improve from 10.08735
 - 75s - loss: 10.5786 - val_loss: 11.2483
Epoch 2400/8000

Epoch 02400: val_loss did not improve from 10.08735
 - 76s - loss: 10.5786 - val_loss: 11.0729
Epoch 2401/8000

Epoch 02401: val_loss did not improve from 10.08735
 - 76s - loss: 10.1086 - val_loss: 11.2071
Epoch 2402/8000

Epoch 02402: val_loss did not improve from 10.08735
 - 75s - loss: 10.3046 - val_loss: 11.0521
Epoch 2403/8000

Epoch 02403: val_loss did not improve from 10.08735
 - 76s - loss: 9.8131 - val_loss: 10.7206
Epoch 2404/8000

Epoch 02404: val_loss did not improve from 10.08735
 - 75s - loss: 10.0301 - val_loss: 11.4092
Epoch 2405/8000

Epoch 02405: val_loss did not improve from 10.08735
 - 76s - loss: 10.0870 - val_loss: 10.9155
Epoch 2406/8000

Epoch 02406: val_loss did not improve from 10.08735
 - 76s - loss: 9.7924 - val_loss: 10.5572
Epoch 2407/8000

Epoch 02407: val_loss did not improve from 10.08735
 - 76s - loss: 9.6310 - val_loss: 10.4846
Epoch 2408/8000

Epoch 02408: val_loss did not improve from 10.08735
 - 76s - loss: 10.2480 - val_loss: 10.6618
Epoch 2409/8000

Epoch 02409: val_loss did not improve from 10.08735
 - 75s - loss: 9.7329 - val_loss: 10.5984
Epoch 2410/8000

Epoch 02410: val_loss did not improve from 10.08735
 - 76s - loss: 9.4336 - val_loss: 10.7538
Epoch 2411/8000

Epoch 02411: val_loss did not improve from 10.08735
 - 75s - loss: 9.1615 - val_loss: 10.7039
Epoch 2412/8000

Epoch 02412: val_loss did not improve from 10.08735
 - 76s - loss: 9.4223 - val_loss: 11.1993
Epoch 2413/8000

Epoch 02413: val_loss did not improve from 10.08735
 - 75s - loss: 9.9370 - val_loss: 11.1359
Epoch 2414/8000

Epoch 02414: val_loss did not improve from 10.08735
 - 75s - loss: 9.7904 - val_loss: 11.5495
Epoch 2415/8000

Epoch 02415: val_loss did not improve from 10.08735
 - 75s - loss: 9.7858 - val_loss: 11.2683
Epoch 2416/8000

Epoch 02416: val_loss did not improve from 10.08735
 - 75s - loss: 9.6443 - val_loss: 10.9197
Epoch 2417/8000

Epoch 02417: val_loss did not improve from 10.08735
 - 76s - loss: 9.6736 - val_loss: 10.9063
Epoch 2418/8000

Epoch 02418: val_loss did not improve from 10.08735
 - 75s - loss: 9.6448 - val_loss: 11.9248
Epoch 2419/8000

Epoch 02419: val_loss did not improve from 10.08735
 - 76s - loss: 10.0164 - val_loss: 10.8901
Epoch 2420/8000

Epoch 02420: val_loss did not improve from 10.08735
 - 76s - loss: 9.0539 - val_loss: 10.4279
Epoch 2421/8000

Epoch 02421: val_loss did not improve from 10.08735
 - 76s - loss: 9.0242 - val_loss: 10.7292
Epoch 2422/8000

Epoch 02422: val_loss did not improve from 10.08735
 - 76s - loss: 9.1224 - val_loss: 10.3062
Epoch 2423/8000

Epoch 02423: val_loss did not improve from 10.08735
 - 75s - loss: 8.9560 - val_loss: 10.4092
Epoch 2424/8000

Epoch 02424: val_loss did not improve from 10.08735
 - 76s - loss: 9.5379 - val_loss: 11.3515
Epoch 2425/8000

Epoch 02425: val_loss did not improve from 10.08735
 - 75s - loss: 9.9339 - val_loss: 10.7093
Epoch 2426/8000

Epoch 02426: val_loss did not improve from 10.08735
 - 76s - loss: 9.7849 - val_loss: 10.7635
Epoch 2427/8000

Epoch 02427: val_loss did not improve from 10.08735
 - 76s - loss: 9.7591 - val_loss: 10.6409
Epoch 2428/8000

Epoch 02428: val_loss did not improve from 10.08735
 - 76s - loss: 9.7376 - val_loss: 10.5780
Epoch 2429/8000

Epoch 02429: val_loss did not improve from 10.08735
 - 76s - loss: 9.5280 - val_loss: 10.6408
Epoch 2430/8000

Epoch 02430: val_loss did not improve from 10.08735
 - 75s - loss: 9.3745 - val_loss: 10.8218
Epoch 2431/8000

Epoch 02431: val_loss improved from 10.08735 to 9.96380, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 9.2532 - val_loss: 9.9638
Epoch 2432/8000

Epoch 02432: val_loss did not improve from 9.96380
 - 75s - loss: 9.0372 - val_loss: 10.5049
Epoch 2433/8000

Epoch 02433: val_loss did not improve from 9.96380
 - 76s - loss: 9.0765 - val_loss: 10.2434
Epoch 2434/8000

Epoch 02434: val_loss did not improve from 9.96380
 - 75s - loss: 8.8917 - val_loss: 10.0693
Epoch 2435/8000

Epoch 02435: val_loss did not improve from 9.96380
 - 76s - loss: 10.1440 - val_loss: 11.3615
Epoch 2436/8000

Epoch 02436: val_loss did not improve from 9.96380
 - 76s - loss: 10.1962 - val_loss: 11.0868
Epoch 2437/8000

Epoch 02437: val_loss improved from 9.96380 to 9.74092, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 75s - loss: 8.9110 - val_loss: 9.7409
Epoch 2438/8000

Epoch 02438: val_loss did not improve from 9.74092
 - 76s - loss: 9.2193 - val_loss: 10.0588
Epoch 2439/8000

Epoch 02439: val_loss did not improve from 9.74092
 - 75s - loss: 8.9359 - val_loss: 10.0072
Epoch 2440/8000

Epoch 02440: val_loss did not improve from 9.74092
 - 76s - loss: 9.5201 - val_loss: 11.2914
Epoch 2441/8000

Epoch 02441: val_loss did not improve from 9.74092
 - 76s - loss: 10.5481 - val_loss: 10.7092
Epoch 2442/8000

Epoch 02442: val_loss did not improve from 9.74092
 - 76s - loss: 10.0201 - val_loss: 10.5159
Epoch 2443/8000

Epoch 02443: val_loss did not improve from 9.74092
 - 76s - loss: 9.5019 - val_loss: 10.1955
Epoch 2444/8000

Epoch 02444: val_loss did not improve from 9.74092
 - 75s - loss: 9.3897 - val_loss: 10.2431
Epoch 2445/8000

Epoch 02445: val_loss did not improve from 9.74092
 - 76s - loss: 9.3629 - val_loss: 10.8819
Epoch 2446/8000

Epoch 02446: val_loss did not improve from 9.74092
 - 75s - loss: 9.3332 - val_loss: 10.1727
Epoch 2447/8000

Epoch 02447: val_loss did not improve from 9.74092
 - 76s - loss: 9.2753 - val_loss: 10.4891
Epoch 2448/8000

Epoch 02448: val_loss did not improve from 9.74092
 - 76s - loss: 9.3675 - val_loss: 11.2074
Epoch 2449/8000

Epoch 02449: val_loss did not improve from 9.74092
 - 76s - loss: 9.3900 - val_loss: 10.7038
Epoch 2450/8000

Epoch 02450: val_loss did not improve from 9.74092
 - 76s - loss: 9.1228 - val_loss: 11.0696
Epoch 2451/8000

Epoch 02451: val_loss did not improve from 9.74092
 - 75s - loss: 9.1281 - val_loss: 11.6953
Epoch 2452/8000

Epoch 02452: val_loss did not improve from 9.74092
 - 76s - loss: 9.7199 - val_loss: 10.5117
Epoch 2453/8000

Epoch 02453: val_loss did not improve from 9.74092
 - 75s - loss: 9.1930 - val_loss: 10.5249
Epoch 2454/8000

Epoch 02454: val_loss did not improve from 9.74092
 - 76s - loss: 9.3103 - val_loss: 10.8744
Epoch 2455/8000

Epoch 02455: val_loss did not improve from 9.74092
 - 76s - loss: 10.3731 - val_loss: 12.3851
Epoch 2456/8000

Epoch 02456: val_loss did not improve from 9.74092
 - 76s - loss: 10.1365 - val_loss: 10.6147
Epoch 2457/8000

Epoch 02457: val_loss did not improve from 9.74092
 - 76s - loss: 9.6920 - val_loss: 10.4605
Epoch 2458/8000

Epoch 02458: val_loss did not improve from 9.74092
 - 75s - loss: 9.2673 - val_loss: 10.2505
Epoch 2459/8000

Epoch 02459: val_loss did not improve from 9.74092
 - 76s - loss: 9.8399 - val_loss: 10.5546
Epoch 2460/8000

Epoch 02460: val_loss did not improve from 9.74092
 - 75s - loss: 8.8975 - val_loss: 10.4073
Epoch 2461/8000

Epoch 02461: val_loss did not improve from 9.74092
 - 76s - loss: 9.3599 - val_loss: 10.9532
Epoch 2462/8000

Epoch 02462: val_loss did not improve from 9.74092
 - 75s - loss: 9.1599 - val_loss: 10.4157
Epoch 2463/8000

Epoch 02463: val_loss did not improve from 9.74092
 - 76s - loss: 8.8563 - val_loss: 10.3771
Epoch 2464/8000

Epoch 02464: val_loss did not improve from 9.74092
 - 76s - loss: 8.9992 - val_loss: 10.3974
Epoch 2465/8000

Epoch 02465: val_loss did not improve from 9.74092
 - 75s - loss: 8.9735 - val_loss: 10.5677
Epoch 2466/8000

Epoch 02466: val_loss did not improve from 9.74092
 - 76s - loss: 8.9973 - val_loss: 10.0257
Epoch 2467/8000

Epoch 02467: val_loss did not improve from 9.74092
 - 75s - loss: 8.7051 - val_loss: 10.4288
Epoch 2468/8000

Epoch 02468: val_loss did not improve from 9.74092
 - 76s - loss: 8.9327 - val_loss: 10.4863
Epoch 2469/8000

Epoch 02469: val_loss did not improve from 9.74092
 - 76s - loss: 8.9115 - val_loss: 10.8346
Epoch 2470/8000

Epoch 02470: val_loss did not improve from 9.74092
 - 76s - loss: 9.5920 - val_loss: 10.5842
Epoch 2471/8000

Epoch 02471: val_loss did not improve from 9.74092
 - 76s - loss: 9.2440 - val_loss: 10.6956
Epoch 2472/8000

Epoch 02472: val_loss did not improve from 9.74092
 - 75s - loss: 8.9007 - val_loss: 11.4563
Epoch 2473/8000

Epoch 02473: val_loss did not improve from 9.74092
 - 76s - loss: 9.2945 - val_loss: 10.9716
Epoch 2474/8000

Epoch 02474: val_loss did not improve from 9.74092
 - 75s - loss: 10.1592 - val_loss: 11.0543
Epoch 2475/8000

Epoch 02475: val_loss did not improve from 9.74092
 - 75s - loss: 8.8055 - val_loss: 10.4086
Epoch 2476/8000

Epoch 02476: val_loss did not improve from 9.74092
 - 75s - loss: 9.2077 - val_loss: 11.8871
Epoch 2477/8000

Epoch 02477: val_loss did not improve from 9.74092
 - 76s - loss: 9.8768 - val_loss: 10.7785
Epoch 2478/8000

Epoch 02478: val_loss did not improve from 9.74092
 - 76s - loss: 9.4310 - val_loss: 11.7103
Epoch 2479/8000

Epoch 02479: val_loss did not improve from 9.74092
 - 75s - loss: 11.7969 - val_loss: 12.4210
Epoch 2480/8000

Epoch 02480: val_loss did not improve from 9.74092
 - 76s - loss: 10.3907 - val_loss: 10.7021
Epoch 2481/8000

Epoch 02481: val_loss did not improve from 9.74092
 - 75s - loss: 9.2622 - val_loss: 10.7634
Epoch 2482/8000

Epoch 02482: val_loss did not improve from 9.74092
 - 76s - loss: 8.8647 - val_loss: 10.9626
Epoch 2483/8000

Epoch 02483: val_loss did not improve from 9.74092
 - 76s - loss: 8.6329 - val_loss: 10.5795
Epoch 2484/8000

Epoch 02484: val_loss did not improve from 9.74092
 - 76s - loss: 9.0063 - val_loss: 10.8760
Epoch 2485/8000

Epoch 02485: val_loss did not improve from 9.74092
 - 76s - loss: 8.7753 - val_loss: 9.9783
Epoch 2486/8000

Epoch 02486: val_loss did not improve from 9.74092
 - 75s - loss: 8.9269 - val_loss: 10.5282
Epoch 2487/8000

Epoch 02487: val_loss did not improve from 9.74092
 - 76s - loss: 8.4588 - val_loss: 10.1496
Epoch 2488/8000

Epoch 02488: val_loss did not improve from 9.74092
 - 75s - loss: 8.6156 - val_loss: 10.2875
Epoch 2489/8000

Epoch 02489: val_loss did not improve from 9.74092
 - 76s - loss: 8.6346 - val_loss: 10.2351
Epoch 2490/8000

Epoch 02490: val_loss did not improve from 9.74092
 - 76s - loss: 8.7387 - val_loss: 11.4594
Epoch 2491/8000

Epoch 02491: val_loss did not improve from 9.74092
 - 76s - loss: 8.9397 - val_loss: 11.3181
Epoch 2492/8000

Epoch 02492: val_loss did not improve from 9.74092
 - 76s - loss: 8.8059 - val_loss: 10.2521
Epoch 2493/8000

Epoch 02493: val_loss did not improve from 9.74092
 - 75s - loss: 8.5257 - val_loss: 11.0567
Epoch 2494/8000

Epoch 02494: val_loss did not improve from 9.74092
 - 76s - loss: 9.4249 - val_loss: 10.3180
Epoch 2495/8000

Epoch 02495: val_loss did not improve from 9.74092
 - 75s - loss: 10.0204 - val_loss: 10.9369
Epoch 2496/8000

Epoch 02496: val_loss did not improve from 9.74092
 - 76s - loss: 9.5276 - val_loss: 10.3482
Epoch 2497/8000

Epoch 02497: val_loss did not improve from 9.74092
 - 76s - loss: 9.6532 - val_loss: 11.3455
Epoch 2498/8000

Epoch 02498: val_loss did not improve from 9.74092
 - 76s - loss: 10.1506 - val_loss: 11.3427
Epoch 2499/8000

Epoch 02499: val_loss did not improve from 9.74092
 - 76s - loss: 10.0108 - val_loss: 11.8188
Epoch 2500/8000

Epoch 02500: val_loss did not improve from 9.74092
 - 75s - loss: 9.7959 - val_loss: 10.9046
Epoch 2501/8000

Epoch 02501: val_loss did not improve from 9.74092
 - 76s - loss: 9.8762 - val_loss: 11.5997
Epoch 2502/8000

Epoch 02502: val_loss did not improve from 9.74092
 - 75s - loss: 9.5098 - val_loss: 11.2805
Epoch 2503/8000

Epoch 02503: val_loss did not improve from 9.74092
 - 76s - loss: 9.5980 - val_loss: 10.9732
Epoch 2504/8000

Epoch 02504: val_loss did not improve from 9.74092
 - 76s - loss: 10.0631 - val_loss: 11.4684
Epoch 2505/8000

Epoch 02505: val_loss did not improve from 9.74092
 - 76s - loss: 9.7649 - val_loss: 10.3832
Epoch 2506/8000

Epoch 02506: val_loss did not improve from 9.74092
 - 76s - loss: 10.1591 - val_loss: 11.6487
Epoch 2507/8000

Epoch 02507: val_loss did not improve from 9.74092
 - 75s - loss: 10.1628 - val_loss: 10.4312
Epoch 2508/8000

Epoch 02508: val_loss did not improve from 9.74092
 - 76s - loss: 10.2358 - val_loss: 11.5000
Epoch 2509/8000

Epoch 02509: val_loss did not improve from 9.74092
 - 75s - loss: 9.8805 - val_loss: 10.4561
Epoch 2510/8000

Epoch 02510: val_loss did not improve from 9.74092
 - 76s - loss: 9.6332 - val_loss: 11.0311
Epoch 2511/8000

Epoch 02511: val_loss did not improve from 9.74092
 - 76s - loss: 9.5969 - val_loss: 10.8165
Epoch 2512/8000

Epoch 02512: val_loss did not improve from 9.74092
 - 76s - loss: 9.1687 - val_loss: 10.0866
Epoch 2513/8000

Epoch 02513: val_loss did not improve from 9.74092
 - 76s - loss: 9.0609 - val_loss: 10.6249
Epoch 2514/8000

Epoch 02514: val_loss did not improve from 9.74092
 - 75s - loss: 9.2141 - val_loss: 10.7776
Epoch 2515/8000

Epoch 02515: val_loss did not improve from 9.74092
 - 76s - loss: 9.5411 - val_loss: 10.8364
Epoch 2516/8000

Epoch 02516: val_loss did not improve from 9.74092
 - 75s - loss: 9.0329 - val_loss: 11.1871
Epoch 2517/8000

Epoch 02517: val_loss did not improve from 9.74092
 - 76s - loss: 9.5106 - val_loss: 10.3452
Epoch 2518/8000

Epoch 02518: val_loss did not improve from 9.74092
 - 75s - loss: 9.3230 - val_loss: 11.3586
Epoch 2519/8000

Epoch 02519: val_loss did not improve from 9.74092
 - 76s - loss: 10.0319 - val_loss: 11.3842
Epoch 2520/8000

Epoch 02520: val_loss did not improve from 9.74092
 - 76s - loss: 10.0651 - val_loss: 11.5901
Epoch 2521/8000

Epoch 02521: val_loss did not improve from 9.74092
 - 75s - loss: 9.8427 - val_loss: 11.2152
Epoch 2522/8000

Epoch 02522: val_loss did not improve from 9.74092
 - 76s - loss: 9.8993 - val_loss: 10.8214
Epoch 2523/8000

Epoch 02523: val_loss did not improve from 9.74092
 - 75s - loss: 9.4679 - val_loss: 10.8734
Epoch 2524/8000

Epoch 02524: val_loss did not improve from 9.74092
 - 76s - loss: 9.3691 - val_loss: 10.9926
Epoch 2525/8000

Epoch 02525: val_loss did not improve from 9.74092
 - 76s - loss: 9.2929 - val_loss: 10.5699
Epoch 2526/8000

Epoch 02526: val_loss did not improve from 9.74092
 - 76s - loss: 9.6848 - val_loss: 13.3652
Epoch 2527/8000

Epoch 02527: val_loss did not improve from 9.74092
 - 76s - loss: 10.5734 - val_loss: 11.6150
Epoch 2528/8000

Epoch 02528: val_loss did not improve from 9.74092
 - 75s - loss: 9.7278 - val_loss: 11.5591
Epoch 2529/8000

Epoch 02529: val_loss did not improve from 9.74092
 - 76s - loss: 9.8433 - val_loss: 10.7864
Epoch 2530/8000

Epoch 02530: val_loss did not improve from 9.74092
 - 76s - loss: 9.7586 - val_loss: 10.4539
Epoch 2531/8000

Epoch 02531: val_loss did not improve from 9.74092
 - 76s - loss: 9.5385 - val_loss: 12.4250
Epoch 2532/8000

Epoch 02532: val_loss did not improve from 9.74092
 - 76s - loss: 10.7453 - val_loss: 11.0559
Epoch 2533/8000

Epoch 02533: val_loss did not improve from 9.74092
 - 76s - loss: 9.6925 - val_loss: 10.7158
Epoch 2534/8000

Epoch 02534: val_loss did not improve from 9.74092
 - 75s - loss: 10.7869 - val_loss: 12.4440
Epoch 2535/8000

Epoch 02535: val_loss did not improve from 9.74092
 - 75s - loss: 11.3981 - val_loss: 11.8484
Epoch 2536/8000

Epoch 02536: val_loss did not improve from 9.74092
 - 76s - loss: 11.2156 - val_loss: 13.0265
Epoch 2537/8000

Epoch 02537: val_loss did not improve from 9.74092
 - 75s - loss: 10.8279 - val_loss: 11.6931
Epoch 2538/8000

Epoch 02538: val_loss did not improve from 9.74092
 - 76s - loss: 9.7918 - val_loss: 10.4783
Epoch 2539/8000

Epoch 02539: val_loss did not improve from 9.74092
 - 76s - loss: 9.4065 - val_loss: 10.5812
Epoch 2540/8000

Epoch 02540: val_loss did not improve from 9.74092
 - 76s - loss: 10.5517 - val_loss: 12.4571
Epoch 2541/8000

Epoch 02541: val_loss did not improve from 9.74092
 - 76s - loss: 11.0543 - val_loss: 12.8072
Epoch 2542/8000

Epoch 02542: val_loss did not improve from 9.74092
 - 76s - loss: 10.9458 - val_loss: 11.6057
Epoch 2543/8000

Epoch 02543: val_loss did not improve from 9.74092
 - 76s - loss: 10.9645 - val_loss: 11.5059
Epoch 2544/8000

Epoch 02544: val_loss did not improve from 9.74092
 - 76s - loss: 10.1501 - val_loss: 10.3889
Epoch 2545/8000

Epoch 02545: val_loss did not improve from 9.74092
 - 76s - loss: 10.6655 - val_loss: 11.2317
Epoch 2546/8000

Epoch 02546: val_loss did not improve from 9.74092
 - 76s - loss: 10.3413 - val_loss: 10.8361
Epoch 2547/8000

Epoch 02547: val_loss did not improve from 9.74092
 - 76s - loss: 9.9635 - val_loss: 10.6986
Epoch 2548/8000

Epoch 02548: val_loss did not improve from 9.74092
 - 76s - loss: 9.7672 - val_loss: 11.6012
Epoch 2549/8000

Epoch 02549: val_loss did not improve from 9.74092
 - 75s - loss: 9.6712 - val_loss: 11.1096
Epoch 2550/8000

Epoch 02550: val_loss did not improve from 9.74092
 - 76s - loss: 9.1837 - val_loss: 10.1644
Epoch 2551/8000

Epoch 02551: val_loss did not improve from 9.74092
 - 75s - loss: 9.6530 - val_loss: 11.0404
Epoch 2552/8000

Epoch 02552: val_loss did not improve from 9.74092
 - 76s - loss: 10.9215 - val_loss: 10.9556
Epoch 2553/8000

Epoch 02553: val_loss did not improve from 9.74092
 - 76s - loss: 10.6494 - val_loss: 11.2811
Epoch 2554/8000

Epoch 02554: val_loss did not improve from 9.74092
 - 76s - loss: 11.6694 - val_loss: 11.2585
Epoch 2555/8000

Epoch 02555: val_loss did not improve from 9.74092
 - 76s - loss: 10.6616 - val_loss: 11.4892
Epoch 2556/8000

Epoch 02556: val_loss did not improve from 9.74092
 - 75s - loss: 10.2507 - val_loss: 11.1402
Epoch 2557/8000

Epoch 02557: val_loss did not improve from 9.74092
 - 76s - loss: 10.2443 - val_loss: 11.0349
Epoch 2558/8000

Epoch 02558: val_loss did not improve from 9.74092
 - 75s - loss: 9.9706 - val_loss: 11.0410
Epoch 2559/8000

Epoch 02559: val_loss did not improve from 9.74092
 - 76s - loss: 10.3874 - val_loss: 10.8895
Epoch 2560/8000

Epoch 02560: val_loss did not improve from 9.74092
 - 76s - loss: 11.1116 - val_loss: 11.1328
Epoch 2561/8000

Epoch 02561: val_loss did not improve from 9.74092
 - 76s - loss: 10.2094 - val_loss: 10.6208
Epoch 2562/8000

Epoch 02562: val_loss did not improve from 9.74092
 - 76s - loss: 9.8538 - val_loss: 10.6504
Epoch 2563/8000

Epoch 02563: val_loss did not improve from 9.74092
 - 75s - loss: 9.5660 - val_loss: 10.4807
Epoch 2564/8000

Epoch 02564: val_loss did not improve from 9.74092
 - 76s - loss: 9.6360 - val_loss: 10.8147
Epoch 2565/8000

Epoch 02565: val_loss did not improve from 9.74092
 - 75s - loss: 9.6381 - val_loss: 10.5144
Epoch 2566/8000

Epoch 02566: val_loss did not improve from 9.74092
 - 76s - loss: 9.7603 - val_loss: 10.3068
Epoch 2567/8000

Epoch 02567: val_loss did not improve from 9.74092
 - 76s - loss: 9.8162 - val_loss: 10.6633
Epoch 2568/8000

Epoch 02568: val_loss did not improve from 9.74092
 - 76s - loss: 9.6865 - val_loss: 10.9509
Epoch 2569/8000

Epoch 02569: val_loss did not improve from 9.74092
 - 76s - loss: 10.5873 - val_loss: 10.8589
Epoch 2570/8000

Epoch 02570: val_loss did not improve from 9.74092
 - 75s - loss: 9.3537 - val_loss: 10.8899
Epoch 2571/8000

Epoch 02571: val_loss did not improve from 9.74092
 - 76s - loss: 9.5448 - val_loss: 10.2387
Epoch 2572/8000

Epoch 02572: val_loss did not improve from 9.74092
 - 76s - loss: 8.9989 - val_loss: 10.5389
Epoch 2573/8000

Epoch 02573: val_loss did not improve from 9.74092
 - 76s - loss: 9.3831 - val_loss: 11.1635
Epoch 2574/8000

Epoch 02574: val_loss did not improve from 9.74092
 - 76s - loss: 10.9023 - val_loss: 11.9417
Epoch 2575/8000

Epoch 02575: val_loss did not improve from 9.74092
 - 76s - loss: 10.2386 - val_loss: 10.1078
Epoch 2576/8000

Epoch 02576: val_loss did not improve from 9.74092
 - 76s - loss: 9.5213 - val_loss: 10.2233
Epoch 2577/8000

Epoch 02577: val_loss did not improve from 9.74092
 - 75s - loss: 9.7706 - val_loss: 9.7976
Epoch 2578/8000

Epoch 02578: val_loss did not improve from 9.74092
 - 76s - loss: 9.0457 - val_loss: 10.3112
Epoch 2579/8000

Epoch 02579: val_loss did not improve from 9.74092
 - 75s - loss: 11.9021 - val_loss: 13.5875
Epoch 2580/8000

Epoch 02580: val_loss did not improve from 9.74092
 - 76s - loss: 12.3867 - val_loss: 11.9675
Epoch 2581/8000

Epoch 02581: val_loss did not improve from 9.74092
 - 76s - loss: 11.6220 - val_loss: 12.0141
Epoch 2582/8000

Epoch 02582: val_loss did not improve from 9.74092
 - 76s - loss: 12.0196 - val_loss: 12.2451
Epoch 2583/8000

Epoch 02583: val_loss did not improve from 9.74092
 - 76s - loss: 12.0751 - val_loss: 13.2625
Epoch 2584/8000

Epoch 02584: val_loss did not improve from 9.74092
 - 75s - loss: 12.2629 - val_loss: 14.3137
Epoch 2585/8000

Epoch 02585: val_loss did not improve from 9.74092
 - 76s - loss: 12.2403 - val_loss: 11.7829
Epoch 2586/8000

Epoch 02586: val_loss did not improve from 9.74092
 - 75s - loss: 10.9267 - val_loss: 11.2450
Epoch 2587/8000

Epoch 02587: val_loss did not improve from 9.74092
 - 76s - loss: 10.2938 - val_loss: 10.9471
Epoch 2588/8000

Epoch 02588: val_loss did not improve from 9.74092
 - 76s - loss: 10.0092 - val_loss: 10.8360
Epoch 2589/8000

Epoch 02589: val_loss did not improve from 9.74092
 - 76s - loss: 9.7698 - val_loss: 12.7223
Epoch 2590/8000

Epoch 02590: val_loss did not improve from 9.74092
 - 76s - loss: 9.7742 - val_loss: 10.5709
Epoch 2591/8000

Epoch 02591: val_loss did not improve from 9.74092
 - 75s - loss: 10.1465 - val_loss: 12.5708
Epoch 2592/8000

Epoch 02592: val_loss did not improve from 9.74092
 - 75s - loss: 10.1094 - val_loss: 10.6727
Epoch 2593/8000

Epoch 02593: val_loss did not improve from 9.74092
 - 75s - loss: 9.2579 - val_loss: 10.2785
Epoch 2594/8000

Epoch 02594: val_loss did not improve from 9.74092
 - 76s - loss: 9.5543 - val_loss: 12.4113
Epoch 2595/8000

Epoch 02595: val_loss did not improve from 9.74092
 - 76s - loss: 9.1878 - val_loss: 11.3120
Epoch 2596/8000

Epoch 02596: val_loss did not improve from 9.74092
 - 76s - loss: 8.8239 - val_loss: 10.0576
Epoch 2597/8000

Epoch 02597: val_loss did not improve from 9.74092
 - 76s - loss: 8.5116 - val_loss: 10.7610
Epoch 2598/8000

Epoch 02598: val_loss did not improve from 9.74092
 - 75s - loss: 9.3460 - val_loss: 9.8732
Epoch 2599/8000

Epoch 02599: val_loss did not improve from 9.74092
 - 76s - loss: 8.9955 - val_loss: 9.8732
Epoch 2600/8000

Epoch 02600: val_loss did not improve from 9.74092
 - 75s - loss: 9.1732 - val_loss: 10.0038
Epoch 2601/8000

Epoch 02601: val_loss improved from 9.74092 to 9.65435, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 9.0521 - val_loss: 9.6544
Epoch 2602/8000

Epoch 02602: val_loss did not improve from 9.65435
 - 76s - loss: 9.2425 - val_loss: 11.5257
Epoch 2603/8000

Epoch 02603: val_loss did not improve from 9.65435
 - 76s - loss: 9.6149 - val_loss: 10.9962
Epoch 2604/8000

Epoch 02604: val_loss did not improve from 9.65435
 - 76s - loss: 9.7205 - val_loss: 10.3265
Epoch 2605/8000

Epoch 02605: val_loss did not improve from 9.65435
 - 75s - loss: 8.9525 - val_loss: 9.8942
Epoch 2606/8000

Epoch 02606: val_loss did not improve from 9.65435
 - 76s - loss: 8.8808 - val_loss: 10.4341
Epoch 2607/8000

Epoch 02607: val_loss did not improve from 9.65435
 - 75s - loss: 8.9194 - val_loss: 10.6035
Epoch 2608/8000

Epoch 02608: val_loss improved from 9.65435 to 9.57022, saving model to ../../model_weights/model_2020-03-28_10-09-41.h5
 - 76s - loss: 8.8044 - val_loss: 9.5702
Epoch 2609/8000

Epoch 02609: val_loss did not improve from 9.57022
 - 76s - loss: 8.9420 - val_loss: 10.3713
Epoch 2610/8000

Epoch 02610: val_loss did not improve from 9.57022
 - 76s - loss: 8.7421 - val_loss: 9.8657
Epoch 2611/8000

Epoch 02611: val_loss did not improve from 9.57022
 - 76s - loss: 9.4982 - val_loss: 11.4264
Epoch 2612/8000

Epoch 02612: val_loss did not improve from 9.57022
 - 75s - loss: 11.8344 - val_loss: 13.1148
Epoch 2613/8000

Epoch 02613: val_loss did not improve from 9.57022
 - 76s - loss: 12.6581 - val_loss: 12.4521
Epoch 2614/8000

Epoch 02614: val_loss did not improve from 9.57022
 - 75s - loss: 12.3836 - val_loss: 11.9954
Epoch 2615/8000

Epoch 02615: val_loss did not improve from 9.57022
 - 76s - loss: 11.6915 - val_loss: 12.8084
Epoch 2616/8000

Epoch 02616: val_loss did not improve from 9.57022
 - 76s - loss: 11.5030 - val_loss: 12.2794
Epoch 2617/8000

Epoch 02617: val_loss did not improve from 9.57022
 - 76s - loss: 10.4957 - val_loss: 11.9946
Epoch 2618/8000

Epoch 02618: val_loss did not improve from 9.57022
 - 76s - loss: 10.1780 - val_loss: 11.1035
Epoch 2619/8000

Epoch 02619: val_loss did not improve from 9.57022
 - 75s - loss: 9.5346 - val_loss: 11.1546
Epoch 2620/8000

Epoch 02620: val_loss did not improve from 9.57022
 - 76s - loss: 9.1316 - val_loss: 9.8947
Epoch 2621/8000

Epoch 02621: val_loss did not improve from 9.57022
 - 75s - loss: 9.6779 - val_loss: 11.1681
Epoch 2622/8000

Epoch 02622: val_loss did not improve from 9.57022
 - 75s - loss: 9.9255 - val_loss: 10.7029
Epoch 2623/8000

Epoch 02623: val_loss did not improve from 9.57022
 - 76s - loss: 11.5632 - val_loss: 13.4235
Epoch 2624/8000

Epoch 02624: val_loss did not improve from 9.57022
 - 76s - loss: 11.6103 - val_loss: 11.4624
Epoch 2625/8000

Epoch 02625: val_loss did not improve from 9.57022
 - 76s - loss: 10.3025 - val_loss: 11.9923
Epoch 2626/8000

Epoch 02626: val_loss did not improve from 9.57022
 - 75s - loss: 11.1209 - val_loss: 12.2148
Epoch 2627/8000

Epoch 02627: val_loss did not improve from 9.57022
 - 76s - loss: 11.5030 - val_loss: 11.1529
Epoch 2628/8000

Epoch 02628: val_loss did not improve from 9.57022
 - 75s - loss: 10.1918 - val_loss: 10.8295
Epoch 2629/8000

Epoch 02629: val_loss did not improve from 9.57022
 - 76s - loss: 10.0353 - val_loss: 10.8690
Epoch 2630/8000

Epoch 02630: val_loss did not improve from 9.57022
 - 76s - loss: 9.7578 - val_loss: 11.1781
Epoch 2631/8000

Epoch 02631: val_loss did not improve from 9.57022
 - 76s - loss: 9.5560 - val_loss: 10.2822
Epoch 2632/8000

Epoch 02632: val_loss did not improve from 9.57022
 - 76s - loss: 9.7694 - val_loss: 11.2618
Epoch 2633/8000

Epoch 02633: val_loss did not improve from 9.57022
 - 75s - loss: 9.7254 - val_loss: 10.6195
Epoch 2634/8000

Epoch 02634: val_loss did not improve from 9.57022
 - 76s - loss: 9.6746 - val_loss: 11.7523
Epoch 2635/8000

Epoch 02635: val_loss did not improve from 9.57022
 - 76s - loss: 11.2421 - val_loss: 11.3847
Epoch 2636/8000

Epoch 02636: val_loss did not improve from 9.57022
 - 76s - loss: 11.8437 - val_loss: 14.1221
Epoch 2637/8000

Epoch 02637: val_loss did not improve from 9.57022
 - 76s - loss: 11.2968 - val_loss: 11.7865
Epoch 2638/8000

Epoch 02638: val_loss did not improve from 9.57022
 - 75s - loss: 10.8717 - val_loss: 10.9471
Epoch 2639/8000

Epoch 02639: val_loss did not improve from 9.57022
 - 76s - loss: 10.3008 - val_loss: 11.1249
Epoch 2640/8000

Epoch 02640: val_loss did not improve from 9.57022
 - 75s - loss: 10.3627 - val_loss: 10.6909
Epoch 2641/8000

Epoch 02641: val_loss did not improve from 9.57022
 - 76s - loss: 10.3005 - val_loss: 10.7840
Epoch 2642/8000

Epoch 02642: val_loss did not improve from 9.57022
 - 75s - loss: 10.2850 - val_loss: 12.2955
Epoch 2643/8000

Epoch 02643: val_loss did not improve from 9.57022
 - 76s - loss: 10.0616 - val_loss: 10.3080
Epoch 2644/8000

Epoch 02644: val_loss did not improve from 9.57022
 - 76s - loss: 9.7684 - val_loss: 10.5420
Epoch 2645/8000

Epoch 02645: val_loss did not improve from 9.57022
 - 76s - loss: 10.0823 - val_loss: 11.3725
Epoch 2646/8000

Epoch 02646: val_loss did not improve from 9.57022
 - 76s - loss: 10.3543 - val_loss: 11.1892
Epoch 2647/8000

Epoch 02647: val_loss did not improve from 9.57022
 - 75s - loss: 10.0969 - val_loss: 11.7954
Epoch 2648/8000

Epoch 02648: val_loss did not improve from 9.57022
 - 76s - loss: 9.9745 - val_loss: 10.8716
Epoch 2649/8000

Epoch 02649: val_loss did not improve from 9.57022
 - 75s - loss: 9.4880 - val_loss: 11.6849
Epoch 2650/8000

Epoch 02650: val_loss did not improve from 9.57022
 - 76s - loss: 10.1387 - val_loss: 11.1517
Epoch 2651/8000

Epoch 02651: val_loss did not improve from 9.57022
 - 75s - loss: 9.8516 - val_loss: 10.3630
Epoch 2652/8000

Epoch 02652: val_loss did not improve from 9.57022
 - 75s - loss: 9.3034 - val_loss: 11.2000
Epoch 2653/8000

Epoch 02653: val_loss did not improve from 9.57022
 - 75s - loss: 9.5116 - val_loss: 11.7953
Epoch 2654/8000

Epoch 02654: val_loss did not improve from 9.57022
 - 75s - loss: 9.8991 - val_loss: 10.9033
Epoch 2655/8000

Epoch 02655: val_loss did not improve from 9.57022
 - 76s - loss: 9.8494 - val_loss: 11.7371
Epoch 2656/8000

Epoch 02656: val_loss did not improve from 9.57022
 - 75s - loss: 9.8905 - val_loss: 11.1911
Epoch 2657/8000

Epoch 02657: val_loss did not improve from 9.57022
 - 76s - loss: 9.6494 - val_loss: 11.0881
Epoch 2658/8000

Epoch 02658: val_loss did not improve from 9.57022
 - 76s - loss: 9.4537 - val_loss: 11.4055
Epoch 2659/8000

Epoch 02659: val_loss did not improve from 9.57022
 - 76s - loss: 10.1049 - val_loss: 11.2289
Epoch 2660/8000

Epoch 02660: val_loss did not improve from 9.57022
 - 76s - loss: 9.9479 - val_loss: 11.2437
Epoch 2661/8000

Epoch 02661: val_loss did not improve from 9.57022
 - 75s - loss: 9.9636 - val_loss: 11.2539
Epoch 2662/8000

Epoch 02662: val_loss did not improve from 9.57022
 - 76s - loss: 9.7408 - val_loss: 10.9171
Epoch 2663/8000

Epoch 02663: val_loss did not improve from 9.57022
 - 75s - loss: 9.4977 - val_loss: 10.3678
Epoch 2664/8000

Epoch 02664: val_loss did not improve from 9.57022
 - 76s - loss: 9.6549 - val_loss: 11.1027
Epoch 2665/8000

Epoch 02665: val_loss did not improve from 9.57022
 - 76s - loss: 9.3252 - val_loss: 10.7319
Epoch 2666/8000

Epoch 02666: val_loss did not improve from 9.57022
 - 75s - loss: 9.5391 - val_loss: 10.6966
Epoch 2667/8000

Epoch 02667: val_loss did not improve from 9.57022
 - 76s - loss: 9.3081 - val_loss: 10.2384
Epoch 2668/8000

Epoch 02668: val_loss did not improve from 9.57022
 - 75s - loss: 8.9247 - val_loss: 9.8395
Epoch 2669/8000

Epoch 02669: val_loss did not improve from 9.57022
 - 76s - loss: 9.7527 - val_loss: 12.2626
Epoch 2670/8000

Epoch 02670: val_loss did not improve from 9.57022
 - 75s - loss: 10.2543 - val_loss: 11.4208
Epoch 2671/8000

Epoch 02671: val_loss did not improve from 9.57022
 - 76s - loss: 9.9683 - val_loss: 11.0942
Epoch 2672/8000

Epoch 02672: val_loss did not improve from 9.57022
 - 76s - loss: 10.2044 - val_loss: 11.0008
Epoch 2673/8000

Epoch 02673: val_loss did not improve from 9.57022
 - 76s - loss: 9.7652 - val_loss: 10.5004
Epoch 2674/8000

Epoch 02674: val_loss did not improve from 9.57022
 - 76s - loss: 10.7190 - val_loss: 11.5271
Epoch 2675/8000

Epoch 02675: val_loss did not improve from 9.57022
 - 75s - loss: 10.0718 - val_loss: 11.4217
Epoch 2676/8000

Epoch 02676: val_loss did not improve from 9.57022
 - 76s - loss: 9.7089 - val_loss: 10.5285
Epoch 2677/8000

Epoch 02677: val_loss did not improve from 9.57022
 - 75s - loss: 9.7387 - val_loss: 10.6402
Epoch 2678/8000

Epoch 02678: val_loss did not improve from 9.57022
 - 76s - loss: 9.5548 - val_loss: 10.7490
Epoch 2679/8000

Epoch 02679: val_loss did not improve from 9.57022
 - 76s - loss: 9.9283 - val_loss: 10.9475
Epoch 2680/8000

Epoch 02680: val_loss did not improve from 9.57022
 - 76s - loss: 9.9959 - val_loss: 11.4928
Epoch 2681/8000

Epoch 02681: val_loss did not improve from 9.57022
 - 75s - loss: 10.2214 - val_loss: 10.9290
Epoch 2682/8000

Epoch 02682: val_loss did not improve from 9.57022
 - 75s - loss: 9.5304 - val_loss: 11.0607
Epoch 2683/8000

Epoch 02683: val_loss did not improve from 9.57022
 - 76s - loss: 10.1611 - val_loss: 10.4251
Epoch 2684/8000

Epoch 02684: val_loss did not improve from 9.57022
 - 75s - loss: 9.8302 - val_loss: 11.3821
Epoch 2685/8000

Epoch 02685: val_loss did not improve from 9.57022
 - 76s - loss: 10.5521 - val_loss: 11.4517
Epoch 2686/8000

Epoch 02686: val_loss did not improve from 9.57022
 - 76s - loss: 10.7324 - val_loss: 11.6362
Epoch 2687/8000

Epoch 02687: val_loss did not improve from 9.57022
 - 76s - loss: 10.4969 - val_loss: 11.1362
Epoch 2688/8000

Epoch 02688: val_loss did not improve from 9.57022
 - 76s - loss: 10.7040 - val_loss: 11.2269
Epoch 2689/8000

Epoch 02689: val_loss did not improve from 9.57022
 - 75s - loss: 10.0464 - val_loss: 10.7356
Epoch 2690/8000

Epoch 02690: val_loss did not improve from 9.57022
 - 76s - loss: 9.8871 - val_loss: 10.9775
Epoch 2691/8000

Epoch 02691: val_loss did not improve from 9.57022
 - 75s - loss: 9.4059 - val_loss: 10.5912
Epoch 2692/8000

Epoch 02692: val_loss did not improve from 9.57022
 - 76s - loss: 9.5051 - val_loss: 10.4119
Epoch 2693/8000

Epoch 02693: val_loss did not improve from 9.57022
 - 76s - loss: 9.7394 - val_loss: 11.3803
Epoch 2694/8000

Epoch 02694: val_loss did not improve from 9.57022
 - 76s - loss: 10.1896 - val_loss: 11.1471
Epoch 2695/8000

Epoch 02695: val_loss did not improve from 9.57022
 - 75s - loss: 9.8015 - val_loss: 10.7438
Epoch 2696/8000

Epoch 02696: val_loss did not improve from 9.57022
 - 75s - loss: 9.8954 - val_loss: 10.8527
Epoch 2697/8000

Epoch 02697: val_loss did not improve from 9.57022
 - 76s - loss: 9.8582 - val_loss: 11.3162
Epoch 2698/8000

Epoch 02698: val_loss did not improve from 9.57022
 - 75s - loss: 9.2631 - val_loss: 10.2400
Epoch 2699/8000

Epoch 02699: val_loss did not improve from 9.57022
 - 76s - loss: 9.6958 - val_loss: 10.7530
Epoch 2700/8000

Epoch 02700: val_loss did not improve from 9.57022
 - 76s - loss: 9.9385 - val_loss: 10.6824
Epoch 2701/8000

Epoch 02701: val_loss did not improve from 9.57022
 - 76s - loss: 9.3199 - val_loss: 10.3056
Epoch 2702/8000

Epoch 02702: val_loss did not improve from 9.57022
 - 76s - loss: 9.6471 - val_loss: 11.0518
Epoch 2703/8000

Epoch 02703: val_loss did not improve from 9.57022
 - 75s - loss: 9.3714 - val_loss: 10.4717
Epoch 2704/8000

Epoch 02704: val_loss did not improve from 9.57022
 - 76s - loss: 9.3292 - val_loss: 11.2577
Epoch 2705/8000

Epoch 02705: val_loss did not improve from 9.57022
 - 75s - loss: 9.3009 - val_loss: 10.4501
Epoch 2706/8000

Epoch 02706: val_loss did not improve from 9.57022
 - 76s - loss: 9.5344 - val_loss: 10.6337
Epoch 2707/8000

Epoch 02707: val_loss did not improve from 9.57022
 - 76s - loss: 9.5893 - val_loss: 10.8474
Epoch 2708/8000

Epoch 02708: val_loss did not improve from 9.57022
 - 75s - loss: 9.9583 - val_loss: 10.8764
Epoch 2709/8000

Epoch 02709: val_loss did not improve from 9.57022
 - 75s - loss: 9.8437 - val_loss: 10.7716
Epoch 2710/8000

Epoch 02710: val_loss did not improve from 9.57022
 - 75s - loss: 9.5818 - val_loss: 10.3548
Epoch 2711/8000

Epoch 02711: val_loss did not improve from 9.57022
 - 76s - loss: 9.5744 - val_loss: 10.9624
Epoch 2712/8000

Epoch 02712: val_loss did not improve from 9.57022
 - 75s - loss: 9.5585 - val_loss: 11.0953
Epoch 2713/8000

Epoch 02713: val_loss did not improve from 9.57022
 - 76s - loss: 9.5624 - val_loss: 11.3062
Epoch 2714/8000

Epoch 02714: val_loss did not improve from 9.57022
 - 76s - loss: 9.8429 - val_loss: 11.2627
Epoch 2715/8000

Epoch 02715: val_loss did not improve from 9.57022
 - 76s - loss: 9.9915 - val_loss: 11.5812
Epoch 2716/8000

Epoch 02716: val_loss did not improve from 9.57022
 - 76s - loss: 10.0688 - val_loss: 10.9627
Epoch 2717/8000

Epoch 02717: val_loss did not improve from 9.57022
 - 75s - loss: 9.7980 - val_loss: 10.4964
Epoch 2718/8000

Epoch 02718: val_loss did not improve from 9.57022
 - 76s - loss: 9.4630 - val_loss: 11.0841
Epoch 2719/8000

Epoch 02719: val_loss did not improve from 9.57022
 - 75s - loss: 9.6219 - val_loss: 10.7163
Epoch 2720/8000

Epoch 02720: val_loss did not improve from 9.57022
 - 76s - loss: 9.3996 - val_loss: 10.7221
Epoch 2721/8000

Epoch 02721: val_loss did not improve from 9.57022
 - 76s - loss: 9.3516 - val_loss: 10.5275
Epoch 2722/8000

Epoch 02722: val_loss did not improve from 9.57022
 - 76s - loss: 9.3118 - val_loss: 10.6392
Epoch 2723/8000

Epoch 02723: val_loss did not improve from 9.57022
 - 75s - loss: 9.5781 - val_loss: 11.2911
Epoch 2724/8000

Epoch 02724: val_loss did not improve from 9.57022
 - 75s - loss: 9.8040 - val_loss: 10.9748
Epoch 2725/8000

Epoch 02725: val_loss did not improve from 9.57022
 - 75s - loss: 9.8180 - val_loss: 11.1436
Epoch 2726/8000

Epoch 02726: val_loss did not improve from 9.57022
 - 75s - loss: 9.4794 - val_loss: 10.3192
Epoch 2727/8000

Epoch 02727: val_loss did not improve from 9.57022
 - 76s - loss: 9.5310 - val_loss: 11.0360
Epoch 2728/8000

Epoch 02728: val_loss did not improve from 9.57022
 - 76s - loss: 9.4846 - val_loss: 10.7628
Epoch 2729/8000

Epoch 02729: val_loss did not improve from 9.57022
 - 76s - loss: 9.3634 - val_loss: 10.6193
Epoch 2730/8000

Epoch 02730: val_loss did not improve from 9.57022
 - 76s - loss: 9.4294 - val_loss: 10.7361
Epoch 2731/8000

Epoch 02731: val_loss did not improve from 9.57022
 - 75s - loss: 9.3382 - val_loss: 10.3356
Epoch 2732/8000

Epoch 02732: val_loss did not improve from 9.57022
 - 76s - loss: 9.3930 - val_loss: 12.3900
Epoch 2733/8000

Epoch 02733: val_loss did not improve from 9.57022
 - 75s - loss: 9.8280 - val_loss: 10.8152
Epoch 2734/8000

Epoch 02734: val_loss did not improve from 9.57022
 - 76s - loss: 9.0151 - val_loss: 10.3577
Epoch 2735/8000

Epoch 02735: val_loss did not improve from 9.57022
 - 76s - loss: 9.7780 - val_loss: 10.3346
Epoch 2736/8000

Epoch 02736: val_loss did not improve from 9.57022
 - 76s - loss: 9.3345 - val_loss: 10.6525
Epoch 2737/8000

Epoch 02737: val_loss did not improve from 9.57022
 - 76s - loss: 9.2858 - val_loss: 10.4443
Epoch 2738/8000

Epoch 02738: val_loss did not improve from 9.57022
 - 75s - loss: 9.7003 - val_loss: 12.2904
Epoch 2739/8000

Epoch 02739: val_loss did not improve from 9.57022
 - 76s - loss: 9.4394 - val_loss: 10.8482
Epoch 2740/8000

Epoch 02740: val_loss did not improve from 9.57022
 - 75s - loss: 9.3958 - val_loss: 10.5487
Epoch 2741/8000

Epoch 02741: val_loss did not improve from 9.57022
 - 76s - loss: 9.5260 - val_loss: 10.8475
Epoch 2742/8000

Epoch 02742: val_loss did not improve from 9.57022
 - 75s - loss: 9.4024 - val_loss: 10.6159
Epoch 2743/8000

Epoch 02743: val_loss did not improve from 9.57022
 - 76s - loss: 10.6560 - val_loss: 10.7838
Epoch 2744/8000

Epoch 02744: val_loss did not improve from 9.57022
 - 76s - loss: 10.1386 - val_loss: 11.4283
Epoch 2745/8000

Epoch 02745: val_loss did not improve from 9.57022
 - 75s - loss: 9.9840 - val_loss: 10.6549
Epoch 2746/8000

Epoch 02746: val_loss did not improve from 9.57022
 - 76s - loss: 9.5796 - val_loss: 11.0499
Epoch 2747/8000

Epoch 02747: val_loss did not improve from 9.57022
 - 75s - loss: 10.3696 - val_loss: 11.4092
Epoch 2748/8000

Epoch 02748: val_loss did not improve from 9.57022
 - 76s - loss: 10.0203 - val_loss: 10.5567
Epoch 2749/8000

Epoch 02749: val_loss did not improve from 9.57022
 - 76s - loss: 9.4363 - val_loss: 10.7132
Epoch 2750/8000

Epoch 02750: val_loss did not improve from 9.57022
 - 76s - loss: 9.2402 - val_loss: 10.2704
Epoch 2751/8000

Epoch 02751: val_loss did not improve from 9.57022
 - 76s - loss: 9.5043 - val_loss: 11.3125
Epoch 2752/8000

Epoch 02752: val_loss did not improve from 9.57022
 - 76s - loss: 9.9578 - val_loss: 10.7590
Epoch 2753/8000

Epoch 02753: val_loss did not improve from 9.57022
 - 76s - loss: 9.7563 - val_loss: 10.7863
Epoch 2754/8000

Epoch 02754: val_loss did not improve from 9.57022
 - 75s - loss: 9.7321 - val_loss: 10.5303
Epoch 2755/8000

Epoch 02755: val_loss did not improve from 9.57022
 - 76s - loss: 9.5291 - val_loss: 10.4727
Epoch 2756/8000

Epoch 02756: val_loss did not improve from 9.57022
 - 76s - loss: 10.0849 - val_loss: 10.7032
Epoch 2757/8000

Epoch 02757: val_loss did not improve from 9.57022
 - 75s - loss: 9.9344 - val_loss: 10.9971
Epoch 2758/8000

Epoch 02758: val_loss did not improve from 9.57022
 - 76s - loss: 9.5345 - val_loss: 10.5556
Epoch 2759/8000

Epoch 02759: val_loss did not improve from 9.57022
 - 75s - loss: 9.3432 - val_loss: 10.7854
Epoch 2760/8000

Epoch 02760: val_loss did not improve from 9.57022
 - 76s - loss: 9.4195 - val_loss: 10.3248
Epoch 2761/8000

Epoch 02761: val_loss did not improve from 9.57022
 - 75s - loss: 9.5373 - val_loss: 11.1052
Epoch 2762/8000

Epoch 02762: val_loss did not improve from 9.57022
 - 76s - loss: 9.7378 - val_loss: 10.5226
Epoch 2763/8000

Epoch 02763: val_loss did not improve from 9.57022
 - 76s - loss: 9.5676 - val_loss: 11.0335
Epoch 2764/8000

Epoch 02764: val_loss did not improve from 9.57022
 - 76s - loss: 10.0830 - val_loss: 10.9745
Epoch 2765/8000

Epoch 02765: val_loss did not improve from 9.57022
 - 76s - loss: 9.8402 - val_loss: 10.6069
Epoch 2766/8000

Epoch 02766: val_loss did not improve from 9.57022
 - 75s - loss: 9.4414 - val_loss: 10.7546
Epoch 2767/8000

Epoch 02767: val_loss did not improve from 9.57022
 - 76s - loss: 9.2701 - val_loss: 10.5355
Epoch 2768/8000

Epoch 02768: val_loss did not improve from 9.57022
 - 75s - loss: 9.9133 - val_loss: 10.8645
