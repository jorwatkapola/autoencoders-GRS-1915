2020-04-26 21:30:33.682413: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-04-26 21:30:33.982795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-26 21:30:33.983336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2020-04-26 21:30:33.983354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-04-26 21:30:34.229204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-26 21:30:34.229247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-04-26 21:30:34.229256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-04-26 21:30:34.235965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-26 21:30:34.449781: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x55e667c12c40
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 131.75566, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 114s - loss: 135.7348 - val_loss: 131.7557
Epoch 2/8000

Epoch 00002: val_loss did not improve from 131.75566
 - 112s - loss: 133.3489 - val_loss: 132.5403
Epoch 3/8000

Epoch 00003: val_loss improved from 131.75566 to 129.82960, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 132.1310 - val_loss: 129.8296
Epoch 4/8000

Epoch 00004: val_loss did not improve from 129.82960
 - 112s - loss: 131.2684 - val_loss: 130.0663
Epoch 5/8000

Epoch 00005: val_loss improved from 129.82960 to 129.55333, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 131.7691 - val_loss: 129.5533
Epoch 6/8000

Epoch 00006: val_loss improved from 129.55333 to 128.46591, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 131.0580 - val_loss: 128.4659
Epoch 7/8000

Epoch 00007: val_loss improved from 128.46591 to 127.63773, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 130.1691 - val_loss: 127.6377
Epoch 8/8000

Epoch 00008: val_loss improved from 127.63773 to 126.75963, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 130.3053 - val_loss: 126.7596
Epoch 9/8000

Epoch 00009: val_loss did not improve from 126.75963
 - 112s - loss: 130.2248 - val_loss: 128.1989
Epoch 10/8000

Epoch 00010: val_loss improved from 126.75963 to 125.96336, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 129.9261 - val_loss: 125.9634
Epoch 11/8000

Epoch 00011: val_loss did not improve from 125.96336
 - 112s - loss: 129.3778 - val_loss: 126.7482
Epoch 12/8000

Epoch 00012: val_loss did not improve from 125.96336
 - 112s - loss: 129.3226 - val_loss: 126.8519
Epoch 13/8000

Epoch 00013: val_loss did not improve from 125.96336
 - 112s - loss: 129.1084 - val_loss: 126.5562
Epoch 14/8000

Epoch 00014: val_loss did not improve from 125.96336
 - 112s - loss: 128.3153 - val_loss: 126.3426
Epoch 15/8000

Epoch 00015: val_loss did not improve from 125.96336
 - 112s - loss: 128.3670 - val_loss: 126.0564
Epoch 16/8000

Epoch 00016: val_loss improved from 125.96336 to 123.68741, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 127.9592 - val_loss: 123.6874
Epoch 17/8000

Epoch 00017: val_loss did not improve from 123.68741
 - 112s - loss: 128.2517 - val_loss: 126.8398
Epoch 18/8000

Epoch 00018: val_loss did not improve from 123.68741
 - 112s - loss: 128.2142 - val_loss: 125.5209
Epoch 19/8000

Epoch 00019: val_loss did not improve from 123.68741
 - 112s - loss: 128.3509 - val_loss: 128.2558
Epoch 20/8000

Epoch 00020: val_loss did not improve from 123.68741
 - 112s - loss: 128.3329 - val_loss: 126.5508
Epoch 21/8000

Epoch 00021: val_loss did not improve from 123.68741
 - 112s - loss: 128.8234 - val_loss: 128.3835
Epoch 22/8000

Epoch 00022: val_loss did not improve from 123.68741
 - 112s - loss: 130.0793 - val_loss: 126.0779
Epoch 23/8000

Epoch 00023: val_loss did not improve from 123.68741
 - 113s - loss: 130.8993 - val_loss: 132.2689
Epoch 24/8000

Epoch 00024: val_loss did not improve from 123.68741
 - 112s - loss: 130.3104 - val_loss: 126.7939
Epoch 25/8000

Epoch 00025: val_loss did not improve from 123.68741
 - 112s - loss: 128.8113 - val_loss: 125.4658
Epoch 26/8000

Epoch 00026: val_loss did not improve from 123.68741
 - 112s - loss: 129.8996 - val_loss: 124.2598
Epoch 27/8000

Epoch 00027: val_loss did not improve from 123.68741
 - 112s - loss: 128.0533 - val_loss: 125.5133
Epoch 28/8000

Epoch 00028: val_loss did not improve from 123.68741
 - 112s - loss: 127.8558 - val_loss: 130.4342
Epoch 29/8000

Epoch 00029: val_loss did not improve from 123.68741
 - 113s - loss: 127.9504 - val_loss: 126.9204
Epoch 30/8000

Epoch 00030: val_loss did not improve from 123.68741
 - 112s - loss: 127.8149 - val_loss: 127.1554
Epoch 31/8000

Epoch 00031: val_loss did not improve from 123.68741
 - 112s - loss: 129.7914 - val_loss: 131.5257
Epoch 32/8000

Epoch 00032: val_loss did not improve from 123.68741
 - 112s - loss: 129.7194 - val_loss: 127.1495
Epoch 33/8000

Epoch 00033: val_loss did not improve from 123.68741
 - 112s - loss: 129.3915 - val_loss: 127.1052
Epoch 34/8000

Epoch 00034: val_loss did not improve from 123.68741
 - 112s - loss: 128.4623 - val_loss: 126.7578
Epoch 35/8000

Epoch 00035: val_loss did not improve from 123.68741
 - 112s - loss: 130.6341 - val_loss: 130.3385
Epoch 36/8000

Epoch 00036: val_loss did not improve from 123.68741
 - 112s - loss: 128.3164 - val_loss: 125.8640
Epoch 37/8000

Epoch 00037: val_loss did not improve from 123.68741
 - 112s - loss: 127.9530 - val_loss: 127.8974
Epoch 38/8000

Epoch 00038: val_loss did not improve from 123.68741
 - 112s - loss: 127.7683 - val_loss: 127.5768
Epoch 39/8000

Epoch 00039: val_loss did not improve from 123.68741
 - 113s - loss: 128.2702 - val_loss: 126.5348
Epoch 40/8000

Epoch 00040: val_loss improved from 123.68741 to 122.36956, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 126.7671 - val_loss: 122.3696
Epoch 41/8000

Epoch 00041: val_loss did not improve from 122.36956
 - 112s - loss: 126.1123 - val_loss: 126.1146
Epoch 42/8000

Epoch 00042: val_loss did not improve from 122.36956
 - 112s - loss: 126.3798 - val_loss: 125.3648
Epoch 43/8000

Epoch 00043: val_loss improved from 122.36956 to 122.13599, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 125.9772 - val_loss: 122.1360
Epoch 44/8000

Epoch 00044: val_loss did not improve from 122.13599
 - 112s - loss: 125.7920 - val_loss: 124.0195
Epoch 45/8000

Epoch 00045: val_loss improved from 122.13599 to 121.59635, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 126.2788 - val_loss: 121.5963
Epoch 46/8000

Epoch 00046: val_loss did not improve from 121.59635
 - 112s - loss: 126.6336 - val_loss: 124.9121
Epoch 47/8000

Epoch 00047: val_loss did not improve from 121.59635
 - 112s - loss: 126.2702 - val_loss: 122.0360
Epoch 48/8000

Epoch 00048: val_loss did not improve from 121.59635
 - 112s - loss: 125.8310 - val_loss: 122.9997
Epoch 49/8000

Epoch 00049: val_loss improved from 121.59635 to 121.25401, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 125.8412 - val_loss: 121.2540
Epoch 50/8000

Epoch 00050: val_loss did not improve from 121.25401
 - 112s - loss: 126.4987 - val_loss: 124.8035
Epoch 51/8000

Epoch 00051: val_loss did not improve from 121.25401
 - 112s - loss: 126.1630 - val_loss: 121.9966
Epoch 52/8000

Epoch 00052: val_loss did not improve from 121.25401
 - 112s - loss: 125.5828 - val_loss: 122.7569
Epoch 53/8000

Epoch 00053: val_loss did not improve from 121.25401
 - 112s - loss: 125.8852 - val_loss: 123.0900
Epoch 54/8000

Epoch 00054: val_loss did not improve from 121.25401
 - 112s - loss: 126.6681 - val_loss: 124.7987
Epoch 55/8000

Epoch 00055: val_loss did not improve from 121.25401
 - 112s - loss: 126.0629 - val_loss: 125.2061
Epoch 56/8000

Epoch 00056: val_loss did not improve from 121.25401
 - 112s - loss: 125.3708 - val_loss: 123.2154
Epoch 57/8000

Epoch 00057: val_loss did not improve from 121.25401
 - 112s - loss: 125.2804 - val_loss: 126.1914
Epoch 58/8000

Epoch 00058: val_loss did not improve from 121.25401
 - 112s - loss: 126.0444 - val_loss: 123.1612
Epoch 59/8000

Epoch 00059: val_loss did not improve from 121.25401
 - 112s - loss: 125.2319 - val_loss: 124.3829
Epoch 60/8000

Epoch 00060: val_loss did not improve from 121.25401
 - 112s - loss: 125.4231 - val_loss: 125.2829
Epoch 61/8000

Epoch 00061: val_loss did not improve from 121.25401
 - 112s - loss: 125.8617 - val_loss: 124.1729
Epoch 62/8000

Epoch 00062: val_loss did not improve from 121.25401
 - 112s - loss: 124.7747 - val_loss: 122.4658
Epoch 63/8000

Epoch 00063: val_loss did not improve from 121.25401
 - 112s - loss: 124.2938 - val_loss: 123.8351
Epoch 64/8000

Epoch 00064: val_loss did not improve from 121.25401
 - 112s - loss: 125.1028 - val_loss: 122.2239
Epoch 65/8000

Epoch 00065: val_loss did not improve from 121.25401
 - 112s - loss: 125.0392 - val_loss: 123.0459
Epoch 66/8000

Epoch 00066: val_loss did not improve from 121.25401
 - 112s - loss: 124.6192 - val_loss: 122.6023
Epoch 67/8000

Epoch 00067: val_loss did not improve from 121.25401
 - 112s - loss: 124.7353 - val_loss: 121.5701
Epoch 68/8000

Epoch 00068: val_loss did not improve from 121.25401
 - 112s - loss: 124.9094 - val_loss: 122.7670
Epoch 69/8000

Epoch 00069: val_loss did not improve from 121.25401
 - 112s - loss: 124.6198 - val_loss: 122.9121
Epoch 70/8000

Epoch 00070: val_loss did not improve from 121.25401
 - 112s - loss: 124.0523 - val_loss: 121.8675
Epoch 71/8000

Epoch 00071: val_loss improved from 121.25401 to 119.57558, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 124.5334 - val_loss: 119.5756
Epoch 72/8000

Epoch 00072: val_loss did not improve from 119.57558
 - 112s - loss: 123.6863 - val_loss: 123.7492
Epoch 73/8000

Epoch 00073: val_loss did not improve from 119.57558
 - 112s - loss: 124.0378 - val_loss: 120.3585
Epoch 74/8000

Epoch 00074: val_loss did not improve from 119.57558
 - 112s - loss: 124.0387 - val_loss: 123.2024
Epoch 75/8000

Epoch 00075: val_loss did not improve from 119.57558
 - 112s - loss: 123.7622 - val_loss: 120.9572
Epoch 76/8000

Epoch 00076: val_loss did not improve from 119.57558
 - 112s - loss: 123.5320 - val_loss: 121.5144
Epoch 77/8000

Epoch 00077: val_loss did not improve from 119.57558
 - 112s - loss: 123.3746 - val_loss: 120.5549
Epoch 78/8000

Epoch 00078: val_loss did not improve from 119.57558
 - 112s - loss: 123.2116 - val_loss: 121.7299
Epoch 79/8000

Epoch 00079: val_loss did not improve from 119.57558
 - 112s - loss: 123.8688 - val_loss: 120.9082
Epoch 80/8000

Epoch 00080: val_loss did not improve from 119.57558
 - 112s - loss: 123.5869 - val_loss: 120.8439
Epoch 81/8000

Epoch 00081: val_loss did not improve from 119.57558
 - 112s - loss: 123.4217 - val_loss: 120.3775
Epoch 82/8000

Epoch 00082: val_loss did not improve from 119.57558
 - 112s - loss: 123.6032 - val_loss: 123.0816
Epoch 83/8000

Epoch 00083: val_loss did not improve from 119.57558
 - 112s - loss: 123.5214 - val_loss: 120.7031
Epoch 84/8000

Epoch 00084: val_loss did not improve from 119.57558
 - 112s - loss: 123.8039 - val_loss: 121.3592
Epoch 85/8000

Epoch 00085: val_loss did not improve from 119.57558
 - 112s - loss: 123.5561 - val_loss: 121.4321
Epoch 86/8000

Epoch 00086: val_loss did not improve from 119.57558
 - 112s - loss: 123.1857 - val_loss: 120.5631
Epoch 87/8000

Epoch 00087: val_loss improved from 119.57558 to 119.31448, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 123.0394 - val_loss: 119.3145
Epoch 88/8000

Epoch 00088: val_loss did not improve from 119.31448
 - 112s - loss: 123.8412 - val_loss: 120.9951
Epoch 89/8000

Epoch 00089: val_loss did not improve from 119.31448
 - 112s - loss: 123.6356 - val_loss: 121.2180
Epoch 90/8000

Epoch 00090: val_loss did not improve from 119.31448
 - 112s - loss: 123.3448 - val_loss: 122.6891
Epoch 91/8000

Epoch 00091: val_loss did not improve from 119.31448
 - 112s - loss: 123.6504 - val_loss: 122.1097
Epoch 92/8000

Epoch 00092: val_loss did not improve from 119.31448
 - 112s - loss: 124.0537 - val_loss: 123.0854
Epoch 93/8000

Epoch 00093: val_loss did not improve from 119.31448
 - 112s - loss: 123.7667 - val_loss: 120.0774
Epoch 94/8000

Epoch 00094: val_loss did not improve from 119.31448
 - 112s - loss: 123.0495 - val_loss: 121.4347
Epoch 95/8000

Epoch 00095: val_loss did not improve from 119.31448
 - 112s - loss: 123.2519 - val_loss: 121.6894
Epoch 96/8000

Epoch 00096: val_loss did not improve from 119.31448
 - 112s - loss: 123.1009 - val_loss: 120.9885
Epoch 97/8000

Epoch 00097: val_loss did not improve from 119.31448
 - 112s - loss: 123.3909 - val_loss: 120.3615
Epoch 98/8000

Epoch 00098: val_loss did not improve from 119.31448
 - 112s - loss: 123.5573 - val_loss: 120.6686
Epoch 99/8000

Epoch 00099: val_loss did not improve from 119.31448
 - 112s - loss: 123.8971 - val_loss: 122.0451
Epoch 100/8000

Epoch 00100: val_loss did not improve from 119.31448
 - 112s - loss: 122.7031 - val_loss: 119.9081
Epoch 101/8000

Epoch 00101: val_loss did not improve from 119.31448
 - 112s - loss: 122.8133 - val_loss: 120.7805
Epoch 102/8000

Epoch 00102: val_loss did not improve from 119.31448
 - 112s - loss: 123.6749 - val_loss: 122.7231
Epoch 103/8000

Epoch 00103: val_loss did not improve from 119.31448
 - 112s - loss: 124.2720 - val_loss: 120.7273
Epoch 104/8000

Epoch 00104: val_loss did not improve from 119.31448
 - 112s - loss: 123.4633 - val_loss: 119.5344
Epoch 105/8000

Epoch 00105: val_loss did not improve from 119.31448
 - 112s - loss: 122.9110 - val_loss: 119.9665
Epoch 106/8000

Epoch 00106: val_loss improved from 119.31448 to 118.91368, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 122.6779 - val_loss: 118.9137
Epoch 107/8000

Epoch 00107: val_loss did not improve from 118.91368
 - 112s - loss: 123.0678 - val_loss: 122.5086
Epoch 108/8000

Epoch 00108: val_loss did not improve from 118.91368
 - 112s - loss: 122.9971 - val_loss: 122.5174
Epoch 109/8000

Epoch 00109: val_loss did not improve from 118.91368
 - 112s - loss: 122.6798 - val_loss: 120.4086
Epoch 110/8000

Epoch 00110: val_loss did not improve from 118.91368
 - 112s - loss: 123.1209 - val_loss: 119.8828
Epoch 111/8000

Epoch 00111: val_loss did not improve from 118.91368
 - 112s - loss: 123.5079 - val_loss: 122.8532
Epoch 112/8000

Epoch 00112: val_loss did not improve from 118.91368
 - 112s - loss: 124.7330 - val_loss: 121.2496
Epoch 113/8000

Epoch 00113: val_loss did not improve from 118.91368
 - 112s - loss: 122.9689 - val_loss: 122.2033
Epoch 114/8000

Epoch 00114: val_loss improved from 118.91368 to 117.28294, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 123.1554 - val_loss: 117.2829
Epoch 115/8000

Epoch 00115: val_loss did not improve from 117.28294
 - 112s - loss: 122.6621 - val_loss: 120.7304
Epoch 116/8000

Epoch 00116: val_loss did not improve from 117.28294
 - 112s - loss: 122.3962 - val_loss: 120.6934
Epoch 117/8000

Epoch 00117: val_loss did not improve from 117.28294
 - 112s - loss: 123.6061 - val_loss: 123.3432
Epoch 118/8000

Epoch 00118: val_loss did not improve from 117.28294
 - 112s - loss: 123.0593 - val_loss: 119.7306
Epoch 119/8000

Epoch 00119: val_loss did not improve from 117.28294
 - 112s - loss: 122.7349 - val_loss: 120.7733
Epoch 120/8000

Epoch 00120: val_loss did not improve from 117.28294
 - 112s - loss: 123.0569 - val_loss: 121.1211
Epoch 121/8000

Epoch 00121: val_loss did not improve from 117.28294
 - 112s - loss: 123.6448 - val_loss: 119.6579
Epoch 122/8000

Epoch 00122: val_loss did not improve from 117.28294
 - 112s - loss: 123.6165 - val_loss: 122.2485
Epoch 123/8000

Epoch 00123: val_loss did not improve from 117.28294
 - 112s - loss: 123.9135 - val_loss: 122.2328
Epoch 124/8000

Epoch 00124: val_loss did not improve from 117.28294
 - 112s - loss: 123.5666 - val_loss: 120.4049
Epoch 125/8000

Epoch 00125: val_loss did not improve from 117.28294
 - 112s - loss: 122.6215 - val_loss: 122.2483
Epoch 126/8000

Epoch 00126: val_loss did not improve from 117.28294
 - 112s - loss: 122.6092 - val_loss: 121.5003
Epoch 127/8000

Epoch 00127: val_loss did not improve from 117.28294
 - 112s - loss: 122.8297 - val_loss: 123.4017
Epoch 128/8000

Epoch 00128: val_loss did not improve from 117.28294
 - 112s - loss: 122.5644 - val_loss: 120.1462
Epoch 129/8000

Epoch 00129: val_loss did not improve from 117.28294
 - 112s - loss: 122.9561 - val_loss: 122.0799
Epoch 130/8000

Epoch 00130: val_loss did not improve from 117.28294
 - 112s - loss: 123.1012 - val_loss: 121.4786
Epoch 131/8000

Epoch 00131: val_loss did not improve from 117.28294
 - 112s - loss: 123.5048 - val_loss: 123.6298
Epoch 132/8000

Epoch 00132: val_loss did not improve from 117.28294
 - 112s - loss: 123.9961 - val_loss: 121.3330
Epoch 133/8000

Epoch 00133: val_loss did not improve from 117.28294
 - 112s - loss: 123.2599 - val_loss: 122.7981
Epoch 134/8000

Epoch 00134: val_loss did not improve from 117.28294
 - 112s - loss: 122.3333 - val_loss: 118.8751
Epoch 135/8000

Epoch 00135: val_loss did not improve from 117.28294
 - 112s - loss: 123.1047 - val_loss: 122.4399
Epoch 136/8000

Epoch 00136: val_loss did not improve from 117.28294
 - 112s - loss: 122.6140 - val_loss: 120.5250
Epoch 137/8000

Epoch 00137: val_loss did not improve from 117.28294
 - 112s - loss: 122.5597 - val_loss: 120.6418
Epoch 138/8000

Epoch 00138: val_loss did not improve from 117.28294
 - 112s - loss: 122.2406 - val_loss: 120.5900
Epoch 139/8000

Epoch 00139: val_loss did not improve from 117.28294
 - 112s - loss: 122.2564 - val_loss: 119.7689
Epoch 140/8000

Epoch 00140: val_loss did not improve from 117.28294
 - 112s - loss: 122.3428 - val_loss: 119.5220
Epoch 141/8000

Epoch 00141: val_loss did not improve from 117.28294
 - 112s - loss: 122.9373 - val_loss: 121.7600
Epoch 142/8000

Epoch 00142: val_loss did not improve from 117.28294
 - 112s - loss: 124.2979 - val_loss: 122.5596
Epoch 143/8000

Epoch 00143: val_loss did not improve from 117.28294
 - 112s - loss: 123.6449 - val_loss: 118.5723
Epoch 144/8000

Epoch 00144: val_loss did not improve from 117.28294
 - 112s - loss: 123.3692 - val_loss: 119.5630
Epoch 145/8000

Epoch 00145: val_loss did not improve from 117.28294
 - 112s - loss: 122.2652 - val_loss: 122.7108
Epoch 146/8000

Epoch 00146: val_loss did not improve from 117.28294
 - 112s - loss: 123.0178 - val_loss: 122.4972
Epoch 147/8000

Epoch 00147: val_loss did not improve from 117.28294
 - 112s - loss: 122.5609 - val_loss: 120.3275
Epoch 148/8000

Epoch 00148: val_loss did not improve from 117.28294
 - 112s - loss: 122.9870 - val_loss: 120.7470
Epoch 149/8000

Epoch 00149: val_loss did not improve from 117.28294
 - 112s - loss: 122.8806 - val_loss: 121.2661
Epoch 150/8000

Epoch 00150: val_loss did not improve from 117.28294
 - 112s - loss: 122.5622 - val_loss: 120.1892
Epoch 151/8000

Epoch 00151: val_loss did not improve from 117.28294
 - 112s - loss: 122.3667 - val_loss: 120.4800
Epoch 152/8000

Epoch 00152: val_loss did not improve from 117.28294
 - 112s - loss: 122.6791 - val_loss: 123.0002
Epoch 153/8000

Epoch 00153: val_loss did not improve from 117.28294
 - 112s - loss: 123.0584 - val_loss: 123.1841
Epoch 154/8000

Epoch 00154: val_loss did not improve from 117.28294
 - 112s - loss: 123.5281 - val_loss: 122.3212
Epoch 155/8000

Epoch 00155: val_loss did not improve from 117.28294
 - 112s - loss: 122.5524 - val_loss: 119.1837
Epoch 156/8000

Epoch 00156: val_loss did not improve from 117.28294
 - 112s - loss: 122.3273 - val_loss: 121.9529
Epoch 157/8000

Epoch 00157: val_loss did not improve from 117.28294
 - 112s - loss: 122.1189 - val_loss: 120.1521
Epoch 158/8000

Epoch 00158: val_loss did not improve from 117.28294
 - 112s - loss: 121.9834 - val_loss: 120.5144
Epoch 159/8000

Epoch 00159: val_loss did not improve from 117.28294
 - 112s - loss: 123.4080 - val_loss: 120.2862
Epoch 160/8000

Epoch 00160: val_loss did not improve from 117.28294
 - 112s - loss: 123.2691 - val_loss: 121.2901
Epoch 161/8000

Epoch 00161: val_loss did not improve from 117.28294
 - 112s - loss: 122.2928 - val_loss: 117.5902
Epoch 162/8000

Epoch 00162: val_loss did not improve from 117.28294
 - 112s - loss: 122.6713 - val_loss: 122.6911
Epoch 163/8000

Epoch 00163: val_loss did not improve from 117.28294
 - 112s - loss: 122.2942 - val_loss: 119.4415
Epoch 164/8000

Epoch 00164: val_loss did not improve from 117.28294
 - 112s - loss: 121.8601 - val_loss: 120.2125
Epoch 165/8000

Epoch 00165: val_loss did not improve from 117.28294
 - 112s - loss: 122.0354 - val_loss: 119.1982
Epoch 166/8000

Epoch 00166: val_loss did not improve from 117.28294
 - 112s - loss: 122.0744 - val_loss: 119.1236
Epoch 167/8000

Epoch 00167: val_loss did not improve from 117.28294
 - 112s - loss: 121.7731 - val_loss: 119.1364
Epoch 168/8000

Epoch 00168: val_loss did not improve from 117.28294
 - 112s - loss: 122.1118 - val_loss: 119.0389
Epoch 169/8000

Epoch 00169: val_loss did not improve from 117.28294
 - 112s - loss: 122.0428 - val_loss: 120.5032
Epoch 170/8000

Epoch 00170: val_loss did not improve from 117.28294
 - 112s - loss: 121.7316 - val_loss: 119.5337
Epoch 171/8000

Epoch 00171: val_loss did not improve from 117.28294
 - 112s - loss: 122.0591 - val_loss: 120.6662
Epoch 172/8000

Epoch 00172: val_loss did not improve from 117.28294
 - 112s - loss: 121.4433 - val_loss: 120.1611
Epoch 173/8000

Epoch 00173: val_loss did not improve from 117.28294
 - 112s - loss: 121.7777 - val_loss: 118.3530
Epoch 174/8000

Epoch 00174: val_loss did not improve from 117.28294
 - 112s - loss: 121.3284 - val_loss: 120.1798
Epoch 175/8000

Epoch 00175: val_loss did not improve from 117.28294
 - 112s - loss: 121.1667 - val_loss: 118.4574
Epoch 176/8000

Epoch 00176: val_loss did not improve from 117.28294
 - 113s - loss: 121.6692 - val_loss: 120.8234
Epoch 177/8000

Epoch 00177: val_loss did not improve from 117.28294
 - 112s - loss: 121.3770 - val_loss: 118.9119
Epoch 178/8000

Epoch 00178: val_loss did not improve from 117.28294
 - 112s - loss: 121.1354 - val_loss: 121.3789
Epoch 179/8000

Epoch 00179: val_loss did not improve from 117.28294
 - 112s - loss: 121.1226 - val_loss: 118.1356
Epoch 180/8000

Epoch 00180: val_loss did not improve from 117.28294
 - 112s - loss: 121.4507 - val_loss: 119.0547
Epoch 181/8000

Epoch 00181: val_loss did not improve from 117.28294
 - 112s - loss: 121.1204 - val_loss: 119.5166
Epoch 182/8000

Epoch 00182: val_loss did not improve from 117.28294
 - 112s - loss: 122.4327 - val_loss: 121.7784
Epoch 183/8000

Epoch 00183: val_loss did not improve from 117.28294
 - 112s - loss: 121.8428 - val_loss: 118.9245
Epoch 184/8000

Epoch 00184: val_loss did not improve from 117.28294
 - 112s - loss: 121.8317 - val_loss: 119.9058
Epoch 185/8000

Epoch 00185: val_loss did not improve from 117.28294
 - 112s - loss: 121.0921 - val_loss: 119.1718
Epoch 186/8000

Epoch 00186: val_loss did not improve from 117.28294
 - 112s - loss: 121.2358 - val_loss: 118.6309
Epoch 187/8000

Epoch 00187: val_loss did not improve from 117.28294
 - 112s - loss: 120.6727 - val_loss: 118.9018
Epoch 188/8000

Epoch 00188: val_loss did not improve from 117.28294
 - 112s - loss: 121.4129 - val_loss: 120.6148
Epoch 189/8000

Epoch 00189: val_loss did not improve from 117.28294
 - 112s - loss: 120.5891 - val_loss: 120.2024
Epoch 190/8000

Epoch 00190: val_loss did not improve from 117.28294
 - 112s - loss: 121.2720 - val_loss: 120.0243
Epoch 191/8000

Epoch 00191: val_loss did not improve from 117.28294
 - 112s - loss: 120.9502 - val_loss: 119.1459
Epoch 192/8000

Epoch 00192: val_loss did not improve from 117.28294
 - 112s - loss: 120.2899 - val_loss: 118.7895
Epoch 193/8000

Epoch 00193: val_loss did not improve from 117.28294
 - 112s - loss: 120.7029 - val_loss: 118.3349
Epoch 194/8000

Epoch 00194: val_loss did not improve from 117.28294
 - 112s - loss: 121.0028 - val_loss: 118.9011
Epoch 195/8000

Epoch 00195: val_loss did not improve from 117.28294
 - 112s - loss: 120.4839 - val_loss: 120.0243
Epoch 196/8000

Epoch 00196: val_loss did not improve from 117.28294
 - 112s - loss: 120.9896 - val_loss: 121.0511
Epoch 197/8000

Epoch 00197: val_loss did not improve from 117.28294
 - 112s - loss: 120.6233 - val_loss: 119.3383
Epoch 198/8000

Epoch 00198: val_loss did not improve from 117.28294
 - 112s - loss: 120.6628 - val_loss: 118.8591
Epoch 199/8000

Epoch 00199: val_loss did not improve from 117.28294
 - 112s - loss: 120.2348 - val_loss: 117.5396
Epoch 200/8000

Epoch 00200: val_loss did not improve from 117.28294
 - 112s - loss: 120.4331 - val_loss: 119.0601
Epoch 201/8000

Epoch 00201: val_loss did not improve from 117.28294
 - 112s - loss: 120.7037 - val_loss: 118.0781
Epoch 202/8000

Epoch 00202: val_loss did not improve from 117.28294
 - 112s - loss: 120.3846 - val_loss: 118.2758
Epoch 203/8000

Epoch 00203: val_loss did not improve from 117.28294
 - 112s - loss: 120.2261 - val_loss: 117.8494
Epoch 204/8000

Epoch 00204: val_loss did not improve from 117.28294
 - 112s - loss: 120.0975 - val_loss: 117.9901
Epoch 205/8000

Epoch 00205: val_loss did not improve from 117.28294
 - 112s - loss: 120.1387 - val_loss: 119.4149
Epoch 206/8000

Epoch 00206: val_loss did not improve from 117.28294
 - 112s - loss: 119.9838 - val_loss: 118.0442
Epoch 207/8000

Epoch 00207: val_loss did not improve from 117.28294
 - 112s - loss: 119.8618 - val_loss: 117.9874
Epoch 208/8000

Epoch 00208: val_loss did not improve from 117.28294
 - 112s - loss: 120.5496 - val_loss: 119.2956
Epoch 209/8000

Epoch 00209: val_loss did not improve from 117.28294
 - 112s - loss: 120.0498 - val_loss: 119.7226
Epoch 210/8000

Epoch 00210: val_loss did not improve from 117.28294
 - 112s - loss: 120.8463 - val_loss: 117.5730
Epoch 211/8000

Epoch 00211: val_loss did not improve from 117.28294
 - 112s - loss: 119.9351 - val_loss: 117.5460
Epoch 212/8000

Epoch 00212: val_loss did not improve from 117.28294
 - 112s - loss: 120.5213 - val_loss: 118.0096
Epoch 213/8000

Epoch 00213: val_loss did not improve from 117.28294
 - 112s - loss: 120.3731 - val_loss: 118.1601
Epoch 214/8000

Epoch 00214: val_loss improved from 117.28294 to 116.79606, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 120.2761 - val_loss: 116.7961
Epoch 215/8000

Epoch 00215: val_loss did not improve from 116.79606
 - 113s - loss: 120.3079 - val_loss: 118.8484
Epoch 216/8000

Epoch 00216: val_loss did not improve from 116.79606
 - 112s - loss: 119.7094 - val_loss: 119.3032
Epoch 217/8000

Epoch 00217: val_loss did not improve from 116.79606
 - 112s - loss: 120.2987 - val_loss: 117.3129
Epoch 218/8000

Epoch 00218: val_loss did not improve from 116.79606
 - 112s - loss: 120.7052 - val_loss: 119.1729
Epoch 219/8000

Epoch 00219: val_loss did not improve from 116.79606
 - 112s - loss: 120.9737 - val_loss: 119.4295
Epoch 220/8000

Epoch 00220: val_loss did not improve from 116.79606
 - 112s - loss: 120.1466 - val_loss: 118.5191
Epoch 221/8000

Epoch 00221: val_loss did not improve from 116.79606
 - 112s - loss: 120.4393 - val_loss: 117.7374
Epoch 222/8000

Epoch 00222: val_loss did not improve from 116.79606
 - 112s - loss: 119.9154 - val_loss: 117.3740
Epoch 223/8000

Epoch 00223: val_loss did not improve from 116.79606
 - 112s - loss: 119.6733 - val_loss: 118.1771
Epoch 224/8000

Epoch 00224: val_loss did not improve from 116.79606
 - 112s - loss: 120.4712 - val_loss: 119.0425
Epoch 225/8000

Epoch 00225: val_loss did not improve from 116.79606
 - 112s - loss: 120.0466 - val_loss: 118.0579
Epoch 226/8000

Epoch 00226: val_loss did not improve from 116.79606
 - 112s - loss: 120.1376 - val_loss: 118.9005
Epoch 227/8000

Epoch 00227: val_loss did not improve from 116.79606
 - 112s - loss: 120.3251 - val_loss: 119.1773
Epoch 228/8000

Epoch 00228: val_loss improved from 116.79606 to 116.35821, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 119.8619 - val_loss: 116.3582
Epoch 229/8000

Epoch 00229: val_loss did not improve from 116.35821
 - 113s - loss: 119.8604 - val_loss: 117.5344
Epoch 230/8000

Epoch 00230: val_loss did not improve from 116.35821
 - 112s - loss: 119.5270 - val_loss: 116.9402
Epoch 231/8000

Epoch 00231: val_loss did not improve from 116.35821
 - 112s - loss: 120.0029 - val_loss: 117.4486
Epoch 232/8000

Epoch 00232: val_loss did not improve from 116.35821
 - 112s - loss: 120.3035 - val_loss: 120.2541
Epoch 233/8000

Epoch 00233: val_loss did not improve from 116.35821
 - 112s - loss: 120.4994 - val_loss: 118.8968
Epoch 234/8000

Epoch 00234: val_loss did not improve from 116.35821
 - 112s - loss: 120.3179 - val_loss: 119.5491
Epoch 235/8000

Epoch 00235: val_loss did not improve from 116.35821
 - 112s - loss: 119.9376 - val_loss: 118.8511
Epoch 236/8000

Epoch 00236: val_loss did not improve from 116.35821
 - 112s - loss: 120.6058 - val_loss: 119.2134
Epoch 237/8000

Epoch 00237: val_loss did not improve from 116.35821
 - 112s - loss: 120.0740 - val_loss: 117.6389
Epoch 238/8000

Epoch 00238: val_loss did not improve from 116.35821
 - 112s - loss: 120.2242 - val_loss: 120.5339
Epoch 239/8000

Epoch 00239: val_loss did not improve from 116.35821
 - 112s - loss: 120.1904 - val_loss: 118.7911
Epoch 240/8000

Epoch 00240: val_loss did not improve from 116.35821
 - 112s - loss: 119.7605 - val_loss: 118.2381
Epoch 241/8000

Epoch 00241: val_loss did not improve from 116.35821
 - 112s - loss: 119.9637 - val_loss: 119.4578
Epoch 242/8000

Epoch 00242: val_loss did not improve from 116.35821
 - 112s - loss: 119.6169 - val_loss: 118.6843
Epoch 243/8000

Epoch 00243: val_loss did not improve from 116.35821
 - 112s - loss: 119.8110 - val_loss: 117.1556
Epoch 244/8000

Epoch 00244: val_loss did not improve from 116.35821
 - 112s - loss: 119.5390 - val_loss: 118.5712
Epoch 245/8000

Epoch 00245: val_loss did not improve from 116.35821
 - 112s - loss: 119.5837 - val_loss: 118.7341
Epoch 246/8000

Epoch 00246: val_loss did not improve from 116.35821
 - 112s - loss: 119.9835 - val_loss: 117.8553
Epoch 247/8000

Epoch 00247: val_loss did not improve from 116.35821
 - 112s - loss: 119.7483 - val_loss: 118.4250
Epoch 248/8000

Epoch 00248: val_loss did not improve from 116.35821
 - 112s - loss: 119.8038 - val_loss: 119.0263
Epoch 249/8000

Epoch 00249: val_loss did not improve from 116.35821
 - 112s - loss: 119.6684 - val_loss: 116.5393
Epoch 250/8000

Epoch 00250: val_loss did not improve from 116.35821
 - 112s - loss: 120.4227 - val_loss: 118.4727
Epoch 251/8000

Epoch 00251: val_loss did not improve from 116.35821
 - 112s - loss: 119.5356 - val_loss: 117.0500
Epoch 252/8000

Epoch 00252: val_loss improved from 116.35821 to 115.40762, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 119.0031 - val_loss: 115.4076
Epoch 253/8000

Epoch 00253: val_loss improved from 115.40762 to 115.38156, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 119.8229 - val_loss: 115.3816
Epoch 254/8000

Epoch 00254: val_loss did not improve from 115.38156
 - 112s - loss: 119.3721 - val_loss: 118.0524
Epoch 255/8000

Epoch 00255: val_loss did not improve from 115.38156
 - 112s - loss: 119.2664 - val_loss: 119.4209
Epoch 256/8000

Epoch 00256: val_loss did not improve from 115.38156
 - 112s - loss: 119.5695 - val_loss: 117.8217
Epoch 257/8000

Epoch 00257: val_loss did not improve from 115.38156
 - 112s - loss: 119.9750 - val_loss: 118.7879
Epoch 258/8000

Epoch 00258: val_loss did not improve from 115.38156
 - 112s - loss: 119.9605 - val_loss: 117.6954
Epoch 259/8000

Epoch 00259: val_loss did not improve from 115.38156
 - 112s - loss: 119.6413 - val_loss: 118.8754
Epoch 260/8000

Epoch 00260: val_loss did not improve from 115.38156
 - 112s - loss: 119.8548 - val_loss: 117.9005
Epoch 261/8000

Epoch 00261: val_loss did not improve from 115.38156
 - 112s - loss: 119.7640 - val_loss: 118.4943
Epoch 262/8000

Epoch 00262: val_loss did not improve from 115.38156
 - 112s - loss: 119.8856 - val_loss: 118.2350
Epoch 263/8000

Epoch 00263: val_loss did not improve from 115.38156
 - 112s - loss: 119.3854 - val_loss: 118.1135
Epoch 264/8000

Epoch 00264: val_loss did not improve from 115.38156
 - 112s - loss: 119.5900 - val_loss: 117.1838
Epoch 265/8000

Epoch 00265: val_loss did not improve from 115.38156
 - 112s - loss: 119.7538 - val_loss: 117.9508
Epoch 266/8000

Epoch 00266: val_loss did not improve from 115.38156
 - 112s - loss: 119.1577 - val_loss: 115.7748
Epoch 267/8000

Epoch 00267: val_loss did not improve from 115.38156
 - 112s - loss: 118.9793 - val_loss: 116.8901
Epoch 268/8000

Epoch 00268: val_loss did not improve from 115.38156
 - 112s - loss: 118.9951 - val_loss: 117.6214
Epoch 269/8000

Epoch 00269: val_loss did not improve from 115.38156
 - 112s - loss: 119.4879 - val_loss: 120.2489
Epoch 270/8000

Epoch 00270: val_loss did not improve from 115.38156
 - 112s - loss: 118.8154 - val_loss: 116.3387
Epoch 271/8000

Epoch 00271: val_loss did not improve from 115.38156
 - 112s - loss: 119.2507 - val_loss: 116.1486
Epoch 272/8000

Epoch 00272: val_loss did not improve from 115.38156
 - 112s - loss: 119.0222 - val_loss: 117.6107
Epoch 273/8000

Epoch 00273: val_loss did not improve from 115.38156
 - 112s - loss: 119.1783 - val_loss: 117.8633
Epoch 274/8000

Epoch 00274: val_loss did not improve from 115.38156
 - 112s - loss: 119.1020 - val_loss: 115.3825
Epoch 275/8000

Epoch 00275: val_loss did not improve from 115.38156
 - 112s - loss: 119.4309 - val_loss: 117.0175
Epoch 276/8000

Epoch 00276: val_loss did not improve from 115.38156
 - 112s - loss: 119.5197 - val_loss: 119.2932
Epoch 277/8000

Epoch 00277: val_loss did not improve from 115.38156
 - 112s - loss: 119.0898 - val_loss: 118.5050
Epoch 278/8000

Epoch 00278: val_loss did not improve from 115.38156
 - 112s - loss: 119.6825 - val_loss: 116.1264
Epoch 279/8000

Epoch 00279: val_loss did not improve from 115.38156
 - 112s - loss: 119.5989 - val_loss: 118.7367
Epoch 280/8000

Epoch 00280: val_loss did not improve from 115.38156
 - 112s - loss: 119.0871 - val_loss: 116.1862
Epoch 281/8000

Epoch 00281: val_loss improved from 115.38156 to 114.78815, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 119.1913 - val_loss: 114.7882
Epoch 282/8000

Epoch 00282: val_loss did not improve from 114.78815
 - 112s - loss: 118.6783 - val_loss: 117.0052
Epoch 283/8000

Epoch 00283: val_loss did not improve from 114.78815
 - 112s - loss: 118.9773 - val_loss: 117.2104
Epoch 284/8000

Epoch 00284: val_loss did not improve from 114.78815
 - 112s - loss: 119.2038 - val_loss: 116.5630
Epoch 285/8000

Epoch 00285: val_loss did not improve from 114.78815
 - 112s - loss: 118.7395 - val_loss: 116.2887
Epoch 286/8000

Epoch 00286: val_loss did not improve from 114.78815
 - 112s - loss: 118.8407 - val_loss: 118.0953
Epoch 287/8000

Epoch 00287: val_loss did not improve from 114.78815
 - 112s - loss: 118.6932 - val_loss: 115.6936
Epoch 288/8000

Epoch 00288: val_loss did not improve from 114.78815
 - 112s - loss: 118.9341 - val_loss: 117.1111
Epoch 289/8000

Epoch 00289: val_loss did not improve from 114.78815
 - 112s - loss: 118.6466 - val_loss: 116.3776
Epoch 290/8000

Epoch 00290: val_loss did not improve from 114.78815
 - 112s - loss: 118.9555 - val_loss: 117.4769
Epoch 291/8000

Epoch 00291: val_loss did not improve from 114.78815
 - 112s - loss: 119.1057 - val_loss: 118.1309
Epoch 292/8000

Epoch 00292: val_loss did not improve from 114.78815
 - 112s - loss: 119.3826 - val_loss: 116.0481
Epoch 293/8000

Epoch 00293: val_loss did not improve from 114.78815
 - 112s - loss: 118.4651 - val_loss: 119.3724
Epoch 294/8000

Epoch 00294: val_loss did not improve from 114.78815
 - 112s - loss: 119.0104 - val_loss: 120.7619
Epoch 295/8000

Epoch 00295: val_loss did not improve from 114.78815
 - 112s - loss: 119.3600 - val_loss: 117.8939
Epoch 296/8000

Epoch 00296: val_loss did not improve from 114.78815
 - 112s - loss: 119.7634 - val_loss: 117.6255
Epoch 297/8000

Epoch 00297: val_loss did not improve from 114.78815
 - 112s - loss: 119.1153 - val_loss: 117.1358
Epoch 298/8000

Epoch 00298: val_loss did not improve from 114.78815
 - 112s - loss: 119.5534 - val_loss: 117.5287
Epoch 299/8000

Epoch 00299: val_loss did not improve from 114.78815
 - 112s - loss: 119.0112 - val_loss: 115.4873
Epoch 300/8000

Epoch 00300: val_loss did not improve from 114.78815
 - 112s - loss: 118.8401 - val_loss: 117.4375
Epoch 301/8000

Epoch 00301: val_loss did not improve from 114.78815
 - 112s - loss: 118.4479 - val_loss: 115.7664
Epoch 302/8000

Epoch 00302: val_loss did not improve from 114.78815
 - 112s - loss: 119.0350 - val_loss: 117.0292
Epoch 303/8000

Epoch 00303: val_loss did not improve from 114.78815
 - 112s - loss: 118.5847 - val_loss: 117.3635
Epoch 304/8000

Epoch 00304: val_loss did not improve from 114.78815
 - 112s - loss: 118.6969 - val_loss: 117.3111
Epoch 305/8000

Epoch 00305: val_loss did not improve from 114.78815
 - 112s - loss: 119.0952 - val_loss: 117.0297
Epoch 306/8000

Epoch 00306: val_loss did not improve from 114.78815
 - 112s - loss: 118.8703 - val_loss: 120.8949
Epoch 307/8000

Epoch 00307: val_loss did not improve from 114.78815
 - 112s - loss: 119.2637 - val_loss: 116.1735
Epoch 308/8000

Epoch 00308: val_loss did not improve from 114.78815
 - 112s - loss: 118.5569 - val_loss: 116.2186
Epoch 309/8000

Epoch 00309: val_loss did not improve from 114.78815
 - 112s - loss: 118.5854 - val_loss: 115.3778
Epoch 310/8000

Epoch 00310: val_loss did not improve from 114.78815
 - 112s - loss: 119.0674 - val_loss: 118.0516
Epoch 311/8000

Epoch 00311: val_loss did not improve from 114.78815
 - 112s - loss: 118.2996 - val_loss: 116.9249
Epoch 312/8000

Epoch 00312: val_loss did not improve from 114.78815
 - 112s - loss: 119.1294 - val_loss: 117.1378
Epoch 313/8000

Epoch 00313: val_loss did not improve from 114.78815
 - 112s - loss: 118.9949 - val_loss: 118.6821
Epoch 314/8000

Epoch 00314: val_loss did not improve from 114.78815
 - 112s - loss: 120.1507 - val_loss: 118.9824
Epoch 315/8000

Epoch 00315: val_loss did not improve from 114.78815
 - 112s - loss: 119.1341 - val_loss: 117.3615
Epoch 316/8000

Epoch 00316: val_loss did not improve from 114.78815
 - 112s - loss: 119.0301 - val_loss: 115.2046
Epoch 317/8000

Epoch 00317: val_loss did not improve from 114.78815
 - 112s - loss: 118.1408 - val_loss: 116.7095
Epoch 318/8000

Epoch 00318: val_loss did not improve from 114.78815
 - 112s - loss: 118.9754 - val_loss: 118.8091
Epoch 319/8000

Epoch 00319: val_loss did not improve from 114.78815
 - 112s - loss: 119.4080 - val_loss: 116.6426
Epoch 320/8000

Epoch 00320: val_loss did not improve from 114.78815
 - 112s - loss: 118.3688 - val_loss: 115.7576
Epoch 321/8000

Epoch 00321: val_loss did not improve from 114.78815
 - 112s - loss: 118.5254 - val_loss: 117.9947
Epoch 322/8000

Epoch 00322: val_loss did not improve from 114.78815
 - 112s - loss: 118.2707 - val_loss: 116.8764
Epoch 323/8000

Epoch 00323: val_loss did not improve from 114.78815
 - 112s - loss: 118.7415 - val_loss: 117.1968
Epoch 324/8000

Epoch 00324: val_loss did not improve from 114.78815
 - 112s - loss: 118.5856 - val_loss: 116.7119
Epoch 325/8000

Epoch 00325: val_loss did not improve from 114.78815
 - 112s - loss: 118.4126 - val_loss: 116.3136
Epoch 326/8000

Epoch 00326: val_loss did not improve from 114.78815
 - 112s - loss: 118.6101 - val_loss: 117.2804
Epoch 327/8000

Epoch 00327: val_loss did not improve from 114.78815
 - 112s - loss: 118.5694 - val_loss: 117.0854
Epoch 328/8000

Epoch 00328: val_loss did not improve from 114.78815
 - 112s - loss: 118.6066 - val_loss: 117.8498
Epoch 329/8000

Epoch 00329: val_loss did not improve from 114.78815
 - 112s - loss: 118.0313 - val_loss: 115.3042
Epoch 330/8000

Epoch 00330: val_loss did not improve from 114.78815
 - 112s - loss: 118.5304 - val_loss: 117.6760
Epoch 331/8000

Epoch 00331: val_loss did not improve from 114.78815
 - 112s - loss: 118.2977 - val_loss: 115.5624
Epoch 332/8000

Epoch 00332: val_loss did not improve from 114.78815
 - 112s - loss: 118.9708 - val_loss: 119.3701
Epoch 333/8000

Epoch 00333: val_loss did not improve from 114.78815
 - 112s - loss: 118.7769 - val_loss: 117.2105
Epoch 334/8000

Epoch 00334: val_loss did not improve from 114.78815
 - 112s - loss: 118.5496 - val_loss: 116.4221
Epoch 335/8000

Epoch 00335: val_loss did not improve from 114.78815
 - 112s - loss: 118.5548 - val_loss: 117.1323
Epoch 336/8000

Epoch 00336: val_loss did not improve from 114.78815
 - 112s - loss: 118.3178 - val_loss: 117.6218
Epoch 337/8000

Epoch 00337: val_loss did not improve from 114.78815
 - 112s - loss: 118.6971 - val_loss: 116.9539
Epoch 338/8000

Epoch 00338: val_loss did not improve from 114.78815
 - 112s - loss: 117.9275 - val_loss: 117.5217
Epoch 339/8000

Epoch 00339: val_loss did not improve from 114.78815
 - 112s - loss: 118.6386 - val_loss: 118.2573
Epoch 340/8000

Epoch 00340: val_loss did not improve from 114.78815
 - 112s - loss: 118.0696 - val_loss: 115.5793
Epoch 341/8000

Epoch 00341: val_loss did not improve from 114.78815
 - 112s - loss: 118.4008 - val_loss: 115.6814
Epoch 342/8000

Epoch 00342: val_loss did not improve from 114.78815
 - 112s - loss: 118.0089 - val_loss: 118.1045
Epoch 343/8000

Epoch 00343: val_loss improved from 114.78815 to 113.34441, saving model to ../../model_weights/model_2020-04-26_21-30-34.h5
 - 112s - loss: 118.4622 - val_loss: 113.3444
Epoch 344/8000

Epoch 00344: val_loss did not improve from 113.34441
 - 112s - loss: 118.4599 - val_loss: 118.0491
Epoch 345/8000

Epoch 00345: val_loss did not improve from 113.34441
 - 112s - loss: 119.1806 - val_loss: 116.7173
Epoch 346/8000

Epoch 00346: val_loss did not improve from 113.34441
 - 112s - loss: 118.2916 - val_loss: 113.5991
Epoch 347/8000

Epoch 00347: val_loss did not improve from 113.34441
 - 112s - loss: 118.1500 - val_loss: 116.7295
Epoch 348/8000

Epoch 00348: val_loss did not improve from 113.34441
 - 112s - loss: 118.3136 - val_loss: 116.3824
Epoch 349/8000

Epoch 00349: val_loss did not improve from 113.34441
 - 112s - loss: 118.5230 - val_loss: 116.2878
Epoch 350/8000

Epoch 00350: val_loss did not improve from 113.34441
 - 112s - loss: 117.9917 - val_loss: 115.7607
Epoch 351/8000

Epoch 00351: val_loss did not improve from 113.34441
 - 112s - loss: 118.9791 - val_loss: 118.0515
Epoch 352/8000

Epoch 00352: val_loss did not improve from 113.34441
 - 112s - loss: 118.9220 - val_loss: 117.5804
Epoch 353/8000

Epoch 00353: val_loss did not improve from 113.34441
 - 112s - loss: 118.6815 - val_loss: 117.3007
Epoch 354/8000

Epoch 00354: val_loss did not improve from 113.34441
 - 112s - loss: 118.8056 - val_loss: 117.0663
Epoch 355/8000

Epoch 00355: val_loss did not improve from 113.34441
 - 112s - loss: 119.1512 - val_loss: 118.4121
Epoch 356/8000

Epoch 00356: val_loss did not improve from 113.34441
 - 112s - loss: 118.5342 - val_loss: 117.8829
Epoch 357/8000

Epoch 00357: val_loss did not improve from 113.34441
 - 112s - loss: 118.5872 - val_loss: 117.3233
Epoch 358/8000

Epoch 00358: val_loss did not improve from 113.34441
 - 112s - loss: 118.1009 - val_loss: 117.5310
Epoch 359/8000

Epoch 00359: val_loss did not improve from 113.34441
 - 112s - loss: 118.4047 - val_loss: 116.3632
Epoch 360/8000

Epoch 00360: val_loss did not improve from 113.34441
 - 112s - loss: 118.8760 - val_loss: 117.6230
Epoch 361/8000

Epoch 00361: val_loss did not improve from 113.34441
 - 112s - loss: 118.4627 - val_loss: 117.8519
Epoch 362/8000

Epoch 00362: val_loss did not improve from 113.34441
 - 112s - loss: 118.3593 - val_loss: 115.7438
Epoch 363/8000

Epoch 00363: val_loss did not improve from 113.34441
 - 112s - loss: 117.8603 - val_loss: 116.1866
Epoch 364/8000

Epoch 00364: val_loss did not improve from 113.34441
 - 112s - loss: 118.0866 - val_loss: 119.8439
Epoch 365/8000

Epoch 00365: val_loss did not improve from 113.34441
 - 112s - loss: 118.8558 - val_loss: 117.5484
Epoch 366/8000

Epoch 00366: val_loss did not improve from 113.34441
 - 112s - loss: 118.3734 - val_loss: 118.1087
Epoch 367/8000

Epoch 00367: val_loss did not improve from 113.34441
 - 112s - loss: 118.1548 - val_loss: 117.7633
Epoch 368/8000

Epoch 00368: val_loss did not improve from 113.34441
 - 112s - loss: 118.0225 - val_loss: 116.4759
Epoch 369/8000

Epoch 00369: val_loss did not improve from 113.34441
 - 112s - loss: 117.9029 - val_loss: 117.5628
Epoch 370/8000

Epoch 00370: val_loss did not improve from 113.34441
 - 112s - loss: 118.3605 - val_loss: 114.8796
Epoch 371/8000

Epoch 00371: val_loss did not improve from 113.34441
 - 112s - loss: 118.0597 - val_loss: 116.8997
Epoch 372/8000

Epoch 00372: val_loss did not improve from 113.34441
 - 112s - loss: 117.8250 - val_loss: 116.4918
Epoch 373/8000

Epoch 00373: val_loss did not improve from 113.34441
 - 112s - loss: 117.7247 - val_loss: 117.0002
Epoch 374/8000

Epoch 00374: val_loss did not improve from 113.34441
 - 112s - loss: 117.7240 - val_loss: 116.9522
Epoch 375/8000

Epoch 00375: val_loss did not improve from 113.34441
 - 112s - loss: 117.1961 - val_loss: 114.6179
Epoch 376/8000

Epoch 00376: val_loss did not improve from 113.34441
 - 112s - loss: 118.2686 - val_loss: 118.0153
Epoch 377/8000

Epoch 00377: val_loss did not improve from 113.34441
 - 112s - loss: 118.2612 - val_loss: 118.5212
Epoch 378/8000

Epoch 00378: val_loss did not improve from 113.34441
 - 112s - loss: 117.9373 - val_loss: 114.7253
Epoch 379/8000

Epoch 00379: val_loss did not improve from 113.34441
 - 112s - loss: 118.0195 - val_loss: 115.6306
Epoch 380/8000

Epoch 00380: val_loss did not improve from 113.34441
 - 112s - loss: 118.1167 - val_loss: 117.6257
Epoch 381/8000

Epoch 00381: val_loss did not improve from 113.34441
 - 112s - loss: 117.7228 - val_loss: 117.9545
Epoch 382/8000

Epoch 00382: val_loss did not improve from 113.34441
 - 112s - loss: 117.9269 - val_loss: 116.3056
Epoch 383/8000

Epoch 00383: val_loss did not improve from 113.34441
 - 112s - loss: 117.8703 - val_loss: 115.1447
Epoch 384/8000

Epoch 00384: val_loss did not improve from 113.34441
 - 112s - loss: 118.0576 - val_loss: 117.8507
Epoch 385/8000

Epoch 00385: val_loss did not improve from 113.34441
 - 112s - loss: 118.2744 - val_loss: 114.6018
Epoch 386/8000

Epoch 00386: val_loss did not improve from 113.34441
 - 112s - loss: 118.0787 - val_loss: 116.7430
Epoch 387/8000

Epoch 00387: val_loss did not improve from 113.34441
 - 112s - loss: 117.9254 - val_loss: 117.8375
Epoch 388/8000

Epoch 00388: val_loss did not improve from 113.34441
 - 112s - loss: 118.1057 - val_loss: 115.8469
Epoch 389/8000

Epoch 00389: val_loss did not improve from 113.34441
 - 112s - loss: 117.8821 - val_loss: 117.5032
Epoch 390/8000

Epoch 00390: val_loss did not improve from 113.34441
 - 112s - loss: 117.0694 - val_loss: 116.9127
Epoch 391/8000

Epoch 00391: val_loss did not improve from 113.34441
 - 112s - loss: 117.9466 - val_loss: 116.6167
Epoch 392/8000

Epoch 00392: val_loss did not improve from 113.34441
 - 112s - loss: 118.3102 - val_loss: 116.8995
Epoch 393/8000

Epoch 00393: val_loss did not improve from 113.34441
 - 112s - loss: 117.1954 - val_loss: 115.6652
Epoch 394/8000

Epoch 00394: val_loss did not improve from 113.34441
 - 112s - loss: 118.0438 - val_loss: 116.9866
Epoch 395/8000

Epoch 00395: val_loss did not improve from 113.34441
 - 112s - loss: 118.4905 - val_loss: 117.2469
Epoch 396/8000

Epoch 00396: val_loss did not improve from 113.34441
 - 112s - loss: 118.4076 - val_loss: 117.4744
Epoch 397/8000

Epoch 00397: val_loss did not improve from 113.34441
 - 112s - loss: 117.9870 - val_loss: 116.4121
Epoch 398/8000

Epoch 00398: val_loss did not improve from 113.34441
 - 112s - loss: 117.9583 - val_loss: 115.4797
Epoch 399/8000

Epoch 00399: val_loss did not improve from 113.34441
 - 112s - loss: 117.8587 - val_loss: 118.3053
Epoch 400/8000

Epoch 00400: val_loss did not improve from 113.34441
 - 112s - loss: 117.9488 - val_loss: 115.7396
Epoch 401/8000

Epoch 00401: val_loss did not improve from 113.34441
 - 112s - loss: 118.0918 - val_loss: 118.4483
Epoch 402/8000

Epoch 00402: val_loss did not improve from 113.34441
 - 112s - loss: 118.4374 - val_loss: 115.0059
Epoch 403/8000

Epoch 00403: val_loss did not improve from 113.34441
 - 112s - loss: 117.3171 - val_loss: 115.8684
Epoch 404/8000

Epoch 00404: val_loss did not improve from 113.34441
 - 112s - loss: 117.9259 - val_loss: 116.4688
Epoch 405/8000

Epoch 00405: val_loss did not improve from 113.34441
 - 112s - loss: 117.7636 - val_loss: 116.4605
Epoch 406/8000

Epoch 00406: val_loss did not improve from 113.34441
 - 112s - loss: 117.7593 - val_loss: 115.8381
Epoch 407/8000

Epoch 00407: val_loss did not improve from 113.34441
 - 112s - loss: 117.9350 - val_loss: 116.3749
Epoch 408/8000

Epoch 00408: val_loss did not improve from 113.34441
 - 112s - loss: 118.1676 - val_loss: 117.8020
Epoch 409/8000

Epoch 00409: val_loss did not improve from 113.34441
 - 112s - loss: 118.4183 - val_loss: 119.3120
Epoch 410/8000

Epoch 00410: val_loss did not improve from 113.34441
 - 112s - loss: 119.6786 - val_loss: 118.6531
Epoch 411/8000

Epoch 00411: val_loss did not improve from 113.34441
 - 112s - loss: 119.2780 - val_loss: 116.3408
Epoch 412/8000

Epoch 00412: val_loss did not improve from 113.34441
 - 112s - loss: 118.0031 - val_loss: 115.6736
Epoch 413/8000

Epoch 00413: val_loss did not improve from 113.34441
 - 112s - loss: 117.7419 - val_loss: 116.9800
Epoch 414/8000

Epoch 00414: val_loss did not improve from 113.34441
 - 112s - loss: 117.6122 - val_loss: 116.3438
Epoch 415/8000

Epoch 00415: val_loss did not improve from 113.34441
 - 112s - loss: 118.2241 - val_loss: 116.6460
Epoch 416/8000

Epoch 00416: val_loss did not improve from 113.34441
 - 112s - loss: 117.9824 - val_loss: 116.6461
Epoch 417/8000

Epoch 00417: val_loss did not improve from 113.34441
 - 112s - loss: 117.7671 - val_loss: 116.2288
