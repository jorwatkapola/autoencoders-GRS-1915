2020-03-25 16:47:34.140597: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-03-25 16:47:34.438338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-25 16:47:34.438883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2020-03-25 16:47:34.438901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-03-25 16:47:34.713996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-25 16:47:34.714041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-03-25 16:47:34.714051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-03-25 16:47:34.724267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-03-25 16:47:35.020836: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x55bc51295510
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 26.65625, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 20s - loss: 36.3082 - val_loss: 26.6563
Epoch 2/8000

Epoch 00002: val_loss did not improve from 26.65625
 - 17s - loss: 28.9774 - val_loss: 35.3132
Epoch 3/8000

Epoch 00003: val_loss improved from 26.65625 to 26.07802, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 27.5205 - val_loss: 26.0780
Epoch 4/8000

Epoch 00004: val_loss improved from 26.07802 to 22.62268, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 24.3772 - val_loss: 22.6227
Epoch 5/8000

Epoch 00005: val_loss improved from 22.62268 to 21.68139, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 23.0808 - val_loss: 21.6814
Epoch 6/8000

Epoch 00006: val_loss did not improve from 21.68139
 - 17s - loss: 24.3224 - val_loss: 24.1985
Epoch 7/8000

Epoch 00007: val_loss did not improve from 21.68139
 - 17s - loss: 24.3623 - val_loss: 25.9201
Epoch 8/8000

Epoch 00008: val_loss did not improve from 21.68139
 - 17s - loss: 23.3829 - val_loss: 22.4497
Epoch 9/8000

Epoch 00009: val_loss improved from 21.68139 to 21.64609, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 22.6836 - val_loss: 21.6461
Epoch 10/8000

Epoch 00010: val_loss did not improve from 21.64609
 - 17s - loss: 23.2084 - val_loss: 22.1398
Epoch 11/8000

Epoch 00011: val_loss improved from 21.64609 to 21.60931, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 22.2004 - val_loss: 21.6093
Epoch 12/8000

Epoch 00012: val_loss did not improve from 21.60931
 - 17s - loss: 22.8152 - val_loss: 21.7361
Epoch 13/8000

Epoch 00013: val_loss improved from 21.60931 to 21.25256, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 22.2263 - val_loss: 21.2526
Epoch 14/8000

Epoch 00014: val_loss did not improve from 21.25256
 - 17s - loss: 22.0910 - val_loss: 21.9763
Epoch 15/8000

Epoch 00015: val_loss did not improve from 21.25256
 - 17s - loss: 22.5776 - val_loss: 21.5640
Epoch 16/8000

Epoch 00016: val_loss did not improve from 21.25256
 - 17s - loss: 22.2749 - val_loss: 22.3774
Epoch 17/8000

Epoch 00017: val_loss did not improve from 21.25256
 - 17s - loss: 22.1592 - val_loss: 21.4505
Epoch 18/8000

Epoch 00018: val_loss did not improve from 21.25256
 - 17s - loss: 21.9068 - val_loss: 21.4737
Epoch 19/8000

Epoch 00019: val_loss did not improve from 21.25256
 - 17s - loss: 21.7706 - val_loss: 21.4347
Epoch 20/8000

Epoch 00020: val_loss did not improve from 21.25256
 - 17s - loss: 21.7000 - val_loss: 21.4478
Epoch 21/8000

Epoch 00021: val_loss did not improve from 21.25256
 - 17s - loss: 22.4844 - val_loss: 21.7835
Epoch 22/8000

Epoch 00022: val_loss did not improve from 21.25256
 - 17s - loss: 21.7771 - val_loss: 21.7864
Epoch 23/8000

Epoch 00023: val_loss improved from 21.25256 to 20.76954, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 21.7923 - val_loss: 20.7695
Epoch 24/8000

Epoch 00024: val_loss did not improve from 20.76954
 - 17s - loss: 21.8474 - val_loss: 21.3175
Epoch 25/8000

Epoch 00025: val_loss did not improve from 20.76954
 - 17s - loss: 22.5872 - val_loss: 23.3365
Epoch 26/8000

Epoch 00026: val_loss did not improve from 20.76954
 - 17s - loss: 22.6162 - val_loss: 21.8866
Epoch 27/8000

Epoch 00027: val_loss did not improve from 20.76954
 - 17s - loss: 21.7969 - val_loss: 21.1588
Epoch 28/8000

Epoch 00028: val_loss did not improve from 20.76954
 - 17s - loss: 21.5656 - val_loss: 21.6759
Epoch 29/8000

Epoch 00029: val_loss did not improve from 20.76954
 - 17s - loss: 21.5142 - val_loss: 20.9414
Epoch 30/8000

Epoch 00030: val_loss improved from 20.76954 to 20.44530, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 21.4978 - val_loss: 20.4453
Epoch 31/8000

Epoch 00031: val_loss did not improve from 20.44530
 - 17s - loss: 21.4087 - val_loss: 21.5712
Epoch 32/8000

Epoch 00032: val_loss did not improve from 20.44530
 - 17s - loss: 20.8980 - val_loss: 21.8823
Epoch 33/8000

Epoch 00033: val_loss did not improve from 20.44530
 - 17s - loss: 22.6573 - val_loss: 23.3909
Epoch 34/8000

Epoch 00034: val_loss did not improve from 20.44530
 - 17s - loss: 23.6184 - val_loss: 20.6656
Epoch 35/8000

Epoch 00035: val_loss did not improve from 20.44530
 - 17s - loss: 21.7991 - val_loss: 21.1583
Epoch 36/8000

Epoch 00036: val_loss improved from 20.44530 to 18.71697, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 19.7032 - val_loss: 18.7170
Epoch 37/8000

Epoch 00037: val_loss improved from 18.71697 to 18.33593, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 18.7717 - val_loss: 18.3359
Epoch 38/8000

Epoch 00038: val_loss improved from 18.33593 to 17.51593, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 18.0792 - val_loss: 17.5159
Epoch 39/8000

Epoch 00039: val_loss did not improve from 17.51593
 - 17s - loss: 18.4169 - val_loss: 18.0398
Epoch 40/8000

Epoch 00040: val_loss improved from 17.51593 to 16.52681, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 17.2520 - val_loss: 16.5268
Epoch 41/8000

Epoch 00041: val_loss improved from 16.52681 to 16.36321, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 16.5510 - val_loss: 16.3632
Epoch 42/8000

Epoch 00042: val_loss improved from 16.36321 to 16.12081, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 16.3192 - val_loss: 16.1208
Epoch 43/8000

Epoch 00043: val_loss improved from 16.12081 to 15.73442, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 16.1983 - val_loss: 15.7344
Epoch 44/8000

Epoch 00044: val_loss improved from 15.73442 to 15.69467, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 15.8931 - val_loss: 15.6947
Epoch 45/8000

Epoch 00045: val_loss did not improve from 15.69467
 - 17s - loss: 15.6508 - val_loss: 15.7381
Epoch 46/8000

Epoch 00046: val_loss improved from 15.69467 to 15.50623, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 15.8713 - val_loss: 15.5062
Epoch 47/8000

Epoch 00047: val_loss did not improve from 15.50623
 - 17s - loss: 15.2831 - val_loss: 15.7119
Epoch 48/8000

Epoch 00048: val_loss improved from 15.50623 to 15.29215, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 15.9600 - val_loss: 15.2921
Epoch 49/8000

Epoch 00049: val_loss improved from 15.29215 to 15.09880, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 15.0915 - val_loss: 15.0988
Epoch 50/8000

Epoch 00050: val_loss did not improve from 15.09880
 - 17s - loss: 15.4572 - val_loss: 15.4007
Epoch 51/8000

Epoch 00051: val_loss improved from 15.09880 to 14.61804, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 14.5688 - val_loss: 14.6180
Epoch 52/8000

Epoch 00052: val_loss improved from 14.61804 to 14.40222, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 14.8036 - val_loss: 14.4022
Epoch 53/8000

Epoch 00053: val_loss did not improve from 14.40222
 - 17s - loss: 15.0376 - val_loss: 15.1662
Epoch 54/8000

Epoch 00054: val_loss did not improve from 14.40222
 - 17s - loss: 14.5906 - val_loss: 17.1504
Epoch 55/8000

Epoch 00055: val_loss improved from 14.40222 to 14.32023, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 15.0978 - val_loss: 14.3202
Epoch 56/8000

Epoch 00056: val_loss did not improve from 14.32023
 - 17s - loss: 15.2687 - val_loss: 14.6846
Epoch 57/8000

Epoch 00057: val_loss did not improve from 14.32023
 - 17s - loss: 14.1671 - val_loss: 14.9788
Epoch 58/8000

Epoch 00058: val_loss did not improve from 14.32023
 - 17s - loss: 14.7272 - val_loss: 14.8650
Epoch 59/8000

Epoch 00059: val_loss improved from 14.32023 to 14.18761, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 14.2012 - val_loss: 14.1876
Epoch 60/8000

Epoch 00060: val_loss improved from 14.18761 to 13.65771, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 13.9596 - val_loss: 13.6577
Epoch 61/8000

Epoch 00061: val_loss did not improve from 13.65771
 - 17s - loss: 13.7171 - val_loss: 14.7792
Epoch 62/8000

Epoch 00062: val_loss did not improve from 13.65771
 - 17s - loss: 13.7449 - val_loss: 13.8120
Epoch 63/8000

Epoch 00063: val_loss did not improve from 13.65771
 - 17s - loss: 14.7912 - val_loss: 18.7765
Epoch 64/8000

Epoch 00064: val_loss did not improve from 13.65771
 - 17s - loss: 14.4920 - val_loss: 13.8563
Epoch 65/8000

Epoch 00065: val_loss improved from 13.65771 to 13.61170, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 13.8332 - val_loss: 13.6117
Epoch 66/8000

Epoch 00066: val_loss did not improve from 13.61170
 - 17s - loss: 13.6306 - val_loss: 13.6197
Epoch 67/8000

Epoch 00067: val_loss improved from 13.61170 to 13.52427, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 13.6100 - val_loss: 13.5243
Epoch 68/8000

Epoch 00068: val_loss did not improve from 13.52427
 - 17s - loss: 13.3897 - val_loss: 13.6163
Epoch 69/8000

Epoch 00069: val_loss improved from 13.52427 to 13.22389, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 13.2203 - val_loss: 13.2239
Epoch 70/8000

Epoch 00070: val_loss improved from 13.22389 to 13.11152, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 13.1035 - val_loss: 13.1115
Epoch 71/8000

Epoch 00071: val_loss did not improve from 13.11152
 - 17s - loss: 13.2291 - val_loss: 13.2635
Epoch 72/8000

Epoch 00072: val_loss improved from 13.11152 to 12.75253, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 13.0903 - val_loss: 12.7525
Epoch 73/8000

Epoch 00073: val_loss did not improve from 12.75253
 - 17s - loss: 12.8979 - val_loss: 12.8505
Epoch 74/8000

Epoch 00074: val_loss did not improve from 12.75253
 - 17s - loss: 13.8883 - val_loss: 15.8264
Epoch 75/8000

Epoch 00075: val_loss did not improve from 12.75253
 - 17s - loss: 14.0391 - val_loss: 13.2313
Epoch 76/8000

Epoch 00076: val_loss did not improve from 12.75253
 - 17s - loss: 12.8749 - val_loss: 12.9694
Epoch 77/8000

Epoch 00077: val_loss did not improve from 12.75253
 - 17s - loss: 13.8851 - val_loss: 13.7969
Epoch 78/8000

Epoch 00078: val_loss did not improve from 12.75253
 - 17s - loss: 13.0559 - val_loss: 12.9009
Epoch 79/8000

Epoch 00079: val_loss improved from 12.75253 to 12.64785, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 13.3306 - val_loss: 12.6478
Epoch 80/8000

Epoch 00080: val_loss did not improve from 12.64785
 - 17s - loss: 12.6782 - val_loss: 12.9277
Epoch 81/8000

Epoch 00081: val_loss did not improve from 12.64785
 - 17s - loss: 12.7202 - val_loss: 13.1277
Epoch 82/8000

Epoch 00082: val_loss did not improve from 12.64785
 - 17s - loss: 12.9737 - val_loss: 13.1425
Epoch 83/8000

Epoch 00083: val_loss did not improve from 12.64785
 - 17s - loss: 12.7965 - val_loss: 13.6794
Epoch 84/8000

Epoch 00084: val_loss did not improve from 12.64785
 - 17s - loss: 13.3128 - val_loss: 13.0912
Epoch 85/8000

Epoch 00085: val_loss did not improve from 12.64785
 - 17s - loss: 13.0182 - val_loss: 13.4874
Epoch 86/8000

Epoch 00086: val_loss improved from 12.64785 to 12.48676, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 13.1421 - val_loss: 12.4868
Epoch 87/8000

Epoch 00087: val_loss did not improve from 12.48676
 - 17s - loss: 12.4496 - val_loss: 12.6037
Epoch 88/8000

Epoch 00088: val_loss did not improve from 12.48676
 - 17s - loss: 12.4595 - val_loss: 14.3508
Epoch 89/8000

Epoch 00089: val_loss did not improve from 12.48676
 - 17s - loss: 12.8507 - val_loss: 12.5309
Epoch 90/8000

Epoch 00090: val_loss did not improve from 12.48676
 - 17s - loss: 12.6065 - val_loss: 12.7442
Epoch 91/8000

Epoch 00091: val_loss did not improve from 12.48676
 - 17s - loss: 12.3055 - val_loss: 12.5237
Epoch 92/8000

Epoch 00092: val_loss improved from 12.48676 to 12.06406, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 12.0508 - val_loss: 12.0641
Epoch 93/8000

Epoch 00093: val_loss did not improve from 12.06406
 - 17s - loss: 12.4464 - val_loss: 12.1412
Epoch 94/8000

Epoch 00094: val_loss did not improve from 12.06406
 - 17s - loss: 12.8714 - val_loss: 16.5016
Epoch 95/8000

Epoch 00095: val_loss did not improve from 12.06406
 - 17s - loss: 13.5336 - val_loss: 12.7181
Epoch 96/8000

Epoch 00096: val_loss did not improve from 12.06406
 - 17s - loss: 12.2989 - val_loss: 12.3437
Epoch 97/8000

Epoch 00097: val_loss improved from 12.06406 to 12.05881, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 12.0690 - val_loss: 12.0588
Epoch 98/8000

Epoch 00098: val_loss did not improve from 12.05881
 - 17s - loss: 12.0523 - val_loss: 12.1736
Epoch 99/8000

Epoch 00099: val_loss did not improve from 12.05881
 - 17s - loss: 12.4797 - val_loss: 12.4471
Epoch 100/8000

Epoch 00100: val_loss did not improve from 12.05881
 - 17s - loss: 11.9263 - val_loss: 12.2052
Epoch 101/8000

Epoch 00101: val_loss did not improve from 12.05881
 - 17s - loss: 12.0921 - val_loss: 12.3176
Epoch 102/8000

Epoch 00102: val_loss did not improve from 12.05881
 - 17s - loss: 11.9593 - val_loss: 12.4484
Epoch 103/8000

Epoch 00103: val_loss did not improve from 12.05881
 - 17s - loss: 11.9004 - val_loss: 12.0764
Epoch 104/8000

Epoch 00104: val_loss did not improve from 12.05881
 - 17s - loss: 12.5095 - val_loss: 13.5649
Epoch 105/8000

Epoch 00105: val_loss did not improve from 12.05881
 - 17s - loss: 12.5500 - val_loss: 12.1834
Epoch 106/8000

Epoch 00106: val_loss did not improve from 12.05881
 - 17s - loss: 12.2843 - val_loss: 12.3190
Epoch 107/8000

Epoch 00107: val_loss improved from 12.05881 to 11.92167, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 11.8226 - val_loss: 11.9217
Epoch 108/8000

Epoch 00108: val_loss did not improve from 11.92167
 - 17s - loss: 12.4258 - val_loss: 12.0333
Epoch 109/8000

Epoch 00109: val_loss improved from 11.92167 to 11.91704, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 11.7621 - val_loss: 11.9170
Epoch 110/8000

Epoch 00110: val_loss did not improve from 11.91704
 - 17s - loss: 12.6724 - val_loss: 12.5860
Epoch 111/8000

Epoch 00111: val_loss did not improve from 11.91704
 - 17s - loss: 12.1300 - val_loss: 12.0611
Epoch 112/8000

Epoch 00112: val_loss did not improve from 11.91704
 - 17s - loss: 12.0898 - val_loss: 12.5700
Epoch 113/8000

Epoch 00113: val_loss did not improve from 11.91704
 - 17s - loss: 12.1305 - val_loss: 12.4314
Epoch 114/8000

Epoch 00114: val_loss did not improve from 11.91704
 - 17s - loss: 12.6246 - val_loss: 13.0643
Epoch 115/8000

Epoch 00115: val_loss did not improve from 11.91704
 - 17s - loss: 12.1709 - val_loss: 11.9922
Epoch 116/8000

Epoch 00116: val_loss did not improve from 11.91704
 - 17s - loss: 11.7793 - val_loss: 12.2797
Epoch 117/8000

Epoch 00117: val_loss did not improve from 11.91704
 - 17s - loss: 12.6013 - val_loss: 13.1406
Epoch 118/8000

Epoch 00118: val_loss did not improve from 11.91704
 - 17s - loss: 12.7611 - val_loss: 12.3568
Epoch 119/8000

Epoch 00119: val_loss did not improve from 11.91704
 - 17s - loss: 11.8841 - val_loss: 12.0035
Epoch 120/8000

Epoch 00120: val_loss did not improve from 11.91704
 - 17s - loss: 12.1164 - val_loss: 12.9423
Epoch 121/8000

Epoch 00121: val_loss improved from 11.91704 to 11.90609, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 12.0336 - val_loss: 11.9061
Epoch 122/8000

Epoch 00122: val_loss improved from 11.90609 to 11.78927, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 11.8227 - val_loss: 11.7893
Epoch 123/8000

Epoch 00123: val_loss did not improve from 11.78927
 - 17s - loss: 11.7739 - val_loss: 12.2890
Epoch 124/8000

Epoch 00124: val_loss improved from 11.78927 to 11.55981, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 11.9281 - val_loss: 11.5598
Epoch 125/8000

Epoch 00125: val_loss did not improve from 11.55981
 - 17s - loss: 11.7053 - val_loss: 11.7881
Epoch 126/8000

Epoch 00126: val_loss did not improve from 11.55981
 - 17s - loss: 11.5539 - val_loss: 11.7739
Epoch 127/8000

Epoch 00127: val_loss did not improve from 11.55981
 - 17s - loss: 11.5820 - val_loss: 11.5707
Epoch 128/8000

Epoch 00128: val_loss did not improve from 11.55981
 - 17s - loss: 11.7972 - val_loss: 11.9924
Epoch 129/8000

Epoch 00129: val_loss did not improve from 11.55981
 - 17s - loss: 11.6588 - val_loss: 11.6133
Epoch 130/8000

Epoch 00130: val_loss did not improve from 11.55981
 - 17s - loss: 13.6342 - val_loss: 11.9225
Epoch 131/8000

Epoch 00131: val_loss did not improve from 11.55981
 - 17s - loss: 11.8246 - val_loss: 12.2958
Epoch 132/8000

Epoch 00132: val_loss did not improve from 11.55981
 - 17s - loss: 11.6361 - val_loss: 12.4215
Epoch 133/8000

Epoch 00133: val_loss did not improve from 11.55981
 - 17s - loss: 12.0210 - val_loss: 12.2462
Epoch 134/8000

Epoch 00134: val_loss did not improve from 11.55981
 - 17s - loss: 11.5558 - val_loss: 11.6163
Epoch 135/8000

Epoch 00135: val_loss did not improve from 11.55981
 - 17s - loss: 11.6293 - val_loss: 12.4457
Epoch 136/8000

Epoch 00136: val_loss did not improve from 11.55981
 - 17s - loss: 11.7999 - val_loss: 12.0341
Epoch 137/8000

Epoch 00137: val_loss did not improve from 11.55981
 - 17s - loss: 11.7362 - val_loss: 12.0967
Epoch 138/8000

Epoch 00138: val_loss improved from 11.55981 to 11.39022, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 11.7154 - val_loss: 11.3902
Epoch 139/8000

Epoch 00139: val_loss did not improve from 11.39022
 - 17s - loss: 12.1672 - val_loss: 11.8611
Epoch 140/8000

Epoch 00140: val_loss did not improve from 11.39022
 - 17s - loss: 11.3171 - val_loss: 11.7589
Epoch 141/8000

Epoch 00141: val_loss did not improve from 11.39022
 - 17s - loss: 11.8134 - val_loss: 11.6311
Epoch 142/8000

Epoch 00142: val_loss did not improve from 11.39022
 - 17s - loss: 11.8941 - val_loss: 11.4792
Epoch 143/8000

Epoch 00143: val_loss did not improve from 11.39022
 - 17s - loss: 11.3828 - val_loss: 11.9021
Epoch 144/8000

Epoch 00144: val_loss did not improve from 11.39022
 - 17s - loss: 11.3005 - val_loss: 11.6184
Epoch 145/8000

Epoch 00145: val_loss did not improve from 11.39022
 - 17s - loss: 11.6910 - val_loss: 12.0335
Epoch 146/8000

Epoch 00146: val_loss did not improve from 11.39022
 - 17s - loss: 11.9566 - val_loss: 11.6654
Epoch 147/8000

Epoch 00147: val_loss did not improve from 11.39022
 - 17s - loss: 11.5782 - val_loss: 11.7669
Epoch 148/8000

Epoch 00148: val_loss did not improve from 11.39022
 - 17s - loss: 11.5131 - val_loss: 11.4918
Epoch 149/8000

Epoch 00149: val_loss did not improve from 11.39022
 - 17s - loss: 11.3302 - val_loss: 11.7489
Epoch 150/8000

Epoch 00150: val_loss did not improve from 11.39022
 - 17s - loss: 11.7732 - val_loss: 12.3476
Epoch 151/8000

Epoch 00151: val_loss did not improve from 11.39022
 - 17s - loss: 11.5169 - val_loss: 11.7004
Epoch 152/8000

Epoch 00152: val_loss did not improve from 11.39022
 - 17s - loss: 11.5836 - val_loss: 11.6064
Epoch 153/8000

Epoch 00153: val_loss did not improve from 11.39022
 - 17s - loss: 11.6559 - val_loss: 12.0157
Epoch 154/8000

Epoch 00154: val_loss improved from 11.39022 to 11.20996, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 11.3820 - val_loss: 11.2100
Epoch 155/8000

Epoch 00155: val_loss did not improve from 11.20996
 - 17s - loss: 11.1449 - val_loss: 11.6401
Epoch 156/8000

Epoch 00156: val_loss did not improve from 11.20996
 - 17s - loss: 11.9375 - val_loss: 11.4523
Epoch 157/8000

Epoch 00157: val_loss improved from 11.20996 to 11.11369, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 11.4211 - val_loss: 11.1137
Epoch 158/8000

Epoch 00158: val_loss did not improve from 11.11369
 - 17s - loss: 11.2465 - val_loss: 11.4750
Epoch 159/8000

Epoch 00159: val_loss did not improve from 11.11369
 - 17s - loss: 11.4470 - val_loss: 11.8152
Epoch 160/8000

Epoch 00160: val_loss did not improve from 11.11369
 - 17s - loss: 11.4469 - val_loss: 11.4620
Epoch 161/8000

Epoch 00161: val_loss did not improve from 11.11369
 - 17s - loss: 11.4718 - val_loss: 12.5465
Epoch 162/8000

Epoch 00162: val_loss did not improve from 11.11369
 - 17s - loss: 12.0554 - val_loss: 12.3726
Epoch 163/8000

Epoch 00163: val_loss did not improve from 11.11369
 - 17s - loss: 11.7388 - val_loss: 11.6779
Epoch 164/8000

Epoch 00164: val_loss did not improve from 11.11369
 - 17s - loss: 12.2257 - val_loss: 12.8103
Epoch 165/8000

Epoch 00165: val_loss did not improve from 11.11369
 - 17s - loss: 11.6438 - val_loss: 12.1897
Epoch 166/8000

Epoch 00166: val_loss did not improve from 11.11369
 - 17s - loss: 11.4205 - val_loss: 11.3433
Epoch 167/8000

Epoch 00167: val_loss did not improve from 11.11369
 - 17s - loss: 11.2487 - val_loss: 11.1988
Epoch 168/8000

Epoch 00168: val_loss did not improve from 11.11369
 - 17s - loss: 11.3761 - val_loss: 11.1694
Epoch 169/8000

Epoch 00169: val_loss did not improve from 11.11369
 - 17s - loss: 11.2758 - val_loss: 11.8587
Epoch 170/8000

Epoch 00170: val_loss did not improve from 11.11369
 - 17s - loss: 11.1822 - val_loss: 11.5494
Epoch 171/8000

Epoch 00171: val_loss improved from 11.11369 to 10.95828, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 11.2560 - val_loss: 10.9583
Epoch 172/8000

Epoch 00172: val_loss did not improve from 10.95828
 - 17s - loss: 11.0826 - val_loss: 11.7137
Epoch 173/8000

Epoch 00173: val_loss did not improve from 10.95828
 - 17s - loss: 11.3736 - val_loss: 11.7732
Epoch 174/8000

Epoch 00174: val_loss did not improve from 10.95828
 - 17s - loss: 11.6195 - val_loss: 11.7256
Epoch 175/8000

Epoch 00175: val_loss did not improve from 10.95828
 - 17s - loss: 11.7883 - val_loss: 12.5662
Epoch 176/8000

Epoch 00176: val_loss did not improve from 10.95828
 - 17s - loss: 11.8005 - val_loss: 11.4315
Epoch 177/8000

Epoch 00177: val_loss did not improve from 10.95828
 - 17s - loss: 11.2097 - val_loss: 11.3416
Epoch 178/8000

Epoch 00178: val_loss did not improve from 10.95828
 - 17s - loss: 11.3807 - val_loss: 11.8842
Epoch 179/8000

Epoch 00179: val_loss did not improve from 10.95828
 - 17s - loss: 11.3490 - val_loss: 11.7689
Epoch 180/8000

Epoch 00180: val_loss did not improve from 10.95828
 - 17s - loss: 11.3140 - val_loss: 11.3374
Epoch 181/8000

Epoch 00181: val_loss did not improve from 10.95828
 - 17s - loss: 11.2848 - val_loss: 11.4825
Epoch 182/8000

Epoch 00182: val_loss did not improve from 10.95828
 - 17s - loss: 11.5341 - val_loss: 12.6753
Epoch 183/8000

Epoch 00183: val_loss did not improve from 10.95828
 - 17s - loss: 11.6986 - val_loss: 11.6293
Epoch 184/8000

Epoch 00184: val_loss did not improve from 10.95828
 - 17s - loss: 11.2810 - val_loss: 11.4055
Epoch 185/8000

Epoch 00185: val_loss did not improve from 10.95828
 - 17s - loss: 12.4020 - val_loss: 12.5293
Epoch 186/8000

Epoch 00186: val_loss did not improve from 10.95828
 - 17s - loss: 11.6624 - val_loss: 12.0775
Epoch 187/8000

Epoch 00187: val_loss did not improve from 10.95828
 - 17s - loss: 11.2379 - val_loss: 11.1385
Epoch 188/8000

Epoch 00188: val_loss did not improve from 10.95828
 - 17s - loss: 11.0370 - val_loss: 11.2748
Epoch 189/8000

Epoch 00189: val_loss did not improve from 10.95828
 - 17s - loss: 11.0607 - val_loss: 11.1777
Epoch 190/8000

Epoch 00190: val_loss did not improve from 10.95828
 - 17s - loss: 11.0924 - val_loss: 11.5625
Epoch 191/8000

Epoch 00191: val_loss did not improve from 10.95828
 - 17s - loss: 11.2019 - val_loss: 11.7247
Epoch 192/8000

Epoch 00192: val_loss did not improve from 10.95828
 - 17s - loss: 11.3217 - val_loss: 11.4048
Epoch 193/8000

Epoch 00193: val_loss improved from 10.95828 to 10.92349, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.9205 - val_loss: 10.9235
Epoch 194/8000

Epoch 00194: val_loss did not improve from 10.92349
 - 17s - loss: 11.0226 - val_loss: 11.1733
Epoch 195/8000

Epoch 00195: val_loss did not improve from 10.92349
 - 17s - loss: 11.1145 - val_loss: 11.6442
Epoch 196/8000

Epoch 00196: val_loss improved from 10.92349 to 10.70607, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.9911 - val_loss: 10.7061
Epoch 197/8000

Epoch 00197: val_loss did not improve from 10.70607
 - 17s - loss: 10.9968 - val_loss: 11.5413
Epoch 198/8000

Epoch 00198: val_loss did not improve from 10.70607
 - 17s - loss: 11.3084 - val_loss: 11.0607
Epoch 199/8000

Epoch 00199: val_loss did not improve from 10.70607
 - 17s - loss: 11.2066 - val_loss: 11.5234
Epoch 200/8000

Epoch 00200: val_loss did not improve from 10.70607
 - 17s - loss: 11.0498 - val_loss: 10.8827
Epoch 201/8000

Epoch 00201: val_loss did not improve from 10.70607
 - 17s - loss: 11.4353 - val_loss: 11.1563
Epoch 202/8000

Epoch 00202: val_loss did not improve from 10.70607
 - 17s - loss: 11.1148 - val_loss: 11.4747
Epoch 203/8000

Epoch 00203: val_loss did not improve from 10.70607
 - 17s - loss: 11.1527 - val_loss: 11.6309
Epoch 204/8000

Epoch 00204: val_loss did not improve from 10.70607
 - 17s - loss: 11.1614 - val_loss: 11.1726
Epoch 205/8000

Epoch 00205: val_loss did not improve from 10.70607
 - 17s - loss: 11.0383 - val_loss: 11.2881
Epoch 206/8000

Epoch 00206: val_loss did not improve from 10.70607
 - 17s - loss: 11.0252 - val_loss: 11.2125
Epoch 207/8000

Epoch 00207: val_loss did not improve from 10.70607
 - 17s - loss: 11.8086 - val_loss: 12.1583
Epoch 208/8000

Epoch 00208: val_loss did not improve from 10.70607
 - 17s - loss: 11.5067 - val_loss: 11.9292
Epoch 209/8000

Epoch 00209: val_loss did not improve from 10.70607
 - 17s - loss: 11.9817 - val_loss: 13.1868
Epoch 210/8000

Epoch 00210: val_loss did not improve from 10.70607
 - 17s - loss: 11.5418 - val_loss: 11.5367
Epoch 211/8000

Epoch 00211: val_loss did not improve from 10.70607
 - 17s - loss: 12.4713 - val_loss: 12.1839
Epoch 212/8000

Epoch 00212: val_loss did not improve from 10.70607
 - 17s - loss: 12.2554 - val_loss: 11.8920
Epoch 213/8000

Epoch 00213: val_loss did not improve from 10.70607
 - 17s - loss: 11.4263 - val_loss: 12.0613
Epoch 214/8000

Epoch 00214: val_loss did not improve from 10.70607
 - 17s - loss: 11.4324 - val_loss: 11.7420
Epoch 215/8000

Epoch 00215: val_loss did not improve from 10.70607
 - 17s - loss: 11.3309 - val_loss: 11.5118
Epoch 216/8000

Epoch 00216: val_loss did not improve from 10.70607
 - 17s - loss: 11.1036 - val_loss: 11.3281
Epoch 217/8000

Epoch 00217: val_loss did not improve from 10.70607
 - 17s - loss: 11.1052 - val_loss: 10.8810
Epoch 218/8000

Epoch 00218: val_loss did not improve from 10.70607
 - 17s - loss: 11.3212 - val_loss: 11.5897
Epoch 219/8000

Epoch 00219: val_loss did not improve from 10.70607
 - 17s - loss: 11.9410 - val_loss: 11.3268
Epoch 220/8000

Epoch 00220: val_loss did not improve from 10.70607
 - 17s - loss: 10.9866 - val_loss: 11.4039
Epoch 221/8000

Epoch 00221: val_loss did not improve from 10.70607
 - 17s - loss: 11.4412 - val_loss: 11.5393
Epoch 222/8000

Epoch 00222: val_loss did not improve from 10.70607
 - 17s - loss: 11.2682 - val_loss: 10.9848
Epoch 223/8000

Epoch 00223: val_loss did not improve from 10.70607
 - 17s - loss: 12.2695 - val_loss: 11.7015
Epoch 224/8000

Epoch 00224: val_loss did not improve from 10.70607
 - 17s - loss: 11.0413 - val_loss: 11.0109
Epoch 225/8000

Epoch 00225: val_loss did not improve from 10.70607
 - 17s - loss: 10.9658 - val_loss: 12.5274
Epoch 226/8000

Epoch 00226: val_loss did not improve from 10.70607
 - 17s - loss: 11.3112 - val_loss: 11.9093
Epoch 227/8000

Epoch 00227: val_loss did not improve from 10.70607
 - 17s - loss: 11.2015 - val_loss: 11.4367
Epoch 228/8000

Epoch 00228: val_loss did not improve from 10.70607
 - 17s - loss: 11.1150 - val_loss: 11.2342
Epoch 229/8000

Epoch 00229: val_loss did not improve from 10.70607
 - 17s - loss: 10.8955 - val_loss: 11.9641
Epoch 230/8000

Epoch 00230: val_loss did not improve from 10.70607
 - 17s - loss: 11.2252 - val_loss: 11.2493
Epoch 231/8000

Epoch 00231: val_loss did not improve from 10.70607
 - 17s - loss: 11.3439 - val_loss: 11.4799
Epoch 232/8000

Epoch 00232: val_loss did not improve from 10.70607
 - 17s - loss: 11.5406 - val_loss: 11.6557
Epoch 233/8000

Epoch 00233: val_loss did not improve from 10.70607
 - 17s - loss: 11.3469 - val_loss: 12.3240
Epoch 234/8000

Epoch 00234: val_loss did not improve from 10.70607
 - 17s - loss: 11.4550 - val_loss: 11.8374
Epoch 235/8000

Epoch 00235: val_loss did not improve from 10.70607
 - 17s - loss: 11.2944 - val_loss: 11.7817
Epoch 236/8000

Epoch 00236: val_loss did not improve from 10.70607
 - 17s - loss: 10.9533 - val_loss: 11.4835
Epoch 237/8000

Epoch 00237: val_loss did not improve from 10.70607
 - 17s - loss: 10.8630 - val_loss: 11.3608
Epoch 238/8000

Epoch 00238: val_loss did not improve from 10.70607
 - 17s - loss: 10.9748 - val_loss: 11.2827
Epoch 239/8000

Epoch 00239: val_loss did not improve from 10.70607
 - 17s - loss: 10.8121 - val_loss: 11.0900
Epoch 240/8000

Epoch 00240: val_loss did not improve from 10.70607
 - 17s - loss: 11.0361 - val_loss: 11.5527
Epoch 241/8000

Epoch 00241: val_loss did not improve from 10.70607
 - 17s - loss: 11.4087 - val_loss: 11.4038
Epoch 242/8000

Epoch 00242: val_loss did not improve from 10.70607
 - 17s - loss: 11.1292 - val_loss: 11.2745
Epoch 243/8000

Epoch 00243: val_loss did not improve from 10.70607
 - 17s - loss: 11.0540 - val_loss: 12.6657
Epoch 244/8000

Epoch 00244: val_loss did not improve from 10.70607
 - 17s - loss: 11.7590 - val_loss: 11.7962
Epoch 245/8000

Epoch 00245: val_loss did not improve from 10.70607
 - 17s - loss: 11.7290 - val_loss: 12.0172
Epoch 246/8000

Epoch 00246: val_loss did not improve from 10.70607
 - 17s - loss: 11.3087 - val_loss: 11.3376
Epoch 247/8000

Epoch 00247: val_loss did not improve from 10.70607
 - 17s - loss: 10.9851 - val_loss: 11.1387
Epoch 248/8000

Epoch 00248: val_loss did not improve from 10.70607
 - 17s - loss: 11.0812 - val_loss: 11.6687
Epoch 249/8000

Epoch 00249: val_loss did not improve from 10.70607
 - 17s - loss: 11.1497 - val_loss: 12.5642
Epoch 250/8000

Epoch 00250: val_loss did not improve from 10.70607
 - 17s - loss: 10.8242 - val_loss: 10.8271
Epoch 251/8000

Epoch 00251: val_loss did not improve from 10.70607
 - 17s - loss: 10.9363 - val_loss: 11.3482
Epoch 252/8000

Epoch 00252: val_loss did not improve from 10.70607
 - 17s - loss: 10.8616 - val_loss: 11.1551
Epoch 253/8000

Epoch 00253: val_loss did not improve from 10.70607
 - 17s - loss: 11.0142 - val_loss: 10.9277
Epoch 254/8000

Epoch 00254: val_loss did not improve from 10.70607
 - 17s - loss: 10.7440 - val_loss: 11.0108
Epoch 255/8000

Epoch 00255: val_loss did not improve from 10.70607
 - 17s - loss: 10.8611 - val_loss: 11.1474
Epoch 256/8000

Epoch 00256: val_loss did not improve from 10.70607
 - 17s - loss: 11.1429 - val_loss: 12.2704
Epoch 257/8000

Epoch 00257: val_loss did not improve from 10.70607
 - 17s - loss: 11.2964 - val_loss: 11.3405
Epoch 258/8000

Epoch 00258: val_loss did not improve from 10.70607
 - 17s - loss: 11.1337 - val_loss: 11.3671
Epoch 259/8000

Epoch 00259: val_loss did not improve from 10.70607
 - 17s - loss: 11.3346 - val_loss: 12.2145
Epoch 260/8000

Epoch 00260: val_loss did not improve from 10.70607
 - 17s - loss: 11.3142 - val_loss: 11.6826
Epoch 261/8000

Epoch 00261: val_loss did not improve from 10.70607
 - 17s - loss: 11.0816 - val_loss: 11.8587
Epoch 262/8000

Epoch 00262: val_loss did not improve from 10.70607
 - 17s - loss: 11.2902 - val_loss: 11.1393
Epoch 263/8000

Epoch 00263: val_loss did not improve from 10.70607
 - 17s - loss: 10.8212 - val_loss: 11.3534
Epoch 264/8000

Epoch 00264: val_loss did not improve from 10.70607
 - 17s - loss: 10.8311 - val_loss: 11.1423
Epoch 265/8000

Epoch 00265: val_loss did not improve from 10.70607
 - 17s - loss: 10.7987 - val_loss: 11.2667
Epoch 266/8000

Epoch 00266: val_loss did not improve from 10.70607
 - 17s - loss: 10.7384 - val_loss: 11.1463
Epoch 267/8000

Epoch 00267: val_loss did not improve from 10.70607
 - 17s - loss: 10.9716 - val_loss: 11.3206
Epoch 268/8000

Epoch 00268: val_loss did not improve from 10.70607
 - 17s - loss: 10.7221 - val_loss: 10.9052
Epoch 269/8000

Epoch 00269: val_loss did not improve from 10.70607
 - 17s - loss: 11.0530 - val_loss: 11.7219
Epoch 270/8000

Epoch 00270: val_loss did not improve from 10.70607
 - 17s - loss: 10.8595 - val_loss: 11.1580
Epoch 271/8000

Epoch 00271: val_loss improved from 10.70607 to 10.69194, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.6941 - val_loss: 10.6919
Epoch 272/8000

Epoch 00272: val_loss did not improve from 10.69194
 - 17s - loss: 10.8194 - val_loss: 10.7851
Epoch 273/8000

Epoch 00273: val_loss improved from 10.69194 to 10.64906, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.7882 - val_loss: 10.6491
Epoch 274/8000

Epoch 00274: val_loss did not improve from 10.64906
 - 17s - loss: 10.9437 - val_loss: 11.2591
Epoch 275/8000

Epoch 00275: val_loss did not improve from 10.64906
 - 17s - loss: 10.5076 - val_loss: 11.0387
Epoch 276/8000

Epoch 00276: val_loss did not improve from 10.64906
 - 17s - loss: 10.9487 - val_loss: 11.2598
Epoch 277/8000

Epoch 00277: val_loss did not improve from 10.64906
 - 17s - loss: 10.6866 - val_loss: 10.7504
Epoch 278/8000

Epoch 00278: val_loss did not improve from 10.64906
 - 17s - loss: 10.5674 - val_loss: 11.1745
Epoch 279/8000

Epoch 00279: val_loss improved from 10.64906 to 10.34259, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.4968 - val_loss: 10.3426
Epoch 280/8000

Epoch 00280: val_loss did not improve from 10.34259
 - 17s - loss: 10.4686 - val_loss: 10.5920
Epoch 281/8000

Epoch 00281: val_loss did not improve from 10.34259
 - 17s - loss: 10.5415 - val_loss: 10.6125
Epoch 282/8000

Epoch 00282: val_loss did not improve from 10.34259
 - 17s - loss: 10.6901 - val_loss: 10.8010
Epoch 283/8000

Epoch 00283: val_loss did not improve from 10.34259
 - 17s - loss: 10.5769 - val_loss: 10.7713
Epoch 284/8000

Epoch 00284: val_loss did not improve from 10.34259
 - 17s - loss: 10.3368 - val_loss: 10.6385
Epoch 285/8000

Epoch 00285: val_loss did not improve from 10.34259
 - 17s - loss: 10.4187 - val_loss: 10.7751
Epoch 286/8000

Epoch 00286: val_loss did not improve from 10.34259
 - 17s - loss: 10.4039 - val_loss: 10.7798
Epoch 287/8000

Epoch 00287: val_loss did not improve from 10.34259
 - 17s - loss: 10.7624 - val_loss: 10.8689
Epoch 288/8000

Epoch 00288: val_loss improved from 10.34259 to 10.33266, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.5856 - val_loss: 10.3327
Epoch 289/8000

Epoch 00289: val_loss did not improve from 10.33266
 - 17s - loss: 10.6922 - val_loss: 11.0857
Epoch 290/8000

Epoch 00290: val_loss did not improve from 10.33266
 - 17s - loss: 12.1271 - val_loss: 12.4662
Epoch 291/8000

Epoch 00291: val_loss did not improve from 10.33266
 - 17s - loss: 11.5450 - val_loss: 11.5510
Epoch 292/8000

Epoch 00292: val_loss did not improve from 10.33266
 - 17s - loss: 11.1257 - val_loss: 10.7737
Epoch 293/8000

Epoch 00293: val_loss did not improve from 10.33266
 - 17s - loss: 10.9549 - val_loss: 10.9990
Epoch 294/8000

Epoch 00294: val_loss did not improve from 10.33266
 - 17s - loss: 10.6415 - val_loss: 10.7375
Epoch 295/8000

Epoch 00295: val_loss did not improve from 10.33266
 - 17s - loss: 10.6562 - val_loss: 11.2799
Epoch 296/8000

Epoch 00296: val_loss did not improve from 10.33266
 - 17s - loss: 10.6680 - val_loss: 10.8128
Epoch 297/8000

Epoch 00297: val_loss did not improve from 10.33266
 - 17s - loss: 10.7133 - val_loss: 10.9307
Epoch 298/8000

Epoch 00298: val_loss did not improve from 10.33266
 - 17s - loss: 10.4362 - val_loss: 11.1446
Epoch 299/8000

Epoch 00299: val_loss did not improve from 10.33266
 - 17s - loss: 10.4111 - val_loss: 10.7500
Epoch 300/8000

Epoch 00300: val_loss did not improve from 10.33266
 - 17s - loss: 10.4234 - val_loss: 11.6125
Epoch 301/8000

Epoch 00301: val_loss did not improve from 10.33266
 - 17s - loss: 11.2415 - val_loss: 11.3590
Epoch 302/8000

Epoch 00302: val_loss did not improve from 10.33266
 - 17s - loss: 10.7812 - val_loss: 10.8537
Epoch 303/8000

Epoch 00303: val_loss did not improve from 10.33266
 - 17s - loss: 11.1839 - val_loss: 11.3573
Epoch 304/8000

Epoch 00304: val_loss did not improve from 10.33266
 - 17s - loss: 10.6717 - val_loss: 11.1749
Epoch 305/8000

Epoch 00305: val_loss improved from 10.33266 to 10.30287, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.6463 - val_loss: 10.3029
Epoch 306/8000

Epoch 00306: val_loss did not improve from 10.30287
 - 17s - loss: 10.3837 - val_loss: 10.8810
Epoch 307/8000

Epoch 00307: val_loss did not improve from 10.30287
 - 17s - loss: 10.5642 - val_loss: 11.4730
Epoch 308/8000

Epoch 00308: val_loss did not improve from 10.30287
 - 17s - loss: 10.7734 - val_loss: 10.4116
Epoch 309/8000

Epoch 00309: val_loss did not improve from 10.30287
 - 17s - loss: 10.4798 - val_loss: 11.1279
Epoch 310/8000

Epoch 00310: val_loss did not improve from 10.30287
 - 17s - loss: 10.4074 - val_loss: 10.5887
Epoch 311/8000

Epoch 00311: val_loss did not improve from 10.30287
 - 17s - loss: 10.1974 - val_loss: 10.9271
Epoch 312/8000

Epoch 00312: val_loss did not improve from 10.30287
 - 17s - loss: 10.3394 - val_loss: 10.6305
Epoch 313/8000

Epoch 00313: val_loss improved from 10.30287 to 10.26902, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.2673 - val_loss: 10.2690
Epoch 314/8000

Epoch 00314: val_loss did not improve from 10.26902
 - 17s - loss: 10.5320 - val_loss: 10.9464
Epoch 315/8000

Epoch 00315: val_loss did not improve from 10.26902
 - 17s - loss: 10.5799 - val_loss: 10.9748
Epoch 316/8000

Epoch 00316: val_loss did not improve from 10.26902
 - 17s - loss: 10.7140 - val_loss: 10.5322
Epoch 317/8000

Epoch 00317: val_loss did not improve from 10.26902
 - 17s - loss: 10.2585 - val_loss: 10.6366
Epoch 318/8000

Epoch 00318: val_loss did not improve from 10.26902
 - 17s - loss: 10.2117 - val_loss: 10.2828
Epoch 319/8000

Epoch 00319: val_loss did not improve from 10.26902
 - 17s - loss: 10.1790 - val_loss: 10.5370
Epoch 320/8000

Epoch 00320: val_loss improved from 10.26902 to 10.13955, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.2012 - val_loss: 10.1395
Epoch 321/8000

Epoch 00321: val_loss did not improve from 10.13955
 - 17s - loss: 10.7938 - val_loss: 10.9000
Epoch 322/8000

Epoch 00322: val_loss did not improve from 10.13955
 - 17s - loss: 10.4192 - val_loss: 10.7029
Epoch 323/8000

Epoch 00323: val_loss did not improve from 10.13955
 - 17s - loss: 10.1751 - val_loss: 10.5771
Epoch 324/8000

Epoch 00324: val_loss did not improve from 10.13955
 - 17s - loss: 10.0696 - val_loss: 10.1718
Epoch 325/8000

Epoch 00325: val_loss did not improve from 10.13955
 - 17s - loss: 10.0297 - val_loss: 10.3080
Epoch 326/8000

Epoch 00326: val_loss did not improve from 10.13955
 - 17s - loss: 10.1380 - val_loss: 10.7136
Epoch 327/8000

Epoch 00327: val_loss did not improve from 10.13955
 - 17s - loss: 10.4767 - val_loss: 11.0590
Epoch 328/8000

Epoch 00328: val_loss did not improve from 10.13955
 - 17s - loss: 10.7535 - val_loss: 10.6246
Epoch 329/8000

Epoch 00329: val_loss did not improve from 10.13955
 - 17s - loss: 10.1537 - val_loss: 10.5517
Epoch 330/8000

Epoch 00330: val_loss did not improve from 10.13955
 - 17s - loss: 9.9281 - val_loss: 10.3796
Epoch 331/8000

Epoch 00331: val_loss did not improve from 10.13955
 - 17s - loss: 9.9601 - val_loss: 10.3045
Epoch 332/8000

Epoch 00332: val_loss did not improve from 10.13955
 - 17s - loss: 10.0412 - val_loss: 10.8391
Epoch 333/8000

Epoch 00333: val_loss did not improve from 10.13955
 - 17s - loss: 10.0322 - val_loss: 10.4774
Epoch 334/8000

Epoch 00334: val_loss improved from 10.13955 to 9.98370, saving model to ../../model_weights/model_2020-03-25_16-47-33.h5
 - 17s - loss: 10.2727 - val_loss: 9.9837
Epoch 335/8000

Epoch 00335: val_loss did not improve from 9.98370
 - 17s - loss: 10.3562 - val_loss: 10.8887
Epoch 336/8000

Epoch 00336: val_loss did not improve from 9.98370
 - 17s - loss: 10.9083 - val_loss: 10.8925
Epoch 337/8000

Epoch 00337: val_loss did not improve from 9.98370
 - 17s - loss: 10.8440 - val_loss: 10.9779
Epoch 338/8000

Epoch 00338: val_loss did not improve from 9.98370
 - 17s - loss: 10.5053 - val_loss: 10.5252
Epoch 339/8000

Epoch 00339: val_loss did not improve from 9.98370
 - 17s - loss: 9.9786 - val_loss: 10.2470
Epoch 340/8000

Epoch 00340: val_loss did not improve from 9.98370
 - 17s - loss: 10.3566 - val_loss: 10.3348
Epoch 341/8000

Epoch 00341: val_loss did not improve from 9.98370
 - 17s - loss: 10.8864 - val_loss: 12.6931
Epoch 342/8000

Epoch 00342: val_loss did not improve from 9.98370
 - 17s - loss: 11.5910 - val_loss: 11.9562
Epoch 343/8000

Epoch 00343: val_loss did not improve from 9.98370
 - 17s - loss: 11.7838 - val_loss: 13.5050
Epoch 344/8000

Epoch 00344: val_loss did not improve from 9.98370
 - 17s - loss: 11.7585 - val_loss: 10.4176
Epoch 345/8000

Epoch 00345: val_loss did not improve from 9.98370
 - 17s - loss: 10.8481 - val_loss: 11.1727
Epoch 346/8000

Epoch 00346: val_loss did not improve from 9.98370
 - 17s - loss: 10.6043 - val_loss: 10.6619
Epoch 347/8000

Epoch 00347: val_loss did not improve from 9.98370
 - 17s - loss: 10.4871 - val_loss: 10.7434
Epoch 348/8000

Epoch 00348: val_loss did not improve from 9.98370
 - 17s - loss: 10.4707 - val_loss: 11.1776
Epoch 349/8000

Epoch 00349: val_loss did not improve from 9.98370
 - 17s - loss: 10.6398 - val_loss: 10.7014
Epoch 350/8000

Epoch 00350: val_loss did not improve from 9.98370
 - 17s - loss: 10.6435 - val_loss: 10.5924
Epoch 351/8000

Epoch 00351: val_loss did not improve from 9.98370
 - 17s - loss: 10.4162 - val_loss: 10.5653
Epoch 352/8000

Epoch 00352: val_loss did not improve from 9.98370
 - 17s - loss: 10.2680 - val_loss: 10.8597
Epoch 353/8000

Epoch 00353: val_loss did not improve from 9.98370
 - 17s - loss: 10.6864 - val_loss: 10.7043
Epoch 354/8000

Epoch 00354: val_loss did not improve from 9.98370
 - 17s - loss: 10.4929 - val_loss: 10.6570
Epoch 355/8000

Epoch 00355: val_loss did not improve from 9.98370
 - 17s - loss: 10.7811 - val_loss: 10.8087
Epoch 356/8000

Epoch 00356: val_loss did not improve from 9.98370
 - 17s - loss: 11.1907 - val_loss: 11.6700
Epoch 357/8000

Epoch 00357: val_loss did not improve from 9.98370
 - 17s - loss: 11.7956 - val_loss: 11.4544
Epoch 358/8000

Epoch 00358: val_loss did not improve from 9.98370
 - 17s - loss: 10.9010 - val_loss: 11.2536
Epoch 359/8000

Epoch 00359: val_loss did not improve from 9.98370
 - 17s - loss: 10.7275 - val_loss: 10.9217
Epoch 360/8000

Epoch 00360: val_loss did not improve from 9.98370
 - 17s - loss: 10.8402 - val_loss: 11.6568
Epoch 361/8000

Epoch 00361: val_loss did not improve from 9.98370
 - 17s - loss: 10.5064 - val_loss: 10.8348
Epoch 362/8000

Epoch 00362: val_loss did not improve from 9.98370
 - 17s - loss: 10.4786 - val_loss: 10.5556
Epoch 363/8000

Epoch 00363: val_loss did not improve from 9.98370
 - 17s - loss: 10.3793 - val_loss: 10.8439
Epoch 364/8000

Epoch 00364: val_loss did not improve from 9.98370
 - 17s - loss: 10.3932 - val_loss: 10.4351
Epoch 365/8000

Epoch 00365: val_loss did not improve from 9.98370
 - 17s - loss: 10.5486 - val_loss: 10.8231
Epoch 366/8000

Epoch 00366: val_loss did not improve from 9.98370
 - 17s - loss: 10.7454 - val_loss: 10.7303
Epoch 367/8000

Epoch 00367: val_loss did not improve from 9.98370
 - 17s - loss: 10.4950 - val_loss: 10.7091
Epoch 368/8000

Epoch 00368: val_loss did not improve from 9.98370
 - 17s - loss: 10.7993 - val_loss: 11.0519
Epoch 369/8000

Epoch 00369: val_loss did not improve from 9.98370
 - 17s - loss: 10.3221 - val_loss: 10.4278
Epoch 370/8000

Epoch 00370: val_loss did not improve from 9.98370
 - 17s - loss: 10.9191 - val_loss: 10.8242
Epoch 371/8000

Epoch 00371: val_loss did not improve from 9.98370
 - 17s - loss: 10.4945 - val_loss: 10.7285
Epoch 372/8000

Epoch 00372: val_loss did not improve from 9.98370
 - 17s - loss: 10.3204 - val_loss: 10.4059
Epoch 373/8000

Epoch 00373: val_loss did not improve from 9.98370
 - 17s - loss: 10.2281 - val_loss: 10.5264
Epoch 374/8000

Epoch 00374: val_loss did not improve from 9.98370
 - 17s - loss: 9.9926 - val_loss: 10.4601
Epoch 375/8000

Epoch 00375: val_loss did not improve from 9.98370
 - 17s - loss: 10.1625 - val_loss: 10.0830
Epoch 376/8000

Epoch 00376: val_loss did not improve from 9.98370
 - 17s - loss: 10.0274 - val_loss: 10.6371
Epoch 377/8000

Epoch 00377: val_loss did not improve from 9.98370
 - 17s - loss: 10.1207 - val_loss: 10.4372
Epoch 378/8000

Epoch 00378: val_loss did not improve from 9.98370
 - 17s - loss: 10.1198 - val_loss: 10.2267
Epoch 379/8000

Epoch 00379: val_loss did not improve from 9.98370
 - 17s - loss: 10.3585 - val_loss: 10.8142
Epoch 380/8000

Epoch 00380: val_loss did not improve from 9.98370
 - 17s - loss: 10.2708 - val_loss: 10.5286
Epoch 381/8000

Epoch 00381: val_loss did not improve from 9.98370
 - 17s - loss: 10.1952 - val_loss: 10.8106
Epoch 382/8000

Epoch 00382: val_loss did not improve from 9.98370
 - 17s - loss: 10.4118 - val_loss: 10.7273
Epoch 383/8000

Epoch 00383: val_loss did not improve from 9.98370
 - 17s - loss: 10.5660 - val_loss: 10.9786
Epoch 384/8000

Epoch 00384: val_loss did not improve from 9.98370
 - 17s - loss: 10.5139 - val_loss: 11.0141
Epoch 385/8000

Epoch 00385: val_loss did not improve from 9.98370
 - 17s - loss: 10.4381 - val_loss: 10.2974
Epoch 386/8000

Epoch 00386: val_loss did not improve from 9.98370
 - 17s - loss: 10.3178 - val_loss: 10.3692
Epoch 387/8000

Epoch 00387: val_loss did not improve from 9.98370
 - 17s - loss: 10.3060 - val_loss: 10.6086
Epoch 388/8000

Epoch 00388: val_loss did not improve from 9.98370
 - 17s - loss: 10.4547 - val_loss: 10.9210
Epoch 389/8000

Epoch 00389: val_loss did not improve from 9.98370
 - 17s - loss: 10.6570 - val_loss: 11.1326
Epoch 390/8000

Epoch 00390: val_loss did not improve from 9.98370
 - 17s - loss: 10.8042 - val_loss: 10.8658
Epoch 391/8000

Epoch 00391: val_loss did not improve from 9.98370
 - 17s - loss: 10.5993 - val_loss: 10.8622
Epoch 392/8000

Epoch 00392: val_loss did not improve from 9.98370
 - 17s - loss: 10.7147 - val_loss: 11.9438
Epoch 393/8000

Epoch 00393: val_loss did not improve from 9.98370
 - 17s - loss: 11.1954 - val_loss: 11.4419
Epoch 394/8000

Epoch 00394: val_loss did not improve from 9.98370
 - 17s - loss: 10.9604 - val_loss: 11.3978
Epoch 395/8000

Epoch 00395: val_loss did not improve from 9.98370
 - 17s - loss: 10.7359 - val_loss: 10.7749
Epoch 396/8000

Epoch 00396: val_loss did not improve from 9.98370
 - 17s - loss: 10.7036 - val_loss: 11.1876
Epoch 397/8000

Epoch 00397: val_loss did not improve from 9.98370
 - 17s - loss: 10.8360 - val_loss: 11.4811
Epoch 398/8000

Epoch 00398: val_loss did not improve from 9.98370
 - 17s - loss: 10.8374 - val_loss: 10.8352
Epoch 399/8000

Epoch 00399: val_loss did not improve from 9.98370
 - 17s - loss: 10.7693 - val_loss: 10.9053
Epoch 400/8000

Epoch 00400: val_loss did not improve from 9.98370
 - 17s - loss: 10.8332 - val_loss: 10.8905
Epoch 401/8000

Epoch 00401: val_loss did not improve from 9.98370
 - 17s - loss: 10.9684 - val_loss: 10.9922
Epoch 402/8000

Epoch 00402: val_loss did not improve from 9.98370
 - 17s - loss: 10.4905 - val_loss: 10.6359
Epoch 403/8000

Epoch 00403: val_loss did not improve from 9.98370
 - 17s - loss: 10.4842 - val_loss: 10.4659
Epoch 404/8000

Epoch 00404: val_loss did not improve from 9.98370
 - 17s - loss: 10.5785 - val_loss: 10.8882
Epoch 405/8000

Epoch 00405: val_loss did not improve from 9.98370
 - 17s - loss: 10.7666 - val_loss: 10.9959
Epoch 406/8000

Epoch 00406: val_loss did not improve from 9.98370
 - 17s - loss: 10.5910 - val_loss: 10.5195
Epoch 407/8000

Epoch 00407: val_loss did not improve from 9.98370
 - 17s - loss: 10.4565 - val_loss: 10.9408
Epoch 408/8000

Epoch 00408: val_loss did not improve from 9.98370
 - 17s - loss: 10.4684 - val_loss: 10.8281
Epoch 409/8000

Epoch 00409: val_loss did not improve from 9.98370
 - 17s - loss: 10.5087 - val_loss: 11.0843
Epoch 410/8000

Epoch 00410: val_loss did not improve from 9.98370
 - 17s - loss: 10.5366 - val_loss: 10.8424
Epoch 411/8000

Epoch 00411: val_loss did not improve from 9.98370
 - 17s - loss: 10.4999 - val_loss: 11.0534
Epoch 412/8000

Epoch 00412: val_loss did not improve from 9.98370
 - 17s - loss: 10.5612 - val_loss: 10.7189
Epoch 413/8000

Epoch 00413: val_loss did not improve from 9.98370
 - 17s - loss: 10.8011 - val_loss: 10.6741
Epoch 414/8000

Epoch 00414: val_loss did not improve from 9.98370
 - 17s - loss: 10.9601 - val_loss: 11.0705
Epoch 415/8000

Epoch 00415: val_loss did not improve from 9.98370
 - 17s - loss: 10.8688 - val_loss: 10.7452
Epoch 416/8000

Epoch 00416: val_loss did not improve from 9.98370
 - 17s - loss: 10.4212 - val_loss: 10.3334
Epoch 417/8000

Epoch 00417: val_loss did not improve from 9.98370
 - 17s - loss: 10.3439 - val_loss: 10.7760
Epoch 418/8000

Epoch 00418: val_loss did not improve from 9.98370
 - 17s - loss: 10.2465 - val_loss: 10.3319
Epoch 419/8000

Epoch 00419: val_loss did not improve from 9.98370
 - 17s - loss: 10.2461 - val_loss: 10.4878
Epoch 420/8000

Epoch 00420: val_loss did not improve from 9.98370
 - 17s - loss: 10.2755 - val_loss: 10.4853
Epoch 421/8000

Epoch 00421: val_loss did not improve from 9.98370
 - 17s - loss: 10.4623 - val_loss: 11.2527
Epoch 422/8000

Epoch 00422: val_loss did not improve from 9.98370
 - 17s - loss: 10.7311 - val_loss: 10.6895
Epoch 423/8000

Epoch 00423: val_loss did not improve from 9.98370
 - 17s - loss: 10.4003 - val_loss: 10.6263
Epoch 424/8000

Epoch 00424: val_loss did not improve from 9.98370
 - 17s - loss: 10.1054 - val_loss: 10.4940
Epoch 425/8000

Epoch 00425: val_loss did not improve from 9.98370
 - 17s - loss: 10.2611 - val_loss: 10.5331
Epoch 426/8000

Epoch 00426: val_loss did not improve from 9.98370
 - 17s - loss: 10.3132 - val_loss: 10.7964
Epoch 427/8000

Epoch 00427: val_loss did not improve from 9.98370
 - 17s - loss: 10.2836 - val_loss: 10.8676
Epoch 428/8000

Epoch 00428: val_loss did not improve from 9.98370
 - 17s - loss: 10.1978 - val_loss: 10.3643
Epoch 429/8000

Epoch 00429: val_loss did not improve from 9.98370
 - 17s - loss: 10.2980 - val_loss: 10.3612
Epoch 430/8000

Epoch 00430: val_loss did not improve from 9.98370
 - 17s - loss: 10.1339 - val_loss: 10.6107
Epoch 431/8000

Epoch 00431: val_loss did not improve from 9.98370
 - 17s - loss: 9.9334 - val_loss: 10.6440
Epoch 432/8000

Epoch 00432: val_loss did not improve from 9.98370
 - 17s - loss: 10.2212 - val_loss: 11.0293
Epoch 433/8000

Epoch 00433: val_loss did not improve from 9.98370
 - 17s - loss: 10.8493 - val_loss: 10.4522
Epoch 434/8000

Epoch 00434: val_loss did not improve from 9.98370
 - 17s - loss: 10.2035 - val_loss: 10.7541
Epoch 00434: early stopping
