2020-12-23 13:48:50.703286: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-12-23 13:48:51.021983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-23 13:48:51.022559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2020-12-23 13:48:51.022577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2020-12-23 13:48:51.333035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-23 13:48:51.333080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2020-12-23 13:48:51.333097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2020-12-23 13:48:51.333362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-12-23 13:48:51.536176: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x55b3df708260
Epoch 1/8000

Epoch 00001: val_loss improved from inf to 14.31280, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 267s - loss: 12.8952 - kl_loss: 1.9205 - val_loss: 14.3128 - val_kl_loss: 1.9847
Epoch 2/8000

Epoch 00002: val_loss improved from 14.31280 to 14.30002, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 268s - loss: 12.8624 - kl_loss: 1.9152 - val_loss: 14.3000 - val_kl_loss: 1.9796
Epoch 3/8000

Epoch 00003: val_loss improved from 14.30002 to 14.27877, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 270s - loss: 12.8461 - kl_loss: 1.9195 - val_loss: 14.2788 - val_kl_loss: 1.9843
Epoch 4/8000

Epoch 00004: val_loss improved from 14.27877 to 14.27462, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 268s - loss: 12.8340 - kl_loss: 1.9172 - val_loss: 14.2746 - val_kl_loss: 1.9719
Epoch 5/8000

Epoch 00005: val_loss improved from 14.27462 to 14.25791, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 268s - loss: 12.8267 - kl_loss: 1.9159 - val_loss: 14.2579 - val_kl_loss: 1.9747
Epoch 6/8000

Epoch 00006: val_loss improved from 14.25791 to 14.25669, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 270s - loss: 12.8221 - kl_loss: 1.9187 - val_loss: 14.2567 - val_kl_loss: 1.9765
Epoch 7/8000

Epoch 00007: val_loss improved from 14.25669 to 14.25581, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 271s - loss: 12.8167 - kl_loss: 1.9180 - val_loss: 14.2558 - val_kl_loss: 1.9803
Epoch 8/8000

Epoch 00008: val_loss did not improve from 14.25581
 - 271s - loss: 12.8112 - kl_loss: 1.9192 - val_loss: 14.2638 - val_kl_loss: 1.9762
Epoch 9/8000

Epoch 00009: val_loss did not improve from 14.25581
 - 268s - loss: 12.8070 - kl_loss: 1.9181 - val_loss: 14.2647 - val_kl_loss: 1.9796
Epoch 10/8000

Epoch 00010: val_loss improved from 14.25581 to 14.24820, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 270s - loss: 12.8041 - kl_loss: 1.9198 - val_loss: 14.2482 - val_kl_loss: 1.9842
Epoch 11/8000

Epoch 00011: val_loss did not improve from 14.24820
 - 270s - loss: 12.8004 - kl_loss: 1.9207 - val_loss: 14.2692 - val_kl_loss: 1.9844
Epoch 12/8000

Epoch 00012: val_loss improved from 14.24820 to 14.23324, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 267s - loss: 12.7981 - kl_loss: 1.9191 - val_loss: 14.2332 - val_kl_loss: 1.9838
Epoch 13/8000

Epoch 00013: val_loss did not improve from 14.23324
 - 269s - loss: 12.7959 - kl_loss: 1.9210 - val_loss: 14.2644 - val_kl_loss: 1.9794
Epoch 14/8000

Epoch 00014: val_loss did not improve from 14.23324
 - 270s - loss: 12.7913 - kl_loss: 1.9214 - val_loss: 14.2479 - val_kl_loss: 1.9865
Epoch 15/8000

Epoch 00015: val_loss did not improve from 14.23324
 - 272s - loss: 12.7874 - kl_loss: 1.9185 - val_loss: 14.2425 - val_kl_loss: 1.9814
Epoch 16/8000

Epoch 00016: val_loss did not improve from 14.23324
 - 269s - loss: 12.7869 - kl_loss: 1.9186 - val_loss: 14.2545 - val_kl_loss: 1.9825
Epoch 17/8000

Epoch 00017: val_loss did not improve from 14.23324
 - 270s - loss: 12.7817 - kl_loss: 1.9202 - val_loss: 14.2395 - val_kl_loss: 1.9801
Epoch 18/8000

Epoch 00018: val_loss improved from 14.23324 to 14.22744, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 269s - loss: 12.7825 - kl_loss: 1.9206 - val_loss: 14.2274 - val_kl_loss: 1.9786
Epoch 19/8000

Epoch 00019: val_loss did not improve from 14.22744
 - 268s - loss: 12.7784 - kl_loss: 1.9192 - val_loss: 14.2498 - val_kl_loss: 1.9785
Epoch 20/8000

Epoch 00020: val_loss did not improve from 14.22744
 - 271s - loss: 12.7787 - kl_loss: 1.9194 - val_loss: 14.2343 - val_kl_loss: 1.9778
Epoch 21/8000

Epoch 00021: val_loss did not improve from 14.22744
 - 270s - loss: 12.7749 - kl_loss: 1.9190 - val_loss: 14.2368 - val_kl_loss: 1.9809
Epoch 22/8000

Epoch 00022: val_loss did not improve from 14.22744
 - 271s - loss: 12.7753 - kl_loss: 1.9227 - val_loss: 14.2389 - val_kl_loss: 1.9941
Epoch 23/8000

Epoch 00023: val_loss did not improve from 14.22744
 - 269s - loss: 12.7728 - kl_loss: 1.9214 - val_loss: 14.2410 - val_kl_loss: 1.9822
Epoch 24/8000

Epoch 00024: val_loss did not improve from 14.22744
 - 271s - loss: 12.7714 - kl_loss: 1.9205 - val_loss: 14.2361 - val_kl_loss: 1.9779
Epoch 25/8000

Epoch 00025: val_loss did not improve from 14.22744
 - 270s - loss: 12.7709 - kl_loss: 1.9231 - val_loss: 14.2315 - val_kl_loss: 1.9833
Epoch 26/8000

Epoch 00026: val_loss improved from 14.22744 to 14.22722, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 268s - loss: 12.7660 - kl_loss: 1.9211 - val_loss: 14.2272 - val_kl_loss: 1.9810
Epoch 27/8000

Epoch 00027: val_loss did not improve from 14.22722
 - 270s - loss: 12.7632 - kl_loss: 1.9195 - val_loss: 14.2346 - val_kl_loss: 1.9802
Epoch 28/8000

Epoch 00028: val_loss did not improve from 14.22722
 - 272s - loss: 12.7651 - kl_loss: 1.9221 - val_loss: 14.2455 - val_kl_loss: 1.9851
Epoch 29/8000

Epoch 00029: val_loss did not improve from 14.22722
 - 272s - loss: 12.7610 - kl_loss: 1.9250 - val_loss: 14.2485 - val_kl_loss: 1.9885
Epoch 30/8000

Epoch 00030: val_loss improved from 14.22722 to 14.22506, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 268s - loss: 12.7598 - kl_loss: 1.9240 - val_loss: 14.2251 - val_kl_loss: 1.9841
Epoch 31/8000

Epoch 00031: val_loss improved from 14.22506 to 14.21655, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 270s - loss: 12.7589 - kl_loss: 1.9222 - val_loss: 14.2165 - val_kl_loss: 1.9824
Epoch 32/8000

Epoch 00032: val_loss did not improve from 14.21655
 - 271s - loss: 12.7555 - kl_loss: 1.9216 - val_loss: 14.2225 - val_kl_loss: 1.9787
Epoch 33/8000

Epoch 00033: val_loss did not improve from 14.21655
 - 268s - loss: 12.7534 - kl_loss: 1.9201 - val_loss: 14.2196 - val_kl_loss: 1.9780
Epoch 34/8000

Epoch 00034: val_loss did not improve from 14.21655
 - 269s - loss: 12.7516 - kl_loss: 1.9224 - val_loss: 14.2395 - val_kl_loss: 1.9850
Epoch 35/8000

Epoch 00035: val_loss did not improve from 14.21655
 - 270s - loss: 12.7513 - kl_loss: 1.9240 - val_loss: 14.2456 - val_kl_loss: 1.9864
Epoch 36/8000

Epoch 00036: val_loss did not improve from 14.21655
 - 273s - loss: 12.7485 - kl_loss: 1.9241 - val_loss: 14.2178 - val_kl_loss: 1.9843
Epoch 37/8000

Epoch 00037: val_loss did not improve from 14.21655
 - 268s - loss: 12.7489 - kl_loss: 1.9219 - val_loss: 14.2302 - val_kl_loss: 1.9789
Epoch 38/8000

Epoch 00038: val_loss did not improve from 14.21655
 - 270s - loss: 12.7484 - kl_loss: 1.9214 - val_loss: 14.2246 - val_kl_loss: 1.9825
Epoch 39/8000

Epoch 00039: val_loss did not improve from 14.21655
 - 270s - loss: 12.7444 - kl_loss: 1.9268 - val_loss: 14.2339 - val_kl_loss: 1.9920
Epoch 40/8000

Epoch 00040: val_loss did not improve from 14.21655
 - 270s - loss: 12.7458 - kl_loss: 1.9259 - val_loss: 14.2398 - val_kl_loss: 1.9800
Epoch 41/8000

Epoch 00041: val_loss did not improve from 14.21655
 - 270s - loss: 12.7469 - kl_loss: 1.9245 - val_loss: 14.2438 - val_kl_loss: 1.9815
Epoch 42/8000

Epoch 00042: val_loss did not improve from 14.21655
 - 269s - loss: 12.7422 - kl_loss: 1.9252 - val_loss: 14.2192 - val_kl_loss: 1.9825
Epoch 43/8000

Epoch 00043: val_loss improved from 14.21655 to 14.20152, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 272s - loss: 12.7436 - kl_loss: 1.9223 - val_loss: 14.2015 - val_kl_loss: 1.9811
Epoch 44/8000

Epoch 00044: val_loss did not improve from 14.20152
 - 269s - loss: 12.7423 - kl_loss: 1.9207 - val_loss: 14.2456 - val_kl_loss: 1.9848
Epoch 45/8000

Epoch 00045: val_loss did not improve from 14.20152
 - 271s - loss: 12.7425 - kl_loss: 1.9228 - val_loss: 14.2367 - val_kl_loss: 1.9860
Epoch 46/8000

Epoch 00046: val_loss did not improve from 14.20152
 - 270s - loss: 12.7400 - kl_loss: 1.9253 - val_loss: 14.2319 - val_kl_loss: 1.9864
Epoch 47/8000

Epoch 00047: val_loss did not improve from 14.20152
 - 268s - loss: 12.7402 - kl_loss: 1.9251 - val_loss: 14.2373 - val_kl_loss: 1.9873
Epoch 48/8000

Epoch 00048: val_loss did not improve from 14.20152
 - 270s - loss: 12.7393 - kl_loss: 1.9260 - val_loss: 14.2173 - val_kl_loss: 1.9897
Epoch 49/8000

Epoch 00049: val_loss did not improve from 14.20152
 - 271s - loss: 12.7367 - kl_loss: 1.9252 - val_loss: 14.2099 - val_kl_loss: 1.9873
Epoch 50/8000

Epoch 00050: val_loss did not improve from 14.20152
 - 273s - loss: 12.7362 - kl_loss: 1.9268 - val_loss: 14.2280 - val_kl_loss: 1.9885
Epoch 51/8000

Epoch 00051: val_loss did not improve from 14.20152
 - 268s - loss: 12.7320 - kl_loss: 1.9238 - val_loss: 14.2302 - val_kl_loss: 1.9838
Epoch 52/8000

Epoch 00052: val_loss did not improve from 14.20152
 - 270s - loss: 12.7332 - kl_loss: 1.9250 - val_loss: 14.2240 - val_kl_loss: 1.9846
Epoch 53/8000

Epoch 00053: val_loss did not improve from 14.20152
 - 271s - loss: 12.7304 - kl_loss: 1.9243 - val_loss: 14.2338 - val_kl_loss: 1.9835
Epoch 54/8000

Epoch 00054: val_loss did not improve from 14.20152
 - 269s - loss: 12.7322 - kl_loss: 1.9256 - val_loss: 14.2168 - val_kl_loss: 1.9861
Epoch 55/8000

Epoch 00055: val_loss did not improve from 14.20152
 - 269s - loss: 12.7310 - kl_loss: 1.9230 - val_loss: 14.2304 - val_kl_loss: 1.9892
Epoch 56/8000

Epoch 00056: val_loss did not improve from 14.20152
 - 270s - loss: 12.7317 - kl_loss: 1.9285 - val_loss: 14.2377 - val_kl_loss: 1.9861
Epoch 57/8000

Epoch 00057: val_loss did not improve from 14.20152
 - 273s - loss: 12.7278 - kl_loss: 1.9254 - val_loss: 14.2227 - val_kl_loss: 1.9914
Epoch 58/8000

Epoch 00058: val_loss did not improve from 14.20152
 - 269s - loss: 12.7286 - kl_loss: 1.9218 - val_loss: 14.2208 - val_kl_loss: 1.9868
Epoch 59/8000

Epoch 00059: val_loss did not improve from 14.20152
 - 269s - loss: 12.7295 - kl_loss: 1.9250 - val_loss: 14.2173 - val_kl_loss: 1.9937
Epoch 60/8000

Epoch 00060: val_loss did not improve from 14.20152
 - 270s - loss: 12.7291 - kl_loss: 1.9257 - val_loss: 14.2090 - val_kl_loss: 1.9914
Epoch 61/8000

Epoch 00061: val_loss did not improve from 14.20152
 - 270s - loss: 12.7251 - kl_loss: 1.9254 - val_loss: 14.2206 - val_kl_loss: 1.9872
Epoch 62/8000

Epoch 00062: val_loss did not improve from 14.20152
 - 270s - loss: 12.7264 - kl_loss: 1.9272 - val_loss: 14.2297 - val_kl_loss: 1.9922
Epoch 63/8000

Epoch 00063: val_loss did not improve from 14.20152
 - 270s - loss: 12.7235 - kl_loss: 1.9224 - val_loss: 14.2225 - val_kl_loss: 1.9854
Epoch 64/8000

Epoch 00064: val_loss did not improve from 14.20152
 - 272s - loss: 12.7232 - kl_loss: 1.9226 - val_loss: 14.2186 - val_kl_loss: 1.9832
Epoch 65/8000

Epoch 00065: val_loss did not improve from 14.20152
 - 270s - loss: 12.7242 - kl_loss: 1.9256 - val_loss: 14.2247 - val_kl_loss: 1.9918
Epoch 66/8000

Epoch 00066: val_loss did not improve from 14.20152
 - 270s - loss: 12.7208 - kl_loss: 1.9268 - val_loss: 14.2109 - val_kl_loss: 1.9854
Epoch 67/8000

Epoch 00067: val_loss did not improve from 14.20152
 - 270s - loss: 12.7198 - kl_loss: 1.9263 - val_loss: 14.2242 - val_kl_loss: 1.9896
Epoch 68/8000

Epoch 00068: val_loss did not improve from 14.20152
 - 269s - loss: 12.7175 - kl_loss: 1.9250 - val_loss: 14.2234 - val_kl_loss: 1.9846
Epoch 69/8000

Epoch 00069: val_loss did not improve from 14.20152
 - 272s - loss: 12.7181 - kl_loss: 1.9223 - val_loss: 14.2161 - val_kl_loss: 1.9868
Epoch 70/8000

Epoch 00070: val_loss did not improve from 14.20152
 - 270s - loss: 12.7181 - kl_loss: 1.9267 - val_loss: 14.2065 - val_kl_loss: 1.9872
Epoch 71/8000

Epoch 00071: val_loss did not improve from 14.20152
 - 271s - loss: 12.7181 - kl_loss: 1.9260 - val_loss: 14.2220 - val_kl_loss: 1.9839
Epoch 72/8000

Epoch 00072: val_loss did not improve from 14.20152
 - 269s - loss: 12.7158 - kl_loss: 1.9252 - val_loss: 14.2111 - val_kl_loss: 1.9840
Epoch 73/8000

Epoch 00073: val_loss did not improve from 14.20152
 - 271s - loss: 12.7161 - kl_loss: 1.9222 - val_loss: 14.2291 - val_kl_loss: 1.9858
Epoch 74/8000

Epoch 00074: val_loss did not improve from 14.20152
 - 272s - loss: 12.7135 - kl_loss: 1.9236 - val_loss: 14.2144 - val_kl_loss: 1.9812
Epoch 75/8000

Epoch 00075: val_loss did not improve from 14.20152
 - 269s - loss: 12.7163 - kl_loss: 1.9273 - val_loss: 14.2287 - val_kl_loss: 1.9858
Epoch 76/8000

Epoch 00076: val_loss did not improve from 14.20152
 - 269s - loss: 12.7147 - kl_loss: 1.9269 - val_loss: 14.2032 - val_kl_loss: 1.9921
Epoch 77/8000

Epoch 00077: val_loss did not improve from 14.20152
 - 270s - loss: 12.7145 - kl_loss: 1.9284 - val_loss: 14.2320 - val_kl_loss: 1.9912
Epoch 78/8000

Epoch 00078: val_loss did not improve from 14.20152
 - 274s - loss: 12.7135 - kl_loss: 1.9286 - val_loss: 14.2084 - val_kl_loss: 1.9943
Epoch 79/8000

Epoch 00079: val_loss did not improve from 14.20152
 - 269s - loss: 12.7132 - kl_loss: 1.9289 - val_loss: 14.2371 - val_kl_loss: 1.9875
Epoch 80/8000

Epoch 00080: val_loss did not improve from 14.20152
 - 270s - loss: 12.7138 - kl_loss: 1.9287 - val_loss: 14.2166 - val_kl_loss: 1.9862
Epoch 81/8000

Epoch 00081: val_loss improved from 14.20152 to 14.20152, saving model to ../../model_weights/model_2020-12-23_13-48-52.h5
 - 271s - loss: 12.7101 - kl_loss: 1.9228 - val_loss: 14.2015 - val_kl_loss: 1.9852
Epoch 82/8000

Epoch 00082: val_loss did not improve from 14.20152
 - 270s - loss: 12.7084 - kl_loss: 1.9249 - val_loss: 14.2050 - val_kl_loss: 1.9840
Epoch 83/8000

Epoch 00083: val_loss did not improve from 14.20152
 - 270s - loss: 12.7076 - kl_loss: 1.9245 - val_loss: 14.2046 - val_kl_loss: 1.9897
Epoch 84/8000

Epoch 00084: val_loss did not improve from 14.20152
 - 269s - loss: 12.7107 - kl_loss: 1.9255 - val_loss: 14.2117 - val_kl_loss: 1.9815
Epoch 85/8000

Epoch 00085: val_loss did not improve from 14.20152
 - 272s - loss: 12.7087 - kl_loss: 1.9235 - val_loss: 14.2042 - val_kl_loss: 1.9828
Epoch 86/8000

Epoch 00086: val_loss did not improve from 14.20152
 - 270s - loss: 12.7100 - kl_loss: 1.9254 - val_loss: 14.2149 - val_kl_loss: 1.9875
Epoch 87/8000

Epoch 00087: val_loss did not improve from 14.20152
 - 270s - loss: 12.7095 - kl_loss: 1.9268 - val_loss: 14.2152 - val_kl_loss: 1.9879
Epoch 88/8000

Epoch 00088: val_loss did not improve from 14.20152
 - 270s - loss: 12.7081 - kl_loss: 1.9271 - val_loss: 14.2110 - val_kl_loss: 1.9823
Epoch 89/8000

Epoch 00089: val_loss did not improve from 14.20152
 - 269s - loss: 12.7079 - kl_loss: 1.9230 - val_loss: 14.2280 - val_kl_loss: 1.9846
Epoch 90/8000

Epoch 00090: val_loss did not improve from 14.20152
 - 272s - loss: 12.7075 - kl_loss: 1.9274 - val_loss: 14.2203 - val_kl_loss: 1.9843
Epoch 91/8000

Epoch 00091: val_loss did not improve from 14.20152
 - 270s - loss: 12.7055 - kl_loss: 1.9284 - val_loss: 14.2081 - val_kl_loss: 1.9860
Epoch 92/8000

Epoch 00092: val_loss did not improve from 14.20152
 - 272s - loss: 12.7077 - kl_loss: 1.9286 - val_loss: 14.2016 - val_kl_loss: 1.9837
Epoch 93/8000

Epoch 00093: val_loss did not improve from 14.20152
 - 269s - loss: 12.7037 - kl_loss: 1.9241 - val_loss: 14.2115 - val_kl_loss: 1.9850
Epoch 00093: early stopping
