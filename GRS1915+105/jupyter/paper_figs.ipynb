{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean\n",
    "from tensorflow.keras.backend import square\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import zscore\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "\n",
    "# np.random.seed(seed=11)\n",
    "\n",
    "# with open('../../../data_GRS1915/468202_len128_s2_4cad_counts_errorfix.pkl', 'rb') as f:\n",
    "#     segments = pickle.load(f)\n",
    "# with open('../../../data_GRS1915/468202_len128_s2_4cad_errors_errorfix.pkl', 'rb') as f:\n",
    "#     errors = pickle.load(f)\n",
    "\n",
    "# # errors = np.expand_dims((np.squeeze(errors)/(np.max(segments, axis=1)-np.min(segments, axis=1))), axis=-1).astype(np.float32)\n",
    "# # segments = np.expand_dims(((np.squeeze(segments)-np.min(segments, axis=1))/(np.max(segments, axis=1)-np.min(segments, axis=1))), axis=-1).astype(np.float32)\n",
    "# # errors = ((errors)/np.std(segments)).astype(np.float32)\n",
    "# # segments = zscore(segments, axis=None).astype(np.float32)  # standardize\n",
    "\n",
    "\n",
    "# errors = ((errors)/np.expand_dims(np.std(segments, axis=1), axis=1)).astype(np.float32)\n",
    "# segments = zscore(segments, axis=1).astype(np.float32)  # standardize per segment\n",
    "\n",
    "\n",
    "def chi2(y_err):\n",
    "    def MSE_scaled(y_in, y_out,):\n",
    "        return mean(square(y_in-y_out)/square(y_err))\n",
    "    return MSE_scaled\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generates data for Keras\n",
    "    https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    https://stackoverflow.com/questions/53105294/implementing-a-batch-dependent-loss-in-keras\n",
    "    \"\"\"\n",
    "    def __init__(self, y_in, y_err, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.y_in = y_in\n",
    "        self.y_err = y_err        \n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.y_in) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        y_in = self.y_in[indexes]\n",
    "        y_err = self.y_err[indexes]\n",
    "        return [y_in, y_err], y_in\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.y_in))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\n",
    "    https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example\"\"\"\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "original_dim = 128\n",
    "intermediate_dim = 512\n",
    "latent_dim = 16\n",
    "\n",
    "# Define encoder model.\n",
    "original_inputs = tf.keras.Input(shape=(original_dim,1), name='Encoder_input')\n",
    "input_err = Input(shape=(original_dim,1))\n",
    "x = layers.CuDNNLSTM(intermediate_dim, return_sequences=False, name=\"Encoder_LSTM\")(original_inputs)\n",
    "z_mean = layers.Dense(latent_dim, name='Latent_mean')(x)\n",
    "z_log_var = layers.Dense(latent_dim, name='Latent_log_variance')(x)\n",
    "z = Sampling(name=\"Sampler\")((z_mean, z_log_var))\n",
    "encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name='Encoder')\n",
    "\n",
    "# Define decoder model.\n",
    "latent_inputs = tf.keras.Input(shape=(latent_dim,), name='Decoder_input')\n",
    "x = layers.RepeatVector(original_dim, name=\"Expand_to_decoder_shape\")(latent_inputs)\n",
    "x = layers.CuDNNLSTM(intermediate_dim, return_sequences=True, name=\"Decoder_LSTM\")(x)\n",
    "outputs = layers.TimeDistributed(layers.Dense(1),name=\"Collapse_to_output_shape\")(x)\n",
    "decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name='Decoder')\n",
    "\n",
    "# Define VAE model.\n",
    "outputs = decoder(z)\n",
    "vae = tf.keras.Model(inputs=[original_inputs, input_err], outputs=outputs, name='vae')\n",
    "\n",
    "# Add KL divergence regularization loss.\n",
    "kl_loss = - 0.5 * tf.reduce_mean(\n",
    "    z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "vae.add_loss(kl_loss)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr=2e-5, clipvalue=0.5) #Adam(clipvalue=0.5)\n",
    "\n",
    "vae.compile(optimizer, loss=chi2(input_err))\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(vae, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Decoder_input (InputLayer)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "Expand_to_decoder_dimensions (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "Decoder_LSTM (CuDNNLSTM)     (None, 128, 512)          1085440   \n",
      "_________________________________________________________________\n",
      "Collapse_to_output_dimension (None, 128, 1)            513       \n",
      "=================================================================\n",
      "Total params: 1,085,953\n",
      "Trainable params: 1,085,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(decoder.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jakub-tf",
   "language": "python",
   "name": "jakub-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
