{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a data set for the comparison with Huppenkothen+2017\n",
    "\n",
    "Main classificatin experiments described in paper Orwat-Kapola+2021 were not directly comparable with the work of Daniela Huppenkothen, because the former classified whole light curves instead of 1024 s segments, and the cadence of the data was 1s/4s instead of 0.125 s.\n",
    "\n",
    "Here we prepare a data set of 1024 s overlapping segments which are be further segmented into 16 s segments with cadence of 0.125s to make a direct comparison with Huppenkothen+2017.\n",
    "\n",
    "In order to reduce the amount of generated data, the 1024 s segments created with a stride of 256 s and the 16 s segments are created with a stride of 16 s. The fact that light curve features are observed in only one phase shift position within those 16 s segments can affect the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.insert(0, '../../') # add parent folder path where /src folder is\n",
    "from src import data_preprocessing\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "# import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "raw_data_dir = \"../../../data_GRS1915/std1/\" # directory path to where lightcurve files are located\n",
    "raw_file_name_suffix = \"_std1_lc.txt\" # light curves were saved as txt files which are directly interpretable by numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1776 lightcurves\n"
     ]
    }
   ],
   "source": [
    "# load light curves from text files\n",
    "\n",
    "lcs=[] # light curves (time stamps, count rate, uncertainty)\n",
    "lc_ids=[] # observation ids\n",
    "\n",
    "for root, dirnames, filenames in os.walk(raw_data_dir): #Std1_PCU2\n",
    "    for filename in fnmatch.filter(filenames, \"*{}\".format(raw_file_name_suffix)):\n",
    "        lc = os.path.join(root, filename)\n",
    "        lc_ids.append(filename.split(\"_\")[0])\n",
    "        f=np.loadtxt(lc)\n",
    "        f=np.transpose(f)\n",
    "        lcs.append(f)\n",
    "        print(\"Loaded {} lightcurves\".format(len(lcs)))\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1776/1776 light curves.\n",
      "Successfully segmented 1427 light curves.\n",
      "Prepared 10614 segments.\n"
     ]
    }
   ],
   "source": [
    "# segmentation of light curves\n",
    "\n",
    "segments_counts=[]\n",
    "segments_times = []\n",
    "segments_errors=[]\n",
    "seg_ids=[]\n",
    "\n",
    "for lc_index, lc in enumerate(lcs):\n",
    "    segments = data_preprocessing.segmentation(time_series = lc, \n",
    "                                       segment_length_sec = 1024, \n",
    "                                       stride_sec = 256, \n",
    "                                       keep_time_stamps = True, \n",
    "                                       input_cadence_sec = 0.125)\n",
    "    if len(segments) > 0:\n",
    "        segments_times.append(segments[:,0,:])\n",
    "        segments_counts.append(segments[:,1,:])\n",
    "        segments_errors.append(segments[:,2,:])\n",
    "        for seg_index, seg in enumerate(segments):\n",
    "            seg_ids.append(lc_ids[lc_index]+\"_{}\".format(seg_index))\n",
    "            \n",
    "    clear_output(wait=True)\n",
    "    print(\"Processed {}/{} light curves.\".format(lc_index+1, len(lcs)))\n",
    "print(\"Successfully segmented {} light curves.\".format(len(segments_times)))\n",
    "\n",
    "segments_counts=np.vstack(segments_counts)\n",
    "segments_errors=np.vstack(segments_errors)\n",
    "segments_counts = np.expand_dims(segments_counts, axis=-1)\n",
    "segments_errors = np.expand_dims(segments_errors, axis=-1)\n",
    "\n",
    "print(\"Prepared {} segments.\".format(len(segments_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentation of 1024 second segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11879"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lcs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gap in gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90601720.25343166"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs[1][0][679]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90601722.37843166"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs[1][0][680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_lcs = 0\n",
    "\n",
    "for lc in lcs:\n",
    "    dts = lc[0][1:]-lc[0][:-1]\n",
    "    gaps = np.where(dts>0.125)[0]\n",
    "    if len(gaps) == 0 and len(lc[0])>=1024/0.125:\n",
    "        potential_lcs+=1\n",
    "        continue\n",
    "    else:\n",
    "        for gap_ind, gap in enumerate(gaps):\n",
    "            if gap_ind == 0:\n",
    "                gti_len =  gap/0.125\n",
    "                if gti_len>=1024:\n",
    "                    potential_lcs+=1\n",
    "                    break\n",
    "            else:\n",
    "                gti_len = (gap-(gaps[gap_ind-1]+1))/0.125\n",
    "                if gti_len>=1024:\n",
    "                    potential_lcs+=1\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1484"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lcs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerprint_env",
   "language": "python",
   "name": "fingerprint_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
