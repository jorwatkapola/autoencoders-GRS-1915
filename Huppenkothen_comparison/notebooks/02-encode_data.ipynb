{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebooks encodes light curve segments into the Shape and Intensity Features of lightcurve Segments. \n",
    "\n",
    "Requirements: Segmented light curves and trained VAE-LSTM network, see notebook 01\n",
    "\n",
    "## Edit the paths below as required and run all cells to encode the segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = \"../models/VAE_weights/model_2021-09-12_17-45-06.h5\" # path to VAE-LSTM weights\n",
    "segment_data_dir = \"../data/segments/\" # path to segmented data\n",
    "\n",
    "\n",
    "### OUTPUTS\n",
    "encodings_dir = \"../data/encodings/\" # where to save the encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkok1g14/anaconda3/envs/jakub-tf/lib/python3.5/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "/home/jkok1g14/anaconda3/envs/jakub-tf/lib/python3.5/site-packages/matplotlib/__init__.py:855: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "/home/jkok1g14/anaconda3/envs/jakub-tf/lib/python3.5/site-packages/matplotlib/__init__.py:846: MatplotlibDeprecationWarning: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 2.2 and will be removed in 3.1.\n",
      "  \"2.2\", name=key, obj_type=\"rcparam\", addendum=addendum)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy import stats\n",
    "# from sklearn.cluster import OPTICS\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean\n",
    "from tensorflow.keras.backend import square\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import CuDNNLSTM #CuDNNLSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "# from tensorflow.keras.layers import Conv1D\n",
    "from scipy.stats import zscore\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "np.random.seed(seed=11)\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the VAE-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z.\n",
    "    https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example\"\"\"\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "original_dim = 128\n",
    "intermediate_dim = 1024\n",
    "latent_dim = 20\n",
    "\n",
    "# Define encoder model.\n",
    "original_inputs = tf.keras.Input(shape=(original_dim,1), name='encoder_input')\n",
    "input_err = Input(shape=(original_dim,1))\n",
    "x = layers.CuDNNLSTM(intermediate_dim, return_sequences=False)(original_inputs)\n",
    "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "z = Sampling()((z_mean, z_log_var))\n",
    "encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name='encoder')\n",
    "\n",
    "# Define decoder model.\n",
    "latent_inputs = tf.keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.RepeatVector(original_dim)(latent_inputs)\n",
    "x = layers.CuDNNLSTM(intermediate_dim, return_sequences=True)(x)\n",
    "outputs = layers.TimeDistributed(layers.Dense(1))(x)\n",
    "decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name='decoder')\n",
    "\n",
    "# Define VAE model.\n",
    "outputs = decoder(z)\n",
    "vae = tf.keras.Model(inputs=[original_inputs, input_err], outputs=outputs, name='vae')\n",
    "\n",
    "vae.load_weights(weights_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the encoder of VAE-LSTM to extract data features from L=128 light curve segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load segments\n",
    "\n",
    "with open('{}/segments_1024s_256stride_0125cad_segmented_to64_train.pkl'.format(segment_data_dir), 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('{}/segments_1024s_256stride_0125cad_segmented_to64_valid.pkl'.format(segment_data_dir), 'rb') as f:\n",
    "    valid_data = pickle.load(f)\n",
    "with open('{}/segments_1024s_256stride_0125cad_segmented_to64_test.pkl'.format(segment_data_dir), 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_data(segment_data, model, save_encoding=False, save_file_dir=None):\n",
    "    \"\"\"\n",
    "    Custom function for the encoding of segmented light curves\n",
    "    \"\"\"\n",
    "    \n",
    "    cadence = np.min(np.diff([seg[2][0] for seg in segment_data]))\n",
    "    \n",
    "    # get rid of the meta-data and make numpy arrays with required dimensions\n",
    "    train_data_counts = [seg[2][1] for seg in segment_data]\n",
    "    \n",
    "    #divide by cadence to turn counts to count rates\n",
    "    train_data_counts = np.vstack(train_data_counts) /cadence\n",
    "    train_data_counts = np.expand_dims(train_data_counts, axis=-1)\n",
    "    train_data_errors = [seg[2][2] for seg in segment_data]\n",
    "    train_data_errors = np.vstack(train_data_errors)\n",
    "    \n",
    "    #error values must be non-zero. replace zeros with a small value\n",
    "    min_nonzero_train = np.min(train_data_errors[train_data_errors!=0])/10\n",
    "    train_data_errors[train_data_errors==0] = min_nonzero_train\n",
    "    train_data_errors = np.expand_dims(train_data_errors, axis=-1)\n",
    "    \n",
    "    # standardize data per segment\n",
    "    train_data_errors = ((train_data_errors)/np.expand_dims(np.std(train_data_counts, axis=1), axis=1)).astype(np.float32)\n",
    "    train_data_counts = zscore(train_data_counts, axis=1).astype(np.float32)  \n",
    "    \n",
    "    #     get lists of metadata\n",
    "    seg_ids = [seg[0] for seg in segment_data]\n",
    "    seg_labels = [seg[1] for seg in segment_data]\n",
    "    \n",
    "    segments = train_data_counts\n",
    "    errors = train_data_errors\n",
    "    \n",
    "    trained_encoder = tf.keras.Model(inputs=model.input, outputs=[model.get_layer(\"z_mean\").output, model.get_layer(\"z_log_var\").output])\n",
    "    segment_encoding = np.zeros((segments.shape[0], 2, 20))\n",
    "    for seg_ind, seg in enumerate(segments):\n",
    "        prediction = trained_encoder.predict([np.expand_dims(seg, axis=0), np.expand_dims(errors[seg_ind], axis=0)])\n",
    "        segment_encoding[seg_ind][0] = prediction[0].flatten()\n",
    "        segment_encoding[seg_ind][1] = prediction[1].flatten()\n",
    "        clear_output(wait=True)\n",
    "        print(\"Encoded {}/{} segments\".format(seg_ind+1, segments.shape[0]))\n",
    "        \n",
    "    \n",
    "    if save_encoding==True and save_file_dir != None:\n",
    "        with open(save_file_dir, 'wb') as f:\n",
    "            pickle.dump((seg_ids, seg_labels, segment_encoding), f)\n",
    "        print(\"Encodings and metadata saved to: \", save_file_dir)\n",
    "        \n",
    "    else:\n",
    "        return (seg_ids, seg_labels, segment_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 483584/483584 segments\n",
      "Encodings and metadata saved to:  ../../../data_GRS1915/segments_1024s_256stride_0125cad_segmented_to64_encoded_train.pkl\n"
     ]
    }
   ],
   "source": [
    "encode_data(train_data, vae, save_encoding=True, save_file_dir='{}/segments_1024s_256stride_0125cad_segmented_to64_encoded_train.pkl'.format(encodings_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 185984/185984 segments\n",
      "Encodings and metadata saved to:  ../../../data_GRS1915/segments_1024s_256stride_0125cad_segmented_to64_encoded_valid.pkl\n"
     ]
    }
   ],
   "source": [
    "encode_data(valid_data, vae, save_encoding=True, save_file_dir='{}/segments_1024s_256stride_0125cad_segmented_to64_encoded_valid.pkl'.format(encodings_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 36224/36224 segments\n",
      "Encodings and metadata saved to:  ../../../data_GRS1915/segments_1024s_256stride_0125cad_segmented_to64_encoded_test.pkl\n"
     ]
    }
   ],
   "source": [
    "encode_data(test_data, vae, save_encoding=True, save_file_dir='{}/segments_1024s_256stride_0125cad_segmented_to64_encoded_test.pkl'.format(encodings_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jakub-tf",
   "language": "python",
   "name": "jakub-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
